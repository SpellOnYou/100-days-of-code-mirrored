{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_copy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YJQReyi-CNVm",
        "tTbuDvuWdh9g"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR7WdFvw8XPN",
        "colab_type": "text"
      },
      "source": [
        "- 01_matmul\n",
        "- 02_fully_connected\n",
        "- 02a_why_sqrt5\n",
        "- 02b_initialization\n",
        "- 03_minibatch_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ios0-s_4_ZwU",
        "colab_type": "text"
      },
      "source": [
        "Table of contents\n",
        "1. Initial Setup\n",
        "2. Basic training Loop\n",
        "3. Using parameters and optim\n",
        "4. Dataset and DataLoader\n",
        "5. Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxTB-ysp_jun",
        "colab_type": "text"
      },
      "source": [
        "# 1. Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1B6I_hCh1c",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "\n",
        "### Fastai for Colab env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCFq0PZ8tOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2efe1d8a-b640-4f1e-9809-dd52e74a7f4c"
      },
      "source": [
        "!git clone http://github.com/fastai/course-v3.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'course-v3'...\n",
            "warning: redirecting to https://github.com/fastai/course-v3.git/\n",
            "remote: Enumerating objects: 5498, done.\u001b[K\n",
            "remote: Total 5498 (delta 0), reused 0 (delta 0), pack-reused 5498\u001b[K\n",
            "Receiving objects: 100% (5498/5498), 257.94 MiB | 25.77 MiB/s, done.\n",
            "Resolving deltas: 100% (2992/2992), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3cSi27X88l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf2b3d88-383c-487f-8195-a8f948060735"
      },
      "source": [
        "%cd course-v3/nbs/dl2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/course-v3/nbs/dl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FacmFUWm9E-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_02 import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAdev1qg-LSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "98dd516d-22f3-43c1-c22e-3ef1074b32fd"
      },
      "source": [
        "!cat exp/nb_02.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#################################################\n",
            "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
            "#################################################\n",
            "# file to edit: dev_nb/02_fully_connected.ipynb\n",
            "\n",
            "from exp.nb_01 import *\n",
            "\n",
            "def get_data():\n",
            "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
            "    with gzip.open(path, 'rb') as f:\n",
            "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
            "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
            "\n",
            "def normalize(x, m, s): return (x-m)/s\n",
            "\n",
            "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
            "\n",
            "from torch.nn import init\n",
            "\n",
            "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()\n",
            "\n",
            "from torch import nn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5tAEA4_9NKW",
        "colab_type": "text"
      },
      "source": [
        "### import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgE-wJ49UaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9571ceff-e6e5-41b1-c272-f6e8093741b2"
      },
      "source": [
        "train_x, train_y, valid_x, valid_y = get_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoL0CV2v9gLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20cd8ac8-dac9-4ee6-d6dc-bef8a5594dca"
      },
      "source": [
        "train_x.shape, train_x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 784]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWzQQ9W49hwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a5897d3-0121-4363-cb6f-c9019527754b"
      },
      "source": [
        "n_in, nh, n_out = train_x.shape[1], 32, train_y.max().item()+1; n_in, nh, n_out"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Sobj9Q1lai",
        "colab_type": "text"
      },
      "source": [
        "[^12]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCU0bL8XA76r",
        "colab_type": "text"
      },
      "source": [
        "[^1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euyGKZhK94Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x\n",
        "    # def forward(self, x, y):\n",
        "    #     for l in self.layers: x = l(x)\n",
        "    #     return(self.loss(x, y))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2WPI509B_-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model(n_in, nh, n_out)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROp_qw-xSaFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b11f85b6-5381-4c5c-c700-1209720b25a5"
      },
      "source": [
        "[(i,v) for i, v in m.named_parameters()]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPwo2EesCEsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = m(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJQReyi-CNVm",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGhM0NZrCsfI",
        "colab_type": "text"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyX4TB0YCzpZ",
        "colab_type": "text"
      },
      "source": [
        "* formula of softmax : $f(x) = \\frac{exp(x)}{\\sum exp(x_i)}$\n",
        "* We need softmax at last layer since we have to map it to the probabilistic space\n",
        "* code of softmax is below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJcewmjDhyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x): return x.exp() / x.exp().sum(-1, keepdim=True)\n",
        "# def softmax(x): return x.exp() / x.exp().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NnUt5FGHAaE",
        "colab_type": "text"
      },
      "source": [
        "[^2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7RiaE7kHZuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42b44b90-e841-4106-beae-d8c875191be1"
      },
      "source": [
        "p = softmax(y_hat); p[0].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BwNmdysHg7A",
        "colab_type": "text"
      },
      "source": [
        "- I need *log* of softmax because we will use cross-entropy which has form of $H(X, q) = H(X) + D(p|q) = - \\sum_{x} p(x)\\  log\\ q(x)$ [^3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8RQd3ZRppI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x.exp() / x.exp().sum(-1, keepdim=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0usabhbXdAvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = log_softmax(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLksrlDQS3ue",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNFW_jxyS7Ek",
        "colab_type": "text"
      },
      "source": [
        "- see the footnote 3 regarding further information of cross entropy\n",
        "- One possible reason is because an information theory is based on descrete and determinate value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tREkCuU65w",
        "colab_type": "text"
      },
      "source": [
        "### Negative log likelihood function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94nPlA0oXJbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(x, y): return -x[range(x.shape[0]), y].mean() #x: prediction, y:target "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcKHlflJX7p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f87331d-5a78-41f6-e508-210819350fad"
      },
      "source": [
        "nll(y_hat, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0017, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFJuF2ibXuIq",
        "colab_type": "text"
      },
      "source": [
        "- Negative value is related to entropy, roughly variable which is rare is meaningful [^4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-8dPvdkcKLb",
        "colab_type": "text"
      },
      "source": [
        "### LogSumExp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2GCqf3cLjN",
        "colab_type": "text"
      },
      "source": [
        "- Further tasks (after reading sum refs) [^5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0jIz5RcQAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbj1y3lYdKBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "5a920678-7211-4939-df3f-ca592b26f208"
      },
      "source": [
        "test_near(log_softmax(y_hat), a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-545abe941205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[-2.5928, -2.2816, -2.2425,  ..., -2.2081, -2.4793, -2.2903],\n        [-2.5356, -2.2368, -2.2793,  ..., -2.1715, -2.3938, -2.4001],\n        [-2.5328, -2.2767, -2.3066,  ..., -2.2603, -2.3657, -2.3038],\n        ...,\n        [-2.5156, -2.2445, -2.3092,  ..., -2.3254, -2.4571, -2.3064],\n        [-2.4585, -2.2299, -2.3311,  ..., -2.1488, -2.5716, -2.3324],\n        [-2.5408, -2.2465, -2.4297,  ..., -2.3465, -2.3813, -2.3038]],\n       grad_fn=<SubBackward0>)\ntensor([[0.0748, 0.1021, 0.1062,  ..., 0.1099, 0.0838, 0.1012],\n        [0.0792, 0.1068, 0.1024,  ..., 0.1140, 0.0913, 0.0907],\n        [0.0794, 0.1026, 0.0996,  ..., 0.1043, 0.0939, 0.0999],\n        ...,\n        [0.0808, 0.1060, 0.0993,  ..., 0.0977, 0.0857, 0.0996],\n        [0.0856, 0.1075, 0.0972,  ..., 0.1166, 0.0764, 0.0971],\n        [0.0788, 0.1058, 0.0881,  ..., 0.0957, 0.0924, 0.0999]],\n       grad_fn=<DivBackward0>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTbuDvuWdh9g",
        "colab_type": "text"
      },
      "source": [
        "# 2. Basic Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Divs4jzj8hi",
        "colab_type": "text"
      },
      "source": [
        "### 1.  \n",
        "\n",
        "First, get the prediction (i.e. output) from the model<br/>\n",
        "Second, get a loss value with prediction and target<br/>\n",
        "Third, get a gradients<br/>\n",
        "Fourth, update parameter using gradients, hyperparams<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0onE5wgks_5",
        "colab_type": "text"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCRPhaHxkv48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, trg): return (torch.argmax(out, dim=-1) == trg).float().mean()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHVOp00UlSCp",
        "colab_type": "text"
      },
      "source": [
        "### 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0i4bbMlc6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 64"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeOYOn9xlS9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = train_x[:bs], train_y[:bs]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSziLoA-ljYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27c8a88f-77be-4e2e-9b20-01fbdf9102e9"
      },
      "source": [
        "xb.shape, yb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sUE6kSdlrIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model(n_in, nh, n_out); pred = m(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4rPVkaOl_8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3bc8bcc-23d3-43d9-fc49-e6cf0315e198"
      },
      "source": [
        "accuracy(pred, yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTuTLFdHllIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c22bc478-24e0-4feb-c2ce-37f7232b5b39"
      },
      "source": [
        "del m, pred, xb, yb\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AxDH79Bmv98",
        "colab_type": "text"
      },
      "source": [
        "### 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DFcFyBmssF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa927aa3-68b6-44d2-9f3f-7b0792eefe4d"
      },
      "source": [
        "n_in, nh, n_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbRnQ8ildlOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "lr = 0.5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmXH9S8Qi0E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = train_x.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHQg9Bxcm9WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "loss_fun = F.cross_entropy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P4W9fUxi4RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    # init model to keep memory, gradients,...etc\n",
        "    model = Model(n_in, nh, n_out)\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs +1): # [^6]\n",
        "            srt, end = bs*i, bs*(i+1)\n",
        "            xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "            loss = loss_fun(model(xb), yb)\n",
        "            loss.backward()\n",
        "            with torch.no_grad(): # [^8]\n",
        "                for l in model.layers:\n",
        "                    if hasattr(l, 'weight'): # [^7]\n",
        "                        l.weight -= l.weight.grad * lr\n",
        "                        l.bias -= l.bias.grad * lr\n",
        "                        l.weight.grad.zero_() # [^8]\n",
        "                        l.bias.grad.zero_()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecrJML9dpRTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFeBXUjTptoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = train_x[:64], train_y[:64]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC5fpaM0pULU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82216dcf-f17a-4bd0-a495-cb9ad969bc61"
      },
      "source": [
        "loss_fun(m(xb), yb), accuracy(m(xb), yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1746, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JejPZBC1p5dD",
        "colab_type": "text"
      },
      "source": [
        "# 3. Using parameters and optimal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8eJC6HKqALX",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3obO2TIqI-u",
        "colab_type": "text"
      },
      "source": [
        "### 1. Re-define model using nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EExMGUQ_s8iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [^10]\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in, nh)\n",
        "        self.l2 = nn.Linear(nh, n_out)\n",
        "    def __call__(self, inp):\n",
        "        return self.l2(F.relu(self.l1(inp)))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDFGQeL5tpRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(n_in, nh, n_out)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueqg78YDtsOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ef9951ec-dbad-4653-a819-30fbf6255fe8"
      },
      "source": [
        "model(train_x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0961,  0.2724, -0.0945,  ...,  0.0623,  0.0917,  0.0012],\n",
              "        [-0.0293,  0.1502, -0.0897,  ...,  0.0503,  0.0137,  0.0230],\n",
              "        [ 0.0341,  0.1869, -0.0146,  ...,  0.0239,  0.0517,  0.0880],\n",
              "        ...,\n",
              "        [ 0.0330,  0.1831, -0.1755,  ...,  0.0696, -0.0377,  0.0496],\n",
              "        [-0.0426,  0.2056, -0.0845,  ...,  0.0192,  0.0120,  0.0798],\n",
              "        [-0.0454,  0.1567, -0.0712,  ...,  0.0363,  0.0298, -0.0153]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNRD1tKQR9p9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79e5182d-5ad1-4c85-b277-bd52a12a6455"
      },
      "source": [
        "[(i, v) for i, v in model.named_parameters()]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('l1.weight', Parameter containing:\n",
              "  tensor([[ 0.0186, -0.0328,  0.0301,  ...,  0.0005, -0.0151,  0.0147],\n",
              "          [ 0.0327, -0.0081,  0.0304,  ..., -0.0073, -0.0331, -0.0279],\n",
              "          [-0.0302, -0.0013, -0.0276,  ...,  0.0203, -0.0166,  0.0228],\n",
              "          ...,\n",
              "          [-0.0028,  0.0140,  0.0253,  ..., -0.0313, -0.0068,  0.0139],\n",
              "          [ 0.0283,  0.0155, -0.0152,  ..., -0.0325, -0.0024,  0.0294],\n",
              "          [-0.0092, -0.0202,  0.0305,  ...,  0.0016, -0.0175, -0.0150]],\n",
              "         requires_grad=True)), ('l1.bias', Parameter containing:\n",
              "  tensor([-0.0187, -0.0113, -0.0275, -0.0315,  0.0252, -0.0221, -0.0248,  0.0099,\n",
              "           0.0327,  0.0138, -0.0205, -0.0173, -0.0245,  0.0059,  0.0187,  0.0253,\n",
              "           0.0123, -0.0293, -0.0302, -0.0250,  0.0342,  0.0259,  0.0007,  0.0189,\n",
              "           0.0327, -0.0311, -0.0343, -0.0215,  0.0144, -0.0047, -0.0228, -0.0276],\n",
              "         requires_grad=True)), ('l2.weight', Parameter containing:\n",
              "  tensor([[-0.0324,  0.0295,  0.1261, -0.0178,  0.0725, -0.0531, -0.0658, -0.1097,\n",
              "           -0.1228, -0.0594, -0.0831, -0.0524,  0.1630,  0.0640, -0.1465, -0.1188,\n",
              "            0.0737,  0.1322,  0.1122, -0.0464,  0.1483, -0.0086,  0.1415,  0.0697,\n",
              "           -0.0867,  0.1557,  0.1676, -0.0759, -0.0165,  0.0989,  0.1122,  0.1105],\n",
              "          [ 0.1263,  0.1278, -0.1505, -0.0228,  0.1453,  0.0367,  0.0920,  0.0253,\n",
              "           -0.1453,  0.1117,  0.0167,  0.0775, -0.0306,  0.0669,  0.0711, -0.0720,\n",
              "           -0.1301, -0.1359,  0.0673, -0.1157, -0.0645,  0.0348,  0.0097, -0.1183,\n",
              "           -0.0781,  0.0154, -0.0559, -0.0363, -0.0233,  0.1369, -0.1094, -0.1526],\n",
              "          [-0.1388, -0.0688, -0.1420,  0.0266, -0.0092, -0.1052,  0.1316,  0.0110,\n",
              "           -0.0360,  0.1607,  0.0604, -0.0753, -0.1102,  0.0310, -0.0946,  0.0338,\n",
              "           -0.0979, -0.1468,  0.1498,  0.0896, -0.0887, -0.0810,  0.1136, -0.1533,\n",
              "            0.0184, -0.1142, -0.0481, -0.1078,  0.0412, -0.1103, -0.0159, -0.0527],\n",
              "          [-0.0623, -0.1468, -0.0595, -0.0309,  0.0742, -0.1440, -0.0563,  0.1635,\n",
              "           -0.1652,  0.1181,  0.0735,  0.0993, -0.1535, -0.0410, -0.0065,  0.1520,\n",
              "           -0.1268,  0.1024,  0.0534,  0.0071, -0.0648, -0.0933, -0.1165, -0.0030,\n",
              "            0.1482,  0.1104, -0.0228, -0.0300,  0.0224,  0.0858, -0.0861,  0.1409],\n",
              "          [ 0.1238,  0.0657, -0.1052,  0.1598,  0.1177,  0.0966,  0.1488, -0.0614,\n",
              "            0.0476, -0.0622, -0.0222, -0.1010,  0.1688,  0.1456, -0.0018, -0.0676,\n",
              "           -0.1250, -0.1168,  0.0063,  0.0209, -0.0982, -0.0519, -0.0232, -0.1190,\n",
              "           -0.0011,  0.0105,  0.1496, -0.1670, -0.1228, -0.0801,  0.1348,  0.1139],\n",
              "          [-0.1347,  0.0795,  0.1022,  0.0979, -0.0282, -0.1765,  0.1019, -0.0919,\n",
              "            0.1099, -0.0674, -0.0705, -0.0222,  0.1174,  0.0713, -0.0796,  0.1482,\n",
              "           -0.0345, -0.0019,  0.1417, -0.0622,  0.1594,  0.0742,  0.0434, -0.0820,\n",
              "           -0.1504, -0.0697, -0.0362, -0.1464, -0.0205, -0.0406,  0.1165,  0.0036],\n",
              "          [ 0.1605, -0.1369, -0.0404, -0.1637, -0.0369, -0.1703,  0.0460,  0.0577,\n",
              "            0.0858, -0.0139, -0.0683,  0.0811,  0.0795,  0.0060,  0.0111, -0.0196,\n",
              "            0.1007,  0.0084,  0.0450,  0.1171,  0.1367, -0.0649, -0.1363, -0.1398,\n",
              "           -0.1493, -0.0652,  0.0673,  0.0348,  0.0301,  0.0184,  0.0464,  0.1086],\n",
              "          [-0.1538,  0.1618,  0.0769, -0.0313,  0.1295, -0.1051,  0.0246,  0.0376,\n",
              "            0.0165, -0.1586,  0.0574,  0.1057,  0.1012,  0.1735,  0.1443, -0.1503,\n",
              "           -0.0481, -0.0794,  0.0260, -0.0086,  0.1021, -0.1647, -0.1309, -0.0097,\n",
              "            0.0424,  0.1511,  0.1651,  0.0528,  0.0306,  0.1642,  0.0669,  0.0176],\n",
              "          [-0.1515,  0.0762, -0.0556,  0.1177, -0.0324, -0.0501,  0.1306,  0.1312,\n",
              "            0.0775, -0.1513, -0.1027, -0.0721,  0.0493, -0.0520, -0.1400,  0.1703,\n",
              "           -0.0148,  0.0469,  0.0868,  0.0238, -0.1426, -0.0693,  0.0878, -0.0129,\n",
              "            0.1699, -0.0730, -0.0579, -0.0879, -0.0074,  0.1599, -0.0687, -0.0238],\n",
              "          [ 0.0176, -0.0767,  0.0096,  0.1504, -0.1532, -0.0773,  0.0193, -0.0367,\n",
              "           -0.0135,  0.0457, -0.0144,  0.0493,  0.1589, -0.0763, -0.1742, -0.1029,\n",
              "           -0.0532, -0.0795, -0.0975, -0.1519, -0.0746, -0.1443,  0.1269, -0.1271,\n",
              "           -0.1595,  0.1081,  0.0150,  0.1519,  0.1296,  0.0747,  0.0722, -0.1098]],\n",
              "         requires_grad=True)), ('l2.bias', Parameter containing:\n",
              "  tensor([-0.0308,  0.0133,  0.0705, -0.1523,  0.0257, -0.0348,  0.1082,  0.1127,\n",
              "          -0.0147,  0.1220], requires_grad=True))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE39Nmt53M05",
        "colab_type": "text"
      },
      "source": [
        "- Difference\n",
        "0. Didn't stack layers in one container\n",
        "1. Inherited from nn.Module\n",
        "2. used ReLU as functional, rather than making it layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFNmmlBPuOdf",
        "colab_type": "text"
      },
      "source": [
        "### 2. nn.module,name_children"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5LmtkluWlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a01e5709-29dc-42db-e58d-7a138cd03c66"
      },
      "source": [
        "[f\"{name}: {layer}\" for name, layer in model.named_children()]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l1: Linear(in_features=784, out_features=32, bias=True)',\n",
              " 'l2: Linear(in_features=32, out_features=10, bias=True)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoYdpWzFunpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a84a013-3fce-48ca-ccdf-51361633b0b7"
      },
      "source": [
        "model.l1 #we can see values from the key"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=32, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAeMJCKB95Qa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "b727ab2b-cfc9-45d2-f5be-e6299ff80ada"
      },
      "source": [
        "[i for i in model.l1.parameters()]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0300,  0.0253,  0.0085,  ..., -0.0247,  0.0232,  0.0345],\n",
              "         [ 0.0279,  0.0283,  0.0356,  ...,  0.0138, -0.0221,  0.0279],\n",
              "         [ 0.0112, -0.0039, -0.0204,  ...,  0.0141,  0.0340,  0.0212],\n",
              "         ...,\n",
              "         [ 0.0209,  0.0137, -0.0065,  ..., -0.0006,  0.0343,  0.0214],\n",
              "         [ 0.0328,  0.0117, -0.0111,  ...,  0.0065, -0.0196,  0.0127],\n",
              "         [ 0.0269,  0.0023,  0.0300,  ...,  0.0049,  0.0136,  0.0310]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.0020,  0.0257, -0.0174, -0.0026, -0.0267, -0.0209, -0.0265,  0.0125,\n",
              "         -0.0185, -0.0341,  0.0343, -0.0306,  0.0104, -0.0223,  0.0034,  0.0107,\n",
              "          0.0163,  0.0094, -0.0101,  0.0136, -0.0335, -0.0309, -0.0290,  0.0246,\n",
              "         -0.0178,  0.0146,  0.0299, -0.0130, -0.0089,  0.0166,  0.0300,  0.0150],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTHV0oeJuqrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(model.l1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_T3QPoux48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e2a356be-db41-4f56-ba54-ed690a615fe6"
      },
      "source": [
        "help(model.l1.__setattr__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method __setattr__ in module torch.nn.modules.module:\n",
            "\n",
            "__setattr__(name, value) method of torch.nn.modules.linear.Linear instance\n",
            "    Implement setattr(self, name, value).\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdI8eBYCu7X6",
        "colab_type": "text"
      },
      "source": [
        "### 2. fit function second"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3KZa_-ku9Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    model = Model(n_in, nh, n_out)\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs +1):\n",
        "            srt, end = bs*i, bs*(i+1)\n",
        "            xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "            loss = loss_fun(model(xb), yb)\n",
        "            \n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for param in model.parameters(): param-= param.grad * lr # [^9]\n",
        "                model.zero_grad()\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBqhKVlhwOUH",
        "colab_type": "text"
      },
      "source": [
        "- What changed?/ why shorter?\n",
        "\n",
        "1. this time we make zero grad to model, not each layer\n",
        "2. don't need the code that checks if they have weight(i.e. parameter), since we already selected parameters in model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAQ45y4uw7Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17a37fe8-a240-490f-af70-3b9f50c270e9"
      },
      "source": [
        "n=train_x.shape[0]\n",
        "m = fit()\n",
        "\n",
        "loss_fun(m(xb), yb), accuracy(m(xb), yb)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1523, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-73KmoCxIld",
        "colab_type": "text"
      },
      "source": [
        "### DummyModule class to simulate pytorch's `__setattr__`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGv5CX2V8EWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a84794c5-15d1-47a7-ec30-49ee48f30682"
      },
      "source": [
        "'abrigaie'.startswith(\"b\"), 'abrigaie'.startswith(\"a\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2zRmV77i8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModel():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.linear1 = nn.Linear(n_in, nh)\n",
        "        self.linear2 = nn.Linear(nh, n_out)\n",
        "    def __setattr__(self, k, v): # [^13] \n",
        "        if not k.startswith('_'): self._modules[k] = v # [^11]\n",
        "        super().__setattr__(k, v) # [^14]\n",
        "\n",
        "    def __repr__(self): return f\"{self._modules}\"\n",
        "\n",
        "    def parameters(self): # [^13]\n",
        "        for l in self._modules.values():\n",
        "            for param in l.parameters(): yield param"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZtUz3RS7iym",
        "colab_type": "text"
      },
      "source": [
        "1. What does the setattr do here?: (maybe) when you initialize the instance, they set attribute to the submodule, with several condition\n",
        "    1. How can i check if I defined parameters properly?: call the parameters\n",
        "1. What does the repr do here?: what to print out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r77fLiGkBIuQ",
        "colab_type": "text"
      },
      "source": [
        "### 5. Call the instance of dummymodule and see repr and shape of parameters in instance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ku8vln7in3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dm = DummyModel(n_in, nh, n_out)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X2EZLLS7idW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f52b100d-9f10-47fb-9ee8-f36017d83606"
      },
      "source": [
        "dm # repr"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'linear1': Linear(in_features=784, out_features=32, bias=True), 'linear2': Linear(in_features=32, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf8ZFxZtA1l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9345561d-f7fb-4f7e-cad3-a6f4ba7f2cb1"
      },
      "source": [
        "[o.shape for o in dm.parameters()]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([32, 784]),\n",
              " torch.Size([32]),\n",
              " torch.Size([10, 32]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xTK-uWEqIBL",
        "colab_type": "text"
      },
      "source": [
        "## Registering modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN5tONVTBRnv",
        "colab_type": "text"
      },
      "source": [
        "we can approach defining layers with rendering stacked layers, but we should also register modules (i.e. `add_modules`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llJzYYnSDCtN",
        "colab_type": "text"
      },
      "source": [
        "1. Re-define Model class ***(4th Model)***\n",
        "\t1. Use original layers approach\n",
        "\t1. Register the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwe6mV9BDJNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)] # [^15]\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for idx, l in enumerate(self.layers): self.add_module(f'layer_{idx}', l)\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x) \n",
        "        return x"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j-YT1LwDH9l",
        "colab_type": "text"
      },
      "source": [
        "2. What is `registering modules`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf0rS8kvEeQo",
        "colab_type": "text"
      },
      "source": [
        "adding layers to the module....... but still can't get why we use this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZx88GmPDLbb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "3. See the model instance (i.e. repr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGFQThpDEnff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Z12AIPEpYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4d8f8519-3ad2-42a4-d54a-44b9d030e1ff"
      },
      "source": [
        "m"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEONBfkcFMWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5b9f7f99-5f78-44b6-ca5d-3ecdf9d8378d"
      },
      "source": [
        "[k for k in m.children()]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=32, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=32, out_features=10, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYVpSrZiFarJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[k.parameters()[0].shape for k in m.children()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3aPbhMrExxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = [k.parameters() for k in m.children()];"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB4C2JPmNkP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c = params[0], params[1], params[2]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwzBdbI0OEr7",
        "colab_type": "text"
      },
      "source": [
        "a - Linear1, b - ReLU, c - Linear2\n",
        "\n",
        "and there's no element in ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Tw5yuuN43Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05e01880-4bd2-411b-d9db-f2d0947b992c"
      },
      "source": [
        "next(a).shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoBesdvTN7mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d76ce57-301c-4b3a-ff96-91ebdaee9bd7"
      },
      "source": [
        "next(a).shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4-JzxHbN87i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "101c7cfb-50e5-40dc-f665-d25e086ff6b9"
      },
      "source": [
        "next(a).shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-bcfca9785a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MymkIWwGOA0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "49f5aa9e-26f5-4ddd-e1fa-76427bdfc504"
      },
      "source": [
        "next(b).shape #ReLU"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-3ec27e7ed78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;31m#ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmhx6k9ZBNIu",
        "colab_type": "text"
      },
      "source": [
        "## nn.ModuleList\n",
        "\n",
        "1. Define class SequentialModel ***(5th Model)***\n",
        "\t1. Use nn.ModuleList"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQbh5IgJM1sB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxeGyUO2Op11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = SequentialModel(layers)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLlgrWnQOt2m",
        "colab_type": "text"
      },
      "source": [
        "2. What does nn.ModuleList do for us?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Z_6FexO1mH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "fc31e193-73ce-43df-f51a-4069f182aef1"
      },
      "source": [
        "m"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBDjexOO4To",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "519344cd-326a-4ca9-bb26-074828b80bb6"
      },
      "source": [
        "[(i, v) for i, v in m.named_parameters()]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layers.0.weight', Parameter containing:\n",
              "  tensor([[ 0.0156,  0.0018,  0.0095,  ...,  0.0163, -0.0154,  0.0163],\n",
              "          [-0.0108, -0.0148,  0.0158,  ...,  0.0348, -0.0046, -0.0230],\n",
              "          [ 0.0134,  0.0082, -0.0097,  ..., -0.0131, -0.0148, -0.0212],\n",
              "          ...,\n",
              "          [ 0.0223, -0.0063, -0.0290,  ...,  0.0034,  0.0196,  0.0169],\n",
              "          [ 0.0082,  0.0315, -0.0330,  ..., -0.0147, -0.0342,  0.0087],\n",
              "          [ 0.0057, -0.0284,  0.0029,  ..., -0.0110,  0.0097, -0.0222]],\n",
              "         requires_grad=True)), ('layers.0.bias', Parameter containing:\n",
              "  tensor([ 0.0180,  0.0223,  0.0285,  0.0128,  0.0309,  0.0078, -0.0285,  0.0139,\n",
              "           0.0001,  0.0006, -0.0126, -0.0234,  0.0284,  0.0147,  0.0012,  0.0067,\n",
              "          -0.0286, -0.0312, -0.0334, -0.0089, -0.0105,  0.0046, -0.0181,  0.0166,\n",
              "           0.0154,  0.0133,  0.0166,  0.0315, -0.0179,  0.0263,  0.0305,  0.0174],\n",
              "         requires_grad=True)), ('layers.2.weight', Parameter containing:\n",
              "  tensor([[-0.0541,  0.1174, -0.0750,  0.0816,  0.1387, -0.1671,  0.1662,  0.0666,\n",
              "           -0.0319, -0.0115,  0.0346, -0.0739, -0.1189, -0.0490,  0.1694, -0.1468,\n",
              "           -0.1342, -0.1542,  0.1440,  0.0307,  0.1130, -0.1374,  0.0865,  0.0239,\n",
              "            0.0954, -0.1634,  0.0382, -0.1516,  0.0447, -0.0425, -0.0052,  0.0922],\n",
              "          [-0.1424,  0.1080,  0.1439,  0.0540,  0.0967,  0.0573, -0.0274,  0.0782,\n",
              "           -0.1252, -0.0012, -0.0509, -0.0952,  0.0200,  0.0850, -0.0577,  0.0596,\n",
              "            0.0096,  0.1691, -0.0188,  0.1763,  0.0159, -0.0851, -0.0788,  0.1352,\n",
              "           -0.0592,  0.0021,  0.1425,  0.0272,  0.0528,  0.1522, -0.0480,  0.0711],\n",
              "          [ 0.0833, -0.0644, -0.1624,  0.0846,  0.1338,  0.0680,  0.1556, -0.0404,\n",
              "           -0.0528,  0.1319,  0.1721, -0.1405, -0.1672, -0.0609, -0.1447, -0.0451,\n",
              "            0.1672,  0.0577,  0.1469,  0.1289, -0.1305,  0.0872,  0.0013,  0.0086,\n",
              "           -0.1727,  0.0830, -0.1571,  0.0164, -0.0157,  0.0078, -0.0803, -0.1440],\n",
              "          [ 0.0769,  0.0332, -0.0119,  0.0134, -0.1163, -0.0612,  0.1661, -0.0019,\n",
              "            0.0725,  0.0772, -0.0284, -0.0657, -0.1083,  0.0711,  0.1454,  0.0495,\n",
              "           -0.1474,  0.0294, -0.1483, -0.1010,  0.0668, -0.1257,  0.0092, -0.1717,\n",
              "            0.1235, -0.0627,  0.0997,  0.0108,  0.1450, -0.1450, -0.0572,  0.1692],\n",
              "          [ 0.1768,  0.0132,  0.0597,  0.0391,  0.1161,  0.0758, -0.0418,  0.0488,\n",
              "            0.1558,  0.0131,  0.1493,  0.0983,  0.1746, -0.1045, -0.0507, -0.0331,\n",
              "            0.0621, -0.0880,  0.0929,  0.1440,  0.0392, -0.1058, -0.1436, -0.0735,\n",
              "           -0.0434,  0.0596,  0.1571, -0.1659,  0.0498, -0.1661,  0.0469,  0.0073],\n",
              "          [-0.0429,  0.1409,  0.0608,  0.1659,  0.0698,  0.1017,  0.0171, -0.0566,\n",
              "           -0.0406, -0.1738, -0.1701, -0.0752,  0.1536, -0.0803,  0.1676, -0.0068,\n",
              "            0.0099,  0.0360,  0.0924,  0.0309, -0.1661, -0.0583, -0.0984, -0.1519,\n",
              "           -0.0820,  0.1605,  0.0046,  0.1212,  0.1689, -0.1007, -0.1605,  0.1477],\n",
              "          [ 0.0201,  0.1474,  0.0844, -0.0472,  0.0021, -0.1165, -0.1143, -0.1349,\n",
              "            0.0089,  0.0054, -0.1170, -0.0141,  0.1104, -0.1758,  0.0121,  0.1553,\n",
              "           -0.1763, -0.0594,  0.0734,  0.0274, -0.1329, -0.0971, -0.1388,  0.0173,\n",
              "            0.1525, -0.1545,  0.1730, -0.0602,  0.1042,  0.0590, -0.0205,  0.1002],\n",
              "          [-0.0335,  0.1516,  0.0085,  0.0064,  0.1717, -0.0127,  0.1621, -0.1116,\n",
              "           -0.1218,  0.0759,  0.1547,  0.0297,  0.1758, -0.0438,  0.0028,  0.0066,\n",
              "            0.0244, -0.1223, -0.1215,  0.0548,  0.0423,  0.0396, -0.0175,  0.1012,\n",
              "            0.1423, -0.1764, -0.1624, -0.1505,  0.0066,  0.0905,  0.1625, -0.0935],\n",
              "          [ 0.1188, -0.0484,  0.1364, -0.1368,  0.0191,  0.1261, -0.0207,  0.0616,\n",
              "           -0.1002,  0.0365,  0.0409,  0.1348,  0.0960, -0.1076,  0.0170, -0.1249,\n",
              "            0.0977,  0.1598, -0.1347,  0.1204,  0.1272,  0.1375,  0.0295, -0.0270,\n",
              "            0.1593, -0.1124, -0.0178,  0.1446,  0.1101, -0.0048,  0.0915,  0.0670],\n",
              "          [-0.1614, -0.1541, -0.1433, -0.0216, -0.0263, -0.0380,  0.0771,  0.0269,\n",
              "           -0.0583, -0.0982,  0.0134,  0.0666, -0.0336,  0.0411, -0.0023, -0.1088,\n",
              "           -0.0520,  0.0101, -0.0028, -0.0257, -0.1638,  0.1490, -0.1467,  0.0265,\n",
              "            0.0678,  0.0227, -0.0116, -0.0251,  0.0113, -0.0578,  0.1271, -0.0390]],\n",
              "         requires_grad=True)), ('layers.2.bias', Parameter containing:\n",
              "  tensor([ 0.1647,  0.1412,  0.0376, -0.1032, -0.0531,  0.0316, -0.1679, -0.0624,\n",
              "           0.1129, -0.1338], requires_grad=True))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuR8f5bBPPPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ad926a37-8e43-4513-e7c2-76a5e495c5df"
      },
      "source": [
        "[f\"name: {i}, value: {v}\" for i, v in m.named_children()]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name: layers, value: ModuleList(\\n  (0): Linear(in_features=784, out_features=32, bias=True)\\n  (1): ReLU()\\n  (2): Linear(in_features=32, out_features=10, bias=True)\\n)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMvpkBu-PhVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75de51b3-1bc4-474e-d379-d6bb1d8531ca"
      },
      "source": [
        "[dir(v) for i, v in m.named_children()]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['__call__',\n",
              "  '__class__',\n",
              "  '__delattr__',\n",
              "  '__delitem__',\n",
              "  '__dict__',\n",
              "  '__dir__',\n",
              "  '__doc__',\n",
              "  '__eq__',\n",
              "  '__format__',\n",
              "  '__ge__',\n",
              "  '__getattr__',\n",
              "  '__getattribute__',\n",
              "  '__getitem__',\n",
              "  '__gt__',\n",
              "  '__hash__',\n",
              "  '__iadd__',\n",
              "  '__init__',\n",
              "  '__init_subclass__',\n",
              "  '__iter__',\n",
              "  '__le__',\n",
              "  '__len__',\n",
              "  '__lt__',\n",
              "  '__module__',\n",
              "  '__ne__',\n",
              "  '__new__',\n",
              "  '__reduce__',\n",
              "  '__reduce_ex__',\n",
              "  '__repr__',\n",
              "  '__setattr__',\n",
              "  '__setitem__',\n",
              "  '__setstate__',\n",
              "  '__sizeof__',\n",
              "  '__str__',\n",
              "  '__subclasshook__',\n",
              "  '__weakref__',\n",
              "  '_apply',\n",
              "  '_backward_hooks',\n",
              "  '_buffers',\n",
              "  '_forward_hooks',\n",
              "  '_forward_pre_hooks',\n",
              "  '_get_abs_string_index',\n",
              "  '_get_name',\n",
              "  '_load_from_state_dict',\n",
              "  '_load_state_dict_pre_hooks',\n",
              "  '_modules',\n",
              "  '_named_members',\n",
              "  '_parameters',\n",
              "  '_register_load_state_dict_pre_hook',\n",
              "  '_register_state_dict_hook',\n",
              "  '_replicate_for_data_parallel',\n",
              "  '_save_to_state_dict',\n",
              "  '_slow_forward',\n",
              "  '_state_dict_hooks',\n",
              "  '_version',\n",
              "  'add_module',\n",
              "  'append',\n",
              "  'apply',\n",
              "  'bfloat16',\n",
              "  'buffers',\n",
              "  'children',\n",
              "  'cpu',\n",
              "  'cuda',\n",
              "  'double',\n",
              "  'dump_patches',\n",
              "  'eval',\n",
              "  'extend',\n",
              "  'extra_repr',\n",
              "  'float',\n",
              "  'forward',\n",
              "  'half',\n",
              "  'insert',\n",
              "  'load_state_dict',\n",
              "  'modules',\n",
              "  'named_buffers',\n",
              "  'named_children',\n",
              "  'named_modules',\n",
              "  'named_parameters',\n",
              "  'parameters',\n",
              "  'register_backward_hook',\n",
              "  'register_buffer',\n",
              "  'register_forward_hook',\n",
              "  'register_forward_pre_hook',\n",
              "  'register_parameter',\n",
              "  'requires_grad_',\n",
              "  'share_memory',\n",
              "  'state_dict',\n",
              "  'to',\n",
              "  'train',\n",
              "  'training',\n",
              "  'type',\n",
              "  'zero_grad']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1nv3RSkBNs_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcULfGs7P_bk",
        "colab_type": "text"
      },
      "source": [
        "1. Make model instance using nn.Sequential  ***(6th Model)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXbFkQotQNta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZODlweu_Qyy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    print(model)\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs +1):\n",
        "            srt, end = bs*i, bs*(i+1)\n",
        "            xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "            loss = loss_fun(model(xb), yb)\n",
        "            \n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for param in model.parameters(): param-= param.grad * lr # [^9]\n",
        "                model.zero_grad()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qghHea3QTvXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b2b67c57-275d-4882-ce3b-3d299503d2b7"
      },
      "source": [
        "fit()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=32, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wf8ZgsDQMuZ",
        "colab_type": "text"
      },
      "source": [
        "Q. Why does this class make jobs easier?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcNaTo1VT-No",
        "colab_type": "text"
      },
      "source": [
        "1. This problems happen when you want to render stack of the layers at once\n",
        "2. so, if you define all the layers to the self, you don't have to check if there is parameters or not since pytorch nn.Module has `__setattr__`\n",
        "3. In the other words, you can get stack of layers, if you `add_modules` to every layers\n",
        "4. Or, you can use `ModuleList(layers)`\n",
        "5. 2-4 process could be done just using `nn.Sequential`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgEmrJMrBOIv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p956rHPXusVr",
        "colab_type": "text"
      },
      "source": [
        "### Define class Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro1KuU2UwP6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5):\n",
        "        self.params, self.lr = list(params), lr\n",
        "    \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params: p -= p.grad * self.lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.params: p.grad.data.zero_()\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "781BL829xZAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXyt8iuqvc8q",
        "colab_type": "text"
      },
      "source": [
        "### Do the one epoch learning with optimizer instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tUMN9vxxPTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04eb2134-1be4-4896-a287-055f7b8271ab"
      },
      "source": [
        "len(list(model.parameters()))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5JaMPKgxHjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl6ZHfmyxf03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs +1):\n",
        "        srt, end = bs*i, bs*(i+1)\n",
        "        xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "        loss = loss_fun(model(xb), yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBIVsp84vikJ",
        "colab_type": "text"
      },
      "source": [
        "### See the loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63C_I-oLyupJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6ca0f9c-bc3f-4fdd-e75c-27e06ddc3207"
      },
      "source": [
        "loss_fun(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1204, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9RzW-jOy6id",
        "colab_type": "text"
      },
      "source": [
        "### 4. Do the one epoch learning using PyTorch’s optim.SGD functionality ***(4th Training Loop)***\n",
        "1. Define get_model function\n",
        "    1. why do we need this function\n",
        "1. return: (1) model instance from nn.Sequential, (2) Optimizer function from optim.SGD\n",
        "1. See the loss and accuracy [^5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXC__oN5y9yZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(n_in, nh, n_out):\n",
        "    model = nn.Sequential(nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out))\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    return model, optim"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N5-CS62zgOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optim = get_model(n_in, nh, n_out)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ql0U5Ikzj00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs +1):\n",
        "        srt, end = bs*i, bs*(i+1)\n",
        "        xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "        loss = loss_fun(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCI63Mtf0Icn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24ec25af-a34f-4757-f1ff-02a5ca8545ec"
      },
      "source": [
        "loss_fun(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1262, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtM43yrn0gmD",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghNUQsZN0koC",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "1. Make class `Dataset` which has three essential components which are indispensable. (hint: 3)\n",
        "\t1. what are three components?\n",
        "2. make dataset object and compare 1) the length and 2) sliced data shape with originals'\n",
        "\n",
        "3. Do the one epoch learning using data from `Datasest` ***(5th training loop)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myznGkRd1PfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x, self.y = x, y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i], self.y[i]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6GLAIqx1f5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds, valid_ds = Dataset(train_x, train_y), Dataset(valid_x, valid_y) "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejq-paDB1gB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(train_ds) == len(train_x)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmEzVwpt1rq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(valid_ds) == len(valid_x)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnEHyNvl1ryY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = train_ds[:bs]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k04ruqqb18OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert xb.shape == (bs, 28*28)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImONUcM31r49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert yb.shape == (bs, )"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQHIB5b61gJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optim = get_model(n_in, nh, n_out)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs +1):\n",
        "        xb, yb = train_ds[(bs*i):(bs*(i+1))]\n",
        "        loss = loss_fun(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q0CMjJI285e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd97d15d-225f-4797-e779-c87f46948001"
      },
      "source": [
        "loss_fun(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1353, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYMf32s0kup",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6LzdmpZ3RI8",
        "colab_type": "text"
      },
      "source": [
        "1. make class `DataLoader` which takes dataset and batch size, and instance is iterator returning next batch\n",
        "\n",
        "2. make `def fit()` which gets data from dataloader class. ***(6th training)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C8p3HEv3SAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, bs): self.ds , self.bs = ds, bs\n",
        "    def __iter__(self):\n",
        "        # return self.ds[(self.bs*i):(self.bs*(i+1))]\n",
        "        for i in range(0, len(self.ds), self.bs): yield self.ds[i: i+self.bs] # [^16]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdk1m1VF4o1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl, valid_dl = DataLoader(train_ds, bs), DataLoader(valid_ds, bs)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjzIId04xgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(valid_dl))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOvZO7Oj5BVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "862ecf9f-2675-44a5-fb76-229b8d8c39c7"
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa993555780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN90lEQVR4nO3df6xfdX3H8deL/qSluBaw7QCHMqJDHcXcwCLFyYgG2Bi4RUKzMJaRXbdAlMW5ESCTZFvEOXUmU0gRQiUI8RehZmSj3pAwo2taENrSDqhYsF1/qJ22gPbne3/cU3Ip93zu5XvO9wf3/XwkN9/v97y/53ve+aavnvM9vz6OCAGY+o7pdwMAeoOwA0kQdiAJwg4kQdiBJKb3cmEzPStma24vFwmk8iu9pP2xz+PVGoXd9kWSviBpmqQvR8StpffP1lyd6wubLBJAweoYqa11vBlve5qkL0q6WNKZkpbZPrPTzwPQXU1+s58jaXNEPBcR+yXdL+mydtoC0LYmYT9Z0o/HvN5aTXsV28O219pee0D7GiwOQBNd3xsfEcsjYigihmZoVrcXB6BGk7Bvk3TqmNenVNMADKAmYV8j6Qzbb7U9U9KVkla20xaAtnV86C0iDtq+TtJ/avTQ210R8VRrnQFoVaPj7BHxkKSHWuoFQBdxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSfR0yGZ05vD5Zxfr/3v9/tra0lOfK867aNaeYn3Vp84v1ve9adzRgV+x8BtP19YO/Wx3cV60izU7kARhB5Ig7EAShB1IgrADSRB2IAnCDiThiOjZwo73gjjXF/ZseW8U0+bPL9Y/84PyQLnvmDGrzXZateqXx9bWbv70nxfnPeGO77fdzpS3Oka0J3aPe/JDo5NqbG+RtFfSIUkHI2KoyecB6J42zqC7ICJ+2sLnAOgifrMDSTQNe0h62PZjtofHe4PtYdtrba89oH0NFwegU00345dGxDbbb5a0yvb/RMSjY98QEcslLZdGd9A1XB6ADjVas0fEtupxl6QHJJ3TRlMA2tdx2G3PtT3vyHNJH5S0oa3GALSryWb8QkkP2D7yOV+NiP9opatsjilfE/7Fn1xQrG/6+cLa2gvrFxfnfcu7txfrFy6svx5dkv5g3pPF+lkzX66t/e0nvlqcd8Wq3y3WD255oVjHq3Uc9oh4TtJZLfYCoIs49AYkQdiBJAg7kARhB5Ig7EASXOKKRqafcnKxvvHm+vrmS28vzvuez1xXrC/61+8V6xmVLnFlzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTBkMxo5uHVbsX7S999SX7y0/Nl7frt+KGpJWlSeHUdhzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXCcHY1MX1R/G2tJOv+jqzv+7IWLft7xvHgt1uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATH2VF0+Pyzi/UP3/HvxfpV83bU1u7cc0px3gV/XSzrULmMo0y4Zrd9l+1dtjeMmbbA9irbz1aP87vbJoCmJrMZf7eki46adoOkkYg4Q9JI9RrAAJsw7BHxqKTdR02+TNKK6vkKSZe33BeAlnX6m31hRGyvnu+QVHuCtO1hScOSNFtzOlwcgKYa742P0ZEha0eHjIjlETEUEUMzNKvp4gB0qNOw77S9WJKqx13ttQSgGzoN+0pJV1fPr5b0YDvtAOiWCX+z275P0vslnWh7q6RPSrpV0tdsXyPpeUlXdLNJdM+O699brP/DtXcX678/58Vifdehl2tr99xUvnH8nKc7vxYerzVh2CNiWU3pwpZ7AdBFnC4LJEHYgSQIO5AEYQeSIOxAElziOgVMm19/0eHTf//24rwbr/hCsT5d04r19fsPFOs3XPFXtbU5azi01kus2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCY6zTwG/uK/+OPsz7/7SBHOXj6Of92T56uXZ/1a+sfCsNWsmWD56hTU7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfYp4OJf39i1z57x5ROK9VkPcU36GwVrdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHRs4Ud7wVxrhn8tW3P3H5ObW3zpbc3+ux9cbBYf9d36u8LL0nv+MfdtbVDm3/UUU+otzpGtCd2e7zahGt223fZ3mV7w5hpt9jeZvuJ6u+SNhsG0L7JbMbfLemicaZ/PiKWVH8PtdsWgLZNGPaIeFRS/bYYgDeEJjvorrO9rtrMr70Rme1h22ttrz2gfQ0WB6CJTsN+m6TTJS2RtF3SZ+veGBHLI2IoIoZmaFaHiwPQVEdhj4idEXEoIg5LukNS/e5gAAOho7DbXjzm5Yckbah7L4DBMOFxdtv3SXq/pBMl7ZT0yer1EkkhaYukj0TE9okWxnH27jhm3rza2t6vn1Sc929Of7hYv3TOno56OuK/flV/y4Qbbxouzjvv/v9utOyMSsfZJ7x5RUQsG2fynY27AtBTnC4LJEHYgSQIO5AEYQeSIOxAElziOsUdM3duse6ZM4v1b28YabOdV/nZ4V8W6xd86RPF+imf+l6b7UwJjS5xBTA1EHYgCcIOJEHYgSQIO5AEYQeSIOxAEhxnR9HhpUuK9ZM+/Xyxfs9pnR+n//bLxxfrt53xmx1/9lTFcXYAhB3IgrADSRB2IAnCDiRB2IEkCDuQBMfZB8C048vHkw/taXY7526avmhhsf7SV46trY2881uNlv2H5/9RsX7wuS2NPv+NiOPsAAg7kAVhB5Ig7EAShB1IgrADSRB2IIkJR3FFc8ec9VvF+g0P3Fes/8WaPy1//qbjamvH7iifR/G2P3m2WJ8zfX+x/nvzf1CsXzVvR7Fecu/eNxfrGY+jNzHhmt32qbYfsb3R9lO2P1ZNX2B7le1nq8f53W8XQKcmsxl/UNLHI+JMSb8j6VrbZ0q6QdJIRJwhaaR6DWBATRj2iNgeEY9Xz/dK2iTpZEmXSVpRvW2FpMu71SSA5l7Xb3bbp0k6W9JqSQsjYntV2iFp3JOkbQ9LGpak2ZrTaZ8AGpr03njbx0n6pqTrI+JVV2bE6NU04+4JiojlETEUEUMzNKtRswA6N6mw256h0aDfGxFHLlXaaXtxVV8saVd3WgTQhgk3421b0p2SNkXE58aUVkq6WtKt1eODXelwCvjhsl8r1t83uzz/xqV3l9+w9PX183pMc3l9cCgOd/zZLxx8uVhffvMfF+tztbrjZWc0md/s50m6StJ6209U027UaMi/ZvsaSc9LuqI7LQJow4Rhj4jvShr3YnhJ3IkCeIPgdFkgCcIOJEHYgSQIO5AEYQeS4BLXHjgw/2C/W+iapes+XKwf90/zamszt/1fcd65P+I4eptYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEhxn74G3f3Rdsf7eR/6yWH/pyl8U6+88qf52zVtfLF9LP5HDy8u3c37TyvKtpONA/a2op+7ZB4OJNTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOHRwVx643gviHPNDWmBblkdI9oTu8e9GzRrdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYsKw2z7V9iO2N9p+yvbHqum32N5m+4nq75LutwugU5O5ecVBSR+PiMdtz5P0mO1VVe3zEfEv3WsPQFsmMz77dknbq+d7bW+SdHK3GwPQrtf1m932aZLOlnRkXJ7rbK+zfZft+TXzDNtea3vtAe1r1CyAzk067LaPk/RNSddHxB5Jt0k6XdISja75PzvefBGxPCKGImJohma10DKATkwq7LZnaDTo90bEtyQpInZGxKGIOCzpDknndK9NAE1NZm+8Jd0paVNEfG7M9MVj3vYhSRvabw9AWyazN/48SVdJWm/7iWrajZKW2V4iKSRtkfSRrnQIoBWT2Rv/XUnjXR/7UPvtAOgWzqADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dMhm23/RNLzYyadKOmnPWvg9RnU3ga1L4neOtVmb78RESeNV+hp2F+zcHttRAz1rYGCQe1tUPuS6K1TveqNzXggCcIOJNHvsC/v8/JLBrW3Qe1LordO9aS3vv5mB9A7/V6zA+gRwg4k0Zew277I9tO2N9u+oR891LG9xfb6ahjqtX3u5S7bu2xvGDNtge1Vtp+tHscdY69PvQ3EMN6FYcb7+t31e/jznv9mtz1N0jOSPiBpq6Q1kpZFxMaeNlLD9hZJQxHR9xMwbL9P0ouSvhIR76qm/bOk3RFxa/Uf5fyI+LsB6e0WSS/2exjvarSixWOHGZd0uaQ/Ux+/u0JfV6gH31s/1uznSNocEc9FxH5J90u6rA99DLyIeFTS7qMmXyZpRfV8hUb/sfRcTW8DISK2R8Tj1fO9ko4MM97X767QV0/0I+wnS/rxmNdbNVjjvYekh20/Znu4382MY2FEbK+e75C0sJ/NjGPCYbx76ahhxgfmu+tk+POm2EH3Wksj4j2SLpZ0bbW5OpBi9DfYIB07ndQw3r0yzjDjr+jnd9fp8OdN9SPs2ySdOub1KdW0gRAR26rHXZIe0OANRb3zyAi61eOuPvfzikEaxnu8YcY1AN9dP4c/70fY10g6w/Zbbc+UdKWklX3o4zVsz612nMj2XEkf1OANRb1S0tXV86slPdjHXl5lUIbxrhtmXH3+7vo+/HlE9PxP0iUa3SP/Q0k39aOHmr7eJunJ6u+pfvcm6T6NbtYd0Oi+jWsknSBpRNKzkr4jacEA9XaPpPWS1mk0WIv71NtSjW6ir5P0RPV3Sb+/u0JfPfneOF0WSIIddEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8DSuZJD86udGUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmQ4k4oo5Fj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccd6e8da-f25f-416a-ca52-f4d61f303b95"
      },
      "source": [
        "yb[0]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo5UXp4-5X-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl, valid_dl = DataLoader(train_ds, bs), DataLoader(valid_ds, bs)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eguCYw9I5i1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optim = get_model(n_in, nh, n_out)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-945zkv5Gov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "        loss = loss_fun(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lq2Ku6k5qk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65ec090b-0133-4587-910f-b08868650269"
      },
      "source": [
        "xb, yb = train_ds[:bs]\n",
        "loss_fun(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1587, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oGp3MS0k19",
        "colab_type": "text"
      },
      "source": [
        "## Random sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06Gmwm_r0k8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO3OYHmj0lDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdMuw9IL0lJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDT5QiH40lPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9w0mADRmwP",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKh7TcqJRQ0-",
        "colab_type": "text"
      },
      "source": [
        "[^1]: I don't have to define parameters no more, but obviously at first I tried to iniailized Model with `w1, b1, ....`, meaning I didn't practice enough the previous part, part of the torch nn, where I get parameters\n",
        "\n",
        "[^2]: be cautious since `train_x.sum(-1)` will squeeze the rank, so that you need arg `keepdim:bool`, false as default\n",
        "\n",
        "[^3]: see *eq (2.46)*, Foundations of Natural Language Processing, Christopher D. Manning and Hinrich Schütze\n",
        "\n",
        "[^4]: Should check for `cross-entropy $\\approx$ softmax of negative likelihood`\n",
        "\n",
        "[^5]: check later, also you just implemented logsumexp in PyTorch, but you should implement it by yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr9R50W2cXUc",
        "colab_type": "text"
      },
      "source": [
        "[^6]: Be careful to take 1 off from size of dataset, in case batch size is divisible number</br>\n",
        "[^7]: study of hasattr() more<br/>\n",
        "[^8]: 1) careful, that is in-place function / 2) should learn more of why I need this\n",
        "\n",
        "[^9]: `parameters` is method, layers is attr. this time we make zero grad to model, not each layer\n",
        "\n",
        "[^10]: things that happen when you don't specify inheritence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv7Jkk5i1p_x",
        "colab_type": "text"
      },
      "source": [
        "[^11]: (solved) Not sure why I need this condition, but  maybe `_modules` would be involved in key, and want to filter it.<br/> What if i don't filter? -> recursive\n",
        "\n",
        "[^12]: Why we don't do normalization of train data, in this case? Is that function is embedded in pytorch?\n",
        "\n",
        "[^13]: (solved) when this dunder is called?, this means they already assigned modules.<br/> maybe at initialization? -> whenever you assign to self\n",
        "\n",
        "[^14]: what if I don't inherit this?  / What module, and submodule, add submodule functions?\n",
        "\n",
        "[^15]: (solved) Why do i need to add nn.ReLU() not a functional? -> because setattr filter all the layers automatically so that you don't have to exclude ReLU (basically, ReLU is also layers, only not to having parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6nYuNCz4j1b",
        "colab_type": "text"
      },
      "source": [
        "[^16]: practice again later"
      ]
    }
  ]
}