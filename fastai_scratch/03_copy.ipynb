{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_copy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fxTB-ysp_jun",
        "K5tAEA4_9NKW",
        "tTbuDvuWdh9g"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR7WdFvw8XPN",
        "colab_type": "text"
      },
      "source": [
        "- 01_matmul\n",
        "- 02_fully_connected\n",
        "- 02a_why_sqrt5\n",
        "- 02b_initialization\n",
        "- 03_minibatch_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ios0-s_4_ZwU",
        "colab_type": "text"
      },
      "source": [
        "Table of contents\n",
        "1. Initial Setup\n",
        "2. Basic training Loop\n",
        "3. Using parameters and optim\n",
        "4. Dataset and DataLoader\n",
        "5. Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxTB-ysp_jun",
        "colab_type": "text"
      },
      "source": [
        "# 1. Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1B6I_hCh1c",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "\n",
        "### Fastai for Colab env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCFq0PZ8tOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bc9af229-4468-442e-d4af-173d2cc4a672"
      },
      "source": [
        "!git clone http://github.com/fastai/course-v3.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'course-v3'...\n",
            "warning: redirecting to https://github.com/fastai/course-v3.git/\n",
            "remote: Enumerating objects: 5498, done.\u001b[K\n",
            "remote: Total 5498 (delta 0), reused 0 (delta 0), pack-reused 5498\u001b[K\n",
            "Receiving objects: 100% (5498/5498), 258.00 MiB | 35.59 MiB/s, done.\n",
            "Resolving deltas: 100% (2992/2992), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3cSi27X88l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ba15c77-3778-4f9c-b038-158a0d088574"
      },
      "source": [
        "%cd course-v3/nbs/dl2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/course-v3/nbs/dl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FacmFUWm9E-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from exp.nb_02 import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAdev1qg-LSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "98dd516d-22f3-43c1-c22e-3ef1074b32fd"
      },
      "source": [
        "!cat exp/nb_02.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#################################################\n",
            "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
            "#################################################\n",
            "# file to edit: dev_nb/02_fully_connected.ipynb\n",
            "\n",
            "from exp.nb_01 import *\n",
            "\n",
            "def get_data():\n",
            "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
            "    with gzip.open(path, 'rb') as f:\n",
            "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
            "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
            "\n",
            "def normalize(x, m, s): return (x-m)/s\n",
            "\n",
            "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
            "\n",
            "from torch.nn import init\n",
            "\n",
            "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()\n",
            "\n",
            "from torch import nn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5tAEA4_9NKW",
        "colab_type": "text"
      },
      "source": [
        "### import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTgE-wJ49UaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5850ed17-da5b-45a4-d114-881be480f2bf"
      },
      "source": [
        "train_x, train_y, valid_x, valid_y = get_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoL0CV2v9gLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20cd8ac8-dac9-4ee6-d6dc-bef8a5594dca"
      },
      "source": [
        "train_x.shape, train_x.type()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 784]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWzQQ9W49hwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "266ccf82-5d68-44fa-b744-2207bd7ca481"
      },
      "source": [
        "n_in, nh, n_out = train_x.shape[1], 32, train_y.max().item()+1; n_in, nh, n_out"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCU0bL8XA76r",
        "colab_type": "text"
      },
      "source": [
        "[^1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euyGKZhK94Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x\n",
        "    # def forward(self, x, y):\n",
        "    #     for l in self.layers: x = l(x)\n",
        "    #     return(self.loss(x, y))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2WPI509B_-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model(n_in, nh, n_out)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPwo2EesCEsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = m(train_x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJQReyi-CNVm",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGhM0NZrCsfI",
        "colab_type": "text"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyX4TB0YCzpZ",
        "colab_type": "text"
      },
      "source": [
        "* formula of softmax : $f(x) = \\frac{exp(x)}{\\sum exp(x_i)}$\n",
        "* We need softmax at last layer since we have to map it to the probabilistic space\n",
        "* code of softmax is below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJcewmjDhyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x): return x.exp() / x.exp().sum(-1, keepdim=True)\n",
        "# def softmax(x): return x.exp() / x.exp().sum()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NnUt5FGHAaE",
        "colab_type": "text"
      },
      "source": [
        "[^2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7RiaE7kHZuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42b44b90-e841-4106-beae-d8c875191be1"
      },
      "source": [
        "p = softmax(y_hat); p[0].sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BwNmdysHg7A",
        "colab_type": "text"
      },
      "source": [
        "- I need *log* of softmax because we will use cross-entropy which has form of $H(X, q) = H(X) + D(p|q) = - \\sum_{x} p(x)\\  log\\ q(x)$ [^3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8RQd3ZRppI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x.exp() / x.exp().sum(-1, keepdim=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0usabhbXdAvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = log_softmax(y_hat)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLksrlDQS3ue",
        "colab_type": "text"
      },
      "source": [
        "### Cross Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNFW_jxyS7Ek",
        "colab_type": "text"
      },
      "source": [
        "- see the footnote 3 regarding further information of cross entropy\n",
        "- One possible reason is because an information theory is based on descrete and determinate value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tREkCuU65w",
        "colab_type": "text"
      },
      "source": [
        "### Negative log likelihood function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94nPlA0oXJbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(x, y): return -x[range(x.shape[0]), y].mean() #x: prediction, y:target "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcKHlflJX7p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4f87331d-5a78-41f6-e508-210819350fad"
      },
      "source": [
        "nll(y_hat, train_y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0017, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFJuF2ibXuIq",
        "colab_type": "text"
      },
      "source": [
        "- Negative value is related to entropy, roughly variable which is rare is meaningful [^4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-8dPvdkcKLb",
        "colab_type": "text"
      },
      "source": [
        "### LogSumExp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2GCqf3cLjN",
        "colab_type": "text"
      },
      "source": [
        "- Further tasks (after reading sum refs) [^5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0jIz5RcQAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbj1y3lYdKBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "5a920678-7211-4939-df3f-ca592b26f208"
      },
      "source": [
        "test_near(log_softmax(y_hat), a)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-545abe941205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[-2.5928, -2.2816, -2.2425,  ..., -2.2081, -2.4793, -2.2903],\n        [-2.5356, -2.2368, -2.2793,  ..., -2.1715, -2.3938, -2.4001],\n        [-2.5328, -2.2767, -2.3066,  ..., -2.2603, -2.3657, -2.3038],\n        ...,\n        [-2.5156, -2.2445, -2.3092,  ..., -2.3254, -2.4571, -2.3064],\n        [-2.4585, -2.2299, -2.3311,  ..., -2.1488, -2.5716, -2.3324],\n        [-2.5408, -2.2465, -2.4297,  ..., -2.3465, -2.3813, -2.3038]],\n       grad_fn=<SubBackward0>)\ntensor([[0.0748, 0.1021, 0.1062,  ..., 0.1099, 0.0838, 0.1012],\n        [0.0792, 0.1068, 0.1024,  ..., 0.1140, 0.0913, 0.0907],\n        [0.0794, 0.1026, 0.0996,  ..., 0.1043, 0.0939, 0.0999],\n        ...,\n        [0.0808, 0.1060, 0.0993,  ..., 0.0977, 0.0857, 0.0996],\n        [0.0856, 0.1075, 0.0972,  ..., 0.1166, 0.0764, 0.0971],\n        [0.0788, 0.1058, 0.0881,  ..., 0.0957, 0.0924, 0.0999]],\n       grad_fn=<DivBackward0>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTbuDvuWdh9g",
        "colab_type": "text"
      },
      "source": [
        "# 2. Basic Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Divs4jzj8hi",
        "colab_type": "text"
      },
      "source": [
        "### 1.  \n",
        "\n",
        "First, get the prediction (i.e. output) from the model<br/>\n",
        "Second, get a loss value with prediction and target<br/>\n",
        "Third, get a gradients<br/>\n",
        "Fourth, update parameter using gradients, hyperparams<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0onE5wgks_5",
        "colab_type": "text"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCRPhaHxkv48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, trg): return (torch.argmax(out, dim=-1) == trg).float().mean()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHVOp00UlSCp",
        "colab_type": "text"
      },
      "source": [
        "### 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0i4bbMlc6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 64"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeOYOn9xlS9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = train_x[:bs], train_y[:bs]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSziLoA-ljYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27c8a88f-77be-4e2e-9b20-01fbdf9102e9"
      },
      "source": [
        "xb.shape, yb.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sUE6kSdlrIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Model(n_in, nh, n_out); pred = m(xb)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4rPVkaOl_8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3bc8bcc-23d3-43d9-fc49-e6cf0315e198"
      },
      "source": [
        "accuracy(pred, yb)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTuTLFdHllIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c22bc478-24e0-4feb-c2ce-37f7232b5b39"
      },
      "source": [
        "del m, pred, xb, yb\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AxDH79Bmv98",
        "colab_type": "text"
      },
      "source": [
        "### 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DFcFyBmssF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa927aa3-68b6-44d2-9f3f-7b0792eefe4d"
      },
      "source": [
        "n_in, nh, n_out"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 32, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbRnQ8ildlOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "lr = 0.5"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmXH9S8Qi0E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = train_x.shape[0]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHQg9Bxcm9WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "loss_fun = F.cross_entropy"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P4W9fUxi4RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    # init model to keep memory, gradients,...etc\n",
        "    model = Model(n_in, nh, n_out)\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs +1): # [^6]\n",
        "            srt, end = bs*i, bs*(i+1)\n",
        "            xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "            loss = loss_fun(model(xb), yb)\n",
        "            loss.backward()\n",
        "            with torch.no_grad(): # [^8]\n",
        "                for l in model.layers:\n",
        "                    if hasattr(l, 'weight'): # [^7]\n",
        "                        l.weight -= l.weight.grad * lr\n",
        "                        l.bias -= l.bias.grad * lr\n",
        "                        l.weight.grad.zero_() # [^8]\n",
        "                        l.bias.grad.zero_()\n",
        "    return model"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecrJML9dpRTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=fit()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFeBXUjTptoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = train_x[:64], train_y[:64]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC5fpaM0pULU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82216dcf-f17a-4bd0-a495-cb9ad969bc61"
      },
      "source": [
        "loss_fun(m(xb), yb), accuracy(m(xb), yb)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1746, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JejPZBC1p5dD",
        "colab_type": "text"
      },
      "source": [
        "# 3. Using parameters and optimal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8eJC6HKqALX",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3obO2TIqI-u",
        "colab_type": "text"
      },
      "source": [
        "### 1. Re-define model using nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EExMGUQ_s8iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [^10]\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in, nh)\n",
        "        self.l2 = nn.Linear(nh, n_out)\n",
        "    def __call__(self, inp):\n",
        "        return self.l2(F.relu(self.l1(inp)))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDFGQeL5tpRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(n_in, nh, n_out)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueqg78YDtsOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "acb9a413-1ef8-4341-d71e-4cc335565a9c"
      },
      "source": [
        "model(train_x)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1136, -0.1931,  0.1854,  ..., -0.0405, -0.1048, -0.1394],\n",
              "        [-0.0593, -0.1301,  0.2580,  ..., -0.0151, -0.0813, -0.0631],\n",
              "        [-0.0358,  0.0146,  0.0793,  ..., -0.0828, -0.0170, -0.2184],\n",
              "        ...,\n",
              "        [-0.0436,  0.0086,  0.1209,  ..., -0.0345,  0.0280, -0.2004],\n",
              "        [-0.0250,  0.0863,  0.0958,  ..., -0.0683, -0.0426, -0.2373],\n",
              "        [-0.0649,  0.0403,  0.0983,  ..., -0.1354, -0.0169, -0.1508]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFNmmlBPuOdf",
        "colab_type": "text"
      },
      "source": [
        "### 2. nn.module,name_children"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5LmtkluWlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5c144da-27d7-40fa-9320-ef86debd4477"
      },
      "source": [
        "[f\"{name}: {layer}\" for name, layer in model.named_children()]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l1: Linear(in_features=784, out_features=32, bias=True)',\n",
              " 'l2: Linear(in_features=32, out_features=10, bias=True)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoYdpWzFunpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fad8c2dd-75fa-4e8d-e506-15eb41d4ea4f"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=32, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTHV0oeJuqrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b14d8530-c035-40ea-f9df-deca76a2ec72"
      },
      "source": [
        "dir(model.l1)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__constants__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_backward_hooks',\n",
              " '_buffers',\n",
              " '_forward_hooks',\n",
              " '_forward_pre_hooks',\n",
              " '_get_name',\n",
              " '_load_from_state_dict',\n",
              " '_load_state_dict_pre_hooks',\n",
              " '_modules',\n",
              " '_named_members',\n",
              " '_parameters',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_replicate_for_data_parallel',\n",
              " '_save_to_state_dict',\n",
              " '_slow_forward',\n",
              " '_state_dict_hooks',\n",
              " '_version',\n",
              " 'add_module',\n",
              " 'apply',\n",
              " 'bfloat16',\n",
              " 'bias',\n",
              " 'buffers',\n",
              " 'children',\n",
              " 'cpu',\n",
              " 'cuda',\n",
              " 'double',\n",
              " 'dump_patches',\n",
              " 'eval',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'forward',\n",
              " 'half',\n",
              " 'in_features',\n",
              " 'load_state_dict',\n",
              " 'modules',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'out_features',\n",
              " 'parameters',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_parameter',\n",
              " 'requires_grad_',\n",
              " 'reset_parameters',\n",
              " 'share_memory',\n",
              " 'state_dict',\n",
              " 'to',\n",
              " 'train',\n",
              " 'training',\n",
              " 'type',\n",
              " 'weight',\n",
              " 'zero_grad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_T3QPoux48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "327236a2-96e9-4f35-a5fd-26e91f79a34c"
      },
      "source": [
        "help(model.l1.__setattr__)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method __setattr__ in module torch.nn.modules.module:\n",
            "\n",
            "__setattr__(name, value) method of torch.nn.modules.linear.Linear instance\n",
            "    Implement setattr(self, name, value).\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdI8eBYCu7X6",
        "colab_type": "text"
      },
      "source": [
        "### 2. fit function second"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3KZa_-ku9Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    model = Model(n_in, nh, n_out)\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs +1):\n",
        "            srt, end = bs*i, bs*(i+1)\n",
        "            xb, yb = train_x[srt:end], train_y[srt:end]\n",
        "            loss = loss_fun(model(xb), yb)\n",
        "            \n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for param in model.parameters(): param-= param.grad * lr # [^9]\n",
        "                model.zero_grad()\n",
        "    return model"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBqhKVlhwOUH",
        "colab_type": "text"
      },
      "source": [
        "- What changed?/ why shorter?\n",
        "\n",
        "1. this time we make zero grad to model, not each layer\n",
        "2. don't need the code which checked if they have weight(i.e. parameter), since we already selected parameters in model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAQ45y4uw7Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47da27e2-48a4-4454-d128-8ccf330e5a18"
      },
      "source": [
        "m = fit()\n",
        "loss_fun(m(xb), yb), accuracy(m(xb), yb)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1144, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-73KmoCxIld",
        "colab_type": "text"
      },
      "source": [
        "### DummyModule class to simulate pytorch's `__setattr__`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyiDaS6xQmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xTK-uWEqIBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Registering modules\n",
        "## nn.ModuleList\n",
        "## nn.Sequential\n",
        "## Optim"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9w0mADRmwP",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKh7TcqJRQ0-",
        "colab_type": "text"
      },
      "source": [
        "[^1]: I don't have to define parameters no more, but obviously at first I tried to iniailized Model with `w1, b1, ....`, meaning I didn't practice enough the previous part, part of the torch nn, where I get parameters\n",
        "\n",
        "[^2]: be cautious since `train_x.sum(-1)` will squeeze the rank, so that you need arg `keepdim:bool`, false as default\n",
        "\n",
        "[^3]: see *eq (2.46)*, Foundations of Natural Language Processing, Christopher D. Manning and Hinrich Schütze\n",
        "\n",
        "[^4]: Should check for `cross-entropy $\\approx$ softmax of negative likelihood`\n",
        "\n",
        "[^5]: check later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr9R50W2cXUc",
        "colab_type": "text"
      },
      "source": [
        "[^6]: Be careful to take 1 off from size of dataset, in case batch size is divisible number</br>\n",
        "[^7]: study of hasattr() more<br/>\n",
        "[^8]: 1) careful, that is in-place function / 2) should learn more of why I need this\n",
        "\n",
        "[^9]: `parameters` is method, layers is attr. this time we make zero grad to model, not each layer\n",
        "\n",
        "[^10]: things that happen when you don't specify inheritence"
      ]
    }
  ]
}