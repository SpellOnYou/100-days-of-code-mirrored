{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minibatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "70gryhdPEefI"
      },
      "source": [
        "import gzip, pickle\n",
        "from torch import tensor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMPtL0ZLEnU3"
      },
      "source": [
        "from torch.functional import F"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D4B1QDOCeSO"
      },
      "source": [
        "from torch import nn\n",
        "import torch"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZosG17cuMcc"
      },
      "source": [
        "def get_data():\n",
        "    # path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    path = '/content/mnist.pkl.gz'\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P1OtuBREQHd"
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()\n",
        "nh, bs = 50, 512\n",
        "c = y_train.max().item()+1\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz-UCON9EbjW"
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "        \n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters(): yield p\n",
        "\n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.parameters():\n",
        "            p.grad.data.zero_()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myVBrhLfEqIK"
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "            model.zero_grad()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUPf5V-OE0T3"
      },
      "source": [
        "epochs, n, lr = 1, x_train.shape[0], 0.5\n",
        "model = DummyModule(x_train.shape[1], nh, 10)\n",
        "fit()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL0CgtxgEQL4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OURGZrmbFcoY"
      },
      "source": [
        "#  A8\n",
        "class Optimizer():\n",
        "    def __init__(self, params, lr): self.params, self.lr = list(params), lr\n",
        "    def zero_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad.data.zero_()\n",
        "\n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params:\n",
        "                p -= p.grad * self.lr\n",
        "\n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SznWFtPtE6N1",
        "outputId": "43d4b61d-be44-4d77-f73a-cc96f01046c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(x_train.shape[1], nh), nn.ReLU(), nn.Linear(nh, c))\n",
        "# accuracy-before train\n",
        "print((model(x_train[:bs]).max(-1).indices == y_train[:bs]).sum()/ bs)\n",
        "opt = Optimizer(model.parameters(), 0.9)\n",
        "fit()\n",
        "print((model(x_train[:bs]).max(-1).indices == y_train[:bs]).sum()/ bs)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1250)\n",
            "tensor(0.9062)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5bKbn-JGQnd"
      },
      "source": [
        "from torch import optim\n",
        "def get_model(model_func, lr=0.9):\n",
        "    model = nn.Sequential(*model_func())\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHz791e0Gwtq"
      },
      "source": [
        "def get_layers():\n",
        "    return nn.Linear(x_train.shape[1], nh), nn.ReLU(), nn.Linear(nh, c)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGHeD6_NH-Tf",
        "outputId": "48649c8d-e34f-4fa6-f09e-64393b5ea04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "model, opt = get_model(get_layers, lr = 0.001)\n",
        "print((model(x_train[:bs]).max(-1).indices == y_train[:bs]).sum()/ bs)\n",
        "fit()\n",
        "print((model(x_train[:bs]).max(-1).indices == y_train[:bs]).sum()/ bs)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0586)\n",
            "tensor(0.8574)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5GMtO3_IORf"
      },
      "source": [
        "----"
      ]
    }
  ]
}