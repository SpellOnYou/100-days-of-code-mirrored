{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batchnorm2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLtRzBDaSPlO"
      },
      "source": [
        "Q1) What are the parameters of batchnorm? What information do you need to train the parameters?  \n",
        "\n",
        "A1) $ \\frac{X - \\mu}{\\sigma} * \\gamma + \\beta $, in which $\\gamma$ and $\\beta$ are optimized using training data (i.e. parameter) and $\\mu$ and $\\sigma$ attained from data.\n",
        "\n",
        "Q2) Why do we use 'exponentially weighted moving average' (chain of linear interpolation) of training data optimizing two parameters? In other words, why can't we use one batch of training set's mean and variance in inference time?  \n",
        "A2) When we get a totally different type of image at inference time, we can not fairly access/evaluate the parameters since attained mean/variance of training data are irrevant to inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmwTnPT0WWMQ",
        "outputId": "17563a17-e1db-40ee-be21-848795fd0dfc"
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 5893, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5893 (delta 0), reused 2 (delta 0), pack-reused 5890\u001b[K\n",
            "Receiving objects: 100% (5893/5893), 263.10 MiB | 33.69 MiB/s, done.\n",
            "Resolving deltas: 100% (3251/3251), done.\n",
            "Checking out files: 100% (887/887), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ei0MPj5WbTs",
        "outputId": "c73608c8-020e-45a6-b5a3-0ee7b27c205c"
      },
      "source": [
        "%cd /content/course-v3/nbs/dl2/\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "from exp.nb_06 import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/course-v3/nbs/dl2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz2BLhg9W9Uj"
      },
      "source": [
        "def get_data():\n",
        "    # path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    path = '/content/mnist.pkl.gz'\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmhp-b2KXss9"
      },
      "source": [
        "- get data and transform those to regularized size\n",
        "- dataset class, which enables slicing and length information\n",
        "- databunch instance, which gives 1) dataloader 2) number of class\n",
        "    1. dataloader\n",
        "        - generate training data in a random order (when shuffle=True)\n",
        "        - in case tensors don't have same length, pad first or last (e.g. pytorch [pad_packed_sequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html))\n",
        "- callback functions\n",
        "    - recorder which records learning rate and loss\n",
        "    - avgstats which records total loss and batch count\n",
        "    - cuda : convert to gpu before batch\n",
        "    - unflatten image\n",
        "\n",
        "- define convolution channels \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTy_uFkOZ36r"
      },
      "source": [
        "# ??AvgStats"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmMrB45IXqXA",
        "outputId": "bf6c6387-ac1a-44e7-a7ae-e354ad77d286"
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()\n",
        "x_train, x_valid = normalize_to(x_train, x_valid)\n",
        "\n",
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "nh, bs = 50, 512\n",
        "c = y_train.max().item()+1\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)\n",
        "mnist_view = view_tfm(1, 28, 28)\n",
        "cbfs = [Recorder,\n",
        "        partial(AvgStatsCallback, accuracy),\n",
        "        # CudaCallback,\n",
        "        partial(BatchTransformXCallback, mnist_view)]\n",
        "nfs = [8, 16, 32, 64, 64]\n",
        "learn, run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)\n",
        "\n",
        "%time run.fit(2, learn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [0.97408328125, tensor(0.6995)]\n",
            "valid: [0.167479296875, tensor(0.9488)]\n",
            "train: [0.17027271484375, tensor(0.9479)]\n",
            "valid: [0.11941851806640626, tensor(0.9643)]\n",
            "CPU times: user 23.6 s, sys: 674 ms, total: 24.3 s\n",
            "Wall time: 12.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j69hJcogVhmS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}