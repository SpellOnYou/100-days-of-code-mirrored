{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv-cuda-hooks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2zEkVsLPovR",
        "outputId": "9c252ba7-c8f6-48c1-de88-c8abffd30d8c"
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3/\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "%cd /content/course-v3/nbs/dl2/\n",
        "from exp.nb_05b import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'course-v3' already exists and is not an empty directory.\n",
            "/content/course-v3/nbs/dl2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DOxqS_QPs55"
      },
      "source": [
        "def get_data():\n",
        "    # path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    path = '/content/mnist.pkl.gz'\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k1Dg0SsrS5c7",
        "outputId": "7084d28c-a180-4cd5-c294-7908cf556962"
      },
      "source": [
        "import inspect; inspect.getsource(normalize)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def normalize(x, m, s): return (x-m)/s\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGR4_j94PvMW"
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()\n",
        "def normalize_to(x_train, x_valid):\n",
        "    m, s = x_train.mean(), x_train.std()\n",
        "    return (x_train-m)/s, (x_valid-m)/s\n",
        "x_train, x_valid = normalize_to(x_train, x_valid)\n",
        "\n",
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "nh, bs = 50, 512\n",
        "c = y_train.max().item()+1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_QGsWUaQBGo"
      },
      "source": [
        "# cnn\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "    def forward(self, x): return self.func(x)\n",
        "\n",
        "def mnist_view(x): return x.view(-1, 1, 28, 28)\n",
        "\n",
        "def flatten(x): return x.view(x.shape[0], -1)\n",
        "\n",
        "def get_cnn_model(data):\n",
        "    return nn.Sequential(\n",
        "        Lambda(mnist_view),\n",
        "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=2), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        Lambda(flatten),\n",
        "        nn.Linear(32, data.c)\n",
        "    )\n",
        "\n",
        "# cuda\n",
        "class CudaCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.model = self.model.cuda()\n",
        "    def begin_batch(self):\n",
        "        self.run.xb, self.run.yb = self.xb.cuda(), self.yb.cuda()    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KhphVJ_QO0_"
      },
      "source": [
        "device = torch.device('cuda', 0)\n",
        "torch.cuda.set_device(device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9bezfyoT4kE",
        "outputId": "6f549a63-e472-43fd-e3e1-cc7bf9c04e8a"
      },
      "source": [
        "loss_func = F.cross_entropy\n",
        "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)\n",
        "\n",
        "cbfs = [Recorder,\n",
        "        partial(AvgStatsCallback, accuracy),\n",
        "        CudaCallback]\n",
        "\n",
        "nfs = [8, 16, 32, 64, 64]\n",
        "model = get_cnn_model(data)\n",
        "opt = optim.SGD(model.parameters(), lr=0.4)\n",
        "learn = Learner(model, opt, loss_func, data)\n",
        "run = Runner(cb_funcs=cbfs)\n",
        "run.fit(3, learn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [1.63212625, tensor(0.4538, device='cuda:0')]\n",
            "valid: [0.60477392578125, tensor(0.8269, device='cuda:0')]\n",
            "train: [0.3539968359375, tensor(0.8923, device='cuda:0')]\n",
            "valid: [0.1935548583984375, tensor(0.9436, device='cuda:0')]\n",
            "train: [0.1789208984375, tensor(0.9454, device='cuda:0')]\n",
            "valid: [0.15004815673828126, tensor(0.9531, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgqEN9a2Ra_Q"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8lOV8cOWU1R"
      },
      "source": [
        "- A5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJFqhc2hYvse",
        "outputId": "f24262e9-ccc1-4694-83ad-dc9e5c79bb10"
      },
      "source": [
        "xb = next(iter(data.train_dl))[0].view(-1, 1, 28, 28)\n",
        "model = nn.Sequential(\n",
        "        Lambda(mnist_view),\n",
        "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=2), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        Lambda(flatten),\n",
        "        nn.Linear(32, data.c)\n",
        "    )\n",
        "model(xb).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFaHN7nSZRrd",
        "outputId": "2f6d26ec-f3b7-490d-a479-9f999e712acb"
      },
      "source": [
        "flatten(model(xb)).shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjPWk-k2RbhF",
        "outputId": "24aa2633-038a-4c8c-ed7c-cbb79ecb78c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def conv2d(ni, nf, ks=3, stride=2):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(ni, nf, ks, stride=stride, padding=ks//2), nn.ReLU())\n",
        "class BatchXTransform(Callback):\n",
        "    _order = 2\n",
        "    def __init__(self, tfm): self.tfms = tfm\n",
        "    def begin_batch(self): self.run.xb = self.tfms(self.xb)\n",
        "\n",
        "def view_tfms(*size):\n",
        "    def _inner(x): return x.view(*((-1,)+size)) #for example, in case of mnist, get 1,28, 28 and render -1, 1, 28, 28\n",
        "    return _inner\n",
        "\n",
        "mnist_tfms = view_tfms(1, 28, 28)\n",
        "\n",
        "def get_cnn_layers(nfs, data):\n",
        "    nfs = [1] + nfs\n",
        "    return [conv2d(nfs[i], nfs[i+1], 5 if i==0 else 3) for i in range(len(nfs)-1)] + [\n",
        "              nn.AdaptiveAvgPool2d(1), Lambda(flatten), nn.Linear(nfs[-1], data.c)]\n",
        "\n",
        "# we need to unpack the list since list is not a module subclass\n",
        "def get_cnn_model(nfs, data):\n",
        "    return nn.Sequential(*get_cnn_layers(nfs, data))\n",
        "\n",
        "        # ipdb.set_trace()\n",
        "\n",
        "def get_runner(model, data, lr=0.6, cbs=None, opt_func=optim.SGD, loss_func=F.cross_entropy):\n",
        "    opt = opt_func(model.parameters(), lr=lr)\n",
        "    learn = Learner(model, opt, loss_func, data)\n",
        "    return learn, Runner(cb_funcs=listify(cbs))\n",
        "    \n",
        "model = get_cnn_model(nfs, data)\n",
        "learn, run = get_runner(model, data, lr=0.4, cbs=cbfs)\n",
        "run.fit(3, learn)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [2.16117265625, tensor(0.2348, device='cuda:0')]\n",
            "valid: [0.92366650390625, tensor(0.7116, device='cuda:0')]\n",
            "train: [0.657170234375, tensor(0.7930, device='cuda:0')]\n",
            "valid: [0.25269130859375, tensor(0.9300, device='cuda:0')]\n",
            "train: [0.23869947265625, tensor(0.9294, device='cuda:0')]\n",
            "valid: [0.18047735595703124, tensor(0.9446, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9LDbbbMgBDd"
      },
      "source": [
        "test AdaptiveAvgPool2d and Maxpool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmdoZg-sa1jX"
      },
      "source": [
        "def get_cnn_model(data):\n",
        "    return nn.Sequential(\n",
        "        Lambda(mnist_view),\n",
        "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=2), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "        nn.MaxPool2d(1),\n",
        "        # Lambda(flatten),\n",
        "        # nn.Linear(32, data.c)\n",
        "    )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PONhpUetgI0V",
        "outputId": "63f38f53-b3fe-44c6-e954-27740672aa65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# nn.AdaptiveAvgPool2d(1)\n",
        "xb, yb = next(iter(data.train_dl))\n",
        "get_cnn_model(data)(xb).shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 32, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7-GJc0_gXGO",
        "outputId": "b15a4002-661d-4b66-daf0-920918a68e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# nn.Maxpool2d(1)\n",
        "xb, yb = next(iter(data.train_dl))\n",
        "get_cnn_model(data)(xb).shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 32, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5fzTWtHhDMu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP_S2KGmkFGW"
      },
      "source": [
        "- A9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48SRWiulnE-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}