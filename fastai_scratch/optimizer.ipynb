{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvL-c-XtYgGA"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npcpPp0DblBz",
        "outputId": "f052865f-4e49-4da5-efea-dba38bee1209"
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3\n",
        "%cd /content/course-v3/nbs/dl2\n",
        "from exp.nb_08 import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 5893, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5893 (delta 0), reused 2 (delta 0), pack-reused 5890\u001b[K\n",
            "Receiving objects: 100% (5893/5893), 263.10 MiB | 29.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3251/3251), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpO7exIEc2Nl",
        "outputId": "86d2c524-8525-476e-8316-d083f9b4da82"
      },
      "source": [
        "torch.optim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.optim' from '/usr/local/lib/python3.7/dist-packages/torch/optim/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjgSM05QdS4P"
      },
      "source": [
        "## Load dataset and vanila model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9RCv7pN3efdG",
        "outputId": "3ae680be-50f5-4976-f8a6-7547ba593099"
      },
      "source": [
        "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhgxDzkyejtC"
      },
      "source": [
        "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
        "bs = 128\n",
        "il = ImageList.from_files(path, tfms=tfms)\n",
        "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
        "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66zCmXQJfhmV"
      },
      "source": [
        "nfs = [32, 64, 128, 256]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfg5SQ-Ofjxo"
      },
      "source": [
        "cbfs = [partial(AvgStatsCallback, accuracy), CudaCallback,\n",
        "        partial(BatchTransformXCallback, norm_imagenette)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADmaIKupfufO"
      },
      "source": [
        "learn, run= get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OvMHrQOgHVf",
        "outputId": "e4fe79ac-e66a-4980-d106-10d29c0a91ad"
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [1.794424569648326, tensor(0.3760, device='cuda:0')]\n",
            "valid: [1.7157151920780256, tensor(0.4456, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3UWY4b_heqY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW-mvxgmhfWI"
      },
      "source": [
        "## Refining the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT7vNzF_hkb3",
        "outputId": "1200c404-b7e1-4707-89cb-64bcbd5532ae"
      },
      "source": [
        "import inspect\n",
        "print(inspect.getsource(compose))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
            "    key = lambda o: getattr(o, order_key, 0)\n",
            "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
            "    return x\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii9HFTuvgLro"
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, stepper, **defaults):\n",
        "        self.param_groups = list(params)\n",
        "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
        "        self.hypers = [{**defaults} for p in self.param_groups]\n",
        "        self.stepper = stepper\n",
        "    def grad_params(self):\n",
        "        gps = []\n",
        "        for pg, hyper in zip(self.param_groups, self.hypers):\n",
        "            for p in pg:\n",
        "                if p.grad is not None:\n",
        "                    gps = gps + [(p, hyper)]\n",
        "        return gps\n",
        "    def zero_grad(self):\n",
        "        for p, hyper in self.grad_params():\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "    def step(self):\n",
        "        for p, hyper in grad_params:\n",
        "            compose(p, self.stepper, **hyper)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aeYqE2UjUPt"
      },
      "source": [
        "opt = Optimizer(learn.model.parameters(), lambda x : x)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U90Lgpr1joh-",
        "outputId": "08e97bde-248d-4061-99ca-4f40ea892cf9"
      },
      "source": [
        "opt.param_groups.__len__()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}