{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl4slp-audio-v5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  Let me try Transformer architecture!!\n",
        "\n",
        "- 20 Oct 2020"
      ],
      "metadata": {
        "id": "bYMZuk-QNKGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/course-v3/ /content/course-v3\n",
        "%cd /content/course-v3/nbs/dl2"
      ],
      "metadata": {
        "id": "-p-B9N_qsun4",
        "outputId": "78b8aaf5-1b1d-4be2-83c3-2106e84ec10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/course-v3'...\n",
            "remote: Enumerating objects: 5893, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5893 (delta 0), reused 2 (delta 0), pack-reused 5890\u001b[K\n",
            "Receiving objects: 100% (5893/5893), 263.10 MiB | 38.77 MiB/s, done.\n",
            "Resolving deltas: 100% (3251/3251), done.\n",
            "/content/course-v3/nbs/dl2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NOTE: if you do not have installed [nvidia/apex](https://github.com/nvidia/apex),  change `from exp.nb_10c import *` to `from exp.nb_10b import *` in `exp.nb_11`"
      ],
      "metadata": {
        "id": "nb6S4CPyqS_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from exp.nb_12a import *"
      ],
      "metadata": {
        "id": "77V-bw0pqR2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Local data (which is divided into separate dataset) is saved to `Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/data/v1/ser'`\n"
      ],
      "metadata": {
        "id": "_U7CK3KXqnr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL3HjY7zp5jZ",
        "outputId": "3976758a-0766-4b3c-aba1-3185165635d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1'); root_path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V93zJPFhqnpC",
        "outputId": "5b7211e1-d39b-437d-d319-5e064ab88443"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/dev')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1FVouZFT7-5"
      },
      "source": [
        "features-entry contains a list of a list with 26 items.\n",
        "- length of inner list: 26 (float numbers - represent one preprocessed speech frame (logMel))\n",
        "\n",
        "- length of outer list: number of frames per data-point, e.g. 10 or 15, ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = root_path/'train'"
      ],
      "metadata": {
        "id": "XxRfMtm7UTb_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audios = get_files(train_path)"
      ],
      "metadata": {
        "id": "vR7U0z1HmgoR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restart-run\n",
        "class AudioList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions = None, recurse=True, include=None, **kwargs):\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "    \n",
        "    def get(self, fn):\n",
        "        return torch.load(fn)"
      ],
      "metadata": {
        "id": "fPJ2emMUmglw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al=AudioList.from_files(train_path); al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSfrsOPbmgil",
        "outputId": "50b5b929-fa49-4960-8e0d-520e04a5085e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AudioList (7800 items)\n",
              "[PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7760_1_1.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7761_0_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7762_0_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7763_1_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7764_1_1.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7765_1_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7766_1_1.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7767_1_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7768_1_0.pt'), PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train/7769_1_1.pt')...]\n",
              "Path: /gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use adaptive pooling to fit the frames"
      ],
      "metadata": {
        "id": "4lnGePmPwoUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## input transform\n",
        "\n",
        "1. load tensor\n",
        "2. tocuda\n",
        "3. transpose, add dimension to first axis\n",
        "4. AdaptiveAvgPooling to fit width(time frames) 250\n"
      ],
      "metadata": {
        "id": "-VsPUxouyOcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToCuda():\n",
        "    _order=10\n",
        "    def __call__(self, ad):\n",
        "        return ad.cuda()"
      ],
      "metadata": {
        "id": "w-bI6BPNzmde"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape():\n",
        "    _order=11\n",
        "    def __call__(self, item):\n",
        "        w, h = item.shape\n",
        "        return item.view(h, w)"
      ],
      "metadata": {
        "id": "4PjKjkXtzoQQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyFeature():\n",
        "    # add features from function\n",
        "    _order= 13\n",
        "    def __init__(self, f, **kwargs):\n",
        "        self.p = partial(f, **kwargs)\n",
        "    def __call__(self, item):\n",
        "        return torch.vstack((item, self.p(item).unsqueeze(0)))"
      ],
      "metadata": {
        "id": "QRDT39VjbW16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mutants of input tensor\n",
        "class PadorTrim():\n",
        "    _order = 20\n",
        "    def __init__(self, max_len):\n",
        "        self.max_len = max_len\n",
        "    def __call__(self, ad):\n",
        "        # h - logmel, here 27, w - frames / various\n",
        "        h, w = ad.shape\n",
        "        pad_size = self.max_len - w\n",
        "        if pad_size >0: return torch.cat((ad, torch.zeros(h, pad_size).cuda()), dim=1)\n",
        "        else: return ad[:, :self.max_len]\n",
        "\n",
        "class TimeFramePooling():\n",
        "    _order= 12\n",
        "    def __init__(self, f, n_tf):\n",
        "        # n_tf: numner of time frames\n",
        "        self.p = f(n_tf)\n",
        "    def __call__(self, item):\n",
        "        return self.p(item)\n",
        "\n",
        "# TimeFramePooling(f= nn.AdaptiveMaxPool1d, n_tf = 150)\n",
        "\n",
        "class DummyChannel():\n",
        "    _order = 30\n",
        "    def __call__(self, item):\n",
        "        return item.unsqueeze(0)"
      ],
      "metadata": {
        "id": "OtJ4_itDz_s8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfms = [ToCuda(), Reshape(), PadorTrim(225), DummyChannel()]\n",
        "compose(al[0], tfms).shape"
      ],
      "metadata": {
        "id": "1EalvurFcVfU",
        "outputId": "f2870ecd-69e5-4e65-e292-d04d0de80a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 26, 225])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "il = AudioList.from_files(train_path, tfms = tfms)"
      ],
      "metadata": {
        "id": "cVNZY7nn0uOM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This scaling process is annoying, because I should have this process 'before' training, while separating train and eval status"
      ],
      "metadata": {
        "id": "CCXGUEseXShG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "il[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCw0tHmT1wPq",
        "outputId": "c6d1d0a7-323c-40f9-b71a-8c2f1f8ca7ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 26, 225])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def re_labeler(fn, pat, subcl='act'):\n",
        "    assert subcl in ['act', 'val', 'all']\n",
        "    if subcl=='all': return ''.join(re.findall(pat, str(fn)))\n",
        "    else:\n",
        "        return re.findall(pat, str(fn))[0] if pat == 'act' else re.findall(pat, str(fn))[1]\n",
        "\n",
        "label_pat = r'_(\\d+)'\n",
        "emotion_labeler = partial(re_labeler, pat=label_pat, subcl='all')"
      ],
      "metadata": {
        "id": "kL9IVX4uzeOT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.2))\n",
        "ll = label_by_func(sd, emotion_labeler, proc_y=CategoryProcessor())"
      ],
      "metadata": {
        "id": "IqzVzlce1vOO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=64\n",
        "c_in = ll.train[0][0].shape[0]\n",
        "c_out = len(uniqueify(ll.train.y))\n",
        "data = ll.to_databunch(bs,c_in=c_in,c_out=c_out)"
      ],
      "metadata": {
        "id": "XPMz25enABaj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_in, c_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjkO31kEAHeJ",
        "outputId": "60860bea-9856-4684-849a-d901790fa9f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "def show_resource(x): print(inspect.getsource(x))\n",
        "show_resource(XResNet)"
      ],
      "metadata": {
        "id": "UDOuL0avxQem",
        "outputId": "1f26cbbd-abb0-48c5-b60b-8f302c3165fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class XResNet(nn.Sequential):\n",
            "    @classmethod\n",
            "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
            "        nfs = [c_in, (c_in+1)*8, 64, 64]\n",
            "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
            "            for i in range(3)]\n",
            "\n",
            "        nfs = [64//expansion,64,128,256,512]\n",
            "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
            "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
            "                  for i,l in enumerate(layers)]\n",
            "        res = cls(\n",
            "            *stem,\n",
            "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
            "            *res_layers,\n",
            "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
            "            nn.Linear(nfs[-1]*expansion, c_out),\n",
            "        )\n",
            "        init_cnn(res)\n",
            "        return res\n",
            "\n",
            "    @staticmethod\n",
            "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
            "        return nn.Sequential(\n",
            "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
            "              for i in range(n_blocks)])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder():\n",
        "    return nn.TransformerEncoderLayer(\n",
        "            d_model=26,\n",
        "            nhead=2,\n",
        "            dim_feedforward=256,\n",
        "            dropout=0.4,\n",
        "            activation='gelu')"
      ],
      "metadata": {
        "id": "zI_4qzMO1h5k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape(x): return x.permute(2,0,1)"
      ],
      "metadata": {
        "id": "rgGgyteP2DNK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self): super().__init__()\n",
        "    def forward(self,x):\n",
        "        return x.squeeze(1).permute(2, 0 ,1)"
      ],
      "metadata": {
        "id": "mrvux3Yd2Kjg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f= nn.Linear(26, 4)\n",
        "    def forward(self,x):\n",
        "        return self.f(x.mean(dim=0))"
      ],
      "metadata": {
        "id": "CXAbjuut3IlZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    return nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=[1,4], stride=[1,4]),\n",
        "        Reshape(),\n",
        "        nn.TransformerEncoder(get_encoder(), 3),\n",
        "        FC()\n",
        "    )"
      ],
      "metadata": {
        "id": "xpUH9sUzxeYB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(data.train_dl))\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "id": "Al75QktK2qfB",
        "outputId": "49155016-1e55-45d6-de9f-e62e98f798ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 26, 225]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model().cuda()"
      ],
      "metadata": {
        "id": "iAY0GCQn18wl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "BH7xQis8194W",
        "outputId": "614b1aa0-e70b-42bd-c436-acdd5f6f779b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): MaxPool2d(kernel_size=[1, 4], stride=[1, 4], padding=0, dilation=1, ceil_mode=False)\n",
              "  (1): Reshape()\n",
              "  (2): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=26, out_features=26, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=26, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "        (linear2): Linear(in_features=256, out_features=26, bias=True)\n",
              "        (norm1): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.4, inplace=False)\n",
              "        (dropout2): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=26, out_features=26, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=26, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "        (linear2): Linear(in_features=256, out_features=26, bias=True)\n",
              "        (norm1): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.4, inplace=False)\n",
              "        (dropout2): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=26, out_features=26, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=26, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "        (linear2): Linear(in_features=256, out_features=26, bias=True)\n",
              "        (norm1): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((26,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.4, inplace=False)\n",
              "        (dropout2): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (3): FC(\n",
              "    (f): Linear(in_features=26, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(xb).shape"
      ],
      "metadata": {
        "id": "R9DlocZJ2t1Y",
        "outputId": "1fe61e00-6d6f-4e47-ddbd-5f77c295865d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-2)\n",
        "loss_func = LabelSmoothingCrossEntropy()\n",
        "lr = 1e-2\n",
        "pct_start = 0.5\n",
        "phases = create_phases(pct_start)\n",
        "sched_lr  = combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
        "sched_mom = combine_scheds(phases, cos_1cycle_anneal(0.95,0.85, 0.95))\n",
        "cbscheds = [ParamScheduler('lr', sched_lr), \n",
        "            ParamScheduler('mom', sched_mom)]"
      ],
      "metadata": {
        "id": "sDKXz6KZ9MNR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq torchmetrics\n",
        "from torchmetrics import F1\n",
        "f1 = F1(num_classes=4)"
      ],
      "metadata": {
        "id": "ao_l1zIz_sMt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1.__name__ = 'fscore'"
      ],
      "metadata": {
        "id": "pa-Qh9JJ4rHD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class Learner():\n",
        "    def __init__(self, model, data, loss_func, opt_func=sgd_opt, lr=1e-2, splitter=param_getter,\n",
        "                 cbs=None, cb_funcs=None):\n",
        "        self.model,self.data,self.loss_func,self.opt_func,self.lr,self.splitter = model,data,loss_func,opt_func,lr,splitter\n",
        "        self.in_train,self.logger,self.opt = False,print,None\n",
        "\n",
        "        # NB: Things marked \"NEW\" are covered in lesson 12\n",
        "        # NEW: avoid need for set_runner\n",
        "        self.cbs = []\n",
        "        self.add_cb(TrainEvalCallback())\n",
        "        self.add_cbs(cbs)\n",
        "        self.add_cbs(cbf() for cbf in listify(cb_funcs))\n",
        "\n",
        "    def add_cbs(self, cbs):\n",
        "        for cb in listify(cbs): self.add_cb(cb)\n",
        "\n",
        "    def add_cb(self, cb):\n",
        "        cb.set_runner(self)\n",
        "        setattr(self, cb.name, cb)\n",
        "        self.cbs.append(cb)\n",
        "\n",
        "    def remove_cbs(self, cbs):\n",
        "        for cb in listify(cbs): self.cbs.remove(cb)\n",
        "\n",
        "    def one_batch(self, i, xb, yb):\n",
        "        try:\n",
        "            self.iter = i\n",
        "            self.xb,self.yb = xb,yb;                        self('begin_batch')\n",
        "            self.pred = self.model(self.xb);                self('after_pred')\n",
        "            self.loss = self.loss_func(self.pred, self.yb); self('after_loss')\n",
        "            if not self.in_train: return\n",
        "            self.loss.backward();                           self('after_backward')\n",
        "            self.opt.step();                                self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException:                        self('after_cancel_batch')\n",
        "        finally:                                            self('after_batch')\n",
        "\n",
        "    def all_batches(self):\n",
        "        self.iters = len(self.dl)\n",
        "        try:\n",
        "            for i,(xb,yb) in enumerate(self.dl): self.one_batch(i, xb, yb)\n",
        "        except CancelEpochException: self('after_cancel_epoch')\n",
        "\n",
        "    def do_begin_fit(self, epochs):\n",
        "        self.epochs,self.loss = epochs,tensor(0.)\n",
        "        self('begin_fit')\n",
        "\n",
        "    def do_begin_epoch(self, epoch):\n",
        "        self.epoch,self.dl = epoch,self.data.train_dl\n",
        "        return self('begin_epoch')\n",
        "\n",
        "    def fit(self, epochs, cbs=None, reset_opt=False):\n",
        "        # NEW: pass callbacks to fit() and have them removed when done\n",
        "        self.add_cbs(cbs)\n",
        "        # NEW: create optimizer on fit(), optionally replacing existing\n",
        "        if reset_opt or not self.opt: self.opt = self.opt_func(self.splitter(self.model), lr=self.lr)\n",
        "\n",
        "        try:\n",
        "            self.do_begin_fit(epochs)\n",
        "            for epoch in range(epochs):\n",
        "                self.do_begin_epoch(epoch)\n",
        "                if not self('begin_epoch'): self.all_batches()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    self.dl = self.data.valid_dl\n",
        "                    if not self('begin_validate'): self.all_batches()\n",
        "                self('after_epoch')\n",
        "\n",
        "        except CancelTrainException: self('after_cancel_train')\n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.remove_cbs(cbs)\n",
        "\n",
        "    ALL_CBS = {'begin_batch', 'after_pred', 'after_loss', 'after_backward', 'after_step',\n",
        "        'after_cancel_batch', 'after_batch', 'after_cancel_epoch', 'begin_fit',\n",
        "        'begin_epoch', 'begin_epoch', 'begin_validate', 'after_epoch',\n",
        "        'after_cancel_train', 'after_fit'}\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        res = False\n",
        "        assert cb_name in self.ALL_CBS\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) and res\n",
        "        return res\n"
      ],
      "metadata": {
        "id": "989AMfY7oa7G",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learner(arch, data, loss_func, opt_func, c_in=None, c_out=None,\n",
        "                lr=1e-2, cuda=True, norm=None, progress=True, mixup=0, xtra_cb=None, **kwargs):\n",
        "    cbfs = [partial(AvgStatsCallback,accuracy)]+listify(xtra_cb)\n",
        "    if progress: cbfs.append(ProgressCallback)\n",
        "    if cuda:     cbfs.append(CudaCallback)\n",
        "    if norm:     cbfs.append(partial(BatchTransformXCallback, norm))\n",
        "    if mixup:    cbfs.append(partial(MixUp, mixup))\n",
        "    arch_args = {}\n",
        "    if not c_in : c_in  = data.c_in\n",
        "    if not c_out: c_out = data.c_out\n",
        "    if c_in:  arch_args['c_in' ]=c_in\n",
        "    if c_out: arch_args['c_out']=c_out\n",
        "    return Learner(arch, data, loss_func, opt_func=opt_func, lr=lr, cb_funcs=cbfs, **kwargs)\n"
      ],
      "metadata": {
        "id": "GGpNDq0l976E"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = learner(model, data, loss_func, opt_func=opt_func)"
      ],
      "metadata": {
        "id": "zwLQiDDK_XhW"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_resource(accuracy)"
      ],
      "metadata": {
        "id": "LfA7GxXa47V3",
        "outputId": "f770b116-e7b6-4993-ac14-ebe76254305c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(300, cbs=cbscheds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZF4d9AZAmAv",
        "outputId": "39d23402-d074-4038-ba6b-7c8549669468"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      \n",
              "    </div>\n",
              "    \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.292441</td>\n",
              "      <td>0.401639</td>\n",
              "      <td>1.304084</td>\n",
              "      <td>0.402408</td>\n",
              "      <td>37:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.265722</td>\n",
              "      <td>0.427997</td>\n",
              "      <td>1.295530</td>\n",
              "      <td>0.403676</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.243031</td>\n",
              "      <td>0.447605</td>\n",
              "      <td>1.479739</td>\n",
              "      <td>0.304816</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.227606</td>\n",
              "      <td>0.452588</td>\n",
              "      <td>1.530696</td>\n",
              "      <td>0.301014</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.216821</td>\n",
              "      <td>0.458534</td>\n",
              "      <td>1.639924</td>\n",
              "      <td>0.224335</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.207194</td>\n",
              "      <td>0.464481</td>\n",
              "      <td>1.520950</td>\n",
              "      <td>0.288973</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.207225</td>\n",
              "      <td>0.466410</td>\n",
              "      <td>1.394439</td>\n",
              "      <td>0.339037</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.198821</td>\n",
              "      <td>0.478464</td>\n",
              "      <td>1.709912</td>\n",
              "      <td>0.254119</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.198704</td>\n",
              "      <td>0.476696</td>\n",
              "      <td>1.722170</td>\n",
              "      <td>0.201521</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.195064</td>\n",
              "      <td>0.477821</td>\n",
              "      <td>1.540053</td>\n",
              "      <td>0.266793</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.192879</td>\n",
              "      <td>0.473642</td>\n",
              "      <td>1.581011</td>\n",
              "      <td>0.295944</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.189421</td>\n",
              "      <td>0.476535</td>\n",
              "      <td>1.775482</td>\n",
              "      <td>0.238276</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.186260</td>\n",
              "      <td>0.484410</td>\n",
              "      <td>1.570972</td>\n",
              "      <td>0.292142</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.190730</td>\n",
              "      <td>0.478464</td>\n",
              "      <td>1.565907</td>\n",
              "      <td>0.299113</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.180537</td>\n",
              "      <td>0.488750</td>\n",
              "      <td>1.506680</td>\n",
              "      <td>0.304182</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.181310</td>\n",
              "      <td>0.483607</td>\n",
              "      <td>1.686179</td>\n",
              "      <td>0.254119</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.182192</td>\n",
              "      <td>0.491000</td>\n",
              "      <td>1.550309</td>\n",
              "      <td>0.296578</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.175905</td>\n",
              "      <td>0.492928</td>\n",
              "      <td>1.690742</td>\n",
              "      <td>0.270596</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.173922</td>\n",
              "      <td>0.488107</td>\n",
              "      <td>1.802636</td>\n",
              "      <td>0.249049</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.178681</td>\n",
              "      <td>0.482321</td>\n",
              "      <td>1.590272</td>\n",
              "      <td>0.260456</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.171886</td>\n",
              "      <td>0.492125</td>\n",
              "      <td>1.461362</td>\n",
              "      <td>0.312421</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.170368</td>\n",
              "      <td>0.497107</td>\n",
              "      <td>1.588501</td>\n",
              "      <td>0.268061</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.174972</td>\n",
              "      <td>0.495661</td>\n",
              "      <td>1.652135</td>\n",
              "      <td>0.262357</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.176379</td>\n",
              "      <td>0.492125</td>\n",
              "      <td>1.489865</td>\n",
              "      <td>0.304182</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.173091</td>\n",
              "      <td>0.493089</td>\n",
              "      <td>1.482346</td>\n",
              "      <td>0.295944</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.166417</td>\n",
              "      <td>0.492285</td>\n",
              "      <td>1.689066</td>\n",
              "      <td>0.264259</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.158618</td>\n",
              "      <td>0.493089</td>\n",
              "      <td>1.484910</td>\n",
              "      <td>0.295944</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.166367</td>\n",
              "      <td>0.494536</td>\n",
              "      <td>1.623305</td>\n",
              "      <td>0.251584</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.158031</td>\n",
              "      <td>0.508518</td>\n",
              "      <td>1.614082</td>\n",
              "      <td>0.281369</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.154050</td>\n",
              "      <td>0.507875</td>\n",
              "      <td>1.738895</td>\n",
              "      <td>0.266160</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.158699</td>\n",
              "      <td>0.507554</td>\n",
              "      <td>1.562833</td>\n",
              "      <td>0.292776</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.160638</td>\n",
              "      <td>0.505464</td>\n",
              "      <td>1.603601</td>\n",
              "      <td>0.283904</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.158012</td>\n",
              "      <td>0.502089</td>\n",
              "      <td>1.524038</td>\n",
              "      <td>0.314956</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.156752</td>\n",
              "      <td>0.513983</td>\n",
              "      <td>1.578967</td>\n",
              "      <td>0.273131</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.155953</td>\n",
              "      <td>0.502089</td>\n",
              "      <td>1.650751</td>\n",
              "      <td>0.284537</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.157723</td>\n",
              "      <td>0.510447</td>\n",
              "      <td>1.539809</td>\n",
              "      <td>0.299747</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.157574</td>\n",
              "      <td>0.503214</td>\n",
              "      <td>1.555873</td>\n",
              "      <td>0.279468</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.161877</td>\n",
              "      <td>0.502250</td>\n",
              "      <td>1.521108</td>\n",
              "      <td>0.297212</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.147637</td>\n",
              "      <td>0.513500</td>\n",
              "      <td>1.598723</td>\n",
              "      <td>0.311787</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.155381</td>\n",
              "      <td>0.513822</td>\n",
              "      <td>1.494768</td>\n",
              "      <td>0.323828</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.150998</td>\n",
              "      <td>0.513018</td>\n",
              "      <td>1.570194</td>\n",
              "      <td>0.260456</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.159108</td>\n",
              "      <td>0.508036</td>\n",
              "      <td>1.446365</td>\n",
              "      <td>0.341572</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.161489</td>\n",
              "      <td>0.507393</td>\n",
              "      <td>1.612960</td>\n",
              "      <td>0.285805</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.153248</td>\n",
              "      <td>0.509000</td>\n",
              "      <td>1.559121</td>\n",
              "      <td>0.311153</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.155796</td>\n",
              "      <td>0.516393</td>\n",
              "      <td>1.475275</td>\n",
              "      <td>0.326996</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.151955</td>\n",
              "      <td>0.513822</td>\n",
              "      <td>1.577104</td>\n",
              "      <td>0.325095</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.157472</td>\n",
              "      <td>0.501929</td>\n",
              "      <td>1.464788</td>\n",
              "      <td>0.320659</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.145150</td>\n",
              "      <td>0.517036</td>\n",
              "      <td>1.558955</td>\n",
              "      <td>0.288973</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.167464</td>\n",
              "      <td>0.495661</td>\n",
              "      <td>1.483881</td>\n",
              "      <td>0.323828</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.152820</td>\n",
              "      <td>0.510286</td>\n",
              "      <td>1.459228</td>\n",
              "      <td>0.344740</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.147716</td>\n",
              "      <td>0.514786</td>\n",
              "      <td>1.539063</td>\n",
              "      <td>0.359949</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.150872</td>\n",
              "      <td>0.512375</td>\n",
              "      <td>1.445937</td>\n",
              "      <td>0.375792</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.142142</td>\n",
              "      <td>0.518643</td>\n",
              "      <td>1.517823</td>\n",
              "      <td>0.344106</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.150739</td>\n",
              "      <td>0.516876</td>\n",
              "      <td>1.510449</td>\n",
              "      <td>0.381496</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.137810</td>\n",
              "      <td>0.522501</td>\n",
              "      <td>1.557418</td>\n",
              "      <td>0.367554</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.149616</td>\n",
              "      <td>0.516393</td>\n",
              "      <td>1.536279</td>\n",
              "      <td>0.365019</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.136836</td>\n",
              "      <td>0.522983</td>\n",
              "      <td>1.507323</td>\n",
              "      <td>0.371990</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.136124</td>\n",
              "      <td>0.527483</td>\n",
              "      <td>1.489891</td>\n",
              "      <td>0.387199</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.125835</td>\n",
              "      <td>0.538412</td>\n",
              "      <td>1.484951</td>\n",
              "      <td>0.394804</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.132438</td>\n",
              "      <td>0.531983</td>\n",
              "      <td>1.511679</td>\n",
              "      <td>0.357414</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.137177</td>\n",
              "      <td>0.529251</td>\n",
              "      <td>1.472701</td>\n",
              "      <td>0.426489</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.157460</td>\n",
              "      <td>0.509161</td>\n",
              "      <td>1.376403</td>\n",
              "      <td>0.391635</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.146898</td>\n",
              "      <td>0.515108</td>\n",
              "      <td>1.428708</td>\n",
              "      <td>0.399873</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.139860</td>\n",
              "      <td>0.520251</td>\n",
              "      <td>1.400077</td>\n",
              "      <td>0.415082</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.134370</td>\n",
              "      <td>0.523144</td>\n",
              "      <td>1.429923</td>\n",
              "      <td>0.407478</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.126710</td>\n",
              "      <td>0.527805</td>\n",
              "      <td>1.463333</td>\n",
              "      <td>0.389734</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.120998</td>\n",
              "      <td>0.545966</td>\n",
              "      <td>1.548924</td>\n",
              "      <td>0.415716</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.127568</td>\n",
              "      <td>0.534555</td>\n",
              "      <td>1.522004</td>\n",
              "      <td>0.372624</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.115913</td>\n",
              "      <td>0.546609</td>\n",
              "      <td>1.416546</td>\n",
              "      <td>0.422687</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.118297</td>\n",
              "      <td>0.541305</td>\n",
              "      <td>1.520342</td>\n",
              "      <td>0.381496</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.118458</td>\n",
              "      <td>0.539376</td>\n",
              "      <td>1.418186</td>\n",
              "      <td>0.420786</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.108016</td>\n",
              "      <td>0.549823</td>\n",
              "      <td>1.522923</td>\n",
              "      <td>0.412548</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.115166</td>\n",
              "      <td>0.547895</td>\n",
              "      <td>1.489505</td>\n",
              "      <td>0.421420</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.106423</td>\n",
              "      <td>0.552716</td>\n",
              "      <td>1.589721</td>\n",
              "      <td>0.409379</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.112385</td>\n",
              "      <td>0.545162</td>\n",
              "      <td>1.503299</td>\n",
              "      <td>0.422053</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.102665</td>\n",
              "      <td>0.555448</td>\n",
              "      <td>1.612704</td>\n",
              "      <td>0.382129</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.111365</td>\n",
              "      <td>0.548377</td>\n",
              "      <td>1.550466</td>\n",
              "      <td>0.396071</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.109168</td>\n",
              "      <td>0.552555</td>\n",
              "      <td>1.516276</td>\n",
              "      <td>0.414449</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.106902</td>\n",
              "      <td>0.556895</td>\n",
              "      <td>1.451987</td>\n",
              "      <td>0.446134</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.115907</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>1.577071</td>\n",
              "      <td>0.413181</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.110089</td>\n",
              "      <td>0.554484</td>\n",
              "      <td>1.482819</td>\n",
              "      <td>0.411280</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.107627</td>\n",
              "      <td>0.552877</td>\n",
              "      <td>1.454661</td>\n",
              "      <td>0.389100</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.103781</td>\n",
              "      <td>0.553038</td>\n",
              "      <td>1.518603</td>\n",
              "      <td>0.403676</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.108134</td>\n",
              "      <td>0.560109</td>\n",
              "      <td>1.531165</td>\n",
              "      <td>0.418885</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.112995</td>\n",
              "      <td>0.548055</td>\n",
              "      <td>1.542460</td>\n",
              "      <td>0.411914</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.106103</td>\n",
              "      <td>0.559949</td>\n",
              "      <td>1.515744</td>\n",
              "      <td>0.432193</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.120411</td>\n",
              "      <td>0.547091</td>\n",
              "      <td>1.461087</td>\n",
              "      <td>0.418885</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.109662</td>\n",
              "      <td>0.556573</td>\n",
              "      <td>1.604003</td>\n",
              "      <td>0.394804</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.115816</td>\n",
              "      <td>0.547573</td>\n",
              "      <td>1.569669</td>\n",
              "      <td>0.423954</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.116449</td>\n",
              "      <td>0.545644</td>\n",
              "      <td>1.587372</td>\n",
              "      <td>0.422687</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.105442</td>\n",
              "      <td>0.558181</td>\n",
              "      <td>1.589236</td>\n",
              "      <td>0.417617</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.117476</td>\n",
              "      <td>0.544841</td>\n",
              "      <td>1.601132</td>\n",
              "      <td>0.407478</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.127771</td>\n",
              "      <td>0.542591</td>\n",
              "      <td>1.527504</td>\n",
              "      <td>0.401141</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.122110</td>\n",
              "      <td>0.546287</td>\n",
              "      <td>1.444291</td>\n",
              "      <td>0.394170</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/course-v3/nbs/dl2/exp/nb_09.py:136: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  state['grad_avg'].mul_(mom).add_(state['mom_damp'], p.grad.data)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-eb0fe6ae3a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_09b.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, cbs, reset_opt)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_09b.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_08.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_08.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mImageList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mItemList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/course-v3/nbs/dl2/exp/nb_08.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m  \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-65029f409554>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(learner, filename):\n",
        "    fname = Path(filename)\n",
        "    fname.parent.mkdir(parents=True, exist_ok = True)\n",
        "    checkpoint_dict = {\n",
        "        'model': learn.model.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint_dict, fname)"
      ],
      "metadata": {
        "id": "s3zas4km5qhK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_checkpoint(learn, Path('/content/2021-12-20-v2-2-transformer.pt'))"
      ],
      "metadata": {
        "id": "fLodHRU8FWph"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "a21jVDRDKvgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Pytorch Transformer Encoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html)\n",
        "- [fastai course-v3 part2, audio](https://github.com/fastai/course-v3/blob/master/nbs/dl2/audio.ipynb)\n",
        "- [Transformer-CNN-emotion recognition](https://github.com/IliaZenkov/transformer-cnn-emotion-recognition/blob/main/notebooks/Parallel_is_All_You_Want.ipynb)\n",
        "- \n"
      ],
      "metadata": {
        "id": "KMp_Qul3KwyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tmsc8x7wKw2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}