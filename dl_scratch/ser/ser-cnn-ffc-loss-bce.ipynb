{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pooling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Main changes  \n",
        "1. BCE loss\n",
        "2. cnn batchsize =1, and pooling -> FFC"
      ],
      "metadata": {
        "id": "7kPMSMvg_d-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "from pathlib import Path\n",
        "drive_path = Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/')"
      ],
      "metadata": {
        "id": "4bMB_Fg6l4ub",
        "outputId": "57a79b6f-8eeb-4731-d1d1-6474857f4bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from exp.nb_08 import *"
      ],
      "metadata": {
        "id": "dK23Yp19bAT_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_data_path = drive_path/'data/v1'"
      ],
      "metadata": {
        "id": "xw7rlEPZpuNv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(drive_data_path).ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCKxWOpFqET8",
        "outputId": "aad65031-a790-4d72-808f-9af475291994"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/dev'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/ser.tar-v1.gz')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemList(ListContainer):\n",
        "    def __init__(self, items, path='.', tfms=None):\n",
        "        super().__init__(items)\n",
        "        self.path,self.tfms = Path(path),tfms\n",
        "\n",
        "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
        "\n",
        "    def new(self, items, cls=None):\n",
        "        if cls is None: cls=self.__class__\n",
        "        return cls(items, self.path, tfms=self.tfms)\n",
        "\n",
        "    def  get(self, i): return i\n",
        "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        res = super().__getitem__(idx)\n",
        "        if isinstance(res,list): return [self._get(o) for o in res]\n",
        "        return self._get(res)\n"
      ],
      "metadata": {
        "id": "G7UTFPBDeSRS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions = None, recurse=True, include=None, **kwargs):\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "    \n",
        "    def get(self, fn):\n",
        "        return torch.load(fn)\n",
        "\n",
        "class Reshape():\n",
        "    \"transpose to [n_features, n_frames]\"\n",
        "    _order=12\n",
        "    def __call__(self, item):\n",
        "        w, h = item.shape\n",
        "        return item.view(h, w)\n",
        "\n",
        "class Enlengthen():\n",
        "    \"if n_features is smaller than threshold, concat them\"\n",
        "    _order = 14\n",
        "    def __init__(self, thres):\n",
        "        self.thres = thres\n",
        "    def __call__(self, item):\n",
        "        if item.shape[-1] > self.thres: return item\n",
        "        return torch.cat([item, item], dim=-1)\n",
        "\n",
        "class DummyChannel():\n",
        "    \"insert pseudo axis in height [n_features, 1, n_frames]\"\n",
        "    _order = 30\n",
        "    def __call__(self, item):\n",
        "        return item.unsqueeze(1)\n",
        "\n",
        "def re_labeler(fn, pat, subcl='act'):\n",
        "    assert subcl in ['act', 'val', 'all']\n",
        "    if subcl=='all': return tuple(int(i) for i in re.findall(pat, str(fn)))\n",
        "    else:\n",
        "        return re.findall(pat, str(fn))[0] if pat == 'act' else re.findall(pat, str(fn))[1]\n"
      ],
      "metadata": {
        "id": "PHB8bfNz-KiH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "s72NONpGdFf0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_splitter(fn, p_valid): return random.random() < p_valid"
      ],
      "metadata": {
        "id": "4yPdJKwZdCN-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qq ipdb"
      ],
      "metadata": {
        "id": "gQVHzudZf9UH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ipdb import set_trace"
      ],
      "metadata": {
        "id": "2fqUFcQBgB5_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CategoryProcessor(Processor):\n",
        "    def __init__(self): self.vocab=None\n",
        "\n",
        "    def __call__(self, items):\n",
        "        #The vocab is defined on the first use.\n",
        "        if self.vocab is None:\n",
        "            # set_trace()\n",
        "            self.vocab = uniqueify(items)\n",
        "            # self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
        "        return [torch.tensor(o).float() for o in items]\n",
        "    def proc1(self, item):  return self.otoi[item]\n",
        "\n",
        "    def deprocess(self, idxs):\n",
        "        assert self.vocab is not None\n",
        "        return [self.deproc1(idx) for idx in idxs]\n",
        "    def deproc1(self, idx): return self.vocab[idx]\n"
      ],
      "metadata": {
        "id": "Lo9Q2I_gfl-_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_files(p, fs, extensions=None):\n",
        "    p = Path(p)\n",
        "    res = [p/f for f in fs if not f.startswith('.')\n",
        "        #    and '_0_0' in f\n",
        "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
        "    return res\n",
        "\n",
        "def get_files(path, extensions=None, recurse=False, include=None):\n",
        "    path = Path(path)\n",
        "    extensions = setify(extensions)\n",
        "    extensions = {e.lower() for e in extensions}\n",
        "    if recurse:\n",
        "        res = []\n",
        "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
        "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
        "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
        "            res += _get_files(p, f, extensions)\n",
        "        return res\n",
        "    else:\n",
        "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
        "        return _get_files(path, f, extensions)"
      ],
      "metadata": {
        "id": "Jb_86tKdlyYU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs, **kwargs))"
      ],
      "metadata": {
        "id": "npt7ZXfs59Yo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = drive_data_path/'train'\n",
        "tfms = [Reshape(), DummyChannel(), Enlengthen(100)]\n",
        "al=AudioList.from_files(train_path, tfms=tfms)"
      ],
      "metadata": {
        "id": "V1-WeGWbceda"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al[4].shape, al.items.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzgHtq8lcpwG",
        "outputId": "d3e699c3-714c-4946-9cb7-e0955d1cf0b9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([26, 1, 136]), 7800)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):\n",
        "    dls = get_dls(sd.train, sd.valid, bs, **kwargs)\n",
        "    return DataBunch(*dls, c_in=c_in, c_out=c_out)\n",
        "\n",
        "SplitData.to_databunch = databunchify"
      ],
      "metadata": {
        "id": "ucopmUtS6Wet"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pat = r'_(\\d+)'\n",
        "emotion_labeler = partial(re_labeler, pat=label_pat, subcl='all')\n",
        "sd = SplitData.split_by_func(al, partial(random_splitter, p_valid=0.01))\n",
        "ll = label_by_func(sd, emotion_labeler, proc_y=CategoryProcessor())"
      ],
      "metadata": {
        "id": "7t-IrdLscir_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbBLDyZkc4Rt",
        "outputId": "a7465b95-5cea-4323-c504-4cc6df67fad7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ItemList (7723 items)\n",
              "[tensor([1., 1.]), tensor([0., 0.]), tensor([0., 0.]), tensor([1., 0.]), tensor([1., 1.]), tensor([1., 0.]), tensor([1., 1.]), tensor([1., 0.]), tensor([1., 0.]), tensor([1., 1.])...]\n",
              "Path: /gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs=1"
      ],
      "metadata": {
        "id": "5oN7RbWZCeb6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_in = ll.train[0][0].shape[0]\n",
        "c_out = 2\n",
        "data = ll.to_databunch(bs,c_in=c_in,c_out=c_out)"
      ],
      "metadata": {
        "id": "DAO3200FesZw"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.train_dl.batch_size, data.valid_dl.batch_size"
      ],
      "metadata": {
        "id": "UDN3bG_o5Zh_",
        "outputId": "f00871f1-8a51-4ff4-e8d3-ea5e763a11c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.c_in, data.c_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ5YJvE6e5KW",
        "outputId": "dae6dcb0-eb16-4249-eb9e-a79b51ee07da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(data.train_dl))"
      ],
      "metadata": {
        "id": "9DmN6vGxe8_o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "id": "SCtBT8F5892Y",
        "outputId": "25314b7f-1679-44c0-e00f-ea392f67b6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 26, 1, 129])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "id": "Y4bcsqEw8-pV",
        "outputId": "b7bce655-85b8-49d3-ea82-de65bb1f82bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "EsHcnnmQlGo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, steppers, **defaults):\n",
        "        self.steppers = listify(steppers)\n",
        "        maybe_update(self.steppers, defaults, get_defaults)\n",
        "        # might be a generator\n",
        "        self.param_groups = list(params)\n",
        "        # ensure params is a list of lists\n",
        "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
        "        self.hypers = [{**defaults} for p in self.param_groups]\n",
        "\n",
        "    def grad_params(self):\n",
        "        return [(p,hyper) for pg,hyper in zip(self.param_groups,self.hypers)\n",
        "            for p in pg if p.grad is not None]\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p,hyper in self.grad_params():\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "\n",
        "    def step(self):\n",
        "        for p,hyper in self.grad_params(): compose(p, self.steppers, **hyper)\n",
        "def maybe_update(os, dest, f):\n",
        "    for o in os:\n",
        "        for k,v in f(o).items():\n",
        "            if k not in dest: dest[k] = v\n",
        "\n",
        "class Stat():\n",
        "    _defaults = {}\n",
        "    def init_state(self, p): raise NotImplementedError\n",
        "    def update(self, p, state, **kwargs): raise NotImplementedError\n",
        "\n",
        "class AverageGrad(Stat):\n",
        "    _defaults = dict(mom=0.9)\n",
        "\n",
        "    def __init__(self, dampening:bool=False): self.dampening=dampening\n",
        "    def init_state(self, p): return {'grad_avg': torch.zeros_like(p.grad.data)}\n",
        "    def update(self, p, state, mom, **kwargs):\n",
        "        state['mom_damp'] = 1-mom if self.dampening else 1.\n",
        "        state['grad_avg'].mul_(mom).add_(state['mom_damp'], p.grad.data)\n",
        "        return state\n",
        "\n",
        "class AverageSqrGrad(Stat):\n",
        "    _defaults = dict(sqr_mom=0.99)\n",
        "\n",
        "    def __init__(self, dampening:bool=True): self.dampening=dampening\n",
        "    def init_state(self, p): return {'sqr_avg': torch.zeros_like(p.grad.data)}\n",
        "    def update(self, p, state, sqr_mom, **kwargs):\n",
        "        state['sqr_damp'] = 1-sqr_mom if self.dampening else 1.\n",
        "        state['sqr_avg'].mul_(sqr_mom).addcmul_(state['sqr_damp'], p.grad.data, p.grad.data)\n",
        "        return state\n",
        "\n",
        "class StepCount(Stat):\n",
        "    def init_state(self, p): return {'step': 0}\n",
        "    def update(self, p, state, **kwargs):\n",
        "        state['step'] += 1\n",
        "        return state\n",
        "\n",
        "def debias(mom, damp, step): return damp * (1 - mom**step) / (1-mom)\n",
        "\n",
        "class StatefulOptimizer(Optimizer):\n",
        "    def __init__(self, params, steppers, stats=None, **defaults):\n",
        "        self.stats = listify(stats)\n",
        "        maybe_update(self.stats, defaults, get_defaults)\n",
        "        super().__init__(params, steppers, **defaults)\n",
        "        self.state = {}\n",
        "\n",
        "    def step(self):\n",
        "        for p,hyper in self.grad_params():\n",
        "            if p not in self.state:\n",
        "                #Create a state for p and call all the statistics to initialize it.\n",
        "                self.state[p] = {}\n",
        "                maybe_update(self.stats, self.state[p], lambda o: o.init_state(p))\n",
        "            state = self.state[p]\n",
        "            for stat in self.stats: state = stat.update(p, state, **hyper)\n",
        "            compose(p, self.steppers, **state, **hyper)\n",
        "            self.state[p] = state\n",
        "\n",
        "def adam_step(p, lr, mom, mom_damp, step, sqr_mom, sqr_damp, grad_avg, sqr_avg, eps, **kwargs):\n",
        "    debias1 = debias(mom,     mom_damp, step)\n",
        "    debias2 = debias(sqr_mom, sqr_damp, step)\n",
        "    p.data.addcdiv_(-lr / debias1, grad_avg, (sqr_avg/debias2).sqrt() + eps)\n",
        "    return p\n",
        "adam_step._defaults = dict(eps=1e-5)\n",
        "\n",
        "def weight_decay(p, lr, wd, **kwargs):\n",
        "    p.data.mul_(1 - lr*wd)\n",
        "    return p\n",
        "weight_decay._defaults = dict(wd=0.)\n",
        "\n",
        "def adam_opt(xtra_step=None, **kwargs):\n",
        "    return partial(StatefulOptimizer, steppers=[adam_step,weight_decay]+listify(xtra_step),\n",
        "                   stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()], **kwargs)\n",
        "    \n",
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-1, )    "
      ],
      "metadata": {
        "id": "M1yJTG9lji3X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_defaults(d): return getattr(d,'_defaults',{})"
      ],
      "metadata": {
        "id": "bzPopnue3D0t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AvgStats"
      ],
      "metadata": {
        "id": "6dY8dNpldlP_",
        "outputId": "cded1d8a-2fe0-404b-ba47-f0f339e6856f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exp.nb_04.AvgStats"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback():\n",
        "    _order=0\n",
        "    def set_runner(self, run): self.run=run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
        "        return camel2snake(name or 'callback')\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        f = getattr(self, cb_name, None)\n",
        "        if f and f(): return True\n",
        "        return False\n",
        "\n",
        "class TrainEvalCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.run.n_epochs=0.\n",
        "        self.run.n_iter=0\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.run.n_epochs += 1./self.iters\n",
        "        self.run.n_iter   += 1\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        self.run.n_epochs=self.epoch\n",
        "        self.model.train()\n",
        "        self.run.in_train=True\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.model.eval()\n",
        "        self.run.in_train=False\n",
        "\n",
        "class CancelTrainException(Exception): pass\n",
        "class CancelEpochException(Exception): pass\n",
        "class CancelBatchException(Exception): pass\n",
        "\n",
        "class Runner():\n",
        "    def __init__(self, cbs=None, cb_funcs=None):\n",
        "        self.in_train = False\n",
        "        cbs = listify(cbs)\n",
        "        for cbf in listify(cb_funcs):\n",
        "            cb = cbf()\n",
        "            setattr(self, cb.name, cb)\n",
        "            cbs.append(cb)\n",
        "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
        "\n",
        "    @property\n",
        "    def opt(self):       return self.learn.opt\n",
        "    @property\n",
        "    def model(self):     return self.learn.model\n",
        "    @property\n",
        "    def loss_func(self): return self.learn.loss_func\n",
        "    @property\n",
        "    def data(self):      return self.learn.data\n",
        "\n",
        "    def one_batch(self, xb, yb):\n",
        "        try:\n",
        "            self.xb,self.yb = xb,yb\n",
        "            self('begin_batch')\n",
        "            self.pred = self.model(self.xb)\n",
        "            self('after_pred')\n",
        "            self.loss = self.loss_func(self.pred, self.yb)\n",
        "            self('after_loss')\n",
        "            if not self.in_train: return\n",
        "            self.loss.backward()\n",
        "            self('after_backward')\n",
        "            self.opt.step()\n",
        "            self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException: self('after_cancel_batch')\n",
        "        finally: self('after_batch')\n",
        "\n",
        "    def all_batches(self, dl):\n",
        "        self.iters = len(dl)\n",
        "        try:\n",
        "            for xb,yb in dl: self.one_batch(xb, yb)\n",
        "        except CancelEpochException: self('after_cancel_epoch')\n",
        "\n",
        "    def fit(self, epochs, learn):\n",
        "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
        "\n",
        "        try:\n",
        "            for cb in self.cbs: cb.set_runner(self)\n",
        "            self('begin_fit')\n",
        "            for epoch in range(epochs):\n",
        "                self.epoch = epoch\n",
        "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
        "                self('after_epoch')\n",
        "\n",
        "        except CancelTrainException: self('after_cancel_train')\n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.learn = None\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        res = False\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
        "            res = cb(cb_name) and res\n",
        "        return res\n",
        "\n",
        "class AvgStats():\n",
        "    def __init__(self, metrics, in_train): self.metrics,self.in_train = listify(metrics),in_train\n",
        "\n",
        "    def reset(self):\n",
        "        self.tot_loss,self.count = 0.,0\n",
        "        self.tot_mets = [0.] * len(self.metrics)\n",
        "\n",
        "    @property\n",
        "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
        "    @property\n",
        "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
        "\n",
        "    def __repr__(self):\n",
        "        if not self.count: return \"\"\n",
        "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
        "\n",
        "    def accumulate(self, run):\n",
        "        bn = run.xb.shape[0]\n",
        "        self.tot_loss += run.loss * bn\n",
        "        self.count += bn\n",
        "        for i,m in enumerate(self.metrics):\n",
        "            self.tot_mets[i] += torch.tensor(m(run.pred, run.yb)) * bn\n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "\n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        print(self.run.n_iter / self.run.iters, stats)\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "\n",
        "    def after_epoch(self):\n",
        "        print(self.train_stats)\n",
        "        print(self.valid_stats)\n",
        "\n",
        "# https://stackoverflow.com/questions/7370801/how-to-measure-elapsed-time-in-python\n",
        "from timeit import default_timer as timer\n",
        "class Recorder(Callback):\n",
        "    def __init__(self):\n",
        "        self.tot_time = []\n",
        "\n",
        "    def begin_fit(self):self.lrs,self.losses = [],[]\n",
        "    \n",
        "    def begin_epoch(self):\n",
        "        self.start_time = timer()\n",
        "\n",
        "    def after_epoch(self):\n",
        "        self.tot_time.append(timer() - self.start_time)\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.lrs.append(self.opt.hypers[-1]['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())\n",
        "\n",
        "    def plot_lr  (self): plt.plot(self.lrs)\n",
        "    def plot_loss(self): plt.plot(self.losses)\n",
        "\n",
        "    def plot(self, skip_last=0):\n",
        "        losses = [o.item() for o in self.losses]\n",
        "        n = len(losses)-skip_last\n",
        "        plt.xscale('log')\n",
        "        plt.plot(self.lrs[:n], losses[:n])\n",
        "\n",
        "class ParamScheduler(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, pname, sched_funcs):\n",
        "        self.pname,self.sched_funcs = pname,listify(sched_funcs)\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        fs = self.sched_funcs\n",
        "        if len(fs)==1: fs = fs*len(self.opt.param_groups)\n",
        "        pos = self.n_epochs/self.epochs\n",
        "        for f,h in zip(fs,self.opt.hypers): h[self.pname] = f(pos)\n",
        "\n",
        "class LR_Find(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
        "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        pos = self.n_iter/self.max_iter\n",
        "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
        "        for pg in self.opt.hypers: pg['lr'] = lr\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
        "            raise CancelTrainException()\n",
        "        if self.loss < self.best_loss: self.best_loss = self.loss\n",
        "\n",
        "def get_runner(model, data, lr=0.6, cbs=None, opt_func=None, loss_func = F.cross_entropy):\n",
        "    if opt_func is None: opt_func = optim.SGD\n",
        "    opt = opt_func(model.parameters(), lr=lr)\n",
        "    learn = Learner(model, opt, loss_func, data)\n",
        "    return learn, Runner(cb_funcs=listify(cbs))"
      ],
      "metadata": {
        "id": "Ds8HJcRt4Xv6"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FramesizeFilter(Callback):\n",
        "    \"if the size of n_frames is less than 100, raise CancelBatchException\"\n",
        "    def begin_batch(self):\n",
        "        if self.run.xb.shape[-1] < 100:\n",
        "            raise CancelBatchException()\n",
        "\n",
        "class SaveModelParam(Callback):\n",
        "    def __init__(self, m_path, f_name:str):\n",
        "        self.m_path = Path(m_path)\n",
        "        self.f_name = f_name\n",
        "    def after_epoch(self):\n",
        "        self.m_path.mkdir(parents=True, exist_ok=True)\n",
        "        checkpoint_dict = {\n",
        "            'model': self.run.model.state_dict(),\n",
        "        }\n",
        "        f_path = self.m_path/f\"{self.f_name}_{self.run.epoch}.pt\"\n",
        "        torch.save(checkpoint_dict, f_path)\n",
        "        print(f'model parameters succesfully saved to {f_path}!')\n"
      ],
      "metadata": {
        "id": "VNSsswuxW_tG"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self): super().__init__()\n",
        "    def forward(self, x):\n",
        "        return x.squeeze(-1).permute(1,0)"
      ],
      "metadata": {
        "id": "OxniMMCvy9qh"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StatMean(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.f(x.mean(0, keepdim=True))"
      ],
      "metadata": {
        "id": "nHhYyG3kBtai"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv1d(1,8, kernel_size=30, stride=1),GeneralRelu(),\n",
        "    nn.Conv1d(8,16, kernel_size=25),GeneralRelu(),\n",
        "    nn.Conv1d(16,32, kernel_size=18),GeneralRelu(),\n",
        "    nn.Conv1d(32,64, kernel_size=7),GeneralRelu(),\n",
        "    nn.Conv1d(64,128, kernel_size=5),GeneralRelu(),\n",
        "    nn.Conv1d(128,128, kernel_size=3),GeneralRelu(), #26, 128, 18 - based on 100 frames\n",
        "    nn.AdaptiveAvgPool1d(1), #26, 128, 1\n",
        "    Flatten(),\n",
        "    nn.Linear(26, 2),\n",
        "    StatMean()\n",
        "    )"
      ],
      "metadata": {
        "id": "1EwucPjayOua"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_chan(x, mean, std):\n",
        "    return (x-mean[...,None,None]) / std[...,None,None]\n",
        "\n",
        "_m = tensor([4.6458, 5.4130, 6.5964, 6.8884, 6.8241, 7.1415, 7.2152, 7.1492, 6.6828,\n",
        "        6.7434, 6.8610, 6.9456, 7.2149, 7.3144, 7.3993, 7.1714, 7.3913, 7.5860,\n",
        "        7.3430, 7.3854, 7.4977, 7.4650, 7.3808, 7.0497, 6.7768, 6.4319])\n",
        "_s = tensor([1.6839, 2.3302, 2.6372, 2.6552, 2.7861, 2.7495, 2.7446, 2.6085, 2.5018,\n",
        "        2.3586, 2.3367, 2.3888, 2.4452, 2.4944, 2.4172, 2.4300, 2.3737, 2.4037,\n",
        "        2.4891, 2.4774, 2.4399, 2.3689, 2.2110, 2.2310, 2.2802, 2.2686])\n",
        "norm_ser = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())\n",
        "\n",
        "class BatchTransformXCallback(Callback):\n",
        "    _order=2\n",
        "    def __init__(self, tfm): self.tfm = tfm\n",
        "    def begin_batch(self):\n",
        "        self.run.xb = self.tfm(self.xb).squeeze(0)\n",
        "        # self.run.yb = self.yb.squeeze(0)"
      ],
      "metadata": {
        "id": "eAce3l3fkefR"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbfs = [partial(AvgStatsCallback,accuracy),\n",
        "        partial(SaveModelParam,drive_path/'checkpoints','ser-cnn-ffc-loss-bce'),\n",
        "        Recorder,\n",
        "        FramesizeFilter,\n",
        "        CudaCallback]"
      ],
      "metadata": {
        "id": "NMqTlV_2kvsn"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbfs.append(partial(BatchTransformXCallback, norm_ser))"
      ],
      "metadata": {
        "id": "40BHfbmWsfBE"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sched = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.1,0.3,0.05))"
      ],
      "metadata": {
        "id": "VDx9rJ1S7evB"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_learn_run(model, data, lr, cbs=None, opt_func=None, **kwargs):\n",
        "    init_cnn(model)\n",
        "    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)"
      ],
      "metadata": {
        "id": "YRndPhvA10xj"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn,run = get_learn_run(model, data, 0.2, cbs=cbfs+[\n",
        "    partial(ParamScheduler, 'lr', sched)], opt_func=opt_func, loss_func = nn.BCELoss()\n",
        ")"
      ],
      "metadata": {
        "id": "D_CtaxjgIxIg"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_summary(run, learn, data, find_all=False):\n",
        "    xb,yb = get_batch(data.valid_dl, run)\n",
        "    device = next(learn.model.parameters()).device#Model may not be on the GPU yet\n",
        "    xb,yb = xb.to(device),yb.to(device)\n",
        "    mods = learn.model.children()\n",
        "    f = lambda hook,mod,inp,out: print(f\"{mod}\\n{out.shape}\\n\")\n",
        "    with Hooks(mods, f) as hooks: learn.model(xb)"
      ],
      "metadata": {
        "id": "ZhGMUtaJ3JP1"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_summary(run, learn, data)"
      ],
      "metadata": {
        "id": "kvkF9C-nGtN1",
        "outputId": "e002a80f-a8f7-43e7-a85e-a8d335c85f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1d(1, 8, kernel_size=(30,), stride=(1,))\n",
            "torch.Size([26, 8, 282])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 8, 282])\n",
            "\n",
            "Conv1d(8, 16, kernel_size=(25,), stride=(1,))\n",
            "torch.Size([26, 16, 258])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 16, 258])\n",
            "\n",
            "Conv1d(16, 32, kernel_size=(18,), stride=(1,))\n",
            "torch.Size([26, 32, 241])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 32, 241])\n",
            "\n",
            "Conv1d(32, 64, kernel_size=(7,), stride=(1,))\n",
            "torch.Size([26, 64, 235])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 64, 235])\n",
            "\n",
            "Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
            "torch.Size([26, 128, 231])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 128, 231])\n",
            "\n",
            "Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "torch.Size([26, 128, 229])\n",
            "\n",
            "GeneralRelu()\n",
            "torch.Size([26, 128, 229])\n",
            "\n",
            "AdaptiveAvgPool1d(output_size=1)\n",
            "torch.Size([26, 128, 1])\n",
            "\n",
            "Flatten()\n",
            "torch.Size([128, 26])\n",
            "\n",
            "Linear(in_features=26, out_features=2, bias=True)\n",
            "torch.Size([128, 2])\n",
            "\n",
            "StatMean(\n",
            "  (f): Sigmoid()\n",
            ")\n",
            "torch.Size([1, 2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.fit(10, learn)"
      ],
      "metadata": {
        "id": "sBgdaf40B9y_",
        "outputId": "c27dad32-107a-4bd1-a56f-5a502154ecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 \n",
            "0.00012948336138806163 train: [1.4664919926570013, tensor(0., device='cuda:0')]\n",
            "0.00025896672277612325 train: [1.461257054255559, tensor(0., device='cuda:0')]\n",
            "0.0003884500841641849 train: [1.1334270575107672, tensor(0.1667, device='cuda:0')]\n",
            "0.0005179334455522465 train: [0.9700820629413311, tensor(0.2500, device='cuda:0')]\n",
            "0.0006474168069403081 train: [0.7760656503530649, tensor(0.4000, device='cuda:0')]\n",
            "0.0007769001683283698 train: [0.8879966735839844, tensor(0.3333, device='cuda:0')]\n",
            "0.0009063835297164314 train: [0.9678438626802884, tensor(0.2857, device='cuda:0')]\n",
            "0.001035866891104493 train: [0.9068122276893029, tensor(0.3125, device='cuda:0')]\n",
            "0.0011653502524925548 train: [0.8593225723657852, tensor(0.3333, device='cuda:0')]\n",
            "0.0012948336138806163 train: [0.8210513188288762, tensor(0.3500, device='cuda:0')]\n",
            "0.001424316975268678 train: [0.7893226463477928, tensor(0.3636, device='cuda:0')]\n",
            "0.0015538003366567395 train: [0.805801489414313, tensor(0.3750, device='cuda:0')]\n",
            "0.0016832836980448013 train: [0.855654925284301, tensor(0.3462, device='cuda:0')]\n",
            "0.0018127670594328628 train: [0.8983494685246394, tensor(0.3214, device='cuda:0')]\n",
            "0.0019422504208209245 train: [0.9352557842548077, tensor(0.3000, device='cuda:0')]\n",
            "0.002071733782208986 train: [0.9062822782076322, tensor(0.3125, device='cuda:0')]\n",
            "0.002201217143597048 train: [0.9382016281196974, tensor(0.2941, device='cuda:0')]\n",
            "0.0023307005049851095 train: [0.966484135032719, tensor(0.2778, device='cuda:0')]\n",
            "0.002460183866373171 train: [0.9408316052394358, tensor(0.2895, device='cuda:0')]\n",
            "0.0025896672277612325 train: [0.9419644282414363, tensor(0.3000, device='cuda:0')]\n",
            "0.0027191505891492945 train: [0.9202044700091575, tensor(0.3095, device='cuda:0')]\n",
            "0.002848633950537356 train: [0.9438299432501093, tensor(0.2955, device='cuda:0')]\n",
            "0.0029781173119254175 train: [0.9027938587609741, tensor(0.3261, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "9.361129094911304 train: [0.7564995885308385, tensor(0.4301, device='cuda:0')]\n",
            "9.361258578272691 train: [0.7567434444101917, tensor(0.4299, device='cuda:0')]\n",
            "9.36138806163408 train: [0.7566513695950251, tensor(0.4300, device='cuda:0')]\n",
            "9.361517544995468 train: [0.7563789968917871, tensor(0.4302, device='cuda:0')]\n",
            "9.361647028356856 train: [0.75644054957165, tensor(0.4302, device='cuda:0')]\n",
            "9.361776511718244 train: [0.7566826706903708, tensor(0.4300, device='cuda:0')]\n",
            "9.361905995079633 train: [0.7569240234212928, tensor(0.4299, device='cuda:0')]\n",
            "9.36203547844102 train: [0.7569803454038323, tensor(0.4299, device='cuda:0')]\n",
            "9.362164961802408 train: [0.7568942683428231, tensor(0.4299, device='cuda:0')]\n",
            "9.362294445163796 train: [0.7569461893339688, tensor(0.4300, device='cuda:0')]\n",
            "9.362423928525185 train: [0.7571842955910786, tensor(0.4298, device='cuda:0')]\n",
            "9.362553411886573 train: [0.7571029296551438, tensor(0.4298, device='cuda:0')]\n",
            "9.36268289524796 train: [0.7573395689292318, tensor(0.4297, device='cuda:0')]\n",
            "9.362812378609348 train: [0.7573826874793069, tensor(0.4297, device='cuda:0')]\n",
            "9.362941861970738 train: [0.7576177638973164, tensor(0.4295, device='cuda:0')]\n",
            "9.363071345332125 train: [0.7578519717569617, tensor(0.4294, device='cuda:0')]\n",
            "9.363200828693513 train: [0.7577786945677039, tensor(0.4294, device='cuda:0')]\n",
            "9.3633303120549 train: [0.757812015700766, tensor(0.4294, device='cuda:0')]\n",
            "9.363459795416288 train: [0.7575406902386461, tensor(0.4296, device='cuda:0')]\n",
            "9.363589278777678 train: [0.7577722781647487, tensor(0.4295, device='cuda:0')]\n",
            "9.363718762139065 train: [0.7575011610705931, tensor(0.4297, device='cuda:0')]\n",
            "9.363848245500453 train: [0.7574363616980302, tensor(0.4297, device='cuda:0')]\n",
            "9.36397772886184 train: [0.7571655585654959, tensor(0.4299, device='cuda:0')]\n",
            "9.36410721222323 train: [0.757395446008825, tensor(0.4298, device='cuda:0')]\n",
            "9.364236695584617 train: [0.7573333840039025, tensor(0.4298, device='cuda:0')]\n",
            "9.364366178946005 train: [0.7572716346153846, tensor(0.4298, device='cuda:0')]\n",
            "9.364495662307393 train: [0.7572096074890836, tensor(0.4298, device='cuda:0')]\n",
            "9.364625145668782 train: [0.7571467131135727, tensor(0.4299, device='cuda:0')]\n",
            "9.36475462903017 train: [0.7568765929875957, tensor(0.4301, device='cuda:0')]\n",
            "9.364884112391557 train: [0.7571068417027872, tensor(0.4299, device='cuda:0')]\n",
            "9.365013595752945 train: [0.7570407304092965, tensor(0.4299, device='cuda:0')]\n",
            "9.365143079114334 train: [0.7569733812160755, tensor(0.4300, device='cuda:0')]\n",
            "9.365272562475722 train: [0.7570037603450166, tensor(0.4300, device='cuda:0')]\n",
            "9.36540204583711 train: [0.7572350268977373, tensor(0.4298, device='cuda:0')]\n",
            "9.365531529198497 train: [0.7571647922542926, tensor(0.4299, device='cuda:0')]\n",
            "9.365661012559887 train: [0.7568953385915685, tensor(0.4301, device='cuda:0')]\n",
            "9.365790495921274 train: [0.7569295504611007, tensor(0.4301, device='cuda:0')]\n",
            "9.365919979282662 train: [0.7566603721003392, tensor(0.4303, device='cuda:0')]\n",
            "9.36604946264405 train: [0.7565888393345457, tensor(0.4303, device='cuda:0')]\n",
            "9.366178946005439 train: [0.7568206144756985, tensor(0.4302, device='cuda:0')]\n",
            "9.366308429366827 train: [0.7567483817802979, tensor(0.4302, device='cuda:0')]\n",
            "9.366437912728214 train: [0.7566755601576158, tensor(0.4302, device='cuda:0')]\n",
            "9.366567396089602 train: [0.7569077510171759, tensor(0.4301, device='cuda:0')]\n",
            "9.366696879450991 train: [0.7568331651437189, tensor(0.4301, device='cuda:0')]\n",
            "9.366826362812379 train: [0.7567575662741834, tensor(0.4301, device='cuda:0')]\n",
            "9.366955846173767 train: [0.7569906531301146, tensor(0.4300, device='cuda:0')]\n",
            "9.367085329535154 train: [0.7572240007975896, tensor(0.4298, device='cuda:0')]\n",
            "9.367214812896544 train: [0.7572679185349998, tensor(0.4298, device='cuda:0')]\n",
            "9.367344296257931 train: [0.7571891860132429, tensor(0.4299, device='cuda:0')]\n",
            "9.367473779619319 train: [0.7569210595309436, tensor(0.4301, device='cuda:0')]\n",
            "9.367603262980706 train: [0.756841760976855, tensor(0.4301, device='cuda:0')]\n",
            "9.367732746342096 train: [0.7570756522537971, tensor(0.4299, device='cuda:0')]\n",
            "9.367862229703483 train: [0.7569952390751272, tensor(0.4300, device='cuda:0')]\n",
            "9.367991713064871 train: [0.7569141390014689, tensor(0.4300, device='cuda:0')]\n",
            "9.368121196426259 train: [0.7569632090029095, tensor(0.4300, device='cuda:0')]\n",
            "9.368250679787648 train: [0.7568808503499592, tensor(0.4300, device='cuda:0')]\n",
            "9.368380163149036 train: [0.7569313303263321, tensor(0.4301, device='cuda:0')]\n",
            "9.368509646510423 train: [0.756848404481068, tensor(0.4301, device='cuda:0')]\n",
            "9.368639129871811 train: [0.7567651659527818, tensor(0.4301, device='cuda:0')]\n",
            "9.368768613233199 train: [0.7570002794874057, tensor(0.4300, device='cuda:0')]\n",
            "9.368898096594588 train: [0.7567332599884683, tensor(0.4302, device='cuda:0')]\n",
            "9.369027579955976 train: [0.7566488257092872, tensor(0.4302, device='cuda:0')]\n",
            "9.369157063317363 train: [0.7563821183332882, tensor(0.4304, device='cuda:0')]\n",
            "9.369286546678751 train: [0.7566179354197159, tensor(0.4302, device='cuda:0')]\n",
            "9.36941603004014 train: [0.7566729168924594, tensor(0.4303, device='cuda:0')]\n",
            "9.369545513401528 train: [0.7565875118499459, tensor(0.4303, device='cuda:0')]\n",
            "9.369674996762916 train: [0.7568229547423713, tensor(0.4301, device='cuda:0')]\n",
            "9.369804480124303 train: [0.7570581790823093, tensor(0.4300, device='cuda:0')]\n",
            "9.369933963485693 train: [0.7567918905916015, tensor(0.4302, device='cuda:0')]\n",
            "9.37006344684708 train: [0.7570266434734394, tensor(0.4300, device='cuda:0')]\n",
            "9.370192930208468 train: [0.757260967284034, tensor(0.4299, device='cuda:0')]\n",
            "9.370322413569856 train: [0.7571775416914428, tensor(0.4299, device='cuda:0')]\n",
            "9.370451896931245 train: [0.7570944385621842, tensor(0.4299, device='cuda:0')]\n",
            "9.370581380292633 train: [0.7573281224678586, tensor(0.4298, device='cuda:0')]\n",
            "9.37071086365402 train: [0.7573789175351675, tensor(0.4298, device='cuda:0')]\n",
            "9.370840347015408 train: [0.7571131705465587, tensor(0.4300, device='cuda:0')]\n",
            "9.370969830376797 train: [0.7573459696159243, tensor(0.4298, device='cuda:0')]\n",
            "9.371099313738185 train: [0.7575782366793883, tensor(0.4297, device='cuda:0')]\n",
            "9.371228797099572 train: [0.7574981168607943, tensor(0.4297, device='cuda:0')]\n",
            "9.37135828046096 train: [0.7574184743241604, tensor(0.4297, device='cuda:0')]\n",
            "9.37148776382235 train: [0.7571531788865687, tensor(0.4299, device='cuda:0')]\n",
            "9.371617247183737 train: [0.7571989658243105, tensor(0.4300, device='cuda:0')]\n",
            "9.371746730545125 train: [0.7571201426657871, tensor(0.4300, device='cuda:0')]\n",
            "9.371876213906512 train: [0.7570415849403833, tensor(0.4300, device='cuda:0')]\n",
            "9.372005697267902 train: [0.7569628719697581, tensor(0.4300, device='cuda:0')]\n",
            "9.37213518062929 train: [0.7571940454377354, tensor(0.4299, device='cuda:0')]\n",
            "9.372264663990677 train: [0.7571143889643213, tensor(0.4299, device='cuda:0')]\n",
            "9.372394147352065 train: [0.7568498486467237, tensor(0.4301, device='cuda:0')]\n",
            "9.372523630713454 train: [0.7567691610803622, tensor(0.4301, device='cuda:0')]\n",
            "9.372653114074842 train: [0.7566876380700741, tensor(0.4302, device='cuda:0')]\n",
            "9.37278259743623 train: [0.7564235237112364, tensor(0.4304, device='cuda:0')]\n",
            "9.372912080797617 train: [0.7561595936610929, tensor(0.4306, device='cuda:0')]\n",
            "9.373041564159006 train: [0.7558958477267849, tensor(0.4308, device='cuda:0')]\n",
            "9.373171047520394 train: [0.7556322857157226, tensor(0.4310, device='cuda:0')]\n",
            "9.373300530881782 train: [0.7555470069643672, tensor(0.4310, device='cuda:0')]\n",
            "9.37343001424317 train: [0.7552837501675154, tensor(0.4312, device='cuda:0')]\n",
            "9.373559497604559 train: [0.7550206767609785, tensor(0.4314, device='cuda:0')]\n",
            "9.373688980965946 train: [0.7552558501680684, tensor(0.4312, device='cuda:0')]\n",
            "9.373818464327334 train: [0.755491069037993, tensor(0.4311, device='cuda:0')]\n",
            "9.373947947688722 train: [0.75522819810235, tensor(0.4313, device='cuda:0')]\n",
            "9.374077431050111 train: [0.7551403637123746, tensor(0.4313, device='cuda:0')]\n",
            "9.374206914411499 train: [0.7553756908132289, tensor(0.4312, device='cuda:0')]\n",
            "9.374336397772886 train: [0.7556109065432742, tensor(0.4310, device='cuda:0')]\n",
            "9.374465881134274 train: [0.7555225609063452, tensor(0.4310, device='cuda:0')]\n",
            "9.374595364495661 train: [0.7552601355638977, tensor(0.4312, device='cuda:0')]\n",
            "9.37472484785705 train: [0.7554953550681089, tensor(0.4311, device='cuda:0')]\n",
            "9.374854331218438 train: [0.7554067764932049, tensor(0.4311, device='cuda:0')]\n",
            "9.374983814579826 train: [0.7554685519037261, tensor(0.4311, device='cuda:0')]\n",
            "9.375113297941214 train: [0.7555298154466501, tensor(0.4311, device='cuda:0')]\n",
            "9.375242781302603 train: [0.755267842556412, tensor(0.4313, device='cuda:0')]\n",
            "9.37537226466399 train: [0.7550060512764964, tensor(0.4315, device='cuda:0')]\n",
            "9.375501748025378 train: [0.7552395683405299, tensor(0.4314, device='cuda:0')]\n",
            "9.375631231386766 train: [0.7551544889557965, tensor(0.4314, device='cuda:0')]\n",
            "9.375760714748155 train: [0.7550699366909492, tensor(0.4314, device='cuda:0')]\n",
            "9.375890198109543 train: [0.7549854949643209, tensor(0.4315, device='cuda:0')]\n",
            "9.37601968147093 train: [0.75490079975712, tensor(0.4315, device='cuda:0')]\n",
            "9.376149164832318 train: [0.755133689517202, tensor(0.4313, device='cuda:0')]\n",
            "9.376278648193708 train: [0.7553665740703799, tensor(0.4312, device='cuda:0')]\n",
            "9.376408131555095 train: [0.7552809001834667, tensor(0.4312, device='cuda:0')]\n",
            "9.376537614916483 train: [0.7550199185317101, tensor(0.4314, device='cuda:0')]\n",
            "9.37666709827787 train: [0.7549336970240468, tensor(0.4314, device='cuda:0')]\n",
            "9.37679658163926 train: [0.7551670552718603, tensor(0.4313, device='cuda:0')]\n",
            "9.376926065000648 train: [0.7554004598590054, tensor(0.4311, device='cuda:0')]\n",
            "9.377055548362035 train: [0.7556337552091629, tensor(0.4310, device='cuda:0')]\n",
            "9.377185031723423 train: [0.7555465599046091, tensor(0.4310, device='cuda:0')]\n",
            "9.377314515084812 train: [0.7557796439820955, tensor(0.4309, device='cuda:0')]\n",
            "9.3774439984462 train: [0.7560125673673534, tensor(0.4307, device='cuda:0')]\n",
            "9.377573481807588 train: [0.7557520530436569, tensor(0.4309, device='cuda:0')]\n",
            "9.377702965168975 train: [0.755984566694931, tensor(0.4308, device='cuda:0')]\n",
            "9.377832448530365 train: [0.7557242414309175, tensor(0.4310, device='cuda:0')]\n",
            "9.377961931891752 train: [0.7556383328644247, tensor(0.4310, device='cuda:0')]\n",
            "9.37809141525314 train: [0.7555525351229552, tensor(0.4310, device='cuda:0')]\n",
            "9.378220898614527 train: [0.7554664863161864, tensor(0.4310, device='cuda:0')]\n",
            "9.378350381975917 train: [0.7552066972906306, tensor(0.4312, device='cuda:0')]\n",
            "9.378479865337304 train: [0.7554391770731417, tensor(0.4311, device='cuda:0')]\n",
            "9.378609348698692 train: [0.7553519652061855, tensor(0.4311, device='cuda:0')]\n",
            "9.37873883206008 train: [0.7552642455341807, tensor(0.4311, device='cuda:0')]\n",
            "9.37886831542147 train: [0.7550048828125, tensor(0.4313, device='cuda:0')]\n",
            "9.378997798782857 train: [0.7552383504647601, tensor(0.4312, device='cuda:0')]\n",
            "9.379127282144244 train: [0.7551489555560689, tensor(0.4312, device='cuda:0')]\n",
            "9.379256765505632 train: [0.754889899310595, tensor(0.4314, device='cuda:0')]\n",
            "9.379386248867021 train: [0.754799500187955, tensor(0.4314, device='cuda:0')]\n",
            "9.379515732228409 train: [0.754540741360328, tensor(0.4316, device='cuda:0')]\n",
            "9.379645215589797 train: [0.7542821598862498, tensor(0.4318, device='cuda:0')]\n",
            "9.379774698951184 train: [0.7541900545497667, tensor(0.4318, device='cuda:0')]\n",
            "9.379904182312572 train: [0.7544257627272128, tensor(0.4317, device='cuda:0')]\n",
            "9.380033665673961 train: [0.7543324368630343, tensor(0.4317, device='cuda:0')]\n",
            "9.380163149035349 train: [0.7545686548169063, tensor(0.4316, device='cuda:0')]\n",
            "9.380292632396737 train: [0.7544742645365667, tensor(0.4316, device='cuda:0')]\n",
            "9.380422115758124 train: [0.7547108889955804, tensor(0.4314, device='cuda:0')]\n",
            "9.380551599119514 train: [0.7546155387080867, tensor(0.4315, device='cuda:0')]\n",
            "9.380681082480901 train: [0.754690467838083, tensor(0.4315, device='cuda:0')]\n",
            "9.380810565842289 train: [0.7545946250591312, tensor(0.4315, device='cuda:0')]\n",
            "9.380940049203677 train: [0.7548316548280527, tensor(0.4314, device='cuda:0')]\n",
            "9.381069532565066 train: [0.7549068950744544, tensor(0.4314, device='cuda:0')]\n",
            "9.381199015926454 train: [0.7546492476699921, tensor(0.4316, device='cuda:0')]\n",
            "9.381328499287841 train: [0.754554216121434, tensor(0.4316, device='cuda:0')]\n",
            "9.381457982649229 train: [0.7544594031213926, tensor(0.4316, device='cuda:0')]\n",
            "9.381587466010618 train: [0.7543645011015238, tensor(0.4316, device='cuda:0')]\n",
            "9.381716949372006 train: [0.7546007149271144, tensor(0.4315, device='cuda:0')]\n",
            "9.381846432733393 train: [0.7543436107652994, tensor(0.4317, device='cuda:0')]\n",
            "9.381975916094781 train: [0.7542483334370415, tensor(0.4317, device='cuda:0')]\n",
            "9.38210539945617 train: [0.7544846524613027, tensor(0.4316, device='cuda:0')]\n",
            "9.382234882817558 train: [0.754559678058072, tensor(0.4316, device='cuda:0')]\n",
            "9.382364366178946 train: [0.7543029377797262, tensor(0.4318, device='cuda:0')]\n",
            "9.382493849540333 train: [0.7540463721546311, tensor(0.4320, device='cuda:0')]\n",
            "9.382623332901723 train: [0.7542817232495488, tensor(0.4318, device='cuda:0')]\n",
            "9.38275281626311 train: [0.7541880911565916, tensor(0.4318, device='cuda:0')]\n",
            "9.382882299624498 train: [0.7544227236565253, tensor(0.4317, device='cuda:0')]\n",
            "9.383011782985886 train: [0.7541664659378919, tensor(0.4319, device='cuda:0')]\n",
            "9.383141266347275 train: [0.7544003852683818, tensor(0.4317, device='cuda:0')]\n",
            "9.383270749708663 train: [0.7543085229646457, tensor(0.4318, device='cuda:0')]\n",
            "9.38340023307005 train: [0.7542169779077811, tensor(0.4318, device='cuda:0')]\n",
            "9.383529716431438 train: [0.7541254439939724, tensor(0.4318, device='cuda:0')]\n",
            "9.383659199792827 train: [0.7540336664808148, tensor(0.4318, device='cuda:0')]\n",
            "9.383788683154215 train: [0.7539413909713168, tensor(0.4319, device='cuda:0')]\n",
            "9.383918166515603 train: [0.7538484652366864, tensor(0.4319, device='cuda:0')]\n",
            "9.38404764987699 train: [0.7537546863599646, tensor(0.4319, device='cuda:0')]\n",
            "9.38417713323838 train: [0.7536599025762588, tensor(0.4319, device='cuda:0')]\n",
            "9.384306616599767 train: [0.7535640131861622, tensor(0.4320, device='cuda:0')]\n",
            "9.384436099961155 train: [0.7534669176265781, tensor(0.4320, device='cuda:0')]\n",
            "9.384565583322543 train: [0.7533685662960602, tensor(0.4320, device='cuda:0')]\n",
            "9.384695066683932 train: [0.7532689096602586, tensor(0.4320, device='cuda:0')]\n",
            "9.38482455004532 train: [0.7531678982518073, tensor(0.4320, device='cuda:0')]\n",
            "9.384954033406707 train: [0.753065584218291, tensor(0.4321, device='cuda:0')]\n",
            "9.385083516768095 train: [0.7528111701695686, tensor(0.4323, device='cuda:0')]\n",
            "9.385213000129484 train: [0.7527064579923622, tensor(0.4323, device='cuda:0')]\n",
            "9.385342483490872 train: [0.75280161289799, tensor(0.4323, device='cuda:0')]\n",
            "9.38547196685226 train: [0.7526950478173109, tensor(0.4323, device='cuda:0')]\n",
            "9.385601450213647 train: [0.7525877943170611, tensor(0.4324, device='cuda:0')]\n",
            "9.385730933575035 train: [0.7524798024224932, tensor(0.4324, device='cuda:0')]\n",
            "9.385860416936424 train: [0.7523710222262565, tensor(0.4324, device='cuda:0')]\n",
            "9.385989900297812 train: [0.7522614545254207, tensor(0.4324, device='cuda:0')]\n",
            "9.3861193836592 train: [0.7525086297105018, tensor(0.4323, device='cuda:0')]\n",
            "9.386248867020587 train: [0.7527561950248725, tensor(0.4321, device='cuda:0')]\n",
            "9.386378350381976 train: [0.7530039983164983, tensor(0.4320, device='cuda:0')]\n",
            "9.386507833743364 train: [0.7528922411840095, tensor(0.4320, device='cuda:0')]\n",
            "9.386637317104752 train: [0.7527803064984729, tensor(0.4320, device='cuda:0')]\n",
            "9.38676680046614 train: [0.752668042834226, tensor(0.4321, device='cuda:0')]\n",
            "9.386896283827529 train: [0.7527762139665564, tensor(0.4321, device='cuda:0')]\n",
            "9.387025767188916 train: [0.7526635221396251, tensor(0.4321, device='cuda:0')]\n",
            "9.387155250550304 train: [0.7524106110098738, tensor(0.4323, device='cuda:0')]\n",
            "9.387284733911692 train: [0.7521578697901863, tensor(0.4325, device='cuda:0')]\n",
            "9.387414217273081 train: [0.7524068731595805, tensor(0.4323, device='cuda:0')]\n",
            "9.387543700634469 train: [0.7525159086360936, tensor(0.4324, device='cuda:0')]\n",
            "9.387673183995856 train: [0.7524034428239545, tensor(0.4324, device='cuda:0')]\n",
            "9.387802667357244 train: [0.7522912540642015, tensor(0.4324, device='cuda:0')]\n",
            "9.387932150718633 train: [0.7521791909308415, tensor(0.4324, device='cuda:0')]\n",
            "9.388061634080021 train: [0.7519270356539622, tensor(0.4326, device='cuda:0')]\n",
            "9.388191117441409 train: [0.7518151193383945, tensor(0.4326, device='cuda:0')]\n",
            "9.388320600802796 train: [0.7517031773450586, tensor(0.4327, device='cuda:0')]\n",
            "9.388450084164186 train: [0.7514514348208305, tensor(0.4329, device='cuda:0')]\n",
            "9.388579567525573 train: [0.7513392871513739, tensor(0.4329, device='cuda:0')]\n",
            "9.38870905088696 train: [0.7515878819766244, tensor(0.4327, device='cuda:0')]\n",
            "9.388838534248348 train: [0.7518363607265101, tensor(0.4326, device='cuda:0')]\n",
            "9.388968017609738 train: [0.7515849104386416, tensor(0.4328, device='cuda:0')]\n",
            "9.389097500971125 train: [0.7514727676619603, tensor(0.4328, device='cuda:0')]\n",
            "9.389226984332513 train: [0.751360699847028, tensor(0.4328, device='cuda:0')]\n",
            "9.3893564676939 train: [0.7511096605219872, tensor(0.4330, device='cuda:0')]\n",
            "9.38948595105529 train: [0.7509975881249679, tensor(0.4330, device='cuda:0')]\n",
            "9.389615434416678 train: [0.7512459166720175, tensor(0.4329, device='cuda:0')]\n",
            "9.389744917778065 train: [0.7511336730223631, tensor(0.4329, device='cuda:0')]\n",
            "9.389874401139453 train: [0.7510214040161957, tensor(0.4329, device='cuda:0')]\n",
            "9.390003884500842 train: [0.7507708965432083, tensor(0.4331, device='cuda:0')]\n",
            "9.39013336786223 train: [0.7506584726960269, tensor(0.4331, device='cuda:0')]\n",
            "9.390262851223618 train: [0.7509071514423077, tensor(0.4330, device='cuda:0')]\n",
            "9.390392334585005 train: [0.7507944567355753, tensor(0.4330, device='cuda:0')]\n",
            "9.390521817946395 train: [0.7506816869683032, tensor(0.4330, device='cuda:0')]\n",
            "9.390651301307782 train: [0.7505687921853788, tensor(0.4331, device='cuda:0')]\n",
            "9.39078078466917 train: [0.7508179198568575, tensor(0.4329, device='cuda:0')]\n",
            "9.390910268030558 train: [0.750704604905286, tensor(0.4329, device='cuda:0')]\n",
            "9.391039751391947 train: [0.7505911654255591, tensor(0.4330, device='cuda:0')]\n",
            "9.391169234753335 train: [0.7504775016148219, tensor(0.4330, device='cuda:0')]\n",
            "9.391298718114722 train: [0.7502280077645509, tensor(0.4332, device='cuda:0')]\n",
            "9.39142820147611 train: [0.750478033048291, tensor(0.4330, device='cuda:0')]\n",
            "9.391557684837498 train: [0.7503638213167646, tensor(0.4331, device='cuda:0')]\n",
            "9.391687168198887 train: [0.7502494858595407, tensor(0.4331, device='cuda:0')]\n",
            "9.391816651560275 train: [0.7504998036699356, tensor(0.4329, device='cuda:0')]\n",
            "9.391946134921662 train: [0.7503851499272384, tensor(0.4330, device='cuda:0')]\n",
            "9.39207561828305 train: [0.7502704227228064, tensor(0.4330, device='cuda:0')]\n",
            "9.39220510164444 train: [0.7505209828262533, tensor(0.4328, device='cuda:0')]\n",
            "9.392334585005827 train: [0.7507714265902367, tensor(0.4327, device='cuda:0')]\n",
            "9.392464068367214 train: [0.7506564862414268, tensor(0.4327, device='cuda:0')]\n",
            "9.392593551728602 train: [0.7505415722810572, tensor(0.4327, device='cuda:0')]\n",
            "9.392723035089992 train: [0.7507918101224298, tensor(0.4326, device='cuda:0')]\n",
            "9.39285251845138 train: [0.7505432035627866, tensor(0.4328, device='cuda:0')]\n",
            "9.392982001812767 train: [0.7502947615887505, tensor(0.4330, device='cuda:0')]\n",
            "9.393111485174154 train: [0.7505446338231176, tensor(0.4328, device='cuda:0')]\n",
            "9.393240968535544 train: [0.7502963557437848, tensor(0.4330, device='cuda:0')]\n",
            "9.393370451896931 train: [0.7505456150475682, tensor(0.4329, device='cuda:0')]\n",
            "9.393499935258319 train: [0.7507943618881119, tensor(0.4327, device='cuda:0')]\n",
            "9.393629418619707 train: [0.7509076485364025, tensor(0.4327, device='cuda:0')]\n",
            "9.393758901981096 train: [0.7507950282394348, tensor(0.4328, device='cuda:0')]\n",
            "9.393888385342484 train: [0.7509058582238848, tensor(0.4328, device='cuda:0')]\n",
            "9.394017868703871 train: [0.7511517768145111, tensor(0.4327, device='cuda:0')]\n",
            "9.394147352065259 train: [0.7512592425107896, tensor(0.4327, device='cuda:0')]\n",
            "9.394276835426648 train: [0.7511499263222343, tensor(0.4327, device='cuda:0')]\n",
            "9.394406318788036 train: [0.7513928948586869, tensor(0.4326, device='cuda:0')]\n",
            "9.394535802149424 train: [0.7512854394925055, tensor(0.4326, device='cuda:0')]\n",
            "9.394665285510811 train: [0.7513856877662137, tensor(0.4326, device='cuda:0')]\n",
            "9.3947947688722 train: [0.7512800876790013, tensor(0.4326, device='cuda:0')]\n",
            "9.394924252233588 train: [0.751519625076011, tensor(0.4325, device='cuda:0')]\n",
            "9.395053735594976 train: [0.7517582132069857, tensor(0.4323, device='cuda:0')]\n",
            "9.395183218956364 train: [0.7519958035556034, tensor(0.4322, device='cuda:0')]\n",
            "9.395312702317753 train: [0.7520867049668413, tensor(0.4322, device='cuda:0')]\n",
            "9.39544218567914 train: [0.752322004681174, tensor(0.4321, device='cuda:0')]\n",
            "9.395571669040528 train: [0.7522231229289454, tensor(0.4321, device='cuda:0')]\n",
            "9.395701152401916 train: [0.752125491516209, tensor(0.4321, device='cuda:0')]\n",
            "9.395830635763305 train: [0.7518783257286584, tensor(0.4323, device='cuda:0')]\n",
            "9.395960119124693 train: [0.7521101271890478, tensor(0.4322, device='cuda:0')]\n",
            "9.39608960248608 train: [0.7518631287893142, tensor(0.4323, device='cuda:0')]\n",
            "9.396219085847468 train: [0.7517692950875045, tensor(0.4324, device='cuda:0')]\n",
            "9.396348569208858 train: [0.7519991783374568, tensor(0.4322, device='cuda:0')]\n",
            "9.396478052570245 train: [0.7519066924401878, tensor(0.4323, device='cuda:0')]\n",
            "9.396607535931633 train: [0.7519810640941544, tensor(0.4323, device='cuda:0')]\n",
            "9.39673701929302 train: [0.751734512925599, tensor(0.4325, device='cuda:0')]\n",
            "9.396866502654408 train: [0.7519622841974889, tensor(0.4323, device='cuda:0')]\n",
            "9.396995986015797 train: [0.7521892662598296, tensor(0.4322, device='cuda:0')]\n",
            "9.397125469377185 train: [0.7519428891663937, tensor(0.4324, device='cuda:0')]\n",
            "9.397254952738573 train: [0.7516966734201048, tensor(0.4325, device='cuda:0')]\n",
            "9.39738443609996 train: [0.7516106949515297, tensor(0.4326, device='cuda:0')]\n",
            "9.39751391946135 train: [0.75152536270074, tensor(0.4326, device='cuda:0')]\n",
            "9.397643402822737 train: [0.7515890488569739, tensor(0.4326, device='cuda:0')]\n",
            "9.397772886184125 train: [0.7513432708815465, tensor(0.4328, device='cuda:0')]\n",
            "9.397902369545513 train: [0.751259730508336, tensor(0.4328, device='cuda:0')]\n",
            "9.398031852906902 train: [0.7511765393256662, tensor(0.4328, device='cuda:0')]\n",
            "9.39816133626829 train: [0.7513998712870354, tensor(0.4327, device='cuda:0')]\n",
            "9.398290819629677 train: [0.7513167377405416, tensor(0.4327, device='cuda:0')]\n",
            "9.398420302991065 train: [0.7515398781046736, tensor(0.4326, device='cuda:0')]\n",
            "9.398549786352454 train: [0.7512945974656056, tensor(0.4328, device='cuda:0')]\n",
            "9.398679269713842 train: [0.7515175504297904, tensor(0.4326, device='cuda:0')]\n",
            "9.39880875307523 train: [0.7514347319703698, tensor(0.4326, device='cuda:0')]\n",
            "9.398938236436617 train: [0.7513518695449073, tensor(0.4327, device='cuda:0')]\n",
            "9.399067719798007 train: [0.7512686693755641, tensor(0.4327, device='cuda:0')]\n",
            "9.399197203159394 train: [0.7514918297428378, tensor(0.4326, device='cuda:0')]\n",
            "9.399326686520782 train: [0.7514075126064896, tensor(0.4326, device='cuda:0')]\n",
            "9.39945616988217 train: [0.7516310694962803, tensor(0.4324, device='cuda:0')]\n",
            "9.399585653243559 train: [0.7515457348945813, tensor(0.4325, device='cuda:0')]\n",
            "9.399715136604947 train: [0.7517697368832762, tensor(0.4323, device='cuda:0')]\n",
            "9.399844619966334 train: [0.7515251793891697, tensor(0.4325, device='cuda:0')]\n",
            "9.399974103327722 train: [0.751280780956848, tensor(0.4327, device='cuda:0')]\n",
            "9.400103586689111 train: [0.7511941570752476, tensor(0.4327, device='cuda:0')]\n",
            "9.400233070050499 train: [0.7509500250774981, tensor(0.4329, device='cuda:0')]\n",
            "9.400362553411886 train: [0.7511749305711751, tensor(0.4327, device='cuda:0')]\n",
            "9.400492036773274 train: [0.7510873519749169, tensor(0.4328, device='cuda:0')]\n",
            "9.400621520134663 train: [0.7509993912337662, tensor(0.4328, device='cuda:0')]\n",
            "9.400751003496051 train: [0.7512248419281952, tensor(0.4327, device='cuda:0')]\n",
            "9.400880486857439 train: [0.7512955673919283, tensor(0.4327, device='cuda:0')]\n",
            "9.401009970218826 train: [0.7512067962648769, tensor(0.4327, device='cuda:0')]\n",
            "9.401139453580216 train: [0.7511179852744937, tensor(0.4327, device='cuda:0')]\n",
            "9.401268936941603 train: [0.75102889095811, tensor(0.4327, device='cuda:0')]\n",
            "9.401398420302991 train: [0.7512546970811107, tensor(0.4326, device='cuda:0')]\n",
            "9.401527903664379 train: [0.7513271964005382, tensor(0.4326, device='cuda:0')]\n",
            "9.401657387025768 train: [0.7512374397481566, tensor(0.4326, device='cuda:0')]\n",
            "9.401786870387156 train: [0.7509942421308863, tensor(0.4328, device='cuda:0')]\n",
            "9.401916353748543 train: [0.7512198644044062, tensor(0.4327, device='cuda:0')]\n",
            "9.402045837109931 train: [0.7511303754075106, tensor(0.4327, device='cuda:0')]\n",
            "9.40217532047132 train: [0.7513557591240422, tensor(0.4326, device='cuda:0')]\n",
            "9.402304803832708 train: [0.7515808999539904, tensor(0.4324, device='cuda:0')]\n",
            "9.402434287194096 train: [0.7516519158513997, tensor(0.4324, device='cuda:0')]\n",
            "9.402563770555483 train: [0.7518760873617497, tensor(0.4323, device='cuda:0')]\n",
            "9.40269325391687 train: [0.7517886661293729, tensor(0.4323, device='cuda:0')]\n",
            "9.40282273727826 train: [0.7520116784853829, tensor(0.4322, device='cuda:0')]\n",
            "9.402952220639648 train: [0.7519256278088842, tensor(0.4322, device='cuda:0')]\n",
            "9.403081704001035 train: [0.7516829928854221, tensor(0.4324, device='cuda:0')]\n",
            "9.403211187362423 train: [0.7519049511476427, tensor(0.4323, device='cuda:0')]\n",
            "9.403340670723813 train: [0.7519685802346637, tensor(0.4323, device='cuda:0')]\n",
            "9.4034701540852 train: [0.7518849792162624, tensor(0.4323, device='cuda:0')]\n",
            "9.403599637446588 train: [0.7518020615130518, tensor(0.4323, device='cuda:0')]\n",
            "9.403729120807975 train: [0.7517194392471253, tensor(0.4323, device='cuda:0')]\n",
            "9.403858604169365 train: [0.7519396251393534, tensor(0.4322, device='cuda:0')]\n",
            "9.403988087530752 train: [0.7518571085275397, tensor(0.4322, device='cuda:0')]\n",
            "9.40411757089214 train: [0.7519178255211557, tensor(0.4322, device='cuda:0')]\n",
            "9.404247054253528 train: [0.7516758957188645, tensor(0.4324, device='cuda:0')]\n",
            "9.404376537614917 train: [0.7515940751261845, tensor(0.4325, device='cuda:0')]\n",
            "9.404506020976305 train: [0.7518135608613653, tensor(0.4323, device='cuda:0')]\n",
            "9.404635504337692 train: [0.7520327606137033, tensor(0.4322, device='cuda:0')]\n",
            "9.40476498769908 train: [0.7519515801117264, tensor(0.4322, device='cuda:0')]\n",
            "9.40489447106047 train: [0.7521703533877783, tensor(0.4321, device='cuda:0')]\n",
            "9.405023954421857 train: [0.7523888414140852, tensor(0.4319, device='cuda:0')]\n",
            "9.405153437783245 train: [0.7524458073527596, tensor(0.4319, device='cuda:0')]\n",
            "9.405282921144632 train: [0.7522043292374346, tensor(0.4321, device='cuda:0')]\n",
            "9.405412404506022 train: [0.7521259231324499, tensor(0.4321, device='cuda:0')]\n",
            "9.40554188786741 train: [0.7521793047194948, tensor(0.4322, device='cuda:0')]\n",
            "9.405671371228797 train: [0.7521024501658569, tensor(0.4322, device='cuda:0')]\n",
            "9.405800854590185 train: [0.7518613916882396, tensor(0.4324, device='cuda:0')]\n",
            "9.405930337951574 train: [0.7519116295781677, tensor(0.4324, device='cuda:0')]\n",
            "9.406059821312962 train: [0.7516707866474893, tensor(0.4326, device='cuda:0')]\n",
            "9.40618930467435 train: [0.7518852931260622, tensor(0.4324, device='cuda:0')]\n",
            "9.406318788035737 train: [0.7519308101669457, tensor(0.4325, device='cuda:0')]\n",
            "9.406448271397126 train: [0.7516901923076923, tensor(0.4326, device='cuda:0')]\n",
            "9.406577754758514 train: [0.751449728394606, tensor(0.4328, device='cuda:0')]\n",
            "9.406707238119902 train: [0.7516616288652186, tensor(0.4327, device='cuda:0')]\n",
            "9.40683672148129 train: [0.7516986097192848, tensor(0.4327, device='cuda:0')]\n",
            "9.406966204842679 train: [0.7516344943856479, tensor(0.4327, device='cuda:0')]\n",
            "9.407095688204066 train: [0.751571764023716, tensor(0.4327, device='cuda:0')]\n",
            "9.407225171565454 train: [0.7517812914588605, tensor(0.4326, device='cuda:0')]\n",
            "9.407354654926841 train: [0.7515412591180372, tensor(0.4328, device='cuda:0')]\n",
            "9.40748413828823 train: [0.7517500870847553, tensor(0.4327, device='cuda:0')]\n",
            "9.407613621649618 train: [0.7516907076849443, tensor(0.4327, device='cuda:0')]\n",
            "9.407743105011006 train: [0.7516317016317017, tensor(0.4327, device='cuda:0')]\n",
            "9.407872588372394 train: [0.7516594951156544, tensor(0.4327, device='cuda:0')]\n",
            "9.408002071733781 train: [0.7516008239897256, tensor(0.4327, device='cuda:0')]\n",
            "9.40813155509517 train: [0.7515421423800068, tensor(0.4328, device='cuda:0')]\n",
            "9.408261038456558 train: [0.7514829716715269, tensor(0.4328, device='cuda:0')]\n",
            "9.408390521817946 train: [0.751691352661073, tensor(0.4326, device='cuda:0')]\n",
            "9.408520005179334 train: [0.7518998401262459, tensor(0.4325, device='cuda:0')]\n",
            "9.408649488540723 train: [0.7518386037647505, tensor(0.4325, device='cuda:0')]\n",
            "9.40877897190211 train: [0.7515993932640299, tensor(0.4327, device='cuda:0')]\n",
            "9.408908455263498 train: [0.7515367144683401, tensor(0.4327, device='cuda:0')]\n",
            "9.409037938624886 train: [0.7517460369022869, tensor(0.4326, device='cuda:0')]\n",
            "9.409167421986275 train: [0.7515070839344222, tensor(0.4328, device='cuda:0')]\n",
            "9.409296905347663 train: [0.7515431267721395, tensor(0.4328, device='cuda:0')]\n",
            "9.40942638870905 train: [0.7517527726700713, tensor(0.4327, device='cuda:0')]\n",
            "9.409555872070438 train: [0.7519621899962137, tensor(0.4325, device='cuda:0')]\n",
            "9.409685355431828 train: [0.7521713312728938, tensor(0.4324, device='cuda:0')]\n",
            "9.409814838793215 train: [0.7522054487433781, tensor(0.4324, device='cuda:0')]\n",
            "9.409944322154603 train: [0.7524137604939477, tensor(0.4323, device='cuda:0')]\n",
            "9.41007380551599 train: [0.7523520506263875, tensor(0.4323, device='cuda:0')]\n",
            "9.41020328887738 train: [0.7523820770175845, tensor(0.4323, device='cuda:0')]\n",
            "9.410332772238768 train: [0.7525891346915763, tensor(0.4322, device='cuda:0')]\n",
            "9.410462255600155 train: [0.7527956327081505, tensor(0.4320, device='cuda:0')]\n",
            "9.410591738961543 train: [0.7527383534910211, tensor(0.4321, device='cuda:0')]\n",
            "9.410721222322932 train: [0.7526818241675598, tensor(0.4321, device='cuda:0')]\n",
            "9.41085070568432 train: [0.7524435583162881, tensor(0.4323, device='cuda:0')]\n",
            "9.410980189045707 train: [0.7526491278450584, tensor(0.4321, device='cuda:0')]\n",
            "9.411109672407095 train: [0.7526722445884944, tensor(0.4321, device='cuda:0')]\n",
            "9.411239155768484 train: [0.7528772791684912, tensor(0.4320, device='cuda:0')]\n",
            "9.411368639129872 train: [0.7528977916990929, tensor(0.4320, device='cuda:0')]\n",
            "9.41149812249126 train: [0.7531019606085286, tensor(0.4319, device='cuda:0')]\n",
            "9.411627605852647 train: [0.753118401765099, tensor(0.4319, device='cuda:0')]\n",
            "9.411757089214037 train: [0.7533214703854658, tensor(0.4318, device='cuda:0')]\n",
            "9.411886572575424 train: [0.753083604433339, tensor(0.4320, device='cuda:0')]\n",
            "9.412016055936812 train: [0.753092637614122, tensor(0.4320, device='cuda:0')]\n",
            "9.4121455392982 train: [0.7532942894810302, tensor(0.4318, device='cuda:0')]\n",
            "9.412275022659589 train: [0.753254386829653, tensor(0.4319, device='cuda:0')]\n",
            "9.412404506020977 train: [0.7532159781099144, tensor(0.4319, device='cuda:0')]\n",
            "9.412533989382364 train: [0.752978520361456, tensor(0.4321, device='cuda:0')]\n",
            "9.412663472743752 train: [0.752941548582996, tensor(0.4321, device='cuda:0')]\n",
            "9.412792956105141 train: [0.752904552766468, tensor(0.4321, device='cuda:0')]\n",
            "9.412922439466529 train: [0.7529057200181708, tensor(0.4321, device='cuda:0')]\n",
            "9.413051922827917 train: [0.7531063240227185, tensor(0.4320, device='cuda:0')]\n",
            "9.413181406189304 train: [0.7533067544520714, tensor(0.4319, device='cuda:0')]\n",
            "9.413310889550694 train: [0.7532696430084233, tensor(0.4319, device='cuda:0')]\n",
            "9.413440372912081 train: [0.753232224090788, tensor(0.4319, device='cuda:0')]\n",
            "9.413569856273469 train: [0.753193883798984, tensor(0.4319, device='cuda:0')]\n",
            "9.413699339634856 train: [0.7531541506964429, tensor(0.4319, device='cuda:0')]\n",
            "9.413828822996244 train: [0.7533548649555191, tensor(0.4318, device='cuda:0')]\n",
            "9.413958306357634 train: [0.7533118021822663, tensor(0.4318, device='cuda:0')]\n",
            "9.414087789719021 train: [0.7533212373465887, tensor(0.4318, device='cuda:0')]\n",
            "9.414217273080409 train: [0.7532753818983214, tensor(0.4319, device='cuda:0')]\n",
            "9.414346756441796 train: [0.7534768907087498, tensor(0.4317, device='cuda:0')]\n",
            "9.414476239803186 train: [0.7534285166904009, tensor(0.4318, device='cuda:0')]\n",
            "9.414605723164573 train: [0.7533786649605492, tensor(0.4318, device='cuda:0')]\n",
            "9.414735206525961 train: [0.7533270542369201, tensor(0.4318, device='cuda:0')]\n",
            "9.414864689887349 train: [0.7532734506872438, tensor(0.4318, device='cuda:0')]\n",
            "9.414994173248738 train: [0.7532965311091291, tensor(0.4318, device='cuda:0')]\n",
            "9.415123656610126 train: [0.7530605359552728, tensor(0.4320, device='cuda:0')]\n",
            "9.415253139971513 train: [0.7530869623154015, tensor(0.4320, device='cuda:0')]\n",
            "9.415382623332901 train: [0.7532910828897934, tensor(0.4319, device='cuda:0')]\n",
            "9.41551210669429 train: [0.7532320727248104, tensor(0.4319, device='cuda:0')]\n",
            "9.415641590055678 train: [0.7531724413630019, tensor(0.4319, device='cuda:0')]\n",
            "9.415771073417066 train: [0.7531119074222228, tensor(0.4320, device='cuda:0')]\n",
            "9.415900556778453 train: [0.7530501428927936, tensor(0.4320, device='cuda:0')]\n",
            "9.416030040139843 train: [0.7530832858675788, tensor(0.4320, device='cuda:0')]\n",
            "9.41615952350123 train: [0.7532888089693509, tensor(0.4319, device='cuda:0')]\n",
            "9.416289006862618 train: [0.7530534797569269, tensor(0.4321, device='cuda:0')]\n",
            "9.416418490224006 train: [0.753259259161942, tensor(0.4319, device='cuda:0')]\n",
            "9.416547973585395 train: [0.7531941678024208, tensor(0.4319, device='cuda:0')]\n",
            "9.416677456946783 train: [0.753230590292783, tensor(0.4320, device='cuda:0')]\n",
            "9.41680694030817 train: [0.7531650328513141, tensor(0.4320, device='cuda:0')]\n",
            "9.416936423669558 train: [0.7530992351330438, tensor(0.4320, device='cuda:0')]\n",
            "9.417065907030947 train: [0.7533052884615384, tensor(0.4319, device='cuda:0')]\n",
            "9.417195390392335 train: [0.7533433637211059, tensor(0.4319, device='cuda:0')]\n",
            "9.417324873753723 train: [0.753276729211113, tensor(0.4319, device='cuda:0')]\n",
            "9.41745435711511 train: [0.7534827218877307, tensor(0.4318, device='cuda:0')]\n",
            "9.4175838404765 train: [0.7532480651696093, tensor(0.4320, device='cuda:0')]\n",
            "9.417713323837887 train: [0.7531814290161893, tensor(0.4320, device='cuda:0')]\n",
            "9.417842807199275 train: [0.753114507020757, tensor(0.4320, device='cuda:0')]\n",
            "9.417972290560662 train: [0.7531537859455029, tensor(0.4320, device='cuda:0')]\n",
            "9.418101773922052 train: [0.7533598236182558, tensor(0.4319, device='cuda:0')]\n",
            "9.41823125728344 train: [0.7532924414137246, tensor(0.4319, device='cuda:0')]\n",
            "9.418360740644827 train: [0.7530582815003228, tensor(0.4321, device='cuda:0')]\n",
            "9.418490224006215 train: [0.7530978558857627, tensor(0.4321, device='cuda:0')]\n",
            "9.418619707367604 train: [0.7530306178608981, tensor(0.4321, device='cuda:0')]\n",
            "9.418749190728992 train: [0.7530696630136168, tensor(0.4321, device='cuda:0')]\n",
            "9.41887867409038 train: [0.7530029885755738, tensor(0.4322, device='cuda:0')]\n",
            "9.419008157451767 train: [0.7529364954131452, tensor(0.4322, device='cuda:0')]\n",
            "9.419137640813155 train: [0.7531418560108833, tensor(0.4321, device='cuda:0')]\n",
            "9.419267124174544 train: [0.7530751280212111, tensor(0.4321, device='cuda:0')]\n",
            "9.419396607535932 train: [0.7528416163536076, tensor(0.4322, device='cuda:0')]\n",
            "9.419655574258707 train: [0.752608249454552, tensor(0.4324, device='cuda:0')]\n",
            "9.419785057620096 train: [0.752813829676289, tensor(0.4323, device='cuda:0')]\n",
            "9.419914540981484 train: [0.7525806159744066, tensor(0.4325, device='cuda:0')]\n",
            "9.420044024342872 train: [0.7525132345540415, tensor(0.4325, device='cuda:0')]\n",
            "9.42017350770426 train: [0.7522802583204334, tensor(0.4327, device='cuda:0')]\n",
            "9.420302991065649 train: [0.7524859645441992, tensor(0.4325, device='cuda:0')]\n",
            "9.420432474427036 train: [0.7524179776751714, tensor(0.4325, device='cuda:0')]\n",
            "9.420561957788424 train: [0.7521852470912941, tensor(0.4327, device='cuda:0')]\n",
            "9.420691441149811 train: [0.7523911635239761, tensor(0.4326, device='cuda:0')]\n",
            "9.420820924511201 train: [0.7523223866068244, tensor(0.4326, device='cuda:0')]\n",
            "9.420950407872589 train: [0.7522532343467719, tensor(0.4326, device='cuda:0')]\n",
            "9.421079891233976 train: [0.7522969095316175, tensor(0.4327, device='cuda:0')]\n",
            "9.421209374595364 train: [0.7522269726683137, tensor(0.4327, device='cuda:0')]\n",
            "9.421338857956753 train: [0.7521566615259933, tensor(0.4327, device='cuda:0')]\n",
            "9.42146834131814 train: [0.7520857445987654, tensor(0.4327, device='cuda:0')]\n",
            "9.421597824679528 train: [0.7522927303865141, tensor(0.4326, device='cuda:0')]\n",
            "9.421727308040916 train: [0.752499866535377, tensor(0.4324, device='cuda:0')]\n",
            "9.421856791402305 train: [0.752427056278019, tensor(0.4325, device='cuda:0')]\n",
            "9.421986274763693 train: [0.7523536425234753, tensor(0.4325, device='cuda:0')]\n",
            "9.42211575812508 train: [0.752279486932559, tensor(0.4325, device='cuda:0')]\n",
            "9.422245241486468 train: [0.7524877604536945, tensor(0.4324, device='cuda:0')]\n",
            "9.422374724847858 train: [0.7525403904639786, tensor(0.4324, device='cuda:0')]\n",
            "9.422504208209245 train: [0.7525932656042772, tensor(0.4324, device='cuda:0')]\n",
            "9.422633691570633 train: [0.7528015739310321, tensor(0.4323, device='cuda:0')]\n",
            "9.42276317493202 train: [0.7525699426775148, tensor(0.4325, device='cuda:0')]\n",
            "9.42289265829341 train: [0.7527776678921279, tensor(0.4323, device='cuda:0')]\n",
            "9.423022141654798 train: [0.7525461864444366, tensor(0.4325, device='cuda:0')]\n",
            "9.423151625016185 train: [0.7527532832119463, tensor(0.4324, device='cuda:0')]\n",
            "9.423281108377573 train: [0.7526801333270294, tensor(0.4324, device='cuda:0')]\n",
            "9.423410591738962 train: [0.7528866001270235, tensor(0.4323, device='cuda:0')]\n",
            "9.42354007510035 train: [0.7528141463688338, tensor(0.4323, device='cuda:0')]\n",
            "9.423669558461738 train: [0.7528613481908788, tensor(0.4323, device='cuda:0')]\n",
            "9.423799041823125 train: [0.7527896383753601, tensor(0.4323, device='cuda:0')]\n",
            "9.423928525184515 train: [0.7527182030678358, tensor(0.4323, device='cuda:0')]\n",
            "9.424058008545902 train: [0.7527643769909155, tensor(0.4324, device='cuda:0')]\n",
            "9.42418749190729 train: [0.7525335384821786, tensor(0.4325, device='cuda:0')]\n",
            "9.424316975268678 train: [0.7527386860055181, tensor(0.4324, device='cuda:0')]\n",
            "9.424446458630067 train: [0.7526685510178222, tensor(0.4324, device='cuda:0')]\n",
            "9.424575941991455 train: [0.7528732092671804, tensor(0.4323, device='cuda:0')]\n",
            "9.424705425352842 train: [0.75264262022912, tensor(0.4325, device='cuda:0')]\n",
            "9.42483490871423 train: [0.7528468850834943, tensor(0.4323, device='cuda:0')]\n",
            "9.424964392075617 train: [0.7527780445038967, tensor(0.4324, device='cuda:0')]\n",
            "9.425093875437007 train: [0.7527093380007768, tensor(0.4324, device='cuda:0')]\n",
            "9.425223358798394 train: [0.752640443737205, tensor(0.4324, device='cuda:0')]\n",
            "9.425352842159782 train: [0.7525710862150082, tensor(0.4324, device='cuda:0')]\n",
            "9.42548232552117 train: [0.7527754740816734, tensor(0.4323, device='cuda:0')]\n",
            "9.42561180888256 train: [0.7527048320099445, tensor(0.4323, device='cuda:0')]\n",
            "9.425741292243947 train: [0.7529096508584221, tensor(0.4322, device='cuda:0')]\n",
            "9.425870775605334 train: [0.752679684563108, tensor(0.4323, device='cuda:0')]\n",
            "9.426000258966722 train: [0.7527271726365238, tensor(0.4324, device='cuda:0')]\n",
            "9.426129742328111 train: [0.7524974024373062, tensor(0.4325, device='cuda:0')]\n",
            "9.426259225689499 train: [0.7525445962242671, tensor(0.4326, device='cuda:0')]\n",
            "9.426388709050887 train: [0.7524733288942601, tensor(0.4326, device='cuda:0')]\n",
            "9.426518192412274 train: [0.7524023341280175, tensor(0.4326, device='cuda:0')]\n",
            "9.426647675773664 train: [0.7521729431724906, tensor(0.4328, device='cuda:0')]\n",
            "9.426777159135051 train: [0.7519436920468666, tensor(0.4329, device='cuda:0')]\n",
            "9.426906642496439 train: [0.7521481811483383, tensor(0.4328, device='cuda:0')]\n",
            "9.427036125857827 train: [0.7520773719217883, tensor(0.4328, device='cuda:0')]\n",
            "9.427165609219216 train: [0.7520064685713951, tensor(0.4329, device='cuda:0')]\n",
            "9.427295092580604 train: [0.7519351967714554, tensor(0.4329, device='cuda:0')]\n",
            "9.427424575941991 train: [0.7518632825301981, tensor(0.4329, device='cuda:0')]\n",
            "9.427554059303379 train: [0.751790543604175, tensor(0.4329, device='cuda:0')]\n",
            "9.427683542664768 train: [0.7517167979716451, tensor(0.4329, device='cuda:0')]\n",
            "9.427813026026156 train: [0.7517692643894567, tensor(0.4330, device='cuda:0')]\n",
            "9.427942509387544 train: [0.7518226122281974, tensor(0.4330, device='cuda:0')]\n",
            "9.428071992748931 train: [0.752028998448566, tensor(0.4328, device='cuda:0')]\n",
            "9.42820147611032 train: [0.7519535357422422, tensor(0.4329, device='cuda:0')]\n",
            "9.428330959471708 train: [0.752159756856035, tensor(0.4327, device='cuda:0')]\n",
            "9.428460442833096 train: [0.7523658527596796, tensor(0.4326, device='cuda:0')]\n",
            "9.428589926194483 train: [0.7525717323742267, tensor(0.4325, device='cuda:0')]\n",
            "9.428719409555873 train: [0.7526241014749814, tensor(0.4325, device='cuda:0')]\n",
            "9.42884889291726 train: [0.7528291854774737, tensor(0.4324, device='cuda:0')]\n",
            "9.428978376278648 train: [0.7530337351162709, tensor(0.4322, device='cuda:0')]\n",
            "9.429107859640036 train: [0.7529610426090657, tensor(0.4323, device='cuda:0')]\n",
            "9.429237343001425 train: [0.752888986013986, tensor(0.4323, device='cuda:0')]\n",
            "9.429366826362813 train: [0.7528172006443269, tensor(0.4323, device='cuda:0')]\n",
            "9.4294963097242 train: [0.7530206871272656, tensor(0.4322, device='cuda:0')]\n",
            "9.429625793085588 train: [0.7532240049110366, tensor(0.4320, device='cuda:0')]\n",
            "9.429755276446977 train: [0.7534270632042745, tensor(0.4319, device='cuda:0')]\n",
            "9.429884759808365 train: [0.753355929244734, tensor(0.4319, device='cuda:0')]\n",
            "9.430014243169753 train: [0.7535585975673601, tensor(0.4318, device='cuda:0')]\n",
            "9.43014372653114 train: [0.7537610070276337, tensor(0.4317, device='cuda:0')]\n",
            "9.430273209892528 train: [0.7536905633051577, tensor(0.4317, device='cuda:0')]\n",
            "9.430402693253917 train: [0.753620207563289, tensor(0.4317, device='cuda:0')]\n",
            "9.430532176615305 train: [0.753549667383221, tensor(0.4317, device='cuda:0')]\n",
            "9.430661659976693 train: [0.7537519711393258, tensor(0.4316, device='cuda:0')]\n",
            "9.43079114333808 train: [0.7535243890224359, tensor(0.4318, device='cuda:0')]\n",
            "9.43092062669947 train: [0.7537268503738187, tensor(0.4316, device='cuda:0')]\n",
            "9.431050110060857 train: [0.753929189539715, tensor(0.4315, device='cuda:0')]\n",
            "9.431179593422245 train: [0.7537017599199443, tensor(0.4317, device='cuda:0')]\n",
            "9.431309076783633 train: [0.7536305525511506, tensor(0.4317, device='cuda:0')]\n",
            "9.431438560145022 train: [0.7535592069409337, tensor(0.4317, device='cuda:0')]\n",
            "9.43156804350641 train: [0.7533320944614458, tensor(0.4319, device='cuda:0')]\n",
            "9.431697526867797 train: [0.7533795712187406, tensor(0.4319, device='cuda:0')]\n",
            "9.431827010229185 train: [0.753581920832368, tensor(0.4318, device='cuda:0')]\n",
            "9.431956493590574 train: [0.7535103591220207, tensor(0.4318, device='cuda:0')]\n",
            "9.432085976951962 train: [0.7537123666379151, tensor(0.4317, device='cuda:0')]\n",
            "9.432344943674737 train: [0.753640989591773, tensor(0.4317, device='cuda:0')]\n",
            "9.432474427036126 train: [0.7534142624589234, tensor(0.4319, device='cuda:0')]\n",
            "9.432603910397514 train: [0.7533427468912667, tensor(0.4319, device='cuda:0')]\n",
            "9.432733393758902 train: [0.7535447877156668, tensor(0.4317, device='cuda:0')]\n",
            "9.43286287712029 train: [0.7537467974006381, tensor(0.4316, device='cuda:0')]\n",
            "9.432992360481679 train: [0.7536747497919749, tensor(0.4316, device='cuda:0')]\n",
            "9.433121843843066 train: [0.7538766893355593, tensor(0.4315, device='cuda:0')]\n",
            "9.433251327204454 train: [0.7540785527113653, tensor(0.4314, device='cuda:0')]\n",
            "9.433380810565842 train: [0.7542802497806157, tensor(0.4313, device='cuda:0')]\n",
            "9.433510293927231 train: [0.7543273469243467, tensor(0.4313, device='cuda:0')]\n",
            "9.433639777288619 train: [0.7542560445948441, tensor(0.4313, device='cuda:0')]\n",
            "9.433769260650006 train: [0.7544568309895713, tensor(0.4312, device='cuda:0')]\n",
            "9.434028227372783 train: [0.7542306070522431, tensor(0.4313, device='cuda:0')]\n",
            "9.434157710734171 train: [0.7541607489248986, tensor(0.4314, device='cuda:0')]\n",
            "9.434287194095559 train: [0.7539347492998086, tensor(0.4315, device='cuda:0')]\n",
            "9.434416677456946 train: [0.7538652917165968, tensor(0.4315, device='cuda:0')]\n",
            "9.434546160818336 train: [0.7540653995179349, tensor(0.4314, device='cuda:0')]\n",
            "9.434675644179723 train: [0.754109254447835, tensor(0.4314, device='cuda:0')]\n",
            "9.434805127541111 train: [0.7540401217824004, tensor(0.4315, device='cuda:0')]\n",
            "9.434934610902499 train: [0.7542397279093588, tensor(0.4313, device='cuda:0')]\n",
            "9.435064094263888 train: [0.7541710469925678, tensor(0.4313, device='cuda:0')]\n",
            "9.435193577625276 train: [0.7543703598005613, tensor(0.4312, device='cuda:0')]\n",
            "9.435323060986663 train: [0.7543017707255375, tensor(0.4312, device='cuda:0')]\n",
            "9.43545254434805 train: [0.7542330430422088, tensor(0.4313, device='cuda:0')]\n",
            "9.43558202770944 train: [0.7541639075463676, tensor(0.4313, device='cuda:0')]\n",
            "9.435711511070828 train: [0.754094095355436, tensor(0.4313, device='cuda:0')]\n",
            "9.435840994432215 train: [0.7540234276305212, tensor(0.4313, device='cuda:0')]\n",
            "9.435970477793603 train: [0.7537983460103329, tensor(0.4315, device='cuda:0')]\n",
            "9.43609996115499 train: [0.7537257463328971, tensor(0.4315, device='cuda:0')]\n",
            "9.43622944451638 train: [0.7535008878166881, tensor(0.4317, device='cuda:0')]\n",
            "9.436358927877768 train: [0.7534262693856248, tensor(0.4317, device='cuda:0')]\n",
            "9.436488411239155 train: [0.7534798969944039, tensor(0.4317, device='cuda:0')]\n",
            "9.436617894600543 train: [0.7534037171844549, tensor(0.4317, device='cuda:0')]\n",
            "9.436747377961932 train: [0.7536068436554506, tensor(0.4316, device='cuda:0')]\n",
            "9.43687686132332 train: [0.753529507802296, tensor(0.4316, device='cuda:0')]\n",
            "9.437006344684708 train: [0.7537331022071287, tensor(0.4315, device='cuda:0')]\n",
            "9.437135828046095 train: [0.7537908525030343, tensor(0.4315, device='cuda:0')]\n",
            "9.437265311407485 train: [0.7537125472184066, tensor(0.4315, device='cuda:0')]\n",
            "9.437394794768872 train: [0.7536341097258142, tensor(0.4316, device='cuda:0')]\n",
            "9.43752427813026 train: [0.7535553613920285, tensor(0.4316, device='cuda:0')]\n",
            "9.437653761491648 train: [0.7534760344472655, tensor(0.4316, device='cuda:0')]\n",
            "9.437783244853037 train: [0.7536806214556846, tensor(0.4315, device='cuda:0')]\n",
            "9.437912728214425 train: [0.7538853547548291, tensor(0.4314, device='cuda:0')]\n",
            "9.438042211575812 train: [0.7538046614333379, tensor(0.4314, device='cuda:0')]\n",
            "9.4381716949372 train: [0.7537235698293391, tensor(0.4314, device='cuda:0')]\n",
            "9.43830117829859 train: [0.7534997801708386, tensor(0.4316, device='cuda:0')]\n",
            "9.438430661659977 train: [0.753276123364614, tensor(0.4317, device='cuda:0')]\n",
            "9.438560145021365 train: [0.7531937450068478, tensor(0.4318, device='cuda:0')]\n",
            "9.438689628382752 train: [0.7533999519373389, tensor(0.4316, device='cuda:0')]\n",
            "9.438819111744142 train: [0.7533166946117347, tensor(0.4316, device='cuda:0')]\n",
            "9.43894859510553 train: [0.753523277326735, tensor(0.4315, device='cuda:0')]\n",
            "9.439078078466917 train: [0.7534393203399298, tensor(0.4315, device='cuda:0')]\n",
            "9.439207561828304 train: [0.7536461894586894, tensor(0.4314, device='cuda:0')]\n",
            "9.439337045189694 train: [0.753853114034588, tensor(0.4313, device='cuda:0')]\n",
            "9.439466528551081 train: [0.7537684221316143, tensor(0.4313, device='cuda:0')]\n",
            "9.439596011912469 train: [0.7539753659140593, tensor(0.4312, device='cuda:0')]\n",
            "9.439725495273857 train: [0.7541821872083229, tensor(0.4310, device='cuda:0')]\n",
            "9.439854978635246 train: [0.7540973842171143, tensor(0.4311, device='cuda:0')]\n",
            "9.439984461996634 train: [0.7540126313903488, tensor(0.4311, device='cuda:0')]\n",
            "9.440113945358021 train: [0.7539276621423373, tensor(0.4311, device='cuda:0')]\n",
            "9.440243428719409 train: [0.7537048044237022, tensor(0.4313, device='cuda:0')]\n",
            "9.440372912080798 train: [0.7537747452661847, tensor(0.4313, device='cuda:0')]\n",
            "9.440502395442186 train: [0.75384446724804, tensor(0.4313, device='cuda:0')]\n",
            "9.440631878803574 train: [0.7536218315518651, tensor(0.4315, device='cuda:0')]\n",
            "9.440761362164961 train: [0.7535373692682428, tensor(0.4315, device='cuda:0')]\n",
            "9.44089084552635 train: [0.7537435043649532, tensor(0.4314, device='cuda:0')]\n",
            "9.441020328887738 train: [0.7539493404850535, tensor(0.4312, device='cuda:0')]\n",
            "9.441149812249126 train: [0.7538658313478557, tensor(0.4313, device='cuda:0')]\n",
            "9.441279295610514 train: [0.7539319472642515, tensor(0.4313, device='cuda:0')]\n",
            "9.441408778971901 train: [0.7541366599294721, tensor(0.4312, device='cuda:0')]\n",
            "9.44153826233329 train: [0.7542005316375343, tensor(0.4312, device='cuda:0')]\n",
            "9.441667745694678 train: [0.7544039821404288, tensor(0.4311, device='cuda:0')]\n",
            "9.441797229056066 train: [0.75432417936445, tensor(0.4311, device='cuda:0')]\n",
            "9.441926712417454 train: [0.7542451314329075, tensor(0.4311, device='cuda:0')]\n",
            "9.442056195778843 train: [0.754446885402278, tensor(0.4310, device='cuda:0')]\n",
            "9.44218567914023 train: [0.754224858655544, tensor(0.4311, device='cuda:0')]\n",
            "9.442315162501618 train: [0.7542811658406319, tensor(0.4312, device='cuda:0')]\n",
            "9.442444645863006 train: [0.7542048748585973, tensor(0.4312, device='cuda:0')]\n",
            "9.442574129224395 train: [0.754404813064031, tensor(0.4310, device='cuda:0')]\n",
            "9.442703612585783 train: [0.7543299437830688, tensor(0.4311, device='cuda:0')]\n",
            "9.44283309594717 train: [0.754529109637424, tensor(0.4309, device='cuda:0')]\n",
            "9.442962579308558 train: [0.7545801249096086, tensor(0.4310, device='cuda:0')]\n",
            "9.443092062669947 train: [0.7546296982661245, tensor(0.4310, device='cuda:0')]\n",
            "9.443221546031335 train: [0.7548271891514974, tensor(0.4309, device='cuda:0')]\n",
            "9.443351029392723 train: [0.7550238585434964, tensor(0.4307, device='cuda:0')]\n",
            "9.44348051275411 train: [0.7549549349381546, tensor(0.4308, device='cuda:0')]\n",
            "9.4436099961155 train: [0.7551503056107137, tensor(0.4306, device='cuda:0')]\n",
            "9.443739479476887 train: [0.7551904748477329, tensor(0.4306, device='cuda:0')]\n",
            "9.443868962838275 train: [0.7551250866822272, tensor(0.4307, device='cuda:0')]\n",
            "9.443998446199663 train: [0.7549037721785102, tensor(0.4308, device='cuda:0')]\n",
            "9.444127929561052 train: [0.7548405312549302, tensor(0.4309, device='cuda:0')]\n",
            "9.44425741292244 train: [0.7550335369631833, tensor(0.4307, device='cuda:0')]\n",
            "9.444386896283827 train: [0.7548124436873522, tensor(0.4309, device='cuda:0')]\n",
            "9.444516379645215 train: [0.7550049048031886, tensor(0.4308, device='cuda:0')]\n",
            "9.444645863006604 train: [0.7551969894588145, tensor(0.4306, device='cuda:0')]\n",
            "9.444775346367992 train: [0.7549760424168429, tensor(0.4308, device='cuda:0')]\n",
            "9.44490482972938 train: [0.7547552246214593, tensor(0.4310, device='cuda:0')]\n",
            "9.445034313090767 train: [0.7546967252867747, tensor(0.4310, device='cuda:0')]\n",
            "9.445163796452157 train: [0.7546385236548018, tensor(0.4310, device='cuda:0')]\n",
            "9.445293279813544 train: [0.7548296444386998, tensor(0.4309, device='cuda:0')]\n",
            "9.445422763174932 train: [0.7547711746331378, tensor(0.4309, device='cuda:0')]\n",
            "9.44555224653632 train: [0.7547123879515636, tensor(0.4309, device='cuda:0')]\n",
            "9.445681729897709 train: [0.754652933745087, tensor(0.4309, device='cuda:0')]\n",
            "9.445811213259097 train: [0.7545924617742152, tensor(0.4310, device='cuda:0')]\n",
            "9.445940696620484 train: [0.7546260184956567, tensor(0.4310, device='cuda:0')]\n",
            "9.446070179981872 train: [0.7545638365609012, tensor(0.4310, device='cuda:0')]\n",
            "9.446199663343261 train: [0.7545008146017004, tensor(0.4310, device='cuda:0')]\n",
            "9.446329146704649 train: [0.7546937198643193, tensor(0.4309, device='cuda:0')]\n",
            "9.446458630066036 train: [0.754473756669955, tensor(0.4311, device='cuda:0')]\n",
            "9.446588113427424 train: [0.7544082770194549, tensor(0.4311, device='cuda:0')]\n",
            "9.446717596788814 train: [0.754602090989043, tensor(0.4310, device='cuda:0')]\n",
            "9.446847080150201 train: [0.754796054584248, tensor(0.4308, device='cuda:0')]\n",
            "9.446976563511589 train: [0.7548378715989251, tensor(0.4309, device='cuda:0')]\n",
            "9.447106046872976 train: [0.7550318285741471, tensor(0.4307, device='cuda:0')]\n",
            "9.447235530234364 train: [0.7552254978346501, tensor(0.4306, device='cuda:0')]\n",
            "9.447365013595753 train: [0.7551587776043764, tensor(0.4306, device='cuda:0')]\n",
            "9.447494496957141 train: [0.755352122570291, tensor(0.4305, device='cuda:0')]\n",
            "9.447623980318529 train: [0.7553920575245975, tensor(0.4305, device='cuda:0')]\n",
            "9.447753463679916 train: [0.7554310087072184, tensor(0.4305, device='cuda:0')]\n",
            "9.447882947041306 train: [0.7552115342712198, tensor(0.4307, device='cuda:0')]\n",
            "9.448012430402693 train: [0.7554032429232109, tensor(0.4306, device='cuda:0')]\n",
            "9.448141913764081 train: [0.7551839040025016, tensor(0.4307, device='cuda:0')]\n",
            "9.448271397125469 train: [0.7552167648208106, tensor(0.4308, device='cuda:0')]\n",
            "9.448400880486858 train: [0.7554069099066922, tensor(0.4306, device='cuda:0')]\n",
            "9.448530363848246 train: [0.7553485053893018, tensor(0.4307, device='cuda:0')]\n",
            "9.448659847209633 train: [0.7553759739481082, tensor(0.4307, device='cuda:0')]\n",
            "9.44878933057102 train: [0.7553200516593438, tensor(0.4307, device='cuda:0')]\n",
            "9.44891881393241 train: [0.7553444641861762, tensor(0.4307, device='cuda:0')]\n",
            "9.449048297293798 train: [0.7552908472739228, tensor(0.4307, device='cuda:0')]\n",
            "9.449177780655186 train: [0.7554783772227917, tensor(0.4306, device='cuda:0')]\n",
            "9.449307264016573 train: [0.7556655374924814, tensor(0.4305, device='cuda:0')]\n",
            "9.449436747377963 train: [0.7554467576611287, tensor(0.4307, device='cuda:0')]\n",
            "9.44956623073935 train: [0.755396652009351, tensor(0.4307, device='cuda:0')]\n",
            "9.449695714100738 train: [0.7554142183048433, tensor(0.4307, device='cuda:0')]\n",
            "9.449825197462125 train: [0.7553653679268374, tensor(0.4307, device='cuda:0')]\n",
            "9.449954680823515 train: [0.7551469279708146, tensor(0.4309, device='cuda:0')]\n",
            "9.450084164184902 train: [0.7553329038517135, tensor(0.4308, device='cuda:0')]\n",
            "9.45021364754629 train: [0.7552853351489551, tensor(0.4308, device='cuda:0')]\n",
            "9.450343130907678 train: [0.7552377071155513, tensor(0.4308, device='cuda:0')]\n",
            "9.450472614269067 train: [0.7552534662045061, tensor(0.4308, device='cuda:0')]\n",
            "9.450602097630455 train: [0.7554391965059197, tensor(0.4307, device='cuda:0')]\n",
            "9.450731580991842 train: [0.7552211135969977, tensor(0.4309, device='cuda:0')]\n",
            "9.45086106435323 train: [0.7551737325174825, tensor(0.4309, device='cuda:0')]\n",
            "9.45099054771462 train: [0.7551261186970127, tensor(0.4309, device='cuda:0')]\n",
            "9.451120031076007 train: [0.7549083147977635, tensor(0.4311, device='cuda:0')]\n",
            "9.451249514437395 train: [0.7548596785999467, tensor(0.4311, device='cuda:0')]\n",
            "9.451378997798782 train: [0.7548102042541632, tensor(0.4311, device='cuda:0')]\n",
            "9.451508481160172 train: [0.7545926796996232, tensor(0.4313, device='cuda:0')]\n",
            "9.45163796452156 train: [0.754779211128471, tensor(0.4311, device='cuda:0')]\n",
            "9.451767447882947 train: [0.7547266871233606, tensor(0.4312, device='cuda:0')]\n",
            "9.451896931244335 train: [0.7547498975614078, tensor(0.4312, device='cuda:0')]\n",
            "9.452026414605724 train: [0.7549369146074133, tensor(0.4311, device='cuda:0')]\n",
            "9.452155897967112 train: [0.7549610023519646, tensor(0.4311, device='cuda:0')]\n",
            "9.4522853813285 train: [0.7547438098886873, tensor(0.4312, device='cuda:0')]\n",
            "9.452414864689887 train: [0.7549305809052897, tensor(0.4311, device='cuda:0')]\n",
            "9.452544348051275 train: [0.754877326436502, tensor(0.4311, device='cuda:0')]\n",
            "9.452673831412664 train: [0.7546603453136401, tensor(0.4313, device='cuda:0')]\n",
            "9.452803314774052 train: [0.7548468929597701, tensor(0.4312, device='cuda:0')]\n",
            "9.45293279813544 train: [0.754630045245619, tensor(0.4313, device='cuda:0')]\n",
            "9.453062281496827 train: [0.7545771971512836, tensor(0.4314, device='cuda:0')]\n",
            "9.453191764858216 train: [0.7545241205912233, tensor(0.4314, device='cuda:0')]\n",
            "9.453321248219604 train: [0.7547106656528747, tensor(0.4313, device='cuda:0')]\n",
            "9.453450731580991 train: [0.7547347491998676, tensor(0.4313, device='cuda:0')]\n",
            "9.453580214942379 train: [0.7545182446820248, tensor(0.4314, device='cuda:0')]\n",
            "9.453709698303769 train: [0.7547046309368864, tensor(0.4313, device='cuda:0')]\n",
            "9.453839181665156 train: [0.754890824171886, tensor(0.4312, device='cuda:0')]\n",
            "9.453968665026544 train: [0.7546744610809798, tensor(0.4314, device='cuda:0')]\n",
            "9.454098148387931 train: [0.754860297966718, tensor(0.4312, device='cuda:0')]\n",
            "9.45422763174932 train: [0.755045942313201, tensor(0.4311, device='cuda:0')]\n",
            "9.454357115110708 train: [0.7549942450876729, tensor(0.4311, device='cuda:0')]\n",
            "9.454486598472096 train: [0.7550149233907375, tensor(0.4311, device='cuda:0')]\n",
            "9.454616081833484 train: [0.7550347298665845, tensor(0.4312, device='cuda:0')]\n",
            "9.454745565194873 train: [0.754984971662815, tensor(0.4312, device='cuda:0')]\n",
            "9.45487504855626 train: [0.7550025406783577, tensor(0.4312, device='cuda:0')]\n",
            "9.455004531917648 train: [0.7551866228745518, tensor(0.4311, device='cuda:0')]\n",
            "9.455134015279036 train: [0.7551396986464793, tensor(0.4311, device='cuda:0')]\n",
            "9.455263498640425 train: [0.7550934023732055, tensor(0.4311, device='cuda:0')]\n",
            "9.455392982001813 train: [0.7550472184065934, tensor(0.4311, device='cuda:0')]\n",
            "9.4555224653632 train: [0.755000717514776, tensor(0.4312, device='cuda:0')]\n",
            "9.455651948724588 train: [0.755016021064886, tensor(0.4312, device='cuda:0')]\n",
            "9.455781432085978 train: [0.7548004869452557, tensor(0.4313, device='cuda:0')]\n",
            "9.455910915447365 train: [0.7547532387436336, tensor(0.4314, device='cuda:0')]\n",
            "9.456040398808753 train: [0.7547055031274004, tensor(0.4314, device='cuda:0')]\n",
            "9.45616988217014 train: [0.7547226732195358, tensor(0.4314, device='cuda:0')]\n",
            "9.45629936553153 train: [0.7549065673597859, tensor(0.4313, device='cuda:0')]\n",
            "9.456428848892918 train: [0.7546913716450311, tensor(0.4314, device='cuda:0')]\n",
            "9.456558332254305 train: [0.7546426804974022, tensor(0.4315, device='cuda:0')]\n",
            "9.456687815615693 train: [0.7545935890587333, tensor(0.4315, device='cuda:0')]\n",
            "9.456817298977082 train: [0.7545437553403589, tensor(0.4315, device='cuda:0')]\n",
            "9.45694678233847 train: [0.7545641078116786, tensor(0.4315, device='cuda:0')]\n",
            "9.457076265699857 train: [0.7545128567792156, tensor(0.4315, device='cuda:0')]\n",
            "9.457205749061245 train: [0.7546973849109059, tensor(0.4314, device='cuda:0')]\n",
            "9.457335232422635 train: [0.7548819790184922, tensor(0.4313, device='cuda:0')]\n",
            "9.457464715784022 train: [0.7548290575501007, tensor(0.4313, device='cuda:0')]\n",
            "9.45759419914541 train: [0.7548528028695786, tensor(0.4313, device='cuda:0')]\n",
            "9.457723682506797 train: [0.7547991510692263, tensor(0.4314, device='cuda:0')]\n",
            "9.457853165868187 train: [0.754984018760793, tensor(0.4312, device='cuda:0')]\n",
            "9.457982649229574 train: [0.7550087241859703, tensor(0.4313, device='cuda:0')]\n",
            "9.458112132590962 train: [0.7549546471172962, tensor(0.4313, device='cuda:0')]\n",
            "9.45824161595235 train: [0.754979090906609, tensor(0.4313, device='cuda:0')]\n",
            "9.458371099313737 train: [0.7549253941134086, tensor(0.4313, device='cuda:0')]\n",
            "9.458500582675127 train: [0.7551098784161355, tensor(0.4312, device='cuda:0')]\n",
            "9.458630066036514 train: [0.755056345471904, tensor(0.4312, device='cuda:0')]\n",
            "9.458759549397902 train: [0.7550025872365723, tensor(0.4312, device='cuda:0')]\n",
            "9.45888903275929 train: [0.7550272383644849, tensor(0.4312, device='cuda:0')]\n",
            "9.459018516120679 train: [0.7552116549744898, tensor(0.4311, device='cuda:0')]\n",
            "9.459147999482067 train: [0.7553958819234039, tensor(0.4310, device='cuda:0')]\n",
            "9.459277482843454 train: [0.7555799193724123, tensor(0.4309, device='cuda:0')]\n",
            "9.459406966204842 train: [0.7557637674825175, tensor(0.4308, device='cuda:0')]\n",
            "9.459536449566231 train: [0.7557106659443331, tensor(0.4308, device='cuda:0')]\n",
            "9.459665932927619 train: [0.755733288744584, tensor(0.4308, device='cuda:0')]\n",
            "9.459795416289007 train: [0.755519442313134, tensor(0.4310, device='cuda:0')]\n",
            "9.459924899650394 train: [0.7557025894897182, tensor(0.4308, device='cuda:0')]\n",
            "9.460054383011784 train: [0.7558854631210842, tensor(0.4307, device='cuda:0')]\n",
            "9.460183866373171 train: [0.7560680634392466, tensor(0.4306, device='cuda:0')]\n",
            "9.460313349734559 train: [0.7562503906759578, tensor(0.4305, device='cuda:0')]\n",
            "9.460442833095946 train: [0.75643236015715, tensor(0.4303, device='cuda:0')]\n",
            "9.460572316457336 train: [0.7566140570675793, tensor(0.4302, device='cuda:0')]\n",
            "9.460701799818724 train: [0.7566294153107553, tensor(0.4302, device='cuda:0')]\n",
            "9.460831283180111 train: [0.7565830059885766, tensor(0.4303, device='cuda:0')]\n",
            "9.460960766541499 train: [0.7565958200351722, tensor(0.4303, device='cuda:0')]\n",
            "9.461090249902888 train: [0.756551481241318, tensor(0.4303, device='cuda:0')]\n",
            "9.461219733264276 train: [0.7567317016111533, tensor(0.4302, device='cuda:0')]\n",
            "9.461349216625663 train: [0.756741242841338, tensor(0.4302, device='cuda:0')]\n",
            "9.461478699987051 train: [0.7566994419715469, tensor(0.4302, device='cuda:0')]\n",
            "9.46160818334844 train: [0.7566583421862805, tensor(0.4302, device='cuda:0')]\n",
            "9.461737666709828 train: [0.7566655253646748, tensor(0.4303, device='cuda:0')]\n",
            "9.461867150071216 train: [0.7566252200704225, tensor(0.4303, device='cuda:0')]\n",
            "9.461996633432603 train: [0.7568044382135043, tensor(0.4302, device='cuda:0')]\n",
            "9.462126116793993 train: [0.7567645394793833, tensor(0.4302, device='cuda:0')]\n",
            "9.46225560015538 train: [0.7565515463638529, tensor(0.4303, device='cuda:0')]\n",
            "9.462385083516768 train: [0.7565579885611012, tensor(0.4304, device='cuda:0')]\n",
            "9.462514566878156 train: [0.7565181082981716, tensor(0.4304, device='cuda:0')]\n",
            "9.462644050239545 train: [0.7564781659654322, tensor(0.4304, device='cuda:0')]\n",
            "9.462773533600933 train: [0.7566572076187799, tensor(0.4303, device='cuda:0')]\n",
            "9.46290301696232 train: [0.7566643729461235, tensor(0.4303, device='cuda:0')]\n",
            "9.463032500323708 train: [0.756623747757581, tensor(0.4303, device='cuda:0')]\n",
            "9.463161983685097 train: [0.7568026820440795, tensor(0.4302, device='cuda:0')]\n",
            "9.463291467046485 train: [0.7565901567191584, tensor(0.4304, device='cuda:0')]\n",
            "9.463420950407873 train: [0.7567689999676068, tensor(0.4302, device='cuda:0')]\n",
            "9.46355043376926 train: [0.7567278850201861, tensor(0.4303, device='cuda:0')]\n",
            "9.46367991713065 train: [0.7569066735733403, tensor(0.4301, device='cuda:0')]\n",
            "9.463809400492037 train: [0.7570854461106915, tensor(0.4300, device='cuda:0')]\n",
            "9.463938883853425 train: [0.7572641183830191, tensor(0.4299, device='cuda:0')]\n",
            "9.464068367214812 train: [0.7572219841064458, tensor(0.4299, device='cuda:0')]\n",
            "9.4641978505762 train: [0.7571794523704295, tensor(0.4299, device='cuda:0')]\n",
            "9.46432733393759 train: [0.7571361025497338, tensor(0.4300, device='cuda:0')]\n",
            "9.464456817298977 train: [0.7570916828269769, tensor(0.4300, device='cuda:0')]\n",
            "9.464586300660365 train: [0.7572709446287401, tensor(0.4299, device='cuda:0')]\n",
            "9.464715784021752 train: [0.7574503584234215, tensor(0.4297, device='cuda:0')]\n",
            "9.464845267383142 train: [0.7574658496415423, tensor(0.4298, device='cuda:0')]\n",
            "9.46497475074453 train: [0.7572539117988895, tensor(0.4299, device='cuda:0')]\n",
            "9.465104234105917 train: [0.7572055708714363, tensor(0.4299, device='cuda:0')]\n",
            "9.465233717467305 train: [0.7573853904502237, tensor(0.4298, device='cuda:0')]\n",
            "9.465363200828694 train: [0.7575651934904626, tensor(0.4297, device='cuda:0')]\n",
            "9.465492684190082 train: [0.7575155463946339, tensor(0.4297, device='cuda:0')]\n",
            "9.46562216755147 train: [0.7574653393459712, tensor(0.4297, device='cuda:0')]\n",
            "9.465751650912857 train: [0.7572537568489471, tensor(0.4299, device='cuda:0')]\n",
            "9.465881134274246 train: [0.7572743868547677, tensor(0.4299, device='cuda:0')]\n",
            "9.466010617635634 train: [0.7572224436820857, tensor(0.4299, device='cuda:0')]\n",
            "9.466140100997022 train: [0.7571700263262414, tensor(0.4299, device='cuda:0')]\n",
            "9.46626958435841 train: [0.7571168836656508, tensor(0.4300, device='cuda:0')]\n",
            "9.466399067719799 train: [0.7570626810428066, tensor(0.4300, device='cuda:0')]\n",
            "9.466528551081186 train: [0.7570882793395255, tensor(0.4300, device='cuda:0')]\n",
            "9.466658034442574 train: [0.7570322719864467, tensor(0.4300, device='cuda:0')]\n",
            "9.466787517803962 train: [0.7572140508425521, tensor(0.4299, device='cuda:0')]\n",
            "9.466917001165351 train: [0.7571565326478342, tensor(0.4299, device='cuda:0')]\n",
            "9.467046484526739 train: [0.7573386778176558, tensor(0.4298, device='cuda:0')]\n",
            "9.467175967888126 train: [0.7571277787149497, tensor(0.4300, device='cuda:0')]\n",
            "9.467305451249514 train: [0.756916997039361, tensor(0.4301, device='cuda:0')]\n",
            "9.467434934610903 train: [0.7568571166691644, tensor(0.4301, device='cuda:0')]\n",
            "9.46756441797229 train: [0.7566465275994179, tensor(0.4303, device='cuda:0')]\n",
            "9.467693901333678 train: [0.756829731464641, tensor(0.4302, device='cuda:0')]\n",
            "9.467823384695066 train: [0.7566192671344228, tensor(0.4303, device='cuda:0')]\n",
            "9.467952868056456 train: [0.7568027108594769, tensor(0.4302, device='cuda:0')]\n",
            "9.468082351417843 train: [0.7567406906080301, tensor(0.4302, device='cuda:0')]\n",
            "9.46821183477923 train: [0.7565304264539295, tensor(0.4304, device='cuda:0')]\n",
            "9.468341318140618 train: [0.7567141593215811, tensor(0.4303, device='cuda:0')]\n",
            "9.468470801502008 train: [0.7566512140057249, tensor(0.4303, device='cuda:0')]\n",
            "9.468600284863395 train: [0.7564411498152736, tensor(0.4305, device='cuda:0')]\n",
            "9.468729768224783 train: [0.7563775646363073, tensor(0.4305, device='cuda:0')]\n",
            "9.46885925158617 train: [0.756313431123538, tensor(0.4305, device='cuda:0')]\n",
            "9.46898873494756 train: [0.7561036354422277, tensor(0.4307, device='cuda:0')]\n",
            "9.469118218308948 train: [0.7562885142017578, tensor(0.4305, device='cuda:0')]\n",
            "9.469247701670335 train: [0.7562225427054232, tensor(0.4306, device='cuda:0')]\n",
            "9.469377185031723 train: [0.75640778571657, tensor(0.4304, device='cuda:0')]\n",
            "9.46950666839311 train: [0.7565930925890402, tensor(0.4303, device='cuda:0')]\n",
            "9.4696361517545 train: [0.7565257597751971, tensor(0.4303, device='cuda:0')]\n",
            "9.469765635115888 train: [0.7564580481914236, tensor(0.4304, device='cuda:0')]\n",
            "9.469895118477275 train: [0.7562486190529432, tensor(0.4305, device='cuda:0')]\n",
            "9.470024601838663 train: [0.7561798573261087, tensor(0.4305, device='cuda:0')]\n",
            "9.470154085200052 train: [0.7561103853603508, tensor(0.4305, device='cuda:0')]\n",
            "9.47028356856144 train: [0.7562972124694116, tensor(0.4304, device='cuda:0')]\n",
            "9.470413051922828 train: [0.7562263338155207, tensor(0.4304, device='cuda:0')]\n",
            "9.470542535284215 train: [0.7560172582463155, tensor(0.4306, device='cuda:0')]\n",
            "9.470672018645605 train: [0.7562051189033465, tensor(0.4305, device='cuda:0')]\n",
            "9.470801502006992 train: [0.7561324978213276, tensor(0.4305, device='cuda:0')]\n",
            "9.47093098536838 train: [0.7560593358212919, tensor(0.4305, device='cuda:0')]\n",
            "9.471060468729767 train: [0.7559855503685765, tensor(0.4305, device='cuda:0')]\n",
            "9.471189952091157 train: [0.7557768298963599, tensor(0.4307, device='cuda:0')]\n",
            "9.471319435452545 train: [0.7557015873479267, tensor(0.4307, device='cuda:0')]\n",
            "9.471448918813932 train: [0.7556256400970028, tensor(0.4307, device='cuda:0')]\n",
            "9.47157840217532 train: [0.7554171916445623, tensor(0.4309, device='cuda:0')]\n",
            "9.47170788553671 train: [0.7556082009207009, tensor(0.4308, device='cuda:0')]\n",
            "9.471837368898097 train: [0.7553998722190409, tensor(0.4309, device='cuda:0')]\n",
            "9.471966852259484 train: [0.7554615775538547, tensor(0.4310, device='cuda:0')]\n",
            "9.472096335620872 train: [0.7556530790957459, tensor(0.4308, device='cuda:0')]\n",
            "9.472225818982261 train: [0.7557146806791694, tensor(0.4309, device='cuda:0')]\n",
            "9.472355302343649 train: [0.7559056760163549, tensor(0.4307, device='cuda:0')]\n",
            "9.472484785705037 train: [0.7558281024970349, tensor(0.4308, device='cuda:0')]\n",
            "9.472614269066424 train: [0.7557508198088039, tensor(0.4308, device='cuda:0')]\n",
            "9.472743752427814 train: [0.7555428531550316, tensor(0.4309, device='cuda:0')]\n",
            "9.472873235789201 train: [0.755335000925828, tensor(0.4311, device='cuda:0')]\n",
            "9.473002719150589 train: [0.7553941917629263, tensor(0.4311, device='cuda:0')]\n",
            "9.473132202511977 train: [0.7555839687189357, tensor(0.4310, device='cuda:0')]\n",
            "9.473261685873366 train: [0.7555081808738953, tensor(0.4310, device='cuda:0')]\n",
            "9.473391169234754 train: [0.7555651284429366, tensor(0.4310, device='cuda:0')]\n",
            "9.473520652596141 train: [0.7557537939824599, tensor(0.4309, device='cuda:0')]\n",
            "9.473650135957529 train: [0.7556796724800879, tensor(0.4309, device='cuda:0')]\n",
            "9.473779619318918 train: [0.7554721821801208, tensor(0.4311, device='cuda:0')]\n",
            "9.473909102680306 train: [0.7553990859709876, tensor(0.4311, device='cuda:0')]\n",
            "9.474038586041694 train: [0.7551917865511273, tensor(0.4313, device='cuda:0')]\n",
            "9.474168069403081 train: [0.7552444404874961, tensor(0.4313, device='cuda:0')]\n",
            "9.47429755276447 train: [0.7554313176452593, tensor(0.4312, device='cuda:0')]\n",
            "9.474427036125858 train: [0.7554819820294868, tensor(0.4312, device='cuda:0')]\n",
            "9.474556519487246 train: [0.7556677855621626, tensor(0.4311, device='cuda:0')]\n",
            "9.474686002848633 train: [0.7554606965554315, tensor(0.4312, device='cuda:0')]\n",
            "9.474815486210023 train: [0.7553923537934668, tensor(0.4312, device='cuda:0')]\n",
            "9.47494496957141 train: [0.7553247068769358, tensor(0.4313, device='cuda:0')]\n",
            "9.475074452932798 train: [0.755508786676426, tensor(0.4311, device='cuda:0')]\n",
            "9.475203936294186 train: [0.7554419674819431, tensor(0.4312, device='cuda:0')]\n",
            "9.475333419655573 train: [0.755625585501663, tensor(0.4310, device='cuda:0')]\n",
            "9.475462903016963 train: [0.7554188479953698, tensor(0.4312, device='cuda:0')]\n",
            "9.47559238637835 train: [0.7553529301148797, tensor(0.4312, device='cuda:0')]\n",
            "9.475721869739738 train: [0.7552870482846386, tensor(0.4312, device='cuda:0')]\n",
            "9.475851353101126 train: [0.7552209560447071, tensor(0.4312, device='cuda:0')]\n",
            "9.475980836462515 train: [0.7551544072045746, tensor(0.4313, device='cuda:0')]\n",
            "9.476110319823903 train: [0.7550873200399327, tensor(0.4313, device='cuda:0')]\n",
            "9.47623980318529 train: [0.7551331242252012, tensor(0.4313, device='cuda:0')]\n",
            "9.476369286546678 train: [0.7550649307597782, tensor(0.4313, device='cuda:0')]\n",
            "9.476498769908067 train: [0.7549962823400324, tensor(0.4313, device='cuda:0')]\n",
            "9.476628253269455 train: [0.7549270153205828, tensor(0.4314, device='cuda:0')]\n",
            "9.476757736630843 train: [0.7549763386766712, tensor(0.4314, device='cuda:0')]\n",
            "9.47688721999223 train: [0.7549059673874271, tensor(0.4314, device='cuda:0')]\n",
            "9.47701670335362 train: [0.754956580651759, tensor(0.4314, device='cuda:0')]\n",
            "9.477146186715007 train: [0.7548856796829125, tensor(0.4314, device='cuda:0')]\n",
            "9.477275670076395 train: [0.7548145716711743, tensor(0.4315, device='cuda:0')]\n",
            "9.477405153437783 train: [0.7547430111611821, tensor(0.4315, device='cuda:0')]\n",
            "9.477534636799172 train: [0.7546709166701591, tensor(0.4315, device='cuda:0')]\n",
            "9.47766412016056 train: [0.7547247164089995, tensor(0.4315, device='cuda:0')]\n",
            "9.477793603521947 train: [0.7545192373138705, tensor(0.4317, device='cuda:0')]\n",
            "9.477923086883335 train: [0.7547060326462459, tensor(0.4315, device='cuda:0')]\n",
            "9.478052570244724 train: [0.7545006704604919, tensor(0.4317, device='cuda:0')]\n",
            "9.478182053606112 train: [0.7544275138371558, tensor(0.4317, device='cuda:0')]\n",
            "9.4783115369675 train: [0.7544825323999498, tensor(0.4317, device='cuda:0')]\n",
            "9.478441020328887 train: [0.754669216259882, tensor(0.4316, device='cuda:0')]\n",
            "9.478570503690277 train: [0.7548556352844628, tensor(0.4315, device='cuda:0')]\n",
            "9.478699987051664 train: [0.7547831149404264, tensor(0.4315, device='cuda:0')]\n",
            "9.478829470413052 train: [0.754710797259315, tensor(0.4315, device='cuda:0')]\n",
            "9.47895895377444 train: [0.7548967266692433, tensor(0.4314, device='cuda:0')]\n",
            "9.479088437135829 train: [0.754691758782556, tensor(0.4316, device='cuda:0')]\n",
            "9.479217920497216 train: [0.7544869021705086, tensor(0.4317, device='cuda:0')]\n",
            "9.479347403858604 train: [0.7545395835507775, tensor(0.4318, device='cuda:0')]\n",
            "9.479476887219992 train: [0.7544683267509078, tensor(0.4318, device='cuda:0')]\n",
            "9.479606370581381 train: [0.7545197621320231, tensor(0.4318, device='cuda:0')]\n",
            "9.479735853942769 train: [0.7544493641018688, tensor(0.4318, device='cuda:0')]\n",
            "9.479865337304156 train: [0.7546337897752153, tensor(0.4317, device='cuda:0')]\n",
            "9.479994820665544 train: [0.7546830212893475, tensor(0.4317, device='cuda:0')]\n",
            "9.480124304026933 train: [0.7546141830179438, tensor(0.4317, device='cuda:0')]\n",
            "9.480253787388321 train: [0.7545458703589882, tensor(0.4317, device='cuda:0')]\n",
            "9.480383270749709 train: [0.7545928074683913, tensor(0.4318, device='cuda:0')]\n",
            "9.480512754111096 train: [0.7545253510109949, tensor(0.4318, device='cuda:0')]\n",
            "9.480642237472484 train: [0.7547079928697824, tensor(0.4317, device='cuda:0')]\n",
            "9.480771720833873 train: [0.7547528155438312, tensor(0.4317, device='cuda:0')]\n",
            "9.480901204195261 train: [0.7547964760928819, tensor(0.4317, device='cuda:0')]\n",
            "9.481030687556649 train: [0.7548384066751258, tensor(0.4317, device='cuda:0')]\n",
            "9.481160170918036 train: [0.7547749554193441, tensor(0.4317, device='cuda:0')]\n",
            "9.481289654279426 train: [0.7548132958679834, tensor(0.4318, device='cuda:0')]\n",
            "9.481419137640813 train: [0.7547523213580529, tensor(0.4318, device='cuda:0')]\n",
            "9.4815486210022 train: [0.7547874005215476, tensor(0.4318, device='cuda:0')]\n",
            "9.481678104363588 train: [0.7549657632065477, tensor(0.4317, device='cuda:0')]\n",
            "9.481807587724978 train: [0.7549083663451155, tensor(0.4317, device='cuda:0')]\n",
            "9.481937071086366 train: [0.7550857079829751, tensor(0.4316, device='cuda:0')]\n",
            "9.482066554447753 train: [0.755030174561003, tensor(0.4316, device='cuda:0')]\n",
            "9.48219603780914 train: [0.7549752385040776, tensor(0.4316, device='cuda:0')]\n",
            "9.48232552117053 train: [0.7549204941498631, tensor(0.4316, device='cuda:0')]\n",
            "9.482455004531918 train: [0.7548656983014289, tensor(0.4317, device='cuda:0')]\n",
            "9.482584487893305 train: [0.7548105270319303, tensor(0.4317, device='cuda:0')]\n",
            "9.482713971254693 train: [0.7547546567636756, tensor(0.4317, device='cuda:0')]\n",
            "9.482843454616082 train: [0.7547851886293933, tensor(0.4317, device='cuda:0')]\n",
            "9.48297293797747 train: [0.7547281413795603, tensor(0.4317, device='cuda:0')]\n",
            "9.483102421338858 train: [0.7546705585155958, tensor(0.4317, device='cuda:0')]\n",
            "9.483231904700245 train: [0.7546121978206853, tensor(0.4318, device='cuda:0')]\n",
            "9.483361388061635 train: [0.7545528982000911, tensor(0.4318, device='cuda:0')]\n",
            "9.483490871423022 train: [0.7544924987324352, tensor(0.4318, device='cuda:0')]\n",
            "9.48362035478441 train: [0.7545301638080854, tensor(0.4318, device='cuda:0')]\n",
            "9.483749838145798 train: [0.7545688589778062, tensor(0.4318, device='cuda:0')]\n",
            "9.483879321507187 train: [0.7547481615746485, tensor(0.4317, device='cuda:0')]\n",
            "9.484008804868575 train: [0.7547871003710748, tensor(0.4317, device='cuda:0')]\n",
            "9.484138288229962 train: [0.7548255338579342, tensor(0.4318, device='cuda:0')]\n",
            "9.48426777159135 train: [0.7546227872734974, tensor(0.4319, device='cuda:0')]\n",
            "9.48439725495274 train: [0.7545619984456333, tensor(0.4319, device='cuda:0')]\n",
            "9.484526738314127 train: [0.754740174883841, tensor(0.4318, device='cuda:0')]\n",
            "9.484656221675515 train: [0.7545376144504314, tensor(0.4320, device='cuda:0')]\n",
            "9.484785705036902 train: [0.7547153793265361, tensor(0.4318, device='cuda:0')]\n",
            "9.484915188398292 train: [0.7546564041092357, tensor(0.4319, device='cuda:0')]\n",
            "9.48504467175968 train: [0.754833719470058, tensor(0.4318, device='cuda:0')]\n",
            "9.485174155121067 train: [0.7550107786399257, tensor(0.4316, device='cuda:0')]\n",
            "9.485303638482455 train: [0.7549527381038287, tensor(0.4317, device='cuda:0')]\n",
            "9.485433121843844 train: [0.7548948091866601, tensor(0.4317, device='cuda:0')]\n",
            "9.485562605205232 train: [0.7550716292062478, tensor(0.4316, device='cuda:0')]\n",
            "9.48569208856662 train: [0.7552483545177372, tensor(0.4314, device='cuda:0')]\n",
            "9.485821571928007 train: [0.7552807383379673, tensor(0.4315, device='cuda:0')]\n",
            "9.485951055289396 train: [0.75507857539944, tensor(0.4316, device='cuda:0')]\n",
            "9.486080538650784 train: [0.7550216551995637, tensor(0.4316, device='cuda:0')]\n",
            "9.486210022012171 train: [0.7551976420700086, tensor(0.4315, device='cuda:0')]\n",
            "9.486339505373559 train: [0.755227915346555, tensor(0.4315, device='cuda:0')]\n",
            "9.486468988734947 train: [0.7554034315867956, tensor(0.4314, device='cuda:0')]\n",
            "9.486598472096336 train: [0.7553483327935764, tensor(0.4314, device='cuda:0')]\n",
            "9.486727955457724 train: [0.7552936649467582, tensor(0.4315, device='cuda:0')]\n",
            "9.486857438819111 train: [0.7552391065887092, tensor(0.4315, device='cuda:0')]\n",
            "9.486986922180499 train: [0.7554140310394066, tensor(0.4314, device='cuda:0')]\n",
            "9.487116405541888 train: [0.7553591487367772, tensor(0.4314, device='cuda:0')]\n",
            "9.487245888903276 train: [0.7553038946671321, tensor(0.4314, device='cuda:0')]\n",
            "9.487375372264664 train: [0.7554790627373694, tensor(0.4313, device='cuda:0')]\n",
            "9.487504855626051 train: [0.7554227639356375, tensor(0.4313, device='cuda:0')]\n",
            "9.48763433898744 train: [0.7552212641319737, tensor(0.4314, device='cuda:0')]\n",
            "9.487763822348828 train: [0.7553969551282051, tensor(0.4313, device='cuda:0')]\n",
            "9.487893305710216 train: [0.7553391211061665, tensor(0.4314, device='cuda:0')]\n",
            "9.488022789071604 train: [0.7555150874661719, tensor(0.4312, device='cuda:0')]\n",
            "9.488152272432993 train: [0.7556911201807784, tensor(0.4311, device='cuda:0')]\n",
            "9.48828175579438 train: [0.7556319733310111, tensor(0.4311, device='cuda:0')]\n",
            "9.488411239155768 train: [0.7555724578766773, tensor(0.4312, device='cuda:0')]\n",
            "9.488540722517156 train: [0.7555122541113706, tensor(0.4312, device='cuda:0')]\n",
            "9.488670205878545 train: [0.7554512826058025, tensor(0.4312, device='cuda:0')]\n",
            "9.488799689239933 train: [0.7553893040999713, tensor(0.4312, device='cuda:0')]\n",
            "9.48892917260132 train: [0.7553262394611906, tensor(0.4312, device='cuda:0')]\n",
            "9.489058655962708 train: [0.7555045519639935, tensor(0.4311, device='cuda:0')]\n",
            "9.489188139324098 train: [0.7554393330844906, tensor(0.4311, device='cuda:0')]\n",
            "9.489317622685485 train: [0.7552385251809594, tensor(0.4313, device='cuda:0')]\n",
            "9.489447106046873 train: [0.7552844849393896, tensor(0.4313, device='cuda:0')]\n",
            "9.48957658940826 train: [0.7554642954763754, tensor(0.4312, device='cuda:0')]\n",
            "9.48970607276965 train: [0.7553965228828277, tensor(0.4312, device='cuda:0')]\n",
            "9.489835556131037 train: [0.7555765273295477, tensor(0.4311, device='cuda:0')]\n",
            "9.489965039492425 train: [0.755624422489841, tensor(0.4311, device='cuda:0')]\n",
            "9.490094522853813 train: [0.755804350655316, tensor(0.4310, device='cuda:0')]\n",
            "9.490224006215202 train: [0.7559840238943201, tensor(0.4309, device='cuda:0')]\n",
            "9.49035348957659 train: [0.7559163627320955, tensor(0.4309, device='cuda:0')]\n",
            "9.490482972937977 train: [0.7557159075841952, tensor(0.4311, device='cuda:0')]\n",
            "9.490612456299365 train: [0.755648672021576, tensor(0.4311, device='cuda:0')]\n",
            "9.490741939660754 train: [0.7558278774796632, tensor(0.4310, device='cuda:0')]\n",
            "9.490871423022142 train: [0.7560069083506583, tensor(0.4308, device='cuda:0')]\n",
            "9.49100090638353 train: [0.7561857647733061, tensor(0.4307, device='cuda:0')]\n",
            "9.491130389744917 train: [0.7562308379848436, tensor(0.4307, device='cuda:0')]\n",
            "9.491259873106307 train: [0.7560306180118531, tensor(0.4309, device='cuda:0')]\n",
            "9.491389356467694 train: [0.7562084512562609, tensor(0.4308, device='cuda:0')]\n",
            "9.491518839829082 train: [0.7561437543255236, tensor(0.4308, device='cuda:0')]\n",
            "9.49164832319047 train: [0.7560794890873016, tensor(0.4308, device='cuda:0')]\n",
            "9.491777806551857 train: [0.7562565325361625, tensor(0.4307, device='cuda:0')]\n",
            "9.491907289913247 train: [0.756433402910548, tensor(0.4306, device='cuda:0')]\n",
            "9.492036773274634 train: [0.7564734820756827, tensor(0.4306, device='cuda:0')]\n",
            "9.492166256636022 train: [0.7564107857985038, tensor(0.4306, device='cuda:0')]\n",
            "9.49229573999741 train: [0.7565866813586017, tensor(0.4305, device='cuda:0')]\n",
            "9.492425223358799 train: [0.7567622459008899, tensor(0.4304, device='cuda:0')]\n",
            "9.492554706720187 train: [0.7567987047033373, tensor(0.4304, device='cuda:0')]\n",
            "9.492684190081574 train: [0.7567386064799773, tensor(0.4304, device='cuda:0')]\n",
            "9.492813673442962 train: [0.7569130402785391, tensor(0.4303, device='cuda:0')]\n",
            "9.492943156804351 train: [0.7568542121219809, tensor(0.4303, device='cuda:0')]\n",
            "9.493072640165739 train: [0.7570280478308951, tensor(0.4302, device='cuda:0')]\n",
            "9.493202123527126 train: [0.7569700920206508, tensor(0.4302, device='cuda:0')]\n",
            "9.493331606888514 train: [0.7569123252093938, tensor(0.4303, device='cuda:0')]\n",
            "9.493461090249903 train: [0.7570858497475772, tensor(0.4302, device='cuda:0')]\n",
            "9.493590573611291 train: [0.757027924521131, tensor(0.4302, device='cuda:0')]\n",
            "9.493720056972679 train: [0.7572014063386561, tensor(0.4301, device='cuda:0')]\n",
            "9.493849540334066 train: [0.7573748759141833, tensor(0.4299, device='cuda:0')]\n",
            "9.493979023695456 train: [0.7574071120427756, tensor(0.4300, device='cuda:0')]\n",
            "9.494108507056843 train: [0.7572077419158888, tensor(0.4301, device='cuda:0')]\n",
            "9.494237990418231 train: [0.757150414347166, tensor(0.4301, device='cuda:0')]\n",
            "9.494367473779619 train: [0.7571812611306741, tensor(0.4301, device='cuda:0')]\n",
            "9.494496957141008 train: [0.7573538756170841, tensor(0.4300, device='cuda:0')]\n",
            "9.494626440502396 train: [0.7572978190295111, tensor(0.4301, device='cuda:0')]\n",
            "9.494755923863783 train: [0.7570987396869692, tensor(0.4302, device='cuda:0')]\n",
            "9.494885407225171 train: [0.7568997649853432, tensor(0.4304, device='cuda:0')]\n",
            "9.49501489058656 train: [0.7567008948421521, tensor(0.4305, device='cuda:0')]\n",
            "9.495144373947948 train: [0.7565021291750015, tensor(0.4307, device='cuda:0')]\n",
            "9.495273857309336 train: [0.7566738609506303, tensor(0.4305, device='cuda:0')]\n",
            "9.495403340670723 train: [0.7566197278207484, tensor(0.4306, device='cuda:0')]\n",
            "9.495532824032113 train: [0.7567912597163335, tensor(0.4304, device='cuda:0')]\n",
            "9.4956623073935 train: [0.756737281881396, tensor(0.4305, device='cuda:0')]\n",
            "9.495791790754888 train: [0.7567643644311486, tensor(0.4305, device='cuda:0')]\n",
            "9.495921274116276 train: [0.7567105007666082, tensor(0.4305, device='cuda:0')]\n",
            "9.496050757477665 train: [0.7566566653473035, tensor(0.4305, device='cuda:0')]\n",
            "9.496180240839053 train: [0.7566024643361225, tensor(0.4305, device='cuda:0')]\n",
            "9.49630972420044 train: [0.7567739672784631, tensor(0.4304, device='cuda:0')]\n",
            "9.496439207561828 train: [0.7569455378015356, tensor(0.4303, device='cuda:0')]\n",
            "9.496568690923217 train: [0.7571170971511464, tensor(0.4302, device='cuda:0')]\n",
            "9.496698174284605 train: [0.7570615734586178, tensor(0.4302, device='cuda:0')]\n",
            "9.496827657645992 train: [0.7570908741945227, tensor(0.4302, device='cuda:0')]\n",
            "9.49695714100738 train: [0.7572624180893041, tensor(0.4301, device='cuda:0')]\n",
            "9.49708662436877 train: [0.7574337149800748, tensor(0.4300, device='cuda:0')]\n",
            "9.497216107730157 train: [0.7573785595535122, tensor(0.4300, device='cuda:0')]\n",
            "9.497345591091545 train: [0.757180500306767, tensor(0.4302, device='cuda:0')]\n",
            "9.497475074452932 train: [0.7571254399195576, tensor(0.4302, device='cuda:0')]\n",
            "9.49760455781432 train: [0.7572965935250714, tensor(0.4301, device='cuda:0')]\n",
            "9.49773404117571 train: [0.7573251511276156, tensor(0.4301, device='cuda:0')]\n",
            "9.497863524537097 train: [0.7572701745991078, tensor(0.4301, device='cuda:0')]\n",
            "9.497993007898485 train: [0.7574409993571328, tensor(0.4300, device='cuda:0')]\n",
            "9.498122491259872 train: [0.7573861781984335, tensor(0.4300, device='cuda:0')]\n",
            "9.498251974621262 train: [0.7575568834959742, tensor(0.4299, device='cuda:0')]\n",
            "9.49838145798265 train: [0.7575019038812831, tensor(0.4299, device='cuda:0')]\n",
            "9.498510941344037 train: [0.7574466393816853, tensor(0.4300, device='cuda:0')]\n",
            "9.498640424705425 train: [0.7572490789645279, tensor(0.4301, device='cuda:0')]\n",
            "9.498769908066814 train: [0.757051621577575, tensor(0.4302, device='cuda:0')]\n",
            "9.498899391428202 train: [0.7570820560028475, tensor(0.4303, device='cuda:0')]\n",
            "9.49902887478959 train: [0.7572532001162767, tensor(0.4302, device='cuda:0')]\n",
            "9.499158358150977 train: [0.75742417675472, tensor(0.4300, device='cuda:0')]\n",
            "9.499287841512366 train: [0.7572268794958623, tensor(0.4302, device='cuda:0')]\n",
            "9.499417324873754 train: [0.7573975391877004, tensor(0.4301, device='cuda:0')]\n",
            "9.499546808235142 train: [0.7573422605040755, tensor(0.4301, device='cuda:0')]\n",
            "9.49967629159653 train: [0.7572870888059103, tensor(0.4301, device='cuda:0')]\n",
            "9.499805774957919 train: [0.7574575214175624, tensor(0.4300, device='cuda:0')]\n",
            "9.499935258319306 train: [0.7574863017039543, tensor(0.4300, device='cuda:0')]\n",
            "9.500064741680694 train: [0.7574312137391217, tensor(0.4300, device='cuda:0')]\n",
            "9.500194225042081 train: [0.757376232549302, tensor(0.4301, device='cuda:0')]\n",
            "9.50032370840347 train: [0.7574047771990162, tensor(0.4301, device='cuda:0')]\n",
            "9.500453191764858 train: [0.7573498314559012, tensor(0.4301, device='cuda:0')]\n",
            "9.500582675126246 train: [0.7572948361962148, tensor(0.4301, device='cuda:0')]\n",
            "9.500712158487634 train: [0.7572394792707293, tensor(0.4301, device='cuda:0')]\n",
            "9.500841641849023 train: [0.7571835268811298, tensor(0.4301, device='cuda:0')]\n",
            "9.50097112521041 train: [0.7571267454718827, tensor(0.4302, device='cuda:0')]\n",
            "9.501100608571798 train: [0.7571589757731239, tensor(0.4302, device='cuda:0')]\n",
            "9.501230091933186 train: [0.7571008268133008, tensor(0.4302, device='cuda:0')]\n",
            "9.501359575294575 train: [0.7569044323056969, tensor(0.4304, device='cuda:0')]\n",
            "9.501489058655963 train: [0.7570761039239546, tensor(0.4302, device='cuda:0')]\n",
            "9.50161854201735 train: [0.7571112743313855, tensor(0.4303, device='cuda:0')]\n",
            "9.501748025378738 train: [0.7572829591109383, tensor(0.4301, device='cuda:0')]\n",
            "9.501877508740128 train: [0.7570867209769371, tensor(0.4303, device='cuda:0')]\n",
            "9.502006992101515 train: [0.7568905845207254, tensor(0.4304, device='cuda:0')]\n",
            "9.502136475462903 train: [0.7568315987787142, tensor(0.4305, device='cuda:0')]\n",
            "9.50226595882429 train: [0.7570029447426603, tensor(0.4303, device='cuda:0')]\n",
            "9.50239544218568 train: [0.7568069822925586, tensor(0.4305, device='cuda:0')]\n",
            "9.502524925547068 train: [0.7567481417472925, tensor(0.4305, device='cuda:0')]\n",
            "9.502654408908455 train: [0.7569194540501543, tensor(0.4304, device='cuda:0')]\n",
            "9.502783892269843 train: [0.7567236652622468, tensor(0.4305, device='cuda:0')]\n",
            "9.50291337563123 train: [0.7566646587993078, tensor(0.4306, device='cuda:0')]\n",
            "9.50304285899262 train: [0.7566054497951634, tensor(0.4306, device='cuda:0')]\n",
            "9.503172342354008 train: [0.7564098939797602, tensor(0.4307, device='cuda:0')]\n",
            "9.503301825715395 train: [0.7565816158566885, tensor(0.4306, device='cuda:0')]\n",
            "9.503431309076783 train: [0.7566181840311588, tensor(0.4306, device='cuda:0')]\n",
            "9.503560792438172 train: [0.7564227764423077, tensor(0.4308, device='cuda:0')]\n",
            "9.50369027579956 train: [0.7562274697610677, tensor(0.4309, device='cuda:0')]\n",
            "9.503819759160947 train: [0.7561679223670624, tensor(0.4309, device='cuda:0')]\n",
            "9.503949242522335 train: [0.7563393300248139, tensor(0.4308, device='cuda:0')]\n",
            "9.504078725883724 train: [0.7562797069738827, tensor(0.4309, device='cuda:0')]\n",
            "9.504208209245112 train: [0.7564510748794667, tensor(0.4307, device='cuda:0')]\n",
            "9.5043376926065 train: [0.7563912987959693, tensor(0.4308, device='cuda:0')]\n",
            "9.504467175967887 train: [0.7565626270400777, tensor(0.4307, device='cuda:0')]\n",
            "9.504596659329277 train: [0.7565991927289849, tensor(0.4307, device='cuda:0')]\n",
            "9.504726142690664 train: [0.7566352750331992, tensor(0.4307, device='cuda:0')]\n",
            "9.504855626052052 train: [0.7564403664100583, tensor(0.4308, device='cuda:0')]\n",
            "9.50498510941344 train: [0.756245558177658, tensor(0.4310, device='cuda:0')]\n",
            "9.505114592774829 train: [0.7561877067159154, tensor(0.4310, device='cuda:0')]\n",
            "9.505244076136217 train: [0.7562206866894366, tensor(0.4310, device='cuda:0')]\n",
            "9.505373559497604 train: [0.7561638766132863, tensor(0.4310, device='cuda:0')]\n",
            "9.505503042858992 train: [0.7561954542755932, tensor(0.4311, device='cuda:0')]\n",
            "9.505632526220381 train: [0.7561396846064815, tensor(0.4311, device='cuda:0')]\n",
            "9.505762009581769 train: [0.7560843299394743, tensor(0.4311, device='cuda:0')]\n",
            "9.505891492943157 train: [0.7560290809768637, tensor(0.4311, device='cuda:0')]\n",
            "9.506020976304544 train: [0.7561981977640709, tensor(0.4310, device='cuda:0')]\n",
            "9.506150459665934 train: [0.7560039022353545, tensor(0.4311, device='cuda:0')]\n",
            "9.506279943027321 train: [0.7559484077683811, tensor(0.4312, device='cuda:0')]\n",
            "9.506409426388709 train: [0.755979212348386, tensor(0.4312, device='cuda:0')]\n",
            "9.506538909750097 train: [0.755785122691814, tensor(0.4313, device='cuda:0')]\n",
            "9.506668393111486 train: [0.7558155677420628, tensor(0.4313, device='cuda:0')]\n",
            "9.506797876472874 train: [0.7556216196877282, tensor(0.4315, device='cuda:0')]\n",
            "9.506927359834261 train: [0.7555672965919407, tensor(0.4315, device='cuda:0')]\n",
            "9.507056843195649 train: [0.7553735116992523, tensor(0.4316, device='cuda:0')]\n",
            "9.507186326557038 train: [0.7551798261834319, tensor(0.4318, device='cuda:0')]\n",
            "9.507315809918426 train: [0.7553481109380238, tensor(0.4317, device='cuda:0')]\n",
            "9.507445293279813 train: [0.7555162324301148, tensor(0.4316, device='cuda:0')]\n",
            "9.507574776641201 train: [0.7556841137980647, tensor(0.4315, device='cuda:0')]\n",
            "9.50770426000259 train: [0.7556316284333622, tensor(0.4315, device='cuda:0')]\n",
            "9.507833743363978 train: [0.7556579643947602, tensor(0.4315, device='cuda:0')]\n",
            "9.507963226725366 train: [0.7558252189678601, tensor(0.4314, device='cuda:0')]\n",
            "9.508092710086753 train: [0.7559921571981256, tensor(0.4313, device='cuda:0')]\n",
            "9.508222193448143 train: [0.7561587793283994, tensor(0.4312, device='cuda:0')]\n",
            "9.50835167680953 train: [0.7563250856012752, tensor(0.4311, device='cuda:0')]\n",
            "9.508481160170918 train: [0.7561316520755459, tensor(0.4312, device='cuda:0')]\n",
            "9.508610643532306 train: [0.755938317467498, tensor(0.4313, device='cuda:0')]\n",
            "9.508740126893693 train: [0.756103784460044, tensor(0.4312, device='cuda:0')]\n",
            "9.508869610255083 train: [0.7562689365084826, tensor(0.4311, device='cuda:0')]\n",
            "9.50899909361647 train: [0.7562231148785425, tensor(0.4311, device='cuda:0')]\n",
            "9.509128576977858 train: [0.7561777004126142, tensor(0.4312, device='cuda:0')]\n",
            "9.509258060339246 train: [0.7563424001384851, tensor(0.4311, device='cuda:0')]\n",
            "9.509387543700635 train: [0.7562970551196952, tensor(0.4311, device='cuda:0')]\n",
            "9.509517027062023 train: [0.7564617170014136, tensor(0.4310, device='cuda:0')]\n",
            "9.50964651042341 train: [0.7562686928327478, tensor(0.4311, device='cuda:0')]\n",
            "9.509775993784798 train: [0.7562228647468603, tensor(0.4311, device='cuda:0')]\n",
            "9.509905477146187 train: [0.7561766768681459, tensor(0.4311, device='cuda:0')]\n",
            "9.510034960507575 train: [0.7561297464009729, tensor(0.4312, device='cuda:0')]\n",
            "9.510164443868963 train: [0.7560818441292967, tensor(0.4312, device='cuda:0')]\n",
            "9.51029392723035 train: [0.7561038027816984, tensor(0.4312, device='cuda:0')]\n",
            "9.51042341059174 train: [0.7560540941940226, tensor(0.4312, device='cuda:0')]\n",
            "9.510552893953127 train: [0.7558615180110898, tensor(0.4314, device='cuda:0')]\n",
            "9.510682377314515 train: [0.7560277498237057, tensor(0.4312, device='cuda:0')]\n",
            "9.510811860675902 train: [0.7561940499911876, tensor(0.4311, device='cuda:0')]\n",
            "9.510941344037292 train: [0.756141921755389, tensor(0.4312, device='cuda:0')]\n",
            "9.51107082739868 train: [0.7560892083822666, tensor(0.4312, device='cuda:0')]\n",
            "9.511200310760067 train: [0.756256053949866, tensor(0.4311, device='cuda:0')]\n",
            "9.511329794121455 train: [0.7564230439099303, tensor(0.4310, device='cuda:0')]\n",
            "9.511459277482844 train: [0.7564524291497976, tensor(0.4310, device='cuda:0')]\n",
            "9.511588760844232 train: [0.7563978573139494, tensor(0.4310, device='cuda:0')]\n",
            "9.51171824420562 train: [0.7563430841315609, tensor(0.4310, device='cuda:0')]\n",
            "9.511847727567007 train: [0.7563733070473734, tensor(0.4310, device='cuda:0')]\n",
            "9.511977210928396 train: [0.7565404367587582, tensor(0.4309, device='cuda:0')]\n",
            "9.512106694289784 train: [0.7567074052867524, tensor(0.4308, device='cuda:0')]\n",
            "9.512236177651172 train: [0.756652532856836, tensor(0.4308, device='cuda:0')]\n",
            "9.51236566101256 train: [0.7568193119142913, tensor(0.4307, device='cuda:0')]\n",
            "9.512495144373949 train: [0.7569860063338083, tensor(0.4306, device='cuda:0')]\n",
            "9.512624627735336 train: [0.7569314098905281, tensor(0.4306, device='cuda:0')]\n",
            "9.512754111096724 train: [0.7568767649339628, tensor(0.4306, device='cuda:0')]\n",
            "9.512883594458112 train: [0.7570433941771337, tensor(0.4305, device='cuda:0')]\n",
            "9.513013077819501 train: [0.7569882153651165, tensor(0.4305, device='cuda:0')]\n",
            "9.513142561180889 train: [0.7571549603542048, tensor(0.4304, device='cuda:0')]\n",
            "9.513272044542276 train: [0.7573217731090799, tensor(0.4303, device='cuda:0')]\n",
            "9.513401527903664 train: [0.7574885013590134, tensor(0.4302, device='cuda:0')]\n",
            "9.513531011265053 train: [0.757519323903812, tensor(0.4302, device='cuda:0')]\n",
            "9.513660494626441 train: [0.7576856895082765, tensor(0.4301, device='cuda:0')]\n",
            "9.513789977987829 train: [0.7574939188958978, tensor(0.4303, device='cuda:0')]\n",
            "9.513919461349216 train: [0.757439484146294, tensor(0.4303, device='cuda:0')]\n",
            "9.514048944710604 train: [0.757467855474907, tensor(0.4303, device='cuda:0')]\n",
            "9.514178428071993 train: [0.7572762854558188, tensor(0.4305, device='cuda:0')]\n",
            "9.51430791143338 train: [0.7572233145725955, tensor(0.4305, device='cuda:0')]\n",
            "9.514437394794768 train: [0.7571705983365093, tensor(0.4305, device='cuda:0')]\n",
            "9.514566878156156 train: [0.7573358465280613, tensor(0.4304, device='cuda:0')]\n",
            "9.514696361517545 train: [0.7572830525809461, tensor(0.4304, device='cuda:0')]\n",
            "9.514825844878933 train: [0.7570917711834768, tensor(0.4305, device='cuda:0')]\n",
            "9.51495532824032 train: [0.7572570658508159, tensor(0.4304, device='cuda:0')]\n",
            "9.515084811601708 train: [0.7570658875963723, tensor(0.4306, device='cuda:0')]\n",
            "9.515214294963098 train: [0.7568748058478624, tensor(0.4307, device='cuda:0')]\n",
            "9.515343778324485 train: [0.7570400301345135, tensor(0.4306, device='cuda:0')]\n",
            "9.515473261685873 train: [0.7569869359087558, tensor(0.4306, device='cuda:0')]\n",
            "9.51560274504726 train: [0.7569336411145601, tensor(0.4306, device='cuda:0')]\n",
            "9.51573222840865 train: [0.7568799186110788, tensor(0.4307, device='cuda:0')]\n",
            "9.515861711770038 train: [0.7568255414864944, tensor(0.4307, device='cuda:0')]\n",
            "9.515991195131425 train: [0.7567702830577311, tensor(0.4307, device='cuda:0')]\n",
            "9.516120678492813 train: [0.7567139925770878, tensor(0.4307, device='cuda:0')]\n",
            "9.516250161854202 train: [0.756747647621585, tensor(0.4307, device='cuda:0')]\n",
            "9.51637964521559 train: [0.7566895751409256, tensor(0.4307, device='cuda:0')]\n",
            "9.516509128576978 train: [0.7566306997540475, tensor(0.4308, device='cuda:0')]\n",
            "9.516638611938365 train: [0.756570870805824, tensor(0.4308, device='cuda:0')]\n",
            "9.516768095299755 train: [0.7563804906168944, tensor(0.4309, device='cuda:0')]\n",
            "9.516897578661142 train: [0.7561902062167393, tensor(0.4311, device='cuda:0')]\n",
            "9.51702706202253 train: [0.7563592945896533, tensor(0.4310, device='cuda:0')]\n",
            "9.517156545383918 train: [0.756169111211582, tensor(0.4311, device='cuda:0')]\n",
            "9.517286028745307 train: [0.7562121264309472, tensor(0.4311, device='cuda:0')]\n",
            "9.517415512106695 train: [0.7561485660293463, tensor(0.4311, device='cuda:0')]\n",
            "9.517544995468082 train: [0.7563182499033629, tensor(0.4310, device='cuda:0')]\n",
            "9.51767447882947 train: [0.7564879240092361, tensor(0.4309, device='cuda:0')]\n",
            "9.51780396219086 train: [0.756657512894564, tensor(0.4308, device='cuda:0')]\n",
            "9.517933445552247 train: [0.7568269411827189, tensor(0.4307, device='cuda:0')]\n",
            "9.518062928913634 train: [0.7566369745810164, tensor(0.4308, device='cuda:0')]\n",
            "9.518192412275022 train: [0.7568059459752919, tensor(0.4307, device='cuda:0')]\n",
            "9.518321895636412 train: [0.756974681819059, tensor(0.4306, device='cuda:0')]\n",
            "9.5184513789978 train: [0.7571430315592985, tensor(0.4305, device='cuda:0')]\n",
            "9.518580862359187 train: [0.7569531762354371, tensor(0.4307, device='cuda:0')]\n",
            "9.518710345720574 train: [0.7568920752019977, tensor(0.4307, device='cuda:0')]\n",
            "9.518839829081964 train: [0.7567023779400424, tensor(0.4308, device='cuda:0')]\n",
            "9.518969312443351 train: [0.7568697989948538, tensor(0.4307, device='cuda:0')]\n",
            "9.519098795804739 train: [0.7568096680139125, tensor(0.4307, device='cuda:0')]\n",
            "9.519228279166127 train: [0.7569767525862567, tensor(0.4306, device='cuda:0')]\n",
            "9.519357762527516 train: [0.7569170011026155, tensor(0.4306, device='cuda:0')]\n",
            "9.519487245888904 train: [0.7567275350197362, tensor(0.4308, device='cuda:0')]\n",
            "9.519616729250291 train: [0.7565381637647263, tensor(0.4309, device='cuda:0')]\n",
            "9.519746212611679 train: [0.7564784916812609, tensor(0.4309, device='cuda:0')]\n",
            "9.519875695973067 train: [0.7564186239754492, tensor(0.4310, device='cuda:0')]\n",
            "9.520005179334456 train: [0.7562294720314694, tensor(0.4311, device='cuda:0')]\n",
            "9.520264146057231 train: [0.7561688701923077, tensor(0.4311, device='cuda:0')]\n",
            "9.520393629418619 train: [0.7561076978351566, tensor(0.4311, device='cuda:0')]\n",
            "9.520523112780008 train: [0.7561485933715835, tensor(0.4312, device='cuda:0')]\n",
            "9.520652596141396 train: [0.7563166267126579, tensor(0.4311, device='cuda:0')]\n",
            "9.520782079502784 train: [0.7561277364462461, tensor(0.4312, device='cuda:0')]\n",
            "9.520911562864171 train: [0.7560654350331316, tensor(0.4312, device='cuda:0')]\n",
            "9.52104104622556 train: [0.756107425400361, tensor(0.4312, device='cuda:0')]\n",
            "9.521170529586948 train: [0.7560450101745023, tensor(0.4312, device='cuda:0')]\n",
            "9.521300012948336 train: [0.7562130846480116, tensor(0.4311, device='cuda:0')]\n",
            "9.521429496309723 train: [0.7563810752729435, tensor(0.4310, device='cuda:0')]\n",
            "9.521558979671113 train: [0.7561924515633992, tensor(0.4312, device='cuda:0')]\n",
            "9.5216884630325 train: [0.7561304519542412, tensor(0.4312, device='cuda:0')]\n",
            "9.521817946393888 train: [0.7562981877684255, tensor(0.4311, device='cuda:0')]\n",
            "9.522076913116665 train: [0.7562361927102302, tensor(0.4311, device='cuda:0')]\n",
            "9.522206396478053 train: [0.7564038186060328, tensor(0.4310, device='cuda:0')]\n",
            "9.52233587983944 train: [0.7563417532809656, tensor(0.4310, device='cuda:0')]\n",
            "9.522465363200828 train: [0.7562794944021989, tensor(0.4310, device='cuda:0')]\n",
            "9.522594846562217 train: [0.7564472835401467, tensor(0.4309, device='cuda:0')]\n",
            "9.522724329923605 train: [0.7563844311176628, tensor(0.4309, device='cuda:0')]\n",
            "9.522853813284993 train: [0.7561962289700844, tensor(0.4311, device='cuda:0')]\n",
            "9.52298329664638 train: [0.756132722804248, tensor(0.4311, device='cuda:0')]\n",
            "9.52311278000777 train: [0.7560687251305646, tensor(0.4311, device='cuda:0')]\n",
            "9.523242263369157 train: [0.7562374787227939, tensor(0.4310, device='cuda:0')]\n",
            "9.523371746730545 train: [0.756172366464942, tensor(0.4310, device='cuda:0')]\n",
            "9.523501230091933 train: [0.7561066891917725, tensor(0.4310, device='cuda:0')]\n",
            "9.523630713453322 train: [0.7560402980172002, tensor(0.4311, device='cuda:0')]\n",
            "9.52376019681471 train: [0.7560897734437694, tensor(0.4311, device='cuda:0')]\n",
            "9.523889680176097 train: [0.756022225578308, tensor(0.4311, device='cuda:0')]\n",
            "9.524019163537485 train: [0.7561928280879994, tensor(0.4310, device='cuda:0')]\n",
            "9.524148646898874 train: [0.7561244678007523, tensor(0.4310, device='cuda:0')]\n",
            "9.524278130260262 train: [0.7559368438633327, tensor(0.4311, device='cuda:0')]\n",
            "9.52440761362165 train: [0.756108011468809, tensor(0.4310, device='cuda:0')]\n",
            "9.524537096983037 train: [0.7560386797447345, tensor(0.4311, device='cuda:0')]\n",
            "9.524666580344427 train: [0.7562101097436533, tensor(0.4309, device='cuda:0')]\n",
            "9.524796063705814 train: [0.7562639141813813, tensor(0.4310, device='cuda:0')]\n",
            "9.524925547067202 train: [0.7561942974930893, tensor(0.4310, device='cuda:0')]\n",
            "9.52505503042859 train: [0.7563655615089198, tensor(0.4309, device='cuda:0')]\n",
            "9.525184513789977 train: [0.7561782031830567, tensor(0.4310, device='cuda:0')]\n",
            "9.525313997151367 train: [0.7561088826818303, tensor(0.4310, device='cuda:0')]\n",
            "9.525443480512754 train: [0.7561620504170873, tensor(0.4310, device='cuda:0')]\n",
            "9.525572963874142 train: [0.756214745573115, tensor(0.4311, device='cuda:0')]\n",
            "9.52570244723553 train: [0.7563851233986256, tensor(0.4310, device='cuda:0')]\n",
            "9.525831930596919 train: [0.7564357301221787, tensor(0.4310, device='cuda:0')]\n",
            "9.525961413958306 train: [0.7564848253867082, tensor(0.4310, device='cuda:0')]\n",
            "9.526090897319694 train: [0.7566533753709199, tensor(0.4309, device='cuda:0')]\n",
            "9.526220380681082 train: [0.7565888115669868, tensor(0.4309, device='cuda:0')]\n",
            "9.526349864042471 train: [0.7565252451376479, tensor(0.4309, device='cuda:0')]\n",
            "9.526479347403859 train: [0.7566921009864858, tensor(0.4308, device='cuda:0')]\n",
            "9.526608830765246 train: [0.7566298765772271, tensor(0.4308, device='cuda:0')]\n",
            "9.526738314126634 train: [0.7565680539591922, tensor(0.4308, device='cuda:0')]\n",
            "9.526867797488023 train: [0.7565064844491928, tensor(0.4309, device='cuda:0')]\n",
            "9.526997280849411 train: [0.7563197388346657, tensor(0.4310, device='cuda:0')]\n",
            "9.527126764210799 train: [0.7562581126841446, tensor(0.4310, device='cuda:0')]\n",
            "9.527256247572186 train: [0.756299494439067, tensor(0.4310, device='cuda:0')]\n",
            "9.527385730933576 train: [0.7562378295652916, tensor(0.4311, device='cuda:0')]\n",
            "9.527515214294963 train: [0.756176121004458, tensor(0.4311, device='cuda:0')]\n",
            "9.527644697656351 train: [0.7561141465397891, tensor(0.4311, device='cuda:0')]\n",
            "9.527774181017739 train: [0.7562805443108777, tensor(0.4310, device='cuda:0')]\n",
            "9.527903664379128 train: [0.7562178341926679, tensor(0.4310, device='cuda:0')]\n",
            "9.528033147740516 train: [0.7563844945704702, tensor(0.4309, device='cuda:0')]\n",
            "9.528162631101903 train: [0.7563211236500569, tensor(0.4309, device='cuda:0')]\n",
            "9.52829211446329 train: [0.7562573399882561, tensor(0.4309, device='cuda:0')]\n",
            "9.52842159782468 train: [0.7560711614210507, tensor(0.4311, device='cuda:0')]\n",
            "9.528551081186068 train: [0.7562386552424317, tensor(0.4310, device='cuda:0')]\n",
            "9.528680564547455 train: [0.7564062884473425, tensor(0.4309, device='cuda:0')]\n",
            "9.528810047908843 train: [0.7564531294351405, tensor(0.4309, device='cuda:0')]\n",
            "9.528939531270233 train: [0.7566205535349427, tensor(0.4308, device='cuda:0')]\n",
            "9.52906901463162 train: [0.7565558298736548, tensor(0.4308, device='cuda:0')]\n",
            "9.529198497993008 train: [0.7564912857622343, tensor(0.4308, device='cuda:0')]\n",
            "9.529327981354395 train: [0.756426625682931, tensor(0.4308, device='cuda:0')]\n",
            "9.529457464715785 train: [0.7565938179219429, tensor(0.4307, device='cuda:0')]\n",
            "9.529586948077172 train: [0.7564079682982824, tensor(0.4309, device='cuda:0')]\n",
            "9.52971643143856 train: [0.7564544331834668, tensor(0.4309, device='cuda:0')]\n",
            "9.529975398161337 train: [0.7566214216746303, tensor(0.4308, device='cuda:0')]\n",
            "9.530104881522725 train: [0.756435702130773, tensor(0.4309, device='cuda:0')]\n",
            "9.530234364884112 train: [0.7566021708352997, tensor(0.4308, device='cuda:0')]\n",
            "9.5303638482455 train: [0.7565387003897108, tensor(0.4308, device='cuda:0')]\n",
            "9.53049333160689 train: [0.7567046936614403, tensor(0.4307, device='cuda:0')]\n",
            "9.530622814968277 train: [0.7565191358650545, tensor(0.4308, device='cuda:0')]\n",
            "9.530752298329665 train: [0.7566846842174741, tensor(0.4307, device='cuda:0')]\n",
            "9.530881781691052 train: [0.7564992222850678, tensor(0.4309, device='cuda:0')]\n",
            "9.53101126505244 train: [0.7564376219299568, tensor(0.4309, device='cuda:0')]\n",
            "9.53114074841383 train: [0.7563762725897939, tensor(0.4309, device='cuda:0')]\n",
            "9.531270231775217 train: [0.7565411785969969, tensor(0.4308, device='cuda:0')]\n",
            "9.531399715136605 train: [0.7563559334504256, tensor(0.4310, device='cuda:0')]\n",
            "9.531529198497992 train: [0.7561707789991526, tensor(0.4311, device='cuda:0')]\n",
            "9.531658681859382 train: [0.7563355406830077, tensor(0.4310, device='cuda:0')]\n",
            "9.53178816522077 train: [0.7563758975456889, tensor(0.4310, device='cuda:0')]\n",
            "9.531917648582157 train: [0.7563156088881153, tensor(0.4310, device='cuda:0')]\n",
            "9.532047131943544 train: [0.7561306454229922, tensor(0.4312, device='cuda:0')]\n",
            "9.532176615304934 train: [0.7561692595683657, tensor(0.4312, device='cuda:0')]\n",
            "9.532306098666322 train: [0.7561103142686573, tensor(0.4312, device='cuda:0')]\n",
            "9.53243558202771 train: [0.7562736008111512, tensor(0.4311, device='cuda:0')]\n",
            "9.532565065389097 train: [0.7563099493271815, tensor(0.4311, device='cuda:0')]\n",
            "9.532694548750486 train: [0.7564725201749276, tensor(0.4310, device='cuda:0')]\n",
            "9.532824032111874 train: [0.7562877894007701, tensor(0.4311, device='cuda:0')]\n",
            "9.532953515473261 train: [0.756103148827186, tensor(0.4313, device='cuda:0')]\n",
            "9.533082998834649 train: [0.7562645509847731, tensor(0.4312, device='cuda:0')]\n",
            "9.533212482196038 train: [0.7562105958112776, tensor(0.4312, device='cuda:0')]\n",
            "9.533341965557426 train: [0.7563713798628183, tensor(0.4311, device='cuda:0')]\n",
            "9.533471448918814 train: [0.756531865619137, tensor(0.4310, device='cuda:0')]\n",
            "9.533600932280201 train: [0.7564796432155384, tensor(0.4310, device='cuda:0')]\n",
            "9.53373041564159 train: [0.7564277392829014, tensor(0.4310, device='cuda:0')]\n",
            "9.533859899002978 train: [0.756375787416337, tensor(0.4310, device='cuda:0')]\n",
            "9.533989382364366 train: [0.7564038133528265, tensor(0.4310, device='cuda:0')]\n",
            "9.534118865725754 train: [0.756431606038602, tensor(0.4311, device='cuda:0')]\n",
            "9.534248349087143 train: [0.7563801302737083, tensor(0.4311, device='cuda:0')]\n",
            "9.53437783244853 train: [0.7565396818986346, tensor(0.4310, device='cuda:0')]\n",
            "9.534507315809918 train: [0.7564887169032283, tensor(0.4310, device='cuda:0')]\n",
            "9.534636799171306 train: [0.7563046115936874, tensor(0.4311, device='cuda:0')]\n",
            "9.534766282532695 train: [0.756253801703163, tensor(0.4311, device='cuda:0')]\n",
            "9.534895765894083 train: [0.7562027241640626, tensor(0.4312, device='cuda:0')]\n",
            "9.53502524925547 train: [0.7563623441475232, tensor(0.4311, device='cuda:0')]\n",
            "9.535154732616858 train: [0.7561784486104097, tensor(0.4312, device='cuda:0')]\n",
            "9.535284215978248 train: [0.7563382160119293, tensor(0.4311, device='cuda:0')]\n",
            "9.535413699339635 train: [0.7562858532339471, tensor(0.4311, device='cuda:0')]\n",
            "9.535543182701023 train: [0.7564457359179936, tensor(0.4310, device='cuda:0')]\n",
            "9.53567266606241 train: [0.756392788578315, tensor(0.4310, device='cuda:0')]\n",
            "9.5358021494238 train: [0.7565528595145141, tensor(0.4309, device='cuda:0')]\n",
            "9.535931632785188 train: [0.7565830018488431, tensor(0.4309, device='cuda:0')]\n",
            "9.536061116146575 train: [0.7567429489124347, tensor(0.4308, device='cuda:0')]\n",
            "9.536190599507963 train: [0.7566896891857838, tensor(0.4308, device='cuda:0')]\n",
            "9.53632008286935 train: [0.7565061157531818, tensor(0.4310, device='cuda:0')]\n",
            "9.53644956623074 train: [0.7564529393039049, tensor(0.4310, device='cuda:0')]\n",
            "9.536579049592127 train: [0.7563994971974558, tensor(0.4310, device='cuda:0')]\n",
            "9.536708532953515 train: [0.7563455710955711, tensor(0.4310, device='cuda:0')]\n",
            "9.536838016314903 train: [0.7562909428716581, tensor(0.4310, device='cuda:0')]\n",
            "9.536967499676292 train: [0.7562354674190602, tensor(0.4311, device='cuda:0')]\n",
            "9.53709698303768 train: [0.7561789997717278, tensor(0.4311, device='cuda:0')]\n",
            "9.537226466399067 train: [0.7563405881476237, tensor(0.4310, device='cuda:0')]\n",
            "9.537355949760455 train: [0.7561574548333023, tensor(0.4311, device='cuda:0')]\n",
            "9.537485433121844 train: [0.7559744101819266, tensor(0.4313, device='cuda:0')]\n",
            "9.537614916483232 train: [0.7559145697976395, tensor(0.4313, device='cuda:0')]\n",
            "9.53774439984462 train: [0.7559553063755141, tensor(0.4313, device='cuda:0')]\n",
            "9.537873883206007 train: [0.7557724434567006, tensor(0.4314, device='cuda:0')]\n",
            "9.538003366567397 train: [0.7555896689842805, tensor(0.4316, device='cuda:0')]\n",
            "9.538132849928784 train: [0.7556317622703095, tensor(0.4316, device='cuda:0')]\n",
            "9.538262333290172 train: [0.755570551751548, tensor(0.4316, device='cuda:0')]\n",
            "9.53839181665156 train: [0.7555093708173775, tensor(0.4316, device='cuda:0')]\n",
            "9.538521300012949 train: [0.7556728358996041, tensor(0.4315, device='cuda:0')]\n",
            "9.538650783374337 train: [0.7556112969156448, tensor(0.4315, device='cuda:0')]\n",
            "9.538780266735724 train: [0.7554288261846822, tensor(0.4317, device='cuda:0')]\n",
            "9.538909750097112 train: [0.7552464435612674, tensor(0.4318, device='cuda:0')]\n",
            "9.539039233458501 train: [0.7551843267838244, tensor(0.4318, device='cuda:0')]\n",
            "9.539168716819889 train: [0.7553483256608257, tensor(0.4317, device='cuda:0')]\n",
            "9.539298200181276 train: [0.755285634337014, tensor(0.4317, device='cuda:0')]\n",
            "9.539427683542664 train: [0.7554498195665887, tensor(0.4316, device='cuda:0')]\n",
            "9.539557166904054 train: [0.7552676517779303, tensor(0.4318, device='cuda:0')]\n",
            "9.539686650265441 train: [0.7552043008447074, tensor(0.4318, device='cuda:0')]\n",
            "9.539816133626829 train: [0.7551406907595899, tensor(0.4318, device='cuda:0')]\n",
            "9.539945616988216 train: [0.7550766044949027, tensor(0.4318, device='cuda:0')]\n",
            "9.540075100349606 train: [0.7550119700072272, tensor(0.4318, device='cuda:0')]\n",
            "9.540204583710993 train: [0.7548301270472062, tensor(0.4320, device='cuda:0')]\n",
            "9.540334067072381 train: [0.7547642806868066, tensor(0.4320, device='cuda:0')]\n",
            "9.540463550433769 train: [0.7549305176197177, tensor(0.4319, device='cuda:0')]\n",
            "9.540593033795158 train: [0.7548634493890586, tensor(0.4319, device='cuda:0')]\n",
            "9.540722517156546 train: [0.7550303054666099, tensor(0.4318, device='cuda:0')]\n",
            "9.540852000517933 train: [0.7549623058187303, tensor(0.4318, device='cuda:0')]\n",
            "9.540981483879321 train: [0.7548938330188331, tensor(0.4318, device='cuda:0')]\n",
            "9.54111096724071 train: [0.7548248151598942, tensor(0.4318, device='cuda:0')]\n",
            "9.541240450602098 train: [0.7547551081730769, tensor(0.4319, device='cuda:0')]\n",
            "9.541369933963486 train: [0.754684712555229, tensor(0.4319, device='cuda:0')]\n",
            "9.541499417324873 train: [0.7548538257078697, tensor(0.4318, device='cuda:0')]\n",
            "9.541628900686263 train: [0.7549136509359006, tensor(0.4318, device='cuda:0')]\n",
            "9.54175838404765 train: [0.7548417525677973, tensor(0.4318, device='cuda:0')]\n",
            "9.541887867409038 train: [0.7550114997922246, tensor(0.4317, device='cuda:0')]\n",
            "9.542017350770426 train: [0.7551813097787954, tensor(0.4316, device='cuda:0')]\n",
            "9.542146834131813 train: [0.7553510382630928, tensor(0.4315, device='cuda:0')]\n",
            "9.542276317493203 train: [0.7555206132114647, tensor(0.4314, device='cuda:0')]\n",
            "9.54240580085459 train: [0.7554485113336532, tensor(0.4314, device='cuda:0')]\n",
            "9.542535284215978 train: [0.7555085979293489, tensor(0.4314, device='cuda:0')]\n",
            "9.542664767577365 train: [0.7553274642448776, tensor(0.4316, device='cuda:0')]\n",
            "9.542794250938755 train: [0.7554961620279887, tensor(0.4314, device='cuda:0')]\n",
            "9.542923734300143 train: [0.7553151181358182, tensor(0.4316, device='cuda:0')]\n",
            "9.54305321766153 train: [0.7552446636227931, tensor(0.4316, device='cuda:0')]\n",
            "9.543182701022918 train: [0.7550637666973745, tensor(0.4317, device='cuda:0')]\n",
            "9.543312184384307 train: [0.7548829564084144, tensor(0.4319, device='cuda:0')]\n",
            "9.543441667745695 train: [0.7548133033922028, tensor(0.4319, device='cuda:0')]\n",
            "9.543571151107082 train: [0.7549808031768973, tensor(0.4318, device='cuda:0')]\n",
            "9.54370063446847 train: [0.7551481508964235, tensor(0.4317, device='cuda:0')]\n",
            "9.54383011782986 train: [0.7549674934440559, tensor(0.4318, device='cuda:0')]\n",
            "9.543959601191247 train: [0.7551343330864901, tensor(0.4317, device='cuda:0')]\n",
            "9.544089084552635 train: [0.7553008055356288, tensor(0.4316, device='cuda:0')]\n",
            "9.544218567914022 train: [0.7553542038286839, tensor(0.4316, device='cuda:0')]\n",
            "9.544348051275412 train: [0.7555197541688116, tensor(0.4315, device='cuda:0')]\n",
            "9.5444775346368 train: [0.7554533849140704, tensor(0.4315, device='cuda:0')]\n",
            "9.544607017998187 train: [0.7552729134891029, tensor(0.4317, device='cuda:0')]\n",
            "9.544736501359575 train: [0.7552077831336922, tensor(0.4317, device='cuda:0')]\n",
            "9.544865984720964 train: [0.7553717753563295, tensor(0.4316, device='cuda:0')]\n",
            "9.544995468082352 train: [0.7555354023587417, tensor(0.4315, device='cuda:0')]\n",
            "9.54512495144374 train: [0.7555822012116762, tensor(0.4315, device='cuda:0')]\n",
            "9.545254434805127 train: [0.7555192101205881, tensor(0.4315, device='cuda:0')]\n",
            "9.545383918166516 train: [0.7556816096594245, tensor(0.4314, device='cuda:0')]\n",
            "9.545513401527904 train: [0.7556197715056229, tensor(0.4314, device='cuda:0')]\n",
            "9.545642884889292 train: [0.7555583927130333, tensor(0.4314, device='cuda:0')]\n",
            "9.54577236825068 train: [0.7557200221188227, tensor(0.4313, device='cuda:0')]\n",
            "9.545901851612069 train: [0.7556590067463519, tensor(0.4314, device='cuda:0')]\n",
            "9.546031334973456 train: [0.7558203203753597, tensor(0.4313, device='cuda:0')]\n",
            "9.546160818334844 train: [0.7557595249111299, tensor(0.4313, device='cuda:0')]\n",
            "9.546290301696231 train: [0.7558015902366864, tensor(0.4313, device='cuda:0')]\n",
            "9.546419785057621 train: [0.7557410428113553, tensor(0.4313, device='cuda:0')]\n",
            "9.546549268419009 train: [0.7559019687391281, tensor(0.4312, device='cuda:0')]\n",
            "9.546678751780396 train: [0.755722077742284, tensor(0.4313, device='cuda:0')]\n",
            "9.546808235141784 train: [0.7558827171297059, tensor(0.4312, device='cuda:0')]\n",
            "9.546937718503173 train: [0.7558230657158018, tensor(0.4313, device='cuda:0')]\n",
            "9.54706720186456 train: [0.7556433218238361, tensor(0.4314, device='cuda:0')]\n",
            "9.547196685225948 train: [0.7556833444209737, tensor(0.4314, device='cuda:0')]\n",
            "9.547326168587336 train: [0.7556243543270373, tensor(0.4314, device='cuda:0')]\n",
            "9.547455651948725 train: [0.7557842548076923, tensor(0.4313, device='cuda:0')]\n",
            "9.547585135310113 train: [0.7559438651378914, tensor(0.4312, device='cuda:0')]\n",
            "9.5477146186715 train: [0.755764306025032, tensor(0.4314, device='cuda:0')]\n",
            "9.547844102032888 train: [0.7555848321931571, tensor(0.4315, device='cuda:0')]\n",
            "9.547973585394276 train: [0.7556216013998466, tensor(0.4315, device='cuda:0')]\n",
            "9.548103068755665 train: [0.7555651349303438, tensor(0.4315, device='cuda:0')]\n",
            "9.548232552117053 train: [0.7553858361323063, tensor(0.4317, device='cuda:0')]\n",
            "9.54836203547844 train: [0.7553303078519938, tensor(0.4317, device='cuda:0')]\n",
            "9.548491518839828 train: [0.7552749484564297, tensor(0.4317, device='cuda:0')]\n",
            "9.548621002201218 train: [0.7550958460261579, tensor(0.4318, device='cuda:0')]\n",
            "9.548750485562605 train: [0.7552540679596601, tensor(0.4317, device='cuda:0')]\n",
            "9.548879968923993 train: [0.7554122148886904, tensor(0.4316, device='cuda:0')]\n",
            "9.54900945228538 train: [0.7552332072548305, tensor(0.4318, device='cuda:0')]\n",
            "9.54913893564677 train: [0.7553910706312759, tensor(0.4317, device='cuda:0')]\n",
            "9.549268419008158 train: [0.755336131367744, tensor(0.4317, device='cuda:0')]\n",
            "9.549397902369545 train: [0.7554937533015174, tensor(0.4316, device='cuda:0')]\n",
            "9.549527385730933 train: [0.7556512294671475, tensor(0.4315, device='cuda:0')]\n",
            "9.549656869092322 train: [0.7556842427173418, tensor(0.4315, device='cuda:0')]\n",
            "9.54978635245371 train: [0.7557162449033455, tensor(0.4315, device='cuda:0')]\n",
            "9.549915835815098 train: [0.755537461784135, tensor(0.4316, device='cuda:0')]\n",
            "9.550045319176485 train: [0.7554856218388399, tensor(0.4316, device='cuda:0')]\n",
            "9.550174802537875 train: [0.7554343748294742, tensor(0.4317, device='cuda:0')]\n",
            "9.550304285899262 train: [0.7552557851427533, tensor(0.4318, device='cuda:0')]\n",
            "9.55043376926065 train: [0.7552835896451102, tensor(0.4318, device='cuda:0')]\n",
            "9.550563252622037 train: [0.7554389007288789, tensor(0.4317, device='cuda:0')]\n",
            "9.550692735983427 train: [0.7555939254756583, tensor(0.4316, device='cuda:0')]\n",
            "9.550822219344814 train: [0.7555453392409432, tensor(0.4316, device='cuda:0')]\n",
            "9.550951702706202 train: [0.7553669342021615, tensor(0.4318, device='cuda:0')]\n",
            "9.55108118606759 train: [0.7553907072846299, tensor(0.4318, device='cuda:0')]\n",
            "9.55121066942898 train: [0.7555447460331148, tensor(0.4317, device='cuda:0')]\n",
            "9.551340152790367 train: [0.7554986279132029, tensor(0.4317, device='cuda:0')]\n",
            "9.551469636151754 train: [0.7556521432168327, tensor(0.4316, device='cuda:0')]\n",
            "9.551599119513142 train: [0.7556069428066038, tensor(0.4316, device='cuda:0')]\n",
            "9.551728602874531 train: [0.75562701784775, tensor(0.4316, device='cuda:0')]\n",
            "9.551858086235919 train: [0.7556463042423748, tensor(0.4316, device='cuda:0')]\n",
            "9.551987569597307 train: [0.7556028367990718, tensor(0.4317, device='cuda:0')]\n",
            "9.552117052958694 train: [0.755755297070978, tensor(0.4316, device='cuda:0')]\n",
            "9.552246536320084 train: [0.7557130277702274, tensor(0.4316, device='cuda:0')]\n",
            "9.552376019681471 train: [0.7558651072049712, tensor(0.4315, device='cuda:0')]\n",
            "9.552505503042859 train: [0.7558233272128743, tensor(0.4315, device='cuda:0')]\n",
            "9.552634986404247 train: [0.7559752383474576, tensor(0.4314, device='cuda:0')]\n",
            "9.552764469765636 train: [0.755933452101852, tensor(0.4314, device='cuda:0')]\n",
            "9.552893953127024 train: [0.7558913320135746, tensor(0.4314, device='cuda:0')]\n",
            "9.553023436488411 train: [0.755908253487867, tensor(0.4314, device='cuda:0')]\n",
            "9.553152919849799 train: [0.7558655231248643, tensor(0.4314, device='cuda:0')]\n",
            "9.553282403211186 train: [0.7558830785734957, tensor(0.4315, device='cuda:0')]\n",
            "9.553411886572576 train: [0.7560351145754223, tensor(0.4314, device='cuda:0')]\n",
            "9.553541369933964 train: [0.7558574329973786, tensor(0.4315, device='cuda:0')]\n",
            "9.553670853295351 train: [0.7558148253370807, tensor(0.4315, device='cuda:0')]\n",
            "9.553800336656739 train: [0.7559666996440252, tensor(0.4314, device='cuda:0')]\n",
            "9.553929820018128 train: [0.7559837873053438, tensor(0.4314, device='cuda:0')]\n",
            "9.554059303379516 train: [0.7559413916457457, tensor(0.4314, device='cuda:0')]\n",
            "9.554188786740903 train: [0.75609305875316, tensor(0.4313, device='cuda:0')]\n",
            "9.554318270102291 train: [0.7561093290217176, tensor(0.4314, device='cuda:0')]\n",
            "9.55444775346368 train: [0.7562606740470346, tensor(0.4313, device='cuda:0')]\n",
            "9.554577236825068 train: [0.756083272997528, tensor(0.4314, device='cuda:0')]\n",
            "9.554706720186456 train: [0.756042947327356, tensor(0.4314, device='cuda:0')]\n",
            "9.554836203547843 train: [0.7560028519253315, tensor(0.4314, device='cuda:0')]\n",
            "9.554965686909233 train: [0.7561537278210537, tensor(0.4313, device='cuda:0')]\n",
            "9.55509517027062 train: [0.7561134139910944, tensor(0.4313, device='cuda:0')]\n",
            "9.555224653632008 train: [0.7560726966332636, tensor(0.4313, device='cuda:0')]\n",
            "9.555354136993396 train: [0.7562237316881993, tensor(0.4312, device='cuda:0')]\n",
            "9.555483620354785 train: [0.7560466301116916, tensor(0.4314, device='cuda:0')]\n",
            "9.555613103716173 train: [0.7560044092087963, tensor(0.4314, device='cuda:0')]\n",
            "9.55574258707756 train: [0.7559615046996543, tensor(0.4314, device='cuda:0')]\n",
            "9.555872070438948 train: [0.7559176357810221, tensor(0.4314, device='cuda:0')]\n",
            "9.556001553800337 train: [0.7559376940399913, tensor(0.4314, device='cuda:0')]\n",
            "9.556131037161725 train: [0.7560898138776428, tensor(0.4313, device='cuda:0')]\n",
            "9.556260520523113 train: [0.7560439078578111, tensor(0.4314, device='cuda:0')]\n",
            "9.5563900038845 train: [0.7559973910091545, tensor(0.4314, device='cuda:0')]\n",
            "9.55651948724589 train: [0.7560207130848348, tensor(0.4314, device='cuda:0')]\n",
            "9.556648970607277 train: [0.7559730296214069, tensor(0.4314, device='cuda:0')]\n",
            "9.556778453968665 train: [0.7557964004088785, tensor(0.4315, device='cuda:0')]\n",
            "9.556907937330053 train: [0.7556198537140855, tensor(0.4317, device='cuda:0')]\n",
            "9.557037420691442 train: [0.7555707534671073, tensor(0.4317, device='cuda:0')]\n",
            "9.55716690405283 train: [0.7555975154456797, tensor(0.4317, device='cuda:0')]\n",
            "9.557296387414217 train: [0.7556245454912734, tensor(0.4317, device='cuda:0')]\n",
            "9.557425870775605 train: [0.7557779261287138, tensor(0.4316, device='cuda:0')]\n",
            "9.557555354136994 train: [0.755804130285545, tensor(0.4316, device='cuda:0')]\n",
            "9.557684837498382 train: [0.7557555349581023, tensor(0.4317, device='cuda:0')]\n",
            "9.55781432085977 train: [0.7555792859993901, tensor(0.4318, device='cuda:0')]\n",
            "9.557943804221157 train: [0.755731903617483, tensor(0.4317, device='cuda:0')]\n",
            "9.558073287582546 train: [0.7556844797830374, tensor(0.4317, device='cuda:0')]\n",
            "9.558202770943934 train: [0.755836791674883, tensor(0.4316, device='cuda:0')]\n",
            "9.558332254305322 train: [0.7557896455391068, tensor(0.4316, device='cuda:0')]\n",
            "9.55846173766671 train: [0.755941861975667, tensor(0.4315, device='cuda:0')]\n",
            "9.558591221028099 train: [0.7560939375380674, tensor(0.4314, device='cuda:0')]\n",
            "9.558720704389486 train: [0.756245942285305, tensor(0.4313, device='cuda:0')]\n",
            "9.558850187750874 train: [0.7563977363782052, tensor(0.4312, device='cuda:0')]\n",
            "9.558979671112262 train: [0.7565493898918745, tensor(0.4311, device='cuda:0')]\n",
            "9.55910915447365 train: [0.7563733663018577, tensor(0.4312, device='cuda:0')]\n",
            "9.559238637835039 train: [0.7565246753493657, tensor(0.4311, device='cuda:0')]\n",
            "9.559368121196426 train: [0.756479483452594, tensor(0.4312, device='cuda:0')]\n",
            "9.559497604557814 train: [0.7564344522964248, tensor(0.4312, device='cuda:0')]\n",
            "9.559627087919202 train: [0.7565854320888317, tensor(0.4311, device='cuda:0')]\n",
            "9.559756571280591 train: [0.756409604658646, tensor(0.4312, device='cuda:0')]\n",
            "9.559886054641979 train: [0.7565605898806119, tensor(0.4311, device='cuda:0')]\n",
            "9.560015538003366 train: [0.7567114351603681, tensor(0.4310, device='cuda:0')]\n",
            "9.560145021364754 train: [0.7565357009673443, tensor(0.4311, device='cuda:0')]\n",
            "9.560274504726143 train: [0.7564909985533389, tensor(0.4312, device='cuda:0')]\n",
            "9.560403988087531 train: [0.756446177393579, tensor(0.4312, device='cuda:0')]\n",
            "9.560533471448919 train: [0.7564009586375564, tensor(0.4312, device='cuda:0')]\n",
            "9.560662954810306 train: [0.7562254595752276, tensor(0.4313, device='cuda:0')]\n",
            "9.560792438171696 train: [0.7561790583792802, tensor(0.4313, device='cuda:0')]\n",
            "9.560921921533083 train: [0.7561319121726487, tensor(0.4314, device='cuda:0')]\n",
            "9.56105140489447 train: [0.7560838124676738, tensor(0.4314, device='cuda:0')]\n",
            "9.561180888255858 train: [0.7560346206224814, tensor(0.4314, device='cuda:0')]\n",
            "9.561310371617248 train: [0.7561872576655674, tensor(0.4313, device='cuda:0')]\n",
            "9.561439854978635 train: [0.7561358368013474, tensor(0.4313, device='cuda:0')]\n",
            "9.561569338340023 train: [0.7560833260945101, tensor(0.4313, device='cuda:0')]\n",
            "9.56169882170141 train: [0.756237237569922, tensor(0.4312, device='cuda:0')]\n",
            "9.5618283050628 train: [0.7561825709744064, tensor(0.4312, device='cuda:0')]\n",
            "9.561957788424188 train: [0.7563373620014245, tensor(0.4311, device='cuda:0')]\n",
            "9.562087271785575 train: [0.7562808895065245, tensor(0.4312, device='cuda:0')]\n",
            "9.562216755146963 train: [0.7564364204383655, tensor(0.4311, device='cuda:0')]\n",
            "9.562346238508352 train: [0.7565922269524369, tensor(0.4310, device='cuda:0')]\n",
            "9.56247572186974 train: [0.7567481698747598, tensor(0.4309, device='cuda:0')]\n",
            "9.562605205231128 train: [0.7566892924633171, tensor(0.4309, device='cuda:0')]\n",
            "9.562734688592515 train: [0.7566299560572922, tensor(0.4309, device='cuda:0')]\n",
            "9.562864171953905 train: [0.7564550935761142, tensor(0.4310, device='cuda:0')]\n",
            "9.562993655315292 train: [0.7564974800716266, tensor(0.4310, device='cuda:0')]\n",
            "9.56312313867668 train: [0.7566543753442792, tensor(0.4309, device='cuda:0')]\n",
            "9.563252622038068 train: [0.7565939220998401, tensor(0.4309, device='cuda:0')]\n",
            "9.563382105399457 train: [0.7567507920315081, tensor(0.4308, device='cuda:0')]\n",
            "9.563511588760845 train: [0.7566902057141842, tensor(0.4309, device='cuda:0')]\n",
            "9.563641072122232 train: [0.7568470503648209, tensor(0.4308, device='cuda:0')]\n",
            "9.56377055548362 train: [0.7566724202193745, tensor(0.4309, device='cuda:0')]\n",
            "9.56390003884501 train: [0.7568292659258273, tensor(0.4308, device='cuda:0')]\n",
            "9.564029522206397 train: [0.7567685788035765, tensor(0.4308, device='cuda:0')]\n",
            "9.564159005567785 train: [0.756925330009223, tensor(0.4307, device='cuda:0')]\n",
            "9.564288488929172 train: [0.7568645794543746, tensor(0.4307, device='cuda:0')]\n",
            "9.56441797229056 train: [0.7566901465022072, tensor(0.4309, device='cuda:0')]\n",
            "9.56454745565195 train: [0.7568468766616449, tensor(0.4308, device='cuda:0')]\n",
            "9.564676939013337 train: [0.7570035346118406, tensor(0.4307, device='cuda:0')]\n",
            "9.564806422374724 train: [0.757159981996067, tensor(0.4306, device='cuda:0')]\n",
            "9.564935905736112 train: [0.7573162189597761, tensor(0.4305, device='cuda:0')]\n",
            "9.565065389097501 train: [0.7572561540453676, tensor(0.4305, device='cuda:0')]\n",
            "9.565194872458889 train: [0.7574120203372576, tensor(0.4304, device='cuda:0')]\n",
            "9.565324355820277 train: [0.7573523758584375, tensor(0.4304, device='cuda:0')]\n",
            "9.565453839181664 train: [0.7572928279450019, tensor(0.4304, device='cuda:0')]\n",
            "9.565583322543054 train: [0.7574484400431675, tensor(0.4303, device='cuda:0')]\n",
            "9.565712805904441 train: [0.757274273926809, tensor(0.4304, device='cuda:0')]\n",
            "9.565842289265829 train: [0.7573152906719717, tensor(0.4305, device='cuda:0')]\n",
            "9.565971772627217 train: [0.7571412352156003, tensor(0.4306, device='cuda:0')]\n",
            "9.566101255988606 train: [0.7572963248550623, tensor(0.4305, device='cuda:0')]\n",
            "9.566230739349994 train: [0.7574511361527859, tensor(0.4304, device='cuda:0')]\n",
            "9.566360222711381 train: [0.7576056002879757, tensor(0.4303, device='cuda:0')]\n",
            "9.566489706072769 train: [0.7576429750287026, tensor(0.4303, device='cuda:0')]\n",
            "9.566619189434158 train: [0.7574690441345271, tensor(0.4304, device='cuda:0')]\n",
            "9.566748672795546 train: [0.7574136060892287, tensor(0.4305, device='cuda:0')]\n",
            "9.566878156156934 train: [0.7575664891269813, tensor(0.4304, device='cuda:0')]\n",
            "9.567007639518321 train: [0.7573926954841442, tensor(0.4305, device='cuda:0')]\n",
            "9.56713712287971 train: [0.7575448929296048, tensor(0.4304, device='cuda:0')]\n",
            "9.567266606241098 train: [0.7576967449685146, tensor(0.4303, device='cuda:0')]\n",
            "9.567396089602486 train: [0.7577268058053821, tensor(0.4303, device='cuda:0')]\n",
            "9.567525572963874 train: [0.7575531347520231, tensor(0.4304, device='cuda:0')]\n",
            "9.567655056325263 train: [0.7573795432912642, tensor(0.4306, device='cuda:0')]\n",
            "9.56778453968665 train: [0.7573302851572826, tensor(0.4306, device='cuda:0')]\n",
            "9.567914023048038 train: [0.7571568242582544, tensor(0.4307, device='cuda:0')]\n",
            "9.568043506409426 train: [0.7571087405981928, tensor(0.4307, device='cuda:0')]\n",
            "9.568172989770815 train: [0.7572584541860383, tensor(0.4306, device='cuda:0')]\n",
            "9.568302473132203 train: [0.7574079616881173, tensor(0.4305, device='cuda:0')]\n",
            "9.56843195649359 train: [0.7575572632459074, tensor(0.4304, device='cuda:0')]\n",
            "9.568561439854978 train: [0.7575104381148479, tensor(0.4305, device='cuda:0')]\n",
            "9.568690923216367 train: [0.7574637718611443, tensor(0.4305, device='cuda:0')]\n",
            "9.568820406577755 train: [0.7572905581012859, tensor(0.4306, device='cuda:0')]\n",
            "9.568949889939143 train: [0.7572436199702789, tensor(0.4306, device='cuda:0')]\n",
            "9.56907937330053 train: [0.7573928571428571, tensor(0.4305, device='cuda:0')]\n",
            "9.56920885666192 train: [0.7575421634395655, tensor(0.4304, device='cuda:0')]\n",
            "9.569338340023307 train: [0.7574943761972549, tensor(0.4304, device='cuda:0')]\n",
            "9.569467823384695 train: [0.7574462676142952, tensor(0.4304, device='cuda:0')]\n",
            "9.569597306746083 train: [0.7573975634365064, tensor(0.4305, device='cuda:0')]\n",
            "9.569726790107472 train: [0.7572246416183702, tensor(0.4306, device='cuda:0')]\n",
            "9.56985627346886 train: [0.7572521421171844, tensor(0.4306, device='cuda:0')]\n",
            "9.569985756830247 train: [0.7572017327221501, tensor(0.4306, device='cuda:0')]\n",
            "9.570115240191635 train: [0.7570289739421542, tensor(0.4308, device='cuda:0')]\n",
            "9.570244723553023 train: [0.7571795301314219, tensor(0.4307, device='cuda:0')]\n",
            "9.570374206914412 train: [0.7571281439128147, tensor(0.4307, device='cuda:0')]\n",
            "9.5705036902758 train: [0.7572788828747062, tensor(0.4306, device='cuda:0')]\n",
            "9.570633173637187 train: [0.7571062640274587, tensor(0.4307, device='cuda:0')]\n",
            "9.570762656998575 train: [0.7570539709478648, tensor(0.4307, device='cuda:0')]\n",
            "9.570892140359964 train: [0.7572050345487845, tensor(0.4306, device='cuda:0')]\n",
            "9.571021623721352 train: [0.7573561662213072, tensor(0.4305, device='cuda:0')]\n",
            "9.57115110708274 train: [0.7575072974878685, tensor(0.4304, device='cuda:0')]\n",
            "9.571280590444127 train: [0.7573348231487319, tensor(0.4306, device='cuda:0')]\n",
            "9.571410073805517 train: [0.7572817851608328, tensor(0.4306, device='cuda:0')]\n",
            "9.571539557166904 train: [0.7574328301705122, tensor(0.4305, device='cuda:0')]\n",
            "9.571669040528292 train: [0.7573795889122255, tensor(0.4305, device='cuda:0')]\n",
            "9.57179852388968 train: [0.7575306796607055, tensor(0.4304, device='cuda:0')]\n",
            "9.571928007251069 train: [0.7574770303397421, tensor(0.4304, device='cuda:0')]\n",
            "9.572057490612456 train: [0.7574230638052262, tensor(0.4304, device='cuda:0')]\n",
            "9.572186973973844 train: [0.7572508830678301, tensor(0.4306, device='cuda:0')]\n",
            "9.572316457335232 train: [0.7574025486232517, tensor(0.4305, device='cuda:0')]\n",
            "9.572445940696621 train: [0.7575542818065825, tensor(0.4304, device='cuda:0')]\n",
            "9.572575424058009 train: [0.7577060143116765, tensor(0.4303, device='cuda:0')]\n",
            "9.572704907419396 train: [0.7575339257324551, tensor(0.4304, device='cuda:0')]\n",
            "9.572834390780784 train: [0.7574787234507091, tensor(0.4304, device='cuda:0')]\n",
            "9.572963874142173 train: [0.7574233415917226, tensor(0.4304, device='cuda:0')]\n",
            "9.573093357503561 train: [0.7575752388569782, tensor(0.4303, device='cuda:0')]\n",
            "9.573222840864949 train: [0.7577271353703025, tensor(0.4302, device='cuda:0')]\n",
            "9.573352324226336 train: [0.7577631469879939, tensor(0.4302, device='cuda:0')]\n",
            "9.573481807587726 train: [0.757914795675803, tensor(0.4301, device='cuda:0')]\n",
            "9.573611290949113 train: [0.757859445861678, tensor(0.4302, device='cuda:0')]\n",
            "9.573740774310501 train: [0.7576876346066651, tensor(0.4303, device='cuda:0')]\n",
            "9.573870257671889 train: [0.7575159012352675, tensor(0.4304, device='cuda:0')]\n",
            "9.573999741033278 train: [0.7575501495799125, tensor(0.4304, device='cuda:0')]\n",
            "9.574129224394666 train: [0.7573785251690426, tensor(0.4306, device='cuda:0')]\n",
            "9.574258707756053 train: [0.7575291701149925, tensor(0.4305, device='cuda:0')]\n",
            "9.57438819111744 train: [0.7573576281833543, tensor(0.4306, device='cuda:0')]\n",
            "9.57451767447883 train: [0.7573887520462896, tensor(0.4306, device='cuda:0')]\n",
            "9.574647157840218 train: [0.7575384082163875, tensor(0.4305, device='cuda:0')]\n",
            "9.574776641201606 train: [0.7573669806517311, tensor(0.4306, device='cuda:0')]\n",
            "9.574906124562993 train: [0.7571956306561086, tensor(0.4308, device='cuda:0')]\n",
            "9.575035607924383 train: [0.7570243581768831, tensor(0.4309, device='cuda:0')]\n",
            "9.57516509128577 train: [0.7569762230151689, tensor(0.4309, device='cuda:0')]\n",
            "9.575294574647158 train: [0.7571242407476652, tensor(0.4308, device='cuda:0')]\n",
            "9.575424058008545 train: [0.7569531005485811, tensor(0.4309, device='cuda:0')]\n",
            "9.575553541369933 train: [0.7567820377009996, tensor(0.4311, device='cuda:0')]\n",
            "9.575683024731322 train: [0.756929523749522, tensor(0.4310, device='cuda:0')]\n",
            "9.57581250809271 train: [0.7570767395440565, tensor(0.4309, device='cuda:0')]\n",
            "9.575941991454098 train: [0.757223685267702, tensor(0.4308, device='cuda:0')]\n",
            "9.576071474815485 train: [0.757370361103392, tensor(0.4307, device='cuda:0')]\n",
            "9.576200958176875 train: [0.7575167672338948, tensor(0.4306, device='cuda:0')]\n",
            "9.576330441538262 train: [0.7575350079422947, tensor(0.4306, device='cuda:0')]\n",
            "9.57645992489965 train: [0.7574930357886698, tensor(0.4306, device='cuda:0')]\n",
            "9.576589408261038 train: [0.7576385017742803, tensor(0.4305, device='cuda:0')]\n",
            "9.576718891622427 train: [0.7574676315663925, tensor(0.4306, device='cuda:0')]\n",
            "9.576848374983815 train: [0.7574278710649553, tensor(0.4307, device='cuda:0')]\n",
            "9.576977858345202 train: [0.7574414374089616, tensor(0.4307, device='cuda:0')]\n",
            "9.57710734170659 train: [0.7575861066685737, tensor(0.4306, device='cuda:0')]\n",
            "9.57723682506798 train: [0.7574154022732, tensor(0.4307, device='cuda:0')]\n",
            "9.577366308429367 train: [0.7575596060703208, tensor(0.4306, device='cuda:0')]\n",
            "9.577495791790755 train: [0.7575230503941441, tensor(0.4306, device='cuda:0')]\n",
            "9.577625275152142 train: [0.757666962027783, tensor(0.4305, device='cuda:0')]\n",
            "9.577754758513532 train: [0.7576310750961106, tensor(0.4305, device='cuda:0')]\n",
            "9.57788424187492 train: [0.7575950690585017, tensor(0.4306, device='cuda:0')]\n",
            "9.578013725236307 train: [0.7575586735356228, tensor(0.4306, device='cuda:0')]\n",
            "9.578143208597695 train: [0.7577026504499438, tensor(0.4305, device='cuda:0')]\n",
            "9.578272691959084 train: [0.7578466977663587, tensor(0.4304, device='cuda:0')]\n",
            "9.578402175320472 train: [0.7578084458407569, tensor(0.4304, device='cuda:0')]\n",
            "9.57853165868186 train: [0.7577694680193345, tensor(0.4304, device='cuda:0')]\n",
            "9.578661142043247 train: [0.7577295621747324, tensor(0.4304, device='cuda:0')]\n",
            "9.578790625404636 train: [0.7576884588375108, tensor(0.4304, device='cuda:0')]\n",
            "9.578920108766024 train: [0.757645956288993, tensor(0.4305, device='cuda:0')]\n",
            "9.579049592127411 train: [0.7576019204851752, tensor(0.4305, device='cuda:0')]\n",
            "9.579179075488799 train: [0.7577481257233671, tensor(0.4304, device='cuda:0')]\n",
            "9.579308558850189 train: [0.75770111837674, tensor(0.4304, device='cuda:0')]\n",
            "9.579438042211576 train: [0.7576526482776483, tensor(0.4304, device='cuda:0')]\n",
            "9.579567525572964 train: [0.757680331618561, tensor(0.4304, device='cuda:0')]\n",
            "9.579697008934351 train: [0.7576294608955662, tensor(0.4304, device='cuda:0')]\n",
            "9.57982649229574 train: [0.7575775345532664, tensor(0.4305, device='cuda:0')]\n",
            "9.579955975657128 train: [0.7577265809641692, tensor(0.4304, device='cuda:0')]\n",
            "9.580085459018516 train: [0.7575566871119351, tensor(0.4305, device='cuda:0')]\n",
            "9.580214942379904 train: [0.757501982997948, tensor(0.4305, device='cuda:0')]\n",
            "9.580344425741293 train: [0.7574463606135572, tensor(0.4305, device='cuda:0')]\n",
            "9.58047390910268 train: [0.7575970533359762, tensor(0.4304, device='cuda:0')]\n",
            "9.580603392464068 train: [0.7575397517748829, tensor(0.4304, device='cuda:0')]\n",
            "9.580732875825456 train: [0.7574816010207598, tensor(0.4305, device='cuda:0')]\n",
            "9.580862359186845 train: [0.7573119902726584, tensor(0.4306, device='cuda:0')]\n",
            "9.580991842548233 train: [0.7571424554640009, tensor(0.4307, device='cuda:0')]\n",
            "9.58112132590962 train: [0.7572953341281592, tensor(0.4306, device='cuda:0')]\n",
            "9.581250809271008 train: [0.7572343316995714, tensor(0.4306, device='cuda:0')]\n",
            "9.581380292632396 train: [0.7573877936241611, tensor(0.4305, device='cuda:0')]\n",
            "9.581509775993785 train: [0.7572183935361216, tensor(0.4307, device='cuda:0')]\n",
            "9.581639259355173 train: [0.7572651573465666, tensor(0.4307, device='cuda:0')]\n",
            "9.58176874271656 train: [0.7574189125135428, tensor(0.4306, device='cuda:0')]\n",
            "9.581898226077948 train: [0.7574654091159176, tensor(0.4306, device='cuda:0')]\n",
            "9.582027709439338 train: [0.7574036447142243, tensor(0.4306, device='cuda:0')]\n",
            "9.582157192800725 train: [0.7573421093051832, tensor(0.4306, device='cuda:0')]\n",
            "9.582286676162113 train: [0.7573875851574715, tensor(0.4306, device='cuda:0')]\n",
            "9.5824161595235 train: [0.7573264834275261, tensor(0.4307, device='cuda:0')]\n",
            "9.58254564288489 train: [0.7574792809821904, tensor(0.4306, device='cuda:0')]\n",
            "9.582675126246277 train: [0.7574185214199862, tensor(0.4306, device='cuda:0')]\n",
            "9.582804609607665 train: [0.757249492515407, tensor(0.4307, device='cuda:0')]\n",
            "9.582934092969053 train: [0.7572935974667903, tensor(0.4307, device='cuda:0')]\n",
            "9.583063576330442 train: [0.7574458638617684, tensor(0.4306, device='cuda:0')]\n",
            "9.58319305969183 train: [0.7573861711298291, tensor(0.4306, device='cuda:0')]\n",
            "9.583322543053217 train: [0.7574284741874625, tensor(0.4307, device='cuda:0')]\n",
            "9.583452026414605 train: [0.7573695487456703, tensor(0.4307, device='cuda:0')]\n",
            "9.583581509775994 train: [0.7573109844036618, tensor(0.4307, device='cuda:0')]\n",
            "9.583710993137382 train: [0.7573518029917387, tensor(0.4307, device='cuda:0')]\n",
            "9.58384047649877 train: [0.7571830901819833, tensor(0.4308, device='cuda:0')]\n",
            "9.583969959860157 train: [0.7572226475501114, tensor(0.4308, device='cuda:0')]\n",
            "9.584099443221547 train: [0.7571657738554031, tensor(0.4309, device='cuda:0')]\n",
            "9.584228926582934 train: [0.7573157568583465, tensor(0.4308, device='cuda:0')]\n",
            "9.584358409944322 train: [0.7574654055881799, tensor(0.4307, device='cuda:0')]\n",
            "9.58448789330571 train: [0.7574099868200336, tensor(0.4307, device='cuda:0')]\n",
            "9.584617376667099 train: [0.7573549269487465, tensor(0.4307, device='cuda:0')]\n",
            "9.584746860028487 train: [0.7573000252361073, tensor(0.4307, device='cuda:0')]\n",
            "9.584876343389874 train: [0.7574490766280084, tensor(0.4306, device='cuda:0')]\n",
            "9.585005826751262 train: [0.7573941115923316, tensor(0.4306, device='cuda:0')]\n",
            "9.585135310112651 train: [0.757338970625951, tensor(0.4307, device='cuda:0')]\n",
            "9.585264793474039 train: [0.7574881810897436, tensor(0.4306, device='cuda:0')]\n",
            "9.585394276835427 train: [0.7574325096559739, tensor(0.4306, device='cuda:0')]\n",
            "9.585523760196814 train: [0.7575819000316099, tensor(0.4305, device='cuda:0')]\n",
            "9.585653243558204 train: [0.757413660657852, tensor(0.4306, device='cuda:0')]\n",
            "9.585782726919591 train: [0.7575631890242861, tensor(0.4305, device='cuda:0')]\n",
            "9.585912210280979 train: [0.75750681667805, tensor(0.4305, device='cuda:0')]\n",
            "9.586041693642366 train: [0.7576563913713339, tensor(0.4304, device='cuda:0')]\n",
            "9.586171177003756 train: [0.7575996900121179, tensor(0.4304, device='cuda:0')]\n",
            "9.586300660365144 train: [0.757542813843765, tensor(0.4305, device='cuda:0')]\n",
            "9.586430143726531 train: [0.7576926142373372, tensor(0.4304, device='cuda:0')]\n",
            "9.586559627087919 train: [0.7576350764327137, tensor(0.4304, device='cuda:0')]\n",
            "9.586689110449306 train: [0.757577231084699, tensor(0.4304, device='cuda:0')]\n",
            "9.586818593810696 train: [0.7575188786100314, tensor(0.4304, device='cuda:0')]\n",
            "9.586948077172083 train: [0.7576695502522627, tensor(0.4303, device='cuda:0')]\n",
            "9.587077560533471 train: [0.7576101381173103, tensor(0.4303, device='cuda:0')]\n",
            "9.587207043894859 train: [0.757653508071386, tensor(0.4303, device='cuda:0')]\n",
            "9.587336527256248 train: [0.7578047817162908, tensor(0.4302, device='cuda:0')]\n",
            "9.587466010617636 train: [0.7577445808356466, tensor(0.4303, device='cuda:0')]\n",
            "9.587595493979023 train: [0.7578959003728675, tensor(0.4302, device='cuda:0')]\n",
            "9.587724977340411 train: [0.7580471529397246, tensor(0.4301, device='cuda:0')]\n",
            "9.5878544607018 train: [0.7581983385806671, tensor(0.4300, device='cuda:0')]\n",
            "9.587983944063188 train: [0.7582418531893896, tensor(0.4300, device='cuda:0')]\n",
            "9.588113427424576 train: [0.7581820873592352, tensor(0.4300, device='cuda:0')]\n",
            "9.588242910785963 train: [0.7581226136924097, tensor(0.4300, device='cuda:0')]\n",
            "9.588372394147353 train: [0.7582730512055362, tensor(0.4299, device='cuda:0')]\n",
            "9.58850187750874 train: [0.7584232894177646, tensor(0.4298, device='cuda:0')]\n",
            "9.588631360870128 train: [0.7585732620712805, tensor(0.4297, device='cuda:0')]\n",
            "9.588760844231516 train: [0.7584056956338889, tensor(0.4299, device='cuda:0')]\n",
            "9.588890327592905 train: [0.7582382032099415, tensor(0.4300, device='cuda:0')]\n",
            "9.589019810954293 train: [0.7580707847504119, tensor(0.4301, device='cuda:0')]\n",
            "9.58914929431568 train: [0.7582199068177959, tensor(0.4300, device='cuda:0')]\n",
            "9.589278777677068 train: [0.7581629835280037, tensor(0.4300, device='cuda:0')]\n",
            "9.589408261038457 train: [0.7583116879328196, tensor(0.4299, device='cuda:0')]\n",
            "9.589537744399845 train: [0.7584601278657367, tensor(0.4298, device='cuda:0')]\n",
            "9.589667227761232 train: [0.758404117076957, tensor(0.4299, device='cuda:0')]\n",
            "9.58979671112262 train: [0.7585522061317954, tensor(0.4298, device='cuda:0')]\n",
            "9.58992619448401 train: [0.7584966634445801, tensor(0.4298, device='cuda:0')]\n",
            "9.590055677845397 train: [0.7586444681338058, tensor(0.4297, device='cuda:0')]\n",
            "9.590185161206785 train: [0.7587921414677764, tensor(0.4296, device='cuda:0')]\n",
            "9.590314644568172 train: [0.7586249698129035, tensor(0.4297, device='cuda:0')]\n",
            "9.590444127929562 train: [0.7587722514613691, tensor(0.4296, device='cuda:0')]\n",
            "9.59057361129095 train: [0.7589193359011062, tensor(0.4295, device='cuda:0')]\n",
            "9.590703094652337 train: [0.7590660909502761, tensor(0.4294, device='cuda:0')]\n",
            "9.590832578013725 train: [0.7592125168263939, tensor(0.4293, device='cuda:0')]\n",
            "9.590962061375114 train: [0.7593585476198538, tensor(0.4292, device='cuda:0')]\n",
            "9.591091544736502 train: [0.7593065075738343, tensor(0.4293, device='cuda:0')]\n",
            "9.59122102809789 train: [0.7592548870097127, tensor(0.4293, device='cuda:0')]\n",
            "9.591350511459277 train: [0.7594002834709276, tensor(0.4292, device='cuda:0')]\n",
            "9.591479994820666 train: [0.7595454838559638, tensor(0.4291, device='cuda:0')]\n",
            "9.591609478182054 train: [0.7596904882941306, tensor(0.4290, device='cuda:0')]\n",
            "9.591738961543442 train: [0.7596400174344886, tensor(0.4290, device='cuda:0')]\n",
            "9.59186844490483 train: [0.759589700805402, tensor(0.4290, device='cuda:0')]\n",
            "9.591997928266219 train: [0.7595392742623699, tensor(0.4290, device='cuda:0')]\n",
            "9.592127411627606 train: [0.7593724525460812, tensor(0.4292, device='cuda:0')]\n",
            "9.592256894988994 train: [0.7594016038309517, tensor(0.4292, device='cuda:0')]\n",
            "9.592386378350382 train: [0.7595464488516424, tensor(0.4291, device='cuda:0')]\n",
            "9.59251586171177 train: [0.7595750215269805, tensor(0.4291, device='cuda:0')]\n",
            "9.592645345073159 train: [0.7596027244644756, tensor(0.4291, device='cuda:0')]\n",
            "9.592774828434546 train: [0.7597467048638067, tensor(0.4290, device='cuda:0')]\n",
            "9.592904311795934 train: [0.7596985622268716, tensor(0.4290, device='cuda:0')]\n",
            "9.593033795157321 train: [0.7597227274164979, tensor(0.4291, device='cuda:0')]\n",
            "9.59316327851871 train: [0.7598655985951124, tensor(0.4290, device='cuda:0')]\n",
            "9.593292761880098 train: [0.7598200303299835, tensor(0.4290, device='cuda:0')]\n",
            "9.593422245241486 train: [0.7599622248984306, tensor(0.4289, device='cuda:0')]\n",
            "9.593551728602874 train: [0.7599179063363783, tensor(0.4289, device='cuda:0')]\n",
            "9.593681211964263 train: [0.7598739363046592, tensor(0.4289, device='cuda:0')]\n",
            "9.59381069532565 train: [0.7598932273240339, tensor(0.4289, device='cuda:0')]\n",
            "9.593940178687038 train: [0.7598496767150629, tensor(0.4289, device='cuda:0')]\n",
            "9.594069662048426 train: [0.7599911829154318, tensor(0.4289, device='cuda:0')]\n",
            "9.594199145409815 train: [0.7599478929912286, tensor(0.4289, device='cuda:0')]\n",
            "9.594328628771203 train: [0.7599044905108567, tensor(0.4289, device='cuda:0')]\n",
            "9.59445811213259 train: [0.7597382458181176, tensor(0.4290, device='cuda:0')]\n",
            "9.594587595493978 train: [0.7596941852370617, tensor(0.4290, device='cuda:0')]\n",
            "9.594717078855368 train: [0.7596495525576544, tensor(0.4290, device='cuda:0')]\n",
            "9.594846562216755 train: [0.7594834726379873, tensor(0.4292, device='cuda:0')]\n",
            "9.594976045578143 train: [0.759625827553594, tensor(0.4291, device='cuda:0')]\n",
            "9.59510552893953 train: [0.7595792691383136, tensor(0.4291, device='cuda:0')]\n",
            "9.59523501230092 train: [0.7596032393363137, tensor(0.4291, device='cuda:0')]\n",
            "9.595364495662308 train: [0.759745999890782, tensor(0.4290, device='cuda:0')]\n",
            "9.595493979023695 train: [0.759888763712265, tensor(0.4289, device='cuda:0')]\n",
            "9.595623462385083 train: [0.7597228491350353, tensor(0.4290, device='cuda:0')]\n",
            "9.595752945746472 train: [0.7597470950245999, tensor(0.4291, device='cuda:0')]\n",
            "9.59588242910786 train: [0.7597000464820535, tensor(0.4291, device='cuda:0')]\n",
            "9.596011912469248 train: [0.7597235655600127, tensor(0.4291, device='cuda:0')]\n",
            "9.596141395830635 train: [0.7596771981767687, tensor(0.4291, device='cuda:0')]\n",
            "9.596270879192025 train: [0.7598192658963174, tensor(0.4290, device='cuda:0')]\n",
            "9.596400362553412 train: [0.7596535835443994, tensor(0.4291, device='cuda:0')]\n",
            "9.5965298459148 train: [0.7596079823204374, tensor(0.4291, device='cuda:0')]\n",
            "9.596659329276187 train: [0.7595624009749514, tensor(0.4292, device='cuda:0')]\n",
            "9.596788812637577 train: [0.7597042389199926, tensor(0.4291, device='cuda:0')]\n",
            "9.596918295998965 train: [0.7598460805262276, tensor(0.4290, device='cuda:0')]\n",
            "9.597047779360352 train: [0.7598000844042693, tensor(0.4290, device='cuda:0')]\n",
            "9.59717726272174 train: [0.7596346227134146, tensor(0.4291, device='cuda:0')]\n",
            "9.59730674608313 train: [0.7595881692877121, tensor(0.4291, device='cuda:0')]\n",
            "9.597436229444517 train: [0.7595412782349887, tensor(0.4291, device='cuda:0')]\n",
            "9.597565712805904 train: [0.7594938190549929, tensor(0.4292, device='cuda:0')]\n",
            "9.597695196167292 train: [0.7594455306035348, tensor(0.4292, device='cuda:0')]\n",
            "9.59782467952868 train: [0.7595885197913355, tensor(0.4291, device='cuda:0')]\n",
            "9.597954162890069 train: [0.7594233200262656, tensor(0.4292, device='cuda:0')]\n",
            "9.598083646251457 train: [0.7593727916394869, tensor(0.4292, device='cuda:0')]\n",
            "9.598213129612844 train: [0.759516683214883, tensor(0.4291, device='cuda:0')]\n",
            "9.598342612974232 train: [0.759660773473158, tensor(0.4290, device='cuda:0')]\n",
            "9.598472096335621 train: [0.7596084635024906, tensor(0.4291, device='cuda:0')]\n",
            "9.598601579697009 train: [0.7595555887464697, tensor(0.4291, device='cuda:0')]\n",
            "9.598731063058397 train: [0.7595020843079596, tensor(0.4291, device='cuda:0')]\n",
            "9.598860546419784 train: [0.7594477548442329, tensor(0.4291, device='cuda:0')]\n",
            "9.598990029781174 train: [0.7593926008926484, tensor(0.4291, device='cuda:0')]\n",
            "9.599119513142561 train: [0.7593364925447897, tensor(0.4291, device='cuda:0')]\n",
            "9.599248996503949 train: [0.7592793652135083, tensor(0.4291, device='cuda:0')]\n",
            "9.599378479865337 train: [0.7593199890056245, tensor(0.4292, device='cuda:0')]\n",
            "9.599507963226726 train: [0.7592611953529117, tensor(0.4292, device='cuda:0')]\n",
            "9.599637446588114 train: [0.7594091339897903, tensor(0.4291, device='cuda:0')]\n",
            "9.599766929949501 train: [0.7593491086171525, tensor(0.4291, device='cuda:0')]\n",
            "9.599896413310889 train: [0.7594976154346412, tensor(0.4290, device='cuda:0')]\n",
            "9.600025896672278 train: [0.7594365549248108, tensor(0.4290, device='cuda:0')]\n",
            "9.600155380033666 train: [0.759375, tensor(0.4290, device='cuda:0')]\n",
            "9.600284863395053 train: [0.7594219859227103, tensor(0.4291, device='cuda:0')]\n",
            "9.600414346756441 train: [0.7593596798412222, tensor(0.4291, device='cuda:0')]\n",
            "9.60054383011783 train: [0.7591952450902821, tensor(0.4292, device='cuda:0')]\n",
            "9.600673313479218 train: [0.7590308815386281, tensor(0.4293, device='cuda:0')]\n",
            "9.600802796840606 train: [0.7589677900224775, tensor(0.4293, device='cuda:0')]\n",
            "9.600932280201993 train: [0.7590172841792486, tensor(0.4293, device='cuda:0')]\n",
            "9.601061763563383 train: [0.7589538328395966, tensor(0.4294, device='cuda:0')]\n",
            "9.60119124692477 train: [0.7591042488227757, tensor(0.4293, device='cuda:0')]\n",
            "9.601320730286158 train: [0.7590405461887809, tensor(0.4293, device='cuda:0')]\n",
            "9.601450213647546 train: [0.7588764293139293, tensor(0.4294, device='cuda:0')]\n",
            "9.601579697008935 train: [0.7590269593476671, tensor(0.4293, device='cuda:0')]\n",
            "9.601709180370323 train: [0.7591774243154727, tensor(0.4292, device='cuda:0')]\n",
            "9.60183866373171 train: [0.7592275125074796, tensor(0.4292, device='cuda:0')]\n",
            "9.601968147093098 train: [0.7593775445768317, tensor(0.4291, device='cuda:0')]\n",
            "9.602097630454487 train: [0.7593145144542283, tensor(0.4292, device='cuda:0')]\n",
            "9.602227113815875 train: [0.759464008749564, tensor(0.4291, device='cuda:0')]\n",
            "9.602356597177263 train: [0.7594016358816593, tensor(0.4291, device='cuda:0')]\n",
            "9.60248608053865 train: [0.7593394845091235, tensor(0.4291, device='cuda:0')]\n",
            "9.60261556390004 train: [0.7591756218668039, tensor(0.4292, device='cuda:0')]\n",
            "9.602745047261427 train: [0.7591136109036595, tensor(0.4292, device='cuda:0')]\n",
            "9.602874530622815 train: [0.7592625984145815, tensor(0.4291, device='cuda:0')]\n",
            "9.603004013984203 train: [0.75930978459216, tensor(0.4292, device='cuda:0')]\n",
            "9.603133497345592 train: [0.7591460696752579, tensor(0.4293, device='cuda:0')]\n",
            "9.60326298070698 train: [0.7590847015064586, tensor(0.4293, device='cuda:0')]\n",
            "9.603392464068367 train: [0.759130729857427, tensor(0.4293, device='cuda:0')]\n",
            "9.603521947429755 train: [0.7589671593489467, tensor(0.4294, device='cuda:0')]\n",
            "9.603651430791142 train: [0.7591150148725682, tensor(0.4293, device='cuda:0')]\n",
            "9.603780914152532 train: [0.7589515182077238, tensor(0.4295, device='cuda:0')]\n",
            "9.60391039751392 train: [0.758891940282747, tensor(0.4295, device='cuda:0')]\n",
            "9.604039880875307 train: [0.7590390696157986, tensor(0.4294, device='cuda:0')]\n",
            "9.604169364236695 train: [0.7588756948698633, tensor(0.4295, device='cuda:0')]\n",
            "9.604298847598084 train: [0.7590223764090976, tensor(0.4294, device='cuda:0')]\n",
            "9.604428330959472 train: [0.7591687362430491, tensor(0.4293, device='cuda:0')]\n",
            "9.60455781432086 train: [0.7591109854062909, tensor(0.4293, device='cuda:0')]\n",
            "9.604687297682247 train: [0.7592568108974359, tensor(0.4292, device='cuda:0')]\n",
            "9.604816781043636 train: [0.759199712013959, tensor(0.4293, device='cuda:0')]\n",
            "9.604946264405024 train: [0.7590365134516172, tensor(0.4294, device='cuda:0')]\n",
            "9.605075747766412 train: [0.7588733850369489, tensor(0.4295, device='cuda:0')]\n",
            "9.6052052311278 train: [0.7588168572939737, tensor(0.4295, device='cuda:0')]\n",
            "9.605334714489189 train: [0.7586538461538461, tensor(0.4296, device='cuda:0')]\n",
            "9.605464197850576 train: [0.7587991301546392, tensor(0.4296, device='cuda:0')]\n",
            "9.605593681211964 train: [0.7588376962513008, tensor(0.4296, device='cuda:0')]\n",
            "9.605723164573352 train: [0.7587817407809558, tensor(0.4296, device='cuda:0')]\n",
            "9.605852647934741 train: [0.7586188771319365, tensor(0.4297, device='cuda:0')]\n",
            "9.605982131296129 train: [0.7585633795188181, tensor(0.4297, device='cuda:0')]\n",
            "9.606111614657516 train: [0.7587080113420692, tensor(0.4296, device='cuda:0')]\n",
            "9.606241098018904 train: [0.7586526473245223, tensor(0.4296, device='cuda:0')]\n",
            "9.606370581380293 train: [0.7587971979701084, tensor(0.4296, device='cuda:0')]\n",
            "9.606500064741681 train: [0.7586345056034767, tensor(0.4297, device='cuda:0')]\n",
            "9.606629548103069 train: [0.7585792573583973, tensor(0.4297, device='cuda:0')]\n",
            "9.606759031464456 train: [0.7585239039986481, tensor(0.4297, device='cuda:0')]\n",
            "9.606888514825846 train: [0.7586684871066902, tensor(0.4296, device='cuda:0')]\n",
            "9.607017998187233 train: [0.7586126877554216, tensor(0.4296, device='cuda:0')]\n",
            "9.60714748154862 train: [0.75875744734089, tensor(0.4295, device='cuda:0')]\n",
            "9.607276964910008 train: [0.7589022092735958, tensor(0.4294, device='cuda:0')]\n",
            "9.607406448271398 train: [0.7588459454201868, tensor(0.4295, device='cuda:0')]\n",
            "9.607535931632786 train: [0.758683521202417, tensor(0.4296, device='cuda:0')]\n",
            "9.607665414994173 train: [0.7586270067202753, tensor(0.4296, device='cuda:0')]\n",
            "9.60779489835556 train: [0.7587720583999868, tensor(0.4295, device='cuda:0')]\n",
            "9.60792438171695 train: [0.7587150992389963, tensor(0.4295, device='cuda:0')]\n",
            "9.608053865078338 train: [0.7586578431392709, tensor(0.4295, device='cuda:0')]\n",
            "9.608183348439725 train: [0.7586001617983257, tensor(0.4295, device='cuda:0')]\n",
            "9.608312831801113 train: [0.7587459302134377, tensor(0.4295, device='cuda:0')]\n",
            "9.608442315162502 train: [0.7585837703651339, tensor(0.4296, device='cuda:0')]\n",
            "9.60857179852389 train: [0.7584216798159106, tensor(0.4297, device='cuda:0')]\n",
            "9.608701281885278 train: [0.7582596585213547, tensor(0.4298, device='cuda:0')]\n",
            "9.608830765246665 train: [0.7583033964980449, tensor(0.4298, device='cuda:0')]\n",
            "9.608960248608053 train: [0.7584497142898208, tensor(0.4297, device='cuda:0')]\n",
            "9.609089731969442 train: [0.7583907522745188, tensor(0.4298, device='cuda:0')]\n",
            "9.60921921533083 train: [0.7582288759133076, tensor(0.4299, device='cuda:0')]\n",
            "9.609348698692218 train: [0.7581700503135362, tensor(0.4299, device='cuda:0')]\n",
            "9.609478182053605 train: [0.7583162075749619, tensor(0.4298, device='cuda:0')]\n",
            "9.609607665414995 train: [0.7584622383868798, tensor(0.4297, device='cuda:0')]\n",
            "9.609737148776382 train: [0.7586081428301917, tensor(0.4296, device='cuda:0')]\n",
            "9.60986663213777 train: [0.7587538569173364, tensor(0.4295, device='cuda:0')]\n",
            "9.609996115499158 train: [0.7586956226530345, tensor(0.4295, device='cuda:0')]\n",
            "9.610125598860547 train: [0.7586376053347761, tensor(0.4296, device='cuda:0')]\n",
            "9.610255082221935 train: [0.7587828998590372, tensor(0.4295, device='cuda:0')]\n",
            "9.610384565583322 train: [0.7587249526810003, tensor(0.4295, device='cuda:0')]\n",
            "9.61051404894471 train: [0.7586669661874335, tensor(0.4295, device='cuda:0')]\n",
            "9.6106435323061 train: [0.7586087484438475, tensor(0.4295, device='cuda:0')]\n",
            "9.610773015667487 train: [0.7585501716521184, tensor(0.4295, device='cuda:0')]\n",
            "9.610902499028875 train: [0.7584911720822282, tensor(0.4295, device='cuda:0')]\n",
            "9.611031982390262 train: [0.7584316221127245, tensor(0.4296, device='cuda:0')]\n",
            "9.611161465751652 train: [0.75857821450491, tensor(0.4295, device='cuda:0')]\n",
            "9.61129094911304 train: [0.7585175208220837, tensor(0.4295, device='cuda:0')]\n",
            "9.611420432474427 train: [0.7586646716413638, tensor(0.4294, device='cuda:0')]\n",
            "9.611549915835814 train: [0.7586030270163071, tensor(0.4294, device='cuda:0')]\n",
            "9.611679399197204 train: [0.758651469902865, tensor(0.4294, device='cuda:0')]\n",
            "9.611808882558591 train: [0.7587000837897491, tensor(0.4294, device='cuda:0')]\n",
            "9.611938365919979 train: [0.7587484854645461, tensor(0.4295, device='cuda:0')]\n",
            "9.612067849281367 train: [0.7588957500898825, tensor(0.4294, device='cuda:0')]\n",
            "9.612197332642756 train: [0.7588345047913535, tensor(0.4294, device='cuda:0')]\n",
            "9.612326816004144 train: [0.7587736045542904, tensor(0.4294, device='cuda:0')]\n",
            "9.612456299365531 train: [0.7589201958802875, tensor(0.4293, device='cuda:0')]\n",
            "9.612585782726919 train: [0.7587591005298565, tensor(0.4294, device='cuda:0')]\n",
            "9.612715266088308 train: [0.7588045584310108, tensor(0.4294, device='cuda:0')]\n",
            "9.612844749449696 train: [0.758950412321076, tensor(0.4293, device='cuda:0')]\n",
            "9.612974232811084 train: [0.7588911456463562, tensor(0.4294, device='cuda:0')]\n",
            "9.613103716172471 train: [0.7587301931234195, tensor(0.4295, device='cuda:0')]\n",
            "9.61323319953386 train: [0.7585693088585502, tensor(0.4296, device='cuda:0')]\n",
            "9.613362682895248 train: [0.7585111798975881, tensor(0.4296, device='cuda:0')]\n",
            "9.613492166256636 train: [0.7584532029543157, tensor(0.4296, device='cuda:0')]\n",
            "9.613621649618024 train: [0.7585979270583728, tensor(0.4295, device='cuda:0')]\n",
            "9.613751132979413 train: [0.758540019964146, tensor(0.4296, device='cuda:0')]\n",
            "9.6138806163408 train: [0.7584820737539308, tensor(0.4296, device='cuda:0')]\n",
            "9.614010099702188 train: [0.75842389754993, tensor(0.4296, device='cuda:0')]\n",
            "9.614139583063576 train: [0.7582633165849607, tensor(0.4297, device='cuda:0')]\n",
            "9.614269066424965 train: [0.7582045116386048, tensor(0.4297, device='cuda:0')]\n",
            "9.614398549786353 train: [0.7583499313186813, tensor(0.4296, device='cuda:0')]\n",
            "9.61452803314774 train: [0.7584954801995508, tensor(0.4295, device='cuda:0')]\n",
            "9.614657516509128 train: [0.7586410310654017, tensor(0.4294, device='cuda:0')]\n",
            "9.614786999870516 train: [0.7587864568080502, tensor(0.4294, device='cuda:0')]\n",
            "9.614916483231905 train: [0.7587269680124274, tensor(0.4294, device='cuda:0')]\n",
            "9.615045966593293 train: [0.7588722505691983, tensor(0.4293, device='cuda:0')]\n",
            "9.61517544995468 train: [0.7590174081955352, tensor(0.4292, device='cuda:0')]\n",
            "9.615304933316068 train: [0.7589582258071071, tensor(0.4292, device='cuda:0')]\n",
            "9.615434416677457 train: [0.7587978712273887, tensor(0.4293, device='cuda:0')]\n",
            "9.615563900038845 train: [0.7589427621583634, tensor(0.4292, device='cuda:0')]\n",
            "9.615693383400233 train: [0.7589860566769556, tensor(0.4293, device='cuda:0')]\n",
            "9.61582286676162 train: [0.7591304660091281, tensor(0.4292, device='cuda:0')]\n",
            "9.61595235012301 train: [0.7590725908762443, tensor(0.4292, device='cuda:0')]\n",
            "9.616081833484397 train: [0.7592164136320096, tensor(0.4291, device='cuda:0')]\n",
            "9.616211316845785 train: [0.7590562075941045, tensor(0.4292, device='cuda:0')]\n",
            "9.616340800207173 train: [0.7588960691536839, tensor(0.4293, device='cuda:0')]\n",
            "9.616470283568562 train: [0.7590391409634449, tensor(0.4292, device='cuda:0')]\n",
            "9.61659976692995 train: [0.7589833104540441, tensor(0.4292, device='cuda:0')]\n",
            "9.616729250291337 train: [0.7588232886723755, tensor(0.4294, device='cuda:0')]\n",
            "9.616858733652725 train: [0.7587679705741666, tensor(0.4294, device='cuda:0')]\n",
            "9.616988217014114 train: [0.7586080616235714, tensor(0.4295, device='cuda:0')]\n",
            "9.617117700375502 train: [0.7585528754983955, tensor(0.4295, device='cuda:0')]\n",
            "9.61724718373689 train: [0.7584975227269044, tensor(0.4295, device='cuda:0')]\n",
            "9.617376667098277 train: [0.7585360460477286, tensor(0.4295, device='cuda:0')]\n",
            "9.617506150459667 train: [0.7583763206221553, tensor(0.4297, device='cuda:0')]\n",
            "9.617635633821054 train: [0.7582166624493927, tensor(0.4298, device='cuda:0')]\n",
            "9.617765117182442 train: [0.7583591966468598, tensor(0.4297, device='cuda:0')]\n",
            "9.61789460054383 train: [0.7583040061067405, tensor(0.4297, device='cuda:0')]\n",
            "9.618024083905219 train: [0.758446398731975, tensor(0.4296, device='cuda:0')]\n",
            "9.618153567266607 train: [0.7583912762734216, tensor(0.4296, device='cuda:0')]\n",
            "9.618283050627994 train: [0.7582317828399255, tensor(0.4298, device='cuda:0')]\n",
            "9.618412533989382 train: [0.758269854980753, tensor(0.4298, device='cuda:0')]\n",
            "9.618542017350771 train: [0.7584120087199431, tensor(0.4297, device='cuda:0')]\n",
            "9.618671500712159 train: [0.758357445052058, tensor(0.4297, device='cuda:0')]\n",
            "9.618800984073546 train: [0.7583030305938545, tensor(0.4297, device='cuda:0')]\n",
            "9.618930467434934 train: [0.7582486389988687, tensor(0.4297, device='cuda:0')]\n",
            "9.619059950796323 train: [0.7583905515365227, tensor(0.4296, device='cuda:0')]\n",
            "9.619189434157711 train: [0.7583357858083223, tensor(0.4297, device='cuda:0')]\n",
            "9.619318917519099 train: [0.7582807907306319, tensor(0.4297, device='cuda:0')]\n",
            "9.619448400880486 train: [0.7582254403014597, tensor(0.4297, device='cuda:0')]\n",
            "9.619577884241876 train: [0.7581695455646138, tensor(0.4297, device='cuda:0')]\n",
            "9.619707367603263 train: [0.758312397612092, tensor(0.4296, device='cuda:0')]\n",
            "9.619836850964651 train: [0.7584554418599022, tensor(0.4295, device='cuda:0')]\n",
            "9.619966334326039 train: [0.7583981476066404, tensor(0.4295, device='cuda:0')]\n",
            "9.620095817687428 train: [0.7585415549341097, tensor(0.4294, device='cuda:0')]\n",
            "9.620225301048816 train: [0.7585839859498468, tensor(0.4295, device='cuda:0')]\n",
            "9.620354784410203 train: [0.7585261339543395, tensor(0.4295, device='cuda:0')]\n",
            "9.620484267771591 train: [0.7584682432377974, tensor(0.4295, device='cuda:0')]\n",
            "9.620613751132979 train: [0.7584101249617238, tensor(0.4295, device='cuda:0')]\n",
            "9.620743234494368 train: [0.7582512623465244, tensor(0.4296, device='cuda:0')]\n",
            "9.620872717855756 train: [0.7581925845751107, tensor(0.4296, device='cuda:0')]\n",
            "9.621002201217143 train: [0.7583367684778057, tensor(0.4295, device='cuda:0')]\n",
            "9.62113168457853 train: [0.7584810807193121, tensor(0.4295, device='cuda:0')]\n",
            "9.62126116793992 train: [0.7586253954422514, tensor(0.4294, device='cuda:0')]\n",
            "9.621390651301308 train: [0.7587696497698263, tensor(0.4293, device='cuda:0')]\n",
            "9.621520134662696 train: [0.7587102963067267, tensor(0.4293, device='cuda:0')]\n",
            "9.621649618024083 train: [0.7586509676725178, tensor(0.4293, device='cuda:0')]\n",
            "9.621779101385473 train: [0.7586959084346749, tensor(0.4293, device='cuda:0')]\n",
            "9.62190858474686 train: [0.7587406419369884, tensor(0.4293, device='cuda:0')]\n",
            "9.622038068108248 train: [0.7587846658332261, tensor(0.4293, device='cuda:0')]\n",
            "9.622167551469635 train: [0.7589279524354955, tensor(0.4293, device='cuda:0')]\n",
            "9.622297034831025 train: [0.7590707396774246, tensor(0.4292, device='cuda:0')]\n",
            "9.622426518192412 train: [0.7590139209156208, tensor(0.4292, device='cuda:0')]\n",
            "9.6225560015538 train: [0.7588553967049033, tensor(0.4293, device='cuda:0')]\n",
            "9.622685484915188 train: [0.7587997132852531, tensor(0.4293, device='cuda:0')]\n",
            "9.622814968276577 train: [0.7588380866589047, tensor(0.4293, device='cuda:0')]\n",
            "9.622944451637965 train: [0.7588755659650306, tensor(0.4293, device='cuda:0')]\n",
            "9.623073934999352 train: [0.7590161788076281, tensor(0.4293, device='cuda:0')]\n",
            "9.62320341836074 train: [0.7589630786684106, tensor(0.4293, device='cuda:0')]\n",
            "9.62333290172213 train: [0.7588047634663522, tensor(0.4294, device='cuda:0')]\n",
            "9.623462385083517 train: [0.7589442377877597, tensor(0.4293, device='cuda:0')]\n",
            "9.623591868444905 train: [0.7588930027827677, tensor(0.4293, device='cuda:0')]\n",
            "9.623721351806292 train: [0.7589244730280144, tensor(0.4293, device='cuda:0')]\n",
            "9.623850835167682 train: [0.7587662978564786, tensor(0.4294, device='cuda:0')]\n",
            "9.62398031852907 train: [0.7587168225151073, tensor(0.4295, device='cuda:0')]\n",
            "9.624109801890457 train: [0.7586677433894231, tensor(0.4295, device='cuda:0')]\n",
            "9.624239285251845 train: [0.7586187472962364, tensor(0.4295, device='cuda:0')]\n",
            "9.624368768613234 train: [0.7585696464614103, tensor(0.4295, device='cuda:0')]\n",
            "9.624498251974622 train: [0.7585202532671887, tensor(0.4295, device='cuda:0')]\n",
            "9.62462773533601 train: [0.7584703802520336, tensor(0.4295, device='cuda:0')]\n",
            "9.624757218697397 train: [0.7584198401104618, tensor(0.4296, device='cuda:0')]\n",
            "9.624886702058786 train: [0.7583685707368993, tensor(0.4296, device='cuda:0')]\n",
            "9.625016185420174 train: [0.7585080376574227, tensor(0.4295, device='cuda:0')]\n",
            "9.625145668781562 train: [0.7585428282589914, tensor(0.4295, device='cuda:0')]\n",
            "9.62527515214295 train: [0.7586826383223764, tensor(0.4294, device='cuda:0')]\n",
            "9.625404635504339 train: [0.7588224527226931, tensor(0.4293, device='cuda:0')]\n",
            "9.625534118865726 train: [0.7587692167788561, tensor(0.4293, device='cuda:0')]\n",
            "9.625663602227114 train: [0.7588047359565829, tensor(0.4293, device='cuda:0')]\n",
            "9.625793085588501 train: [0.7589444378406239, tensor(0.4293, device='cuda:0')]\n",
            "9.625922568949889 train: [0.7588915218233677, tensor(0.4293, device='cuda:0')]\n",
            "9.626052052311278 train: [0.7588386901909098, tensor(0.4293, device='cuda:0')]\n",
            "9.626181535672666 train: [0.758785755714126, tensor(0.4293, device='cuda:0')]\n",
            "9.626311019034054 train: [0.7587325313193657, tensor(0.4293, device='cuda:0')]\n",
            "9.626440502395441 train: [0.7585750525872529, tensor(0.4294, device='cuda:0')]\n",
            "9.62656998575683 train: [0.758417639212572, tensor(0.4295, device='cuda:0')]\n",
            "9.626699469118218 train: [0.7583634021903926, tensor(0.4296, device='cuda:0')]\n",
            "9.626828952479606 train: [0.7584012453528632, tensor(0.4296, device='cuda:0')]\n",
            "9.626958435840994 train: [0.7583464733951759, tensor(0.4296, device='cuda:0')]\n",
            "9.627087919202383 train: [0.758291474943779, tensor(0.4296, device='cuda:0')]\n",
            "9.62721740256377 train: [0.7582361255620934, tensor(0.4296, device='cuda:0')]\n",
            "9.627346885925158 train: [0.7581803009166999, tensor(0.4296, device='cuda:0')]\n",
            "9.627476369286546 train: [0.7580231976632982, tensor(0.4298, device='cuda:0')]\n",
            "9.627605852647935 train: [0.7579663197598445, tensor(0.4298, device='cuda:0')]\n",
            "9.627735336009323 train: [0.7581083752230579, tensor(0.4297, device='cuda:0')]\n",
            "9.62786481937071 train: [0.7579513844640553, tensor(0.4298, device='cuda:0')]\n",
            "9.627994302732098 train: [0.7579951524924351, tensor(0.4298, device='cuda:0')]\n",
            "9.628123786093488 train: [0.7579369591221757, tensor(0.4298, device='cuda:0')]\n",
            "9.628253269454875 train: [0.7580795249219944, tensor(0.4297, device='cuda:0')]\n",
            "9.628382752816263 train: [0.757922670064779, tensor(0.4299, device='cuda:0')]\n",
            "9.62851223617765 train: [0.7579668429354571, tensor(0.4299, device='cuda:0')]\n",
            "9.62864171953904 train: [0.7580106246519768, tensor(0.4299, device='cuda:0')]\n",
            "9.628771202900428 train: [0.7581526844937011, tensor(0.4298, device='cuda:0')]\n",
            "9.628900686261815 train: [0.7580955868028498, tensor(0.4298, device='cuda:0')]\n",
            "9.629030169623203 train: [0.7579388907328203, tensor(0.4299, device='cuda:0')]\n",
            "9.629159652984592 train: [0.7580800700836154, tensor(0.4298, device='cuda:0')]\n",
            "9.62928913634598 train: [0.7579234419699619, tensor(0.4300, device='cuda:0')]\n",
            "9.629418619707367 train: [0.7578679284914115, tensor(0.4300, device='cuda:0')]\n",
            "9.629548103068755 train: [0.7578126241143203, tensor(0.4300, device='cuda:0')]\n",
            "9.629677586430144 train: [0.7579530924887625, tensor(0.4299, device='cuda:0')]\n",
            "9.629807069791532 train: [0.7580934408348154, tensor(0.4298, device='cuda:0')]\n",
            "9.62993655315292 train: [0.7580385582876875, tensor(0.4298, device='cuda:0')]\n",
            "9.630066036514307 train: [0.7579837603971554, tensor(0.4298, device='cuda:0')]\n",
            "9.630195519875697 train: [0.7580224087857675, tensor(0.4299, device='cuda:0')]\n",
            "9.630325003237084 train: [0.7579676988131505, tensor(0.4299, device='cuda:0')]\n",
            "9.630454486598472 train: [0.7580060247354728, tensor(0.4299, device='cuda:0')]\n",
            "9.63058396995986 train: [0.7578497348334655, tensor(0.4300, device='cuda:0')]\n",
            "9.630713453321249 train: [0.7579893444848802, tensor(0.4299, device='cuda:0')]\n",
            "9.630842936682637 train: [0.7578331224435602, tensor(0.4300, device='cuda:0')]\n",
            "9.630972420044024 train: [0.7579722445671987, tensor(0.4299, device='cuda:0')]\n",
            "9.631101903405412 train: [0.7579194077644131, tensor(0.4300, device='cuda:0')]\n",
            "9.631231386766801 train: [0.7578668402915313, tensor(0.4300, device='cuda:0')]\n",
            "9.631360870128189 train: [0.7579019759456976, tensor(0.4300, device='cuda:0')]\n",
            "9.631490353489577 train: [0.757849804900936, tensor(0.4300, device='cuda:0')]\n",
            "9.631619836850964 train: [0.7577977790401241, tensor(0.4300, device='cuda:0')]\n",
            "9.631749320212352 train: [0.7577457127534947, tensor(0.4300, device='cuda:0')]\n",
            "9.631878803573741 train: [0.7578842196897753, tensor(0.4299, device='cuda:0')]\n",
            "9.632008286935129 train: [0.758022731453642, tensor(0.4298, device='cuda:0')]\n",
            "9.632137770296517 train: [0.758057668081353, tensor(0.4299, device='cuda:0')]\n",
            "9.632267253657904 train: [0.7580920342381247, tensor(0.4299, device='cuda:0')]\n",
            "9.632396737019294 train: [0.7580405787417763, tensor(0.4299, device='cuda:0')]\n",
            "9.632526220380681 train: [0.7578847636176773, tensor(0.4300, device='cuda:0')]\n",
            "9.632655703742069 train: [0.7580222684284992, tensor(0.4299, device='cuda:0')]\n",
            "9.632785187103456 train: [0.7581594697807843, tensor(0.4298, device='cuda:0')]\n",
            "9.632914670464846 train: [0.7581903848129069, tensor(0.4298, device='cuda:0')]\n",
            "9.633044153826233 train: [0.7581414304785377, tensor(0.4299, device='cuda:0')]\n",
            "9.633173637187621 train: [0.7581704855078186, tensor(0.4299, device='cuda:0')]\n",
            "9.633303120549009 train: [0.7580148356442367, tensor(0.4300, device='cuda:0')]\n",
            "9.633432603910398 train: [0.7581503558402805, tensor(0.4299, device='cuda:0')]\n",
            "9.633562087271786 train: [0.7579947739901183, tensor(0.4300, device='cuda:0')]\n",
            "9.633691570633173 train: [0.7581296261955115, tensor(0.4299, device='cuda:0')]\n",
            "9.633821053994561 train: [0.7582641148915188, tensor(0.4298, device='cuda:0')]\n",
            "9.63395053735595 train: [0.758220268919196, tensor(0.4299, device='cuda:0')]\n",
            "9.634080020717338 train: [0.7580648003383227, tensor(0.4300, device='cuda:0')]\n",
            "9.634209504078726 train: [0.7580219987896994, tensor(0.4300, device='cuda:0')]\n",
            "9.634338987440113 train: [0.7579793379593864, tensor(0.4300, device='cuda:0')]\n",
            "9.634468470801503 train: [0.7579366330390921, tensor(0.4300, device='cuda:0')]\n",
            "9.63459795416289 train: [0.7578935762493499, tensor(0.4300, device='cuda:0')]\n",
            "9.634727437524278 train: [0.7580275511691299, tensor(0.4299, device='cuda:0')]\n",
            "9.634856920885666 train: [0.7579835703539753, tensor(0.4300, device='cuda:0')]\n",
            "9.634986404247055 train: [0.7580071603509103, tensor(0.4300, device='cuda:0')]\n",
            "9.635115887608443 train: [0.7579625250964491, tensor(0.4300, device='cuda:0')]\n",
            "9.63524537096983 train: [0.7580969912072169, tensor(0.4299, device='cuda:0')]\n",
            "9.635374854331218 train: [0.758051740980781, tensor(0.4299, device='cuda:0')]\n",
            "9.635504337692607 train: [0.7578966567457195, tensor(0.4300, device='cuda:0')]\n",
            "9.635633821053995 train: [0.7578507284799472, tensor(0.4300, device='cuda:0')]\n",
            "9.635763304415383 train: [0.7578771433065912, tensor(0.4301, device='cuda:0')]\n",
            "9.63589278777677 train: [0.757830562021295, tensor(0.4301, device='cuda:0')]\n",
            "9.63602227113816 train: [0.7578576458228505, tensor(0.4301, device='cuda:0')]\n",
            "9.636151754499547 train: [0.7579927393332705, tensor(0.4300, device='cuda:0')]\n",
            "9.636281237860935 train: [0.7579460401865706, tensor(0.4300, device='cuda:0')]\n",
            "9.636540204583712 train: [0.7578992987349729, tensor(0.4300, device='cuda:0')]\n",
            "9.6366696879451 train: [0.7580343623326734, tensor(0.4299, device='cuda:0')]\n",
            "9.636799171306487 train: [0.7578795666695465, tensor(0.4301, device='cuda:0')]\n",
            "9.636928654667875 train: [0.7580147018406257, tensor(0.4300, device='cuda:0')]\n",
            "9.637058138029262 train: [0.7578599733854633, tensor(0.4301, device='cuda:0')]\n",
            "9.637187621390652 train: [0.7578128066130299, tensor(0.4301, device='cuda:0')]\n",
            "9.63731710475204 train: [0.7579479339969865, tensor(0.4300, device='cuda:0')]\n",
            "9.637446588113427 train: [0.7579005846318614, tensor(0.4300, device='cuda:0')]\n",
            "9.637576071474815 train: [0.7580357615627794, tensor(0.4299, device='cuda:0')]\n",
            "9.637705554836204 train: [0.7578811865706174, tensor(0.4301, device='cuda:0')]\n",
            "9.637835038197592 train: [0.7578333896926214, tensor(0.4301, device='cuda:0')]\n",
            "9.63796452155898 train: [0.7577853673092603, tensor(0.4301, device='cuda:0')]\n",
            "9.638094004920367 train: [0.75773693585302, tensor(0.4301, device='cuda:0')]\n",
            "9.638223488281756 train: [0.7576879119059934, tensor(0.4301, device='cuda:0')]\n",
            "9.638352971643144 train: [0.7576381734099065, tensor(0.4301, device='cuda:0')]\n",
            "9.638482455004532 train: [0.7575876596036346, tensor(0.4301, device='cuda:0')]\n",
            "9.63861193836592 train: [0.7575363097755431, tensor(0.4302, device='cuda:0')]\n",
            "9.638741421727309 train: [0.7574840020906415, tensor(0.4302, device='cuda:0')]\n",
            "9.638870905088696 train: [0.7576219243686295, tensor(0.4301, device='cuda:0')]\n",
            "9.639000388450084 train: [0.7574677481528443, tensor(0.4302, device='cuda:0')]\n",
            "9.639129871811472 train: [0.7573136346740746, tensor(0.4303, device='cuda:0')]\n",
            "9.639259355172861 train: [0.7572584198183326, tensor(0.4303, device='cuda:0')]\n",
            "9.639388838534249 train: [0.7572995988212011, tensor(0.4303, device='cuda:0')]\n",
            "9.639518321895636 train: [0.7574391291214377, tensor(0.4303, device='cuda:0')]\n",
            "9.639647805257024 train: [0.7575787248619951, tensor(0.4302, device='cuda:0')]\n",
            "9.639777288618413 train: [0.7577182638563165, tensor(0.4301, device='cuda:0')]\n",
            "9.6399067719798 train: [0.7578576850780798, tensor(0.4300, device='cuda:0')]\n",
            "9.640036255341188 train: [0.75770371155409, tensor(0.4301, device='cuda:0')]\n",
            "9.640165738702576 train: [0.7578428959827497, tensor(0.4300, device='cuda:0')]\n",
            "9.640295222063965 train: [0.7578835926271636, tensor(0.4300, device='cuda:0')]\n",
            "9.640424705425353 train: [0.7577297076337368, tensor(0.4302, device='cuda:0')]\n",
            "9.64055418878674 train: [0.757675069392392, tensor(0.4302, device='cuda:0')]\n",
            "9.640683672148128 train: [0.7578132318386911, tensor(0.4301, device='cuda:0')]\n",
            "9.640813155509518 train: [0.7579510943158404, tensor(0.4300, device='cuda:0')]\n",
            "9.640942638870905 train: [0.7578976026889523, tensor(0.4300, device='cuda:0')]\n",
            "9.641072122232293 train: [0.7580350264276798, tensor(0.4299, device='cuda:0')]\n",
            "9.64120160559368 train: [0.758172211616461, tensor(0.4298, device='cuda:0')]\n",
            "9.64133108895507 train: [0.7583090974756691, tensor(0.4297, device='cuda:0')]\n",
            "9.641460572316458 train: [0.7582570385473031, tensor(0.4298, device='cuda:0')]\n",
            "9.641590055677845 train: [0.7582053052212279, tensor(0.4298, device='cuda:0')]\n",
            "9.641719539039233 train: [0.7583416140596991, tensor(0.4297, device='cuda:0')]\n",
            "9.641849022400622 train: [0.758290128062274, tensor(0.4297, device='cuda:0')]\n",
            "9.64197850576201 train: [0.7584263036373693, tensor(0.4296, device='cuda:0')]\n",
            "9.642107989123398 train: [0.7584601340273234, tensor(0.4296, device='cuda:0')]\n",
            "9.642237472484785 train: [0.7584933423341692, tensor(0.4296, device='cuda:0')]\n",
            "9.642366955846175 train: [0.7586287858143881, tensor(0.4296, device='cuda:0')]\n",
            "9.642496439207562 train: [0.7585791790240219, tensor(0.4296, device='cuda:0')]\n",
            "9.64262592256895 train: [0.7585300787208542, tensor(0.4296, device='cuda:0')]\n",
            "9.642755405930338 train: [0.7586647030960644, tensor(0.4295, device='cuda:0')]\n",
            "9.642884889291725 train: [0.7586161523486121, tensor(0.4295, device='cuda:0')]\n",
            "9.643014372653115 train: [0.7587505225752509, tensor(0.4294, device='cuda:0')]\n",
            "9.643143856014502 train: [0.7587022171179508, tensor(0.4294, device='cuda:0')]\n",
            "9.64327333937589 train: [0.7586539311898431, tensor(0.4295, device='cuda:0')]\n",
            "9.643402822737277 train: [0.7586054825959206, tensor(0.4295, device='cuda:0')]\n",
            "9.643532306098667 train: [0.7587399892363648, tensor(0.4294, device='cuda:0')]\n",
            "9.643661789460054 train: [0.7587703355672105, tensor(0.4294, device='cuda:0')]\n",
            "9.643791272821442 train: [0.7589048152665351, tensor(0.4293, device='cuda:0')]\n",
            "9.64405023954422 train: [0.7590391192952343, tensor(0.4292, device='cuda:0')]\n",
            "9.644179722905607 train: [0.7589906418409977, tensor(0.4292, device='cuda:0')]\n",
            "9.644309206266994 train: [0.7588374342023539, tensor(0.4294, device='cuda:0')]\n",
            "9.644438689628382 train: [0.7587891989443453, tensor(0.4294, device='cuda:0')]\n",
            "9.644568172989771 train: [0.7587408618923449, tensor(0.4294, device='cuda:0')]\n",
            "9.644697656351159 train: [0.7585877973650316, tensor(0.4295, device='cuda:0')]\n",
            "9.644827139712547 train: [0.7587220634095634, tensor(0.4294, device='cuda:0')]\n",
            "9.644956623073934 train: [0.7588563358966604, tensor(0.4293, device='cuda:0')]\n",
            "9.645086106435324 train: [0.7588865975883995, tensor(0.4293, device='cuda:0')]\n",
            "9.645215589796711 train: [0.7590206616415736, tensor(0.4292, device='cuda:0')]\n",
            "9.645345073158099 train: [0.759154429432921, tensor(0.4292, device='cuda:0')]\n",
            "9.645474556519487 train: [0.7591066318642571, tensor(0.4292, device='cuda:0')]\n",
            "9.645604039880876 train: [0.7592400257817827, tensor(0.4291, device='cuda:0')]\n",
            "9.645733523242264 train: [0.759192774905105, tensor(0.4291, device='cuda:0')]\n",
            "9.645863006603651 train: [0.7593259162303665, tensor(0.4290, device='cuda:0')]\n",
            "9.645992489965039 train: [0.7592789695645104, tensor(0.4290, device='cuda:0')]\n",
            "9.646121973326428 train: [0.7594119794569862, tensor(0.4289, device='cuda:0')]\n",
            "9.646251456687816 train: [0.7595448753425081, tensor(0.4289, device='cuda:0')]\n",
            "9.646380940049204 train: [0.7595715519075994, tensor(0.4289, device='cuda:0')]\n",
            "9.646510423410591 train: [0.7595253189653839, tensor(0.4289, device='cuda:0')]\n",
            "9.64663990677198 train: [0.7594793463588403, tensor(0.4289, device='cuda:0')]\n",
            "9.646769390133368 train: [0.7596116988468499, tensor(0.4288, device='cuda:0')]\n",
            "9.646898873494756 train: [0.7594589823814605, tensor(0.4289, device='cuda:0')]\n",
            "9.647028356856143 train: [0.759591225357557, tensor(0.4288, device='cuda:0')]\n",
            "9.647157840217533 train: [0.7597232944093186, tensor(0.4288, device='cuda:0')]\n",
            "9.64728732357892 train: [0.7596781130701226, tensor(0.4288, device='cuda:0')]\n",
            "9.647416806940308 train: [0.759809990882962, tensor(0.4287, device='cuda:0')]\n",
            "9.647546290301696 train: [0.7599417553725648, tensor(0.4286, device='cuda:0')]\n",
            "9.647675773663085 train: [0.759789156626506, tensor(0.4287, device='cuda:0')]\n",
            "9.647805257024473 train: [0.7597446619268605, tensor(0.4287, device='cuda:0')]\n",
            "9.64793474038586 train: [0.7595921640019455, tensor(0.4288, device='cuda:0')]\n",
            "9.648064223747248 train: [0.759547726693836, tensor(0.4289, device='cuda:0')]\n",
            "9.648193707108636 train: [0.7596792910390172, tensor(0.4288, device='cuda:0')]\n",
            "9.648323190470025 train: [0.7598108628770928, tensor(0.4287, device='cuda:0')]\n",
            "9.648452673831413 train: [0.7599423216737634, tensor(0.4286, device='cuda:0')]\n",
            "9.6485821571928 train: [0.7598977292884577, tensor(0.4286, device='cuda:0')]\n",
            "9.648711640554188 train: [0.7600291179600271, tensor(0.4285, device='cuda:0')]\n",
            "9.648841123915577 train: [0.760160453960251, tensor(0.4284, device='cuda:0')]\n",
            "9.648970607276965 train: [0.7601158446701094, tensor(0.4285, device='cuda:0')]\n",
            "9.649100090638353 train: [0.7599635473660281, tensor(0.4286, device='cuda:0')]\n",
            "9.64922957399974 train: [0.760094877765964, tensor(0.4285, device='cuda:0')]\n",
            "9.64935905736113 train: [0.7600501278713275, tensor(0.4285, device='cuda:0')]\n",
            "9.649488540722517 train: [0.7600052153930871, tensor(0.4285, device='cuda:0')]\n",
            "9.649618024083905 train: [0.7601366991991992, tensor(0.4284, device='cuda:0')]\n",
            "9.649747507445293 train: [0.7600911257852436, tensor(0.4284, device='cuda:0')]\n",
            "9.649876990806682 train: [0.7601167070434568, tensor(0.4285, device='cuda:0')]\n",
            "9.65000647416807 train: [0.7601423381852741, tensor(0.4285, device='cuda:0')]\n",
            "9.650135957529457 train: [0.7599902793058612, tensor(0.4286, device='cuda:0')]\n",
            "9.650265440890845 train: [0.75983828125, tensor(0.4287, device='cuda:0')]\n",
            "9.650394924252234 train: [0.7597931735768231, tensor(0.4287, device='cuda:0')]\n",
            "9.650524407613622 train: [0.759641275701258, tensor(0.4288, device='cuda:0')]\n",
            "9.65065389097501 train: [0.7596657149940804, tensor(0.4288, device='cuda:0')]\n",
            "9.650783374336397 train: [0.7596210891863432, tensor(0.4289, device='cuda:0')]\n",
            "9.650912857697787 train: [0.7594693167409513, tensor(0.4290, device='cuda:0')]\n",
            "9.651042341059174 train: [0.7596002585359107, tensor(0.4289, device='cuda:0')]\n",
            "9.651171824420562 train: [0.7597310880152403, tensor(0.4288, device='cuda:0')]\n",
            "9.65130130778195 train: [0.7596872047992442, tensor(0.4288, device='cuda:0')]\n",
            "9.651430791143339 train: [0.7596433990931708, tensor(0.4288, device='cuda:0')]\n",
            "9.651560274504726 train: [0.7597740816444035, tensor(0.4287, device='cuda:0')]\n",
            "9.651689757866114 train: [0.759904712037364, tensor(0.4287, device='cuda:0')]\n",
            "9.651819241227502 train: [0.7598607092976856, tensor(0.4287, device='cuda:0')]\n",
            "9.651948724588891 train: [0.7599913302337, tensor(0.4286, device='cuda:0')]\n",
            "9.652078207950279 train: [0.7601219589955815, tensor(0.4285, device='cuda:0')]\n",
            "9.652207691311666 train: [0.7599703893128308, tensor(0.4286, device='cuda:0')]\n",
            "9.652337174673054 train: [0.7599262887605815, tensor(0.4286, device='cuda:0')]\n",
            "9.652466658034443 train: [0.7599495848729704, tensor(0.4286, device='cuda:0')]\n",
            "9.652596141395831 train: [0.7597981401569733, tensor(0.4288, device='cuda:0')]\n",
            "9.652725624757219 train: [0.7597543397589162, tensor(0.4288, device='cuda:0')]\n",
            "9.652855108118606 train: [0.7598846800298805, tensor(0.4287, device='cuda:0')]\n",
            "9.652984591479996 train: [0.7597333387273452, tensor(0.4288, device='cuda:0')]\n",
            "9.653114074841383 train: [0.759582057696137, tensor(0.4289, device='cuda:0')]\n",
            "9.653243558202771 train: [0.7597122945986922, tensor(0.4288, device='cuda:0')]\n",
            "9.653373041564159 train: [0.7598424198462763, tensor(0.4287, device='cuda:0')]\n",
            "9.653502524925548 train: [0.7596912074244164, tensor(0.4289, device='cuda:0')]\n",
            "9.653632008286936 train: [0.7596483262993969, tensor(0.4289, device='cuda:0')]\n",
            "9.653761491648323 train: [0.7597782072959863, tensor(0.4288, device='cuda:0')]\n",
            "9.65389097500971 train: [0.7599079768680007, tensor(0.4287, device='cuda:0')]\n",
            "9.654020458371098 train: [0.7599291297971764, tensor(0.4287, device='cuda:0')]\n",
            "9.654149941732488 train: [0.7598870717999694, tensor(0.4287, device='cuda:0')]\n",
            "9.654279425093875 train: [0.760016383996147, tensor(0.4286, device='cuda:0')]\n",
            "9.654408908455263 train: [0.7600359502071359, tensor(0.4287, device='cuda:0')]\n",
            "9.65453839181665 train: [0.7601648232244111, tensor(0.4286, device='cuda:0')]\n",
            "9.65466787517804 train: [0.760124721604627, tensor(0.4286, device='cuda:0')]\n",
            "9.654797358539428 train: [0.7599737534374761, tensor(0.4287, device='cuda:0')]\n",
            "9.654926841900815 train: [0.7599905082444859, tensor(0.4287, device='cuda:0')]\n",
            "9.655056325262203 train: [0.7601185720857959, tensor(0.4286, device='cuda:0')]\n",
            "9.655185808623592 train: [0.7602463465164748, tensor(0.4285, device='cuda:0')]\n",
            "9.65531529198498 train: [0.7602091904300303, tensor(0.4286, device='cuda:0')]\n",
            "9.655444775346368 train: [0.7601724664224664, tensor(0.4286, device='cuda:0')]\n",
            "9.655574258707755 train: [0.7600216684723727, tensor(0.4287, device='cuda:0')]\n",
            "9.655703742069145 train: [0.7599851154151283, tensor(0.4287, device='cuda:0')]\n",
            "9.655833225430532 train: [0.7601124917059443, tensor(0.4286, device='cuda:0')]\n",
            "9.65596270879192 train: [0.7600756372765815, tensor(0.4286, device='cuda:0')]\n",
            "9.656092192153308 train: [0.7602030642486849, tensor(0.4285, device='cuda:0')]\n",
            "9.656221675514697 train: [0.7601656109942376, tensor(0.4286, device='cuda:0')]\n",
            "9.656351158876085 train: [0.7601805051744372, tensor(0.4286, device='cuda:0')]\n",
            "9.656480642237472 train: [0.7603080737420761, tensor(0.4285, device='cuda:0')]\n",
            "9.65661012559886 train: [0.7603229338063897, tensor(0.4285, device='cuda:0')]\n",
            "9.65673960896025 train: [0.7604502451447068, tensor(0.4284, device='cuda:0')]\n",
            "9.656869092321637 train: [0.7605773870939494, tensor(0.4283, device='cuda:0')]\n",
            "9.656998575683025 train: [0.7605408558682015, tensor(0.4283, device='cuda:0')]\n",
            "9.657128059044412 train: [0.7605045174991246, tensor(0.4284, device='cuda:0')]\n",
            "9.657257542405802 train: [0.7606313948776293, tensor(0.4283, device='cuda:0')]\n",
            "9.65738702576719 train: [0.760758222057369, tensor(0.4282, device='cuda:0')]\n",
            "9.657516509128577 train: [0.7606077556368671, tensor(0.4283, device='cuda:0')]\n",
            "9.657645992489964 train: [0.7606202750186337, tensor(0.4283, device='cuda:0')]\n",
            "9.657775475851354 train: [0.7605844915328345, tensor(0.4283, device='cuda:0')]\n",
            "9.657904959212742 train: [0.7605489003793696, tensor(0.4283, device='cuda:0')]\n",
            "9.65803444257413 train: [0.760675440388416, tensor(0.4283, device='cuda:0')]\n",
            "9.658163925935517 train: [0.7606874615270621, tensor(0.4283, device='cuda:0')]\n",
            "9.658293409296906 train: [0.7605371874335167, tensor(0.4284, device='cuda:0')]\n",
            "9.658422892658294 train: [0.7605484002529664, tensor(0.4284, device='cuda:0')]\n",
            "9.658552376019681 train: [0.7603982129701361, tensor(0.4285, device='cuda:0')]\n",
            "9.658681859381069 train: [0.7605241832143671, tensor(0.4284, device='cuda:0')]\n",
            "9.658811342742458 train: [0.76049096635944, tensor(0.4284, device='cuda:0')]\n",
            "9.658940826103846 train: [0.7606166313704058, tensor(0.4284, device='cuda:0')]\n",
            "9.659070309465234 train: [0.7604665491621638, tensor(0.4285, device='cuda:0')]\n",
            "9.659199792826621 train: [0.7604342525077014, tensor(0.4285, device='cuda:0')]\n",
            "9.659329276188009 train: [0.7602842654756486, tensor(0.4286, device='cuda:0')]\n",
            "9.659458759549398 train: [0.7602519582505347, tensor(0.4286, device='cuda:0')]\n",
            "9.659588242910786 train: [0.7601020663029301, tensor(0.4287, device='cuda:0')]\n",
            "9.659717726272174 train: [0.7602276593466163, tensor(0.4286, device='cuda:0')]\n",
            "9.659847209633561 train: [0.7603532621054546, tensor(0.4286, device='cuda:0')]\n",
            "9.65997669299495 train: [0.7604788153656689, tensor(0.4285, device='cuda:0')]\n",
            "9.660106176356338 train: [0.7604456728874947, tensor(0.4285, device='cuda:0')]\n",
            "9.660235659717726 train: [0.7604122475417039, tensor(0.4285, device='cuda:0')]\n",
            "9.660365143079114 train: [0.7605379517034265, tensor(0.4284, device='cuda:0')]\n",
            "9.660494626440503 train: [0.7606636655269814, tensor(0.4283, device='cuda:0')]\n",
            "9.66062410980189 train: [0.7605139285849485, tensor(0.4284, device='cuda:0')]\n",
            "9.660753593163278 train: [0.7606397750669917, tensor(0.4284, device='cuda:0')]\n",
            "9.660883076524666 train: [0.7606509257787667, tensor(0.4284, device='cuda:0')]\n",
            "9.661012559886055 train: [0.7606161989815221, tensor(0.4284, device='cuda:0')]\n",
            "9.661142043247443 train: [0.7605814858454881, tensor(0.4284, device='cuda:0')]\n",
            "9.66127152660883 train: [0.7605464318130247, tensor(0.4284, device='cuda:0')]\n",
            "9.661401009970218 train: [0.7605584192277444, tensor(0.4284, device='cuda:0')]\n",
            "9.661530493331608 train: [0.7605226746911433, tensor(0.4284, device='cuda:0')]\n",
            "9.661659976692995 train: [0.7606487006569, tensor(0.4284, device='cuda:0')]\n",
            "9.661789460054383 train: [0.7607747361390329, tensor(0.4283, device='cuda:0')]\n",
            "9.66191894341577 train: [0.7607877909173342, tensor(0.4283, device='cuda:0')]\n",
            "9.66204842677716 train: [0.7608005454572927, tensor(0.4283, device='cuda:0')]\n",
            "9.662177910138547 train: [0.7609262408227083, tensor(0.4282, device='cuda:0')]\n",
            "9.662307393499935 train: [0.7608911741606126, tensor(0.4282, device='cuda:0')]\n",
            "9.662436876861323 train: [0.7607418040832352, tensor(0.4283, device='cuda:0')]\n",
            "9.662566360222712 train: [0.760592492639843, tensor(0.4285, device='cuda:0')]\n",
            "9.6626958435841 train: [0.7605582786461478, tensor(0.4285, device='cuda:0')]\n",
            "9.662825326945487 train: [0.7605240191251263, tensor(0.4285, device='cuda:0')]\n",
            "9.662954810306875 train: [0.7604894783399221, tensor(0.4285, device='cuda:0')]\n",
            "9.663084293668264 train: [0.7604543618092537, tensor(0.4285, device='cuda:0')]\n",
            "9.663213777029652 train: [0.7604184931184013, tensor(0.4285, device='cuda:0')]\n",
            "9.66334326039104 train: [0.7605444539532218, tensor(0.4284, device='cuda:0')]\n",
            "9.663472743752427 train: [0.7605068737184513, tensor(0.4285, device='cuda:0')]\n",
            "9.663602227113817 train: [0.7604684249649527, tensor(0.4285, device='cuda:0')]\n",
            "9.663731710475204 train: [0.760319430367585, tensor(0.4286, device='cuda:0')]\n",
            "9.663861193836592 train: [0.7602790321517366, tensor(0.4286, device='cuda:0')]\n",
            "9.66399067719798 train: [0.7602376493341167, tensor(0.4286, device='cuda:0')]\n",
            "9.664120160559369 train: [0.7603654392161588, tensor(0.4285, device='cuda:0')]\n",
            "9.664249643920757 train: [0.7603220556178845, tensor(0.4285, device='cuda:0')]\n",
            "9.664379127282144 train: [0.7604505435355406, tensor(0.4285, device='cuda:0')]\n",
            "9.664508610643532 train: [0.7604053373852175, tensor(0.4285, device='cuda:0')]\n",
            "9.664638094004921 train: [0.7603592670597354, tensor(0.4285, device='cuda:0')]\n",
            "9.664767577366309 train: [0.7603870418020946, tensor(0.4285, device='cuda:0')]\n",
            "9.664897060727696 train: [0.7603395238757917, tensor(0.4285, device='cuda:0')]\n",
            "9.665026544089084 train: [0.7604695866926386, tensor(0.4284, device='cuda:0')]\n",
            "9.665156027450472 train: [0.7604209550530115, tensor(0.4284, device='cuda:0')]\n",
            "9.665285510811861 train: [0.760272319213478, tensor(0.4286, device='cuda:0')]\n",
            "9.665414994173249 train: [0.7604031410193773, tensor(0.4285, device='cuda:0')]\n",
            "9.665544477534636 train: [0.7602545667440707, tensor(0.4286, device='cuda:0')]\n",
            "9.665673960896024 train: [0.7602042541361744, tensor(0.4286, device='cuda:0')]\n",
            "9.665803444257413 train: [0.7602377671461839, tensor(0.4286, device='cuda:0')]\n",
            "9.665932927618801 train: [0.7601869493826326, tensor(0.4286, device='cuda:0')]\n",
            "9.666062410980189 train: [0.7601359168030817, tensor(0.4286, device='cuda:0')]\n",
            "9.666191894341576 train: [0.7602675504699771, tensor(0.4286, device='cuda:0')]\n",
            "9.666321377702966 train: [0.7601191766310875, tensor(0.4287, device='cuda:0')]\n",
            "9.666450861064353 train: [0.7600674249530956, tensor(0.4287, device='cuda:0')]\n",
            "9.666580344425741 train: [0.76001540037216, tensor(0.4287, device='cuda:0')]\n",
            "9.666709827787129 train: [0.7601475409221167, tensor(0.4286, device='cuda:0')]\n",
            "9.666839311148518 train: [0.760094876451308, tensor(0.4286, device='cuda:0')]\n",
            "9.666968794509906 train: [0.7602273600716889, tensor(0.4285, device='cuda:0')]\n",
            "9.667098277871293 train: [0.7603599091880342, tensor(0.4285, device='cuda:0')]\n",
            "9.667227761232681 train: [0.760211719768976, tensor(0.4286, device='cuda:0')]\n",
            "9.66735724459407 train: [0.7603443373778404, tensor(0.4285, device='cuda:0')]\n",
            "9.667486727955458 train: [0.7602909248602556, tensor(0.4285, device='cuda:0')]\n",
            "9.667616211316846 train: [0.7603288947551766, tensor(0.4285, device='cuda:0')]\n",
            "9.667745694678233 train: [0.7602755645644521, tensor(0.4285, device='cuda:0')]\n",
            "9.667875178039623 train: [0.7601275358330338, tensor(0.4286, device='cuda:0')]\n",
            "9.66800466140101 train: [0.7600743240966742, tensor(0.4287, device='cuda:0')]\n",
            "9.668134144762398 train: [0.7600210161092313, tensor(0.4287, device='cuda:0')]\n",
            "9.668263628123785 train: [0.7598731233254, tensor(0.4288, device='cuda:0')]\n",
            "9.668393111485175 train: [0.7600058342375038, tensor(0.4287, device='cuda:0')]\n",
            "9.668522594846563 train: [0.7599521030965242, tensor(0.4287, device='cuda:0')]\n",
            "9.66865207820795 train: [0.7598981591082488, tensor(0.4287, device='cuda:0')]\n",
            "9.668781561569338 train: [0.7600311382910304, tensor(0.4286, device='cuda:0')]\n",
            "9.669040528292115 train: [0.7600707788760618, tensor(0.4287, device='cuda:0')]\n",
            "9.669170011653502 train: [0.7600164928608806, tensor(0.4287, device='cuda:0')]\n",
            "9.66929949501489 train: [0.7601494299156926, tensor(0.4286, device='cuda:0')]\n",
            "9.66942897837628 train: [0.760095208093587, tensor(0.4286, device='cuda:0')]\n",
            "9.669558461737667 train: [0.7600409489682326, tensor(0.4286, device='cuda:0')]\n",
            "9.669687945099055 train: [0.7598933395394176, tensor(0.4287, device='cuda:0')]\n",
            "9.669817428460442 train: [0.7600263722927558, tensor(0.4286, device='cuda:0')]\n",
            "9.669946911821832 train: [0.7601593533929185, tensor(0.4286, device='cuda:0')]\n",
            "9.67007639518322 train: [0.7602922828699833, tensor(0.4285, device='cuda:0')]\n",
            "9.670205878544607 train: [0.760331861854185, tensor(0.4285, device='cuda:0')]\n",
            "9.670335361905995 train: [0.7602779114802544, tensor(0.4285, device='cuda:0')]\n",
            "9.670464845267382 train: [0.7604102159964187, tensor(0.4284, device='cuda:0')]\n",
            "9.670594328628772 train: [0.7603567958539714, tensor(0.4284, device='cuda:0')]\n",
            "9.67072381199016 train: [0.7604887424300055, tensor(0.4283, device='cuda:0')]\n",
            "9.670853295351547 train: [0.7603413037439973, tensor(0.4285, device='cuda:0')]\n",
            "9.670982778712935 train: [0.760378322703416, tensor(0.4285, device='cuda:0')]\n",
            "9.671112262074324 train: [0.7602309625633572, tensor(0.4286, device='cuda:0')]\n",
            "9.671241745435712 train: [0.7602665330213286, tensor(0.4286, device='cuda:0')]\n",
            "9.6713712287971 train: [0.760397205074807, tensor(0.4285, device='cuda:0')]\n",
            "9.671500712158487 train: [0.760430576196755, tensor(0.4285, device='cuda:0')]\n",
            "9.671630195519876 train: [0.7605602930606864, tensor(0.4284, device='cuda:0')]\n",
            "9.671759678881264 train: [0.7605117074056147, tensor(0.4285, device='cuda:0')]\n",
            "9.671889162242651 train: [0.7604638385412014, tensor(0.4285, device='cuda:0')]\n",
            "9.67201864560404 train: [0.7604164534360066, tensor(0.4285, device='cuda:0')]\n",
            "9.672148128965429 train: [0.7603693192389557, tensor(0.4285, device='cuda:0')]\n",
            "9.672277612326816 train: [0.7604977598516303, tensor(0.4284, device='cuda:0')]\n",
            "9.672407095688204 train: [0.7606260345372713, tensor(0.4283, device='cuda:0')]\n",
            "9.672536579049591 train: [0.7607542015009744, tensor(0.4283, device='cuda:0')]\n",
            "9.67266606241098 train: [0.7606071105880778, tensor(0.4284, device='cuda:0')]\n",
            "9.672795545772368 train: [0.7605609725609302, tensor(0.4284, device='cuda:0')]\n",
            "9.672925029133756 train: [0.7606887293345426, tensor(0.4283, device='cuda:0')]\n",
            "9.673054512495144 train: [0.7606428256224452, tensor(0.4283, device='cuda:0')]\n",
            "9.673183995856533 train: [0.7606693894156462, tensor(0.4283, device='cuda:0')]\n",
            "9.67331347921792 train: [0.7607968770894935, tensor(0.4282, device='cuda:0')]\n",
            "9.673442962579308 train: [0.7607516174198532, tensor(0.4283, device='cuda:0')]\n",
            "9.673572445940696 train: [0.7607064912665052, tensor(0.4283, device='cuda:0')]\n",
            "9.673701929302085 train: [0.7608337239196614, tensor(0.4282, device='cuda:0')]\n",
            "9.673831412663473 train: [0.7606868731719448, tensor(0.4283, device='cuda:0')]\n",
            "9.67396089602486 train: [0.7606417856374136, tensor(0.4283, device='cuda:0')]\n",
            "9.674090379386248 train: [0.7607689571305599, tensor(0.4282, device='cuda:0')]\n",
            "9.674219862747638 train: [0.7608961375237417, tensor(0.4281, device='cuda:0')]\n",
            "9.674349346109025 train: [0.7608509198130703, tensor(0.4282, device='cuda:0')]\n",
            "9.674478829470413 train: [0.7608056036592601, tensor(0.4282, device='cuda:0')]\n",
            "9.6746083128318 train: [0.7607599574008987, tensor(0.4282, device='cuda:0')]\n",
            "9.67473779619319 train: [0.7608873889819703, tensor(0.4281, device='cuda:0')]\n",
            "9.674867279554578 train: [0.7609146497954252, tensor(0.4281, device='cuda:0')]\n",
            "9.674996762915965 train: [0.761042118256262, tensor(0.4280, device='cuda:0')]\n",
            "9.675126246277353 train: [0.7609958827593616, tensor(0.4280, device='cuda:0')]\n",
            "9.675255729638742 train: [0.7609496071989451, tensor(0.4281, device='cuda:0')]\n",
            "9.67538521300013 train: [0.7609031180101913, tensor(0.4281, device='cuda:0')]\n",
            "9.675514696361518 train: [0.7608562417619442, tensor(0.4281, device='cuda:0')]\n",
            "9.675644179722905 train: [0.7608088629969645, tensor(0.4281, device='cuda:0')]\n",
            "9.675773663084295 train: [0.7607608663468941, tensor(0.4281, device='cuda:0')]\n",
            "9.675903146445682 train: [0.760712136532171, tensor(0.4281, device='cuda:0')]\n",
            "9.67603262980707 train: [0.7606626161689407, tensor(0.4281, device='cuda:0')]\n",
            "9.676162113168457 train: [0.760696051940462, tensor(0.4282, device='cuda:0')]\n",
            "9.676291596529845 train: [0.7605497642381657, tensor(0.4283, device='cuda:0')]\n",
            "9.676421079891234 train: [0.7605845954180409, tensor(0.4283, device='cuda:0')]\n",
            "9.676550563252622 train: [0.7607144903587377, tensor(0.4282, device='cuda:0')]\n",
            "9.67668004661401 train: [0.7608443353686483, tensor(0.4281, device='cuda:0')]\n",
            "9.676809529975397 train: [0.7607931144866374, tensor(0.4281, device='cuda:0')]\n",
            "9.676939013336787 train: [0.7607418555567871, tensor(0.4281, device='cuda:0')]\n",
            "9.677068496698174 train: [0.7608716782041431, tensor(0.4281, device='cuda:0')]\n",
            "9.677197980059562 train: [0.7609068690815618, tensor(0.4281, device='cuda:0')]\n",
            "9.67732746342095 train: [0.7608555601404644, tensor(0.4281, device='cuda:0')]\n",
            "9.677456946782339 train: [0.7608903368061196, tensor(0.4281, device='cuda:0')]\n",
            "9.677586430143727 train: [0.7608393967776466, tensor(0.4281, device='cuda:0')]\n",
            "9.677715913505114 train: [0.760788591625703, tensor(0.4281, device='cuda:0')]\n",
            "9.677845396866502 train: [0.7608227846057913, tensor(0.4281, device='cuda:0')]\n",
            "9.677974880227891 train: [0.76077223269489, tensor(0.4282, device='cuda:0')]\n",
            "9.678104363589279 train: [0.7607217578044319, tensor(0.4282, device='cuda:0')]\n",
            "9.678233846950667 train: [0.760671244652998, tensor(0.4282, device='cuda:0')]\n",
            "9.678363330312054 train: [0.7606205204400661, tensor(0.4282, device='cuda:0')]\n",
            "9.678492813673444 train: [0.7605694700940712, tensor(0.4282, device='cuda:0')]\n",
            "9.678622297034831 train: [0.7606048750442256, tensor(0.4282, device='cuda:0')]\n",
            "9.678751780396219 train: [0.7605532715153213, tensor(0.4282, device='cuda:0')]\n",
            "9.678881263757606 train: [0.7606831274867374, tensor(0.4282, device='cuda:0')]\n",
            "9.679010747118996 train: [0.7606311258711123, tensor(0.4282, device='cuda:0')]\n",
            "9.679140230480384 train: [0.7605789140065699, tensor(0.4282, device='cuda:0')]\n",
            "9.679269713841771 train: [0.7605263769532689, tensor(0.4282, device='cuda:0')]\n",
            "9.679399197203159 train: [0.7604734573786666, tensor(0.4282, device='cuda:0')]\n",
            "9.679528680564548 train: [0.76042004048583, tensor(0.4282, device='cuda:0')]\n",
            "9.679658163925936 train: [0.7602745333980983, tensor(0.4283, device='cuda:0')]\n",
            "9.679787647287323 train: [0.760220082761843, tensor(0.4284, device='cuda:0')]\n",
            "9.679917130648711 train: [0.7601651356784475, tensor(0.4284, device='cuda:0')]\n",
            "9.6800466140101 train: [0.7601096349684452, tensor(0.4284, device='cuda:0')]\n",
            "9.680176097371488 train: [0.7601529177084866, tensor(0.4284, device='cuda:0')]\n",
            "9.680305580732876 train: [0.7600964640346749, tensor(0.4284, device='cuda:0')]\n",
            "9.680435064094263 train: [0.7602294404992943, tensor(0.4283, device='cuda:0')]\n",
            "9.680564547455653 train: [0.7600841644739743, tensor(0.4284, device='cuda:0')]\n",
            "9.68069403081704 train: [0.7600268951529937, tensor(0.4284, device='cuda:0')]\n",
            "9.680823514178428 train: [0.7601603252883697, tensor(0.4284, device='cuda:0')]\n",
            "9.680952997539816 train: [0.7601026041972733, tensor(0.4284, device='cuda:0')]\n",
            "9.681082480901205 train: [0.7599574633524772, tensor(0.4285, device='cuda:0')]\n",
            "9.681211964262593 train: [0.7598993441052075, tensor(0.4285, device='cuda:0')]\n",
            "9.68134144762398 train: [0.7598409602720719, tensor(0.4285, device='cuda:0')]\n",
            "9.681470930985368 train: [0.7597823120045508, tensor(0.4285, device='cuda:0')]\n",
            "9.681600414346756 train: [0.7597232847885753, tensor(0.4285, device='cuda:0')]\n",
            "9.681729897708145 train: [0.7597725609353447, tensor(0.4286, device='cuda:0')]\n",
            "9.681859381069533 train: [0.7597129849873091, tensor(0.4286, device='cuda:0')]\n",
            "9.68198886443092 train: [0.7598480795817931, tensor(0.4285, device='cuda:0')]\n",
            "9.682118347792308 train: [0.7597881682188165, tensor(0.4285, device='cuda:0')]\n",
            "9.682247831153697 train: [0.7599234260902079, tensor(0.4284, device='cuda:0')]\n",
            "9.682377314515085 train: [0.7598632368679539, tensor(0.4284, device='cuda:0')]\n",
            "9.682506797876473 train: [0.7598028988149331, tensor(0.4284, device='cuda:0')]\n",
            "9.68263628123786 train: [0.7599384200470419, tensor(0.4284, device='cuda:0')]\n",
            "9.68276576459925 train: [0.7597936698717949, tensor(0.4285, device='cuda:0')]\n",
            "9.682895247960637 train: [0.7597330361982333, tensor(0.4285, device='cuda:0')]\n",
            "9.683024731322025 train: [0.7595883802507469, tensor(0.4286, device='cuda:0')]\n",
            "9.683154214683412 train: [0.7595275227342617, tensor(0.4286, device='cuda:0')]\n",
            "9.683283698044802 train: [0.7596634249363122, tensor(0.4285, device='cuda:0')]\n",
            "9.68341318140619 train: [0.7596023475810584, tensor(0.4285, device='cuda:0')]\n",
            "9.683542664767577 train: [0.759541179128615, tensor(0.4286, device='cuda:0')]\n",
            "9.683672148128965 train: [0.7595941789152925, tensor(0.4286, device='cuda:0')]\n",
            "9.683801631490354 train: [0.7595328638411798, tensor(0.4286, device='cuda:0')]\n",
            "9.683931114851742 train: [0.7594714578122486, tensor(0.4286, device='cuda:0')]\n",
            "9.68406059821313 train: [0.7594099608803744, tensor(0.4286, device='cuda:0')]\n",
            "9.684190081574517 train: [0.7595463328666676, tensor(0.4285, device='cuda:0')]\n",
            "9.684319564935906 train: [0.7596001378716779, tensor(0.4285, device='cuda:0')]\n",
            "9.684449048297294 train: [0.7595384802649848, tensor(0.4286, device='cuda:0')]\n",
            "9.684578531658682 train: [0.7596747501169043, tensor(0.4285, device='cuda:0')]\n",
            "9.68470801502007 train: [0.7597281005734532, tensor(0.4285, device='cuda:0')]\n",
            "9.684837498381459 train: [0.7596668532165708, tensor(0.4285, device='cuda:0')]\n",
            "9.684966981742846 train: [0.7596058002658059, tensor(0.4285, device='cuda:0')]\n",
            "9.685096465104234 train: [0.7597414405189533, tensor(0.4284, device='cuda:0')]\n",
            "9.685225948465622 train: [0.759680624698892, tensor(0.4284, device='cuda:0')]\n",
            "9.685355431827011 train: [0.7596198889760619, tensor(0.4285, device='cuda:0')]\n",
            "9.685484915188399 train: [0.7595591762984691, tensor(0.4285, device='cuda:0')]\n",
            "9.685614398549786 train: [0.7594151020996265, tensor(0.4286, device='cuda:0')]\n",
            "9.685743881911174 train: [0.7595505929152869, tensor(0.4285, device='cuda:0')]\n",
            "9.685873365272563 train: [0.7596860323502815, tensor(0.4284, device='cuda:0')]\n",
            "9.686002848633951 train: [0.7596253531717098, tensor(0.4284, device='cuda:0')]\n",
            "9.686132331995339 train: [0.7594813756597364, tensor(0.4285, device='cuda:0')]\n",
            "9.686261815356726 train: [0.7594208152031311, tensor(0.4286, device='cuda:0')]\n",
            "9.686391298718116 train: [0.7592769310016906, tensor(0.4287, device='cuda:0')]\n",
            "9.686520782079503 train: [0.759328906170312, tensor(0.4287, device='cuda:0')]\n",
            "9.68665026544089 train: [0.7592685228183275, tensor(0.4287, device='cuda:0')]\n",
            "9.686779748802278 train: [0.7594035516474152, tensor(0.4286, device='cuda:0')]\n",
            "9.686909232163668 train: [0.759259779676259, tensor(0.4287, device='cuda:0')]\n",
            "9.687038715525055 train: [0.7591160621332577, tensor(0.4288, device='cuda:0')]\n",
            "9.687168198886443 train: [0.7589723989875095, tensor(0.4289, device='cuda:0')]\n",
            "9.68729768224783 train: [0.7590228945309657, tensor(0.4289, device='cuda:0')]\n",
            "9.687427165609218 train: [0.7591571031243634, tensor(0.4289, device='cuda:0')]\n",
            "9.687556648970608 train: [0.7590135137347048, tensor(0.4290, device='cuda:0')]\n",
            "9.687686132331995 train: [0.7591470482878506, tensor(0.4289, device='cuda:0')]\n",
            "9.687815615693383 train: [0.7592802482838111, tensor(0.4288, device='cuda:0')]\n",
            "9.68794509905477 train: [0.7592226579540498, tensor(0.4288, device='cuda:0')]\n",
            "9.68807458241616 train: [0.7591654301389879, tensor(0.4288, device='cuda:0')]\n",
            "9.688204065777548 train: [0.7591084510727368, tensor(0.4289, device='cuda:0')]\n",
            "9.688333549138935 train: [0.7590516070753826, tensor(0.4289, device='cuda:0')]\n",
            "9.688463032500323 train: [0.7589947277941647, tensor(0.4289, device='cuda:0')]\n",
            "9.688592515861712 train: [0.7589377565010532, tensor(0.4289, device='cuda:0')]\n",
            "9.6887219992231 train: [0.758984068618551, tensor(0.4289, device='cuda:0')]\n",
            "9.688851482584488 train: [0.7588407829722194, tensor(0.4290, device='cuda:0')]\n",
            "9.688980965945875 train: [0.7588869824788744, tensor(0.4290, device='cuda:0')]\n",
            "9.689110449307265 train: [0.7588301879345886, tensor(0.4290, device='cuda:0')]\n",
            "9.689239932668652 train: [0.7587735282111756, tensor(0.4291, device='cuda:0')]\n",
            "9.68936941603004 train: [0.7587169465485467, tensor(0.4291, device='cuda:0')]\n",
            "9.689498899391427 train: [0.7586602728832371, tensor(0.4291, device='cuda:0')]\n",
            "9.689628382752817 train: [0.7585172104142793, tensor(0.4292, device='cuda:0')]\n",
            "9.689757866114205 train: [0.7584602558663999, tensor(0.4292, device='cuda:0')]\n",
            "9.689887349475592 train: [0.7584030962263467, tensor(0.4292, device='cuda:0')]\n",
            "9.69001683283698 train: [0.7582601631136014, tensor(0.4293, device='cuda:0')]\n",
            "9.69014631619837 train: [0.7582024965212854, tensor(0.4293, device='cuda:0')]\n",
            "9.690275799559757 train: [0.7581445120029273, tensor(0.4294, device='cuda:0')]\n",
            "9.690405282921144 train: [0.7580862097381804, tensor(0.4294, device='cuda:0')]\n",
            "9.690534766282532 train: [0.7580274767311314, tensor(0.4294, device='cuda:0')]\n",
            "9.690664249643921 train: [0.7579683132250916, tensor(0.4294, device='cuda:0')]\n",
            "9.690793733005309 train: [0.7579087194631893, tensor(0.4294, device='cuda:0')]\n",
            "9.690923216366697 train: [0.7580435302921716, tensor(0.4293, device='cuda:0')]\n",
            "9.691052699728084 train: [0.7581785731087692, tensor(0.4292, device='cuda:0')]\n",
            "9.691182183089474 train: [0.7581178427346407, tensor(0.4293, device='cuda:0')]\n",
            "9.691311666450861 train: [0.7580568525894252, tensor(0.4293, device='cuda:0')]\n",
            "9.691441149812249 train: [0.7581112288595362, tensor(0.4293, device='cuda:0')]\n",
            "9.691570633173637 train: [0.7582469484081639, tensor(0.4292, device='cuda:0')]\n",
            "9.691700116535026 train: [0.7583826169248123, tensor(0.4291, device='cuda:0')]\n",
            "9.691829599896414 train: [0.7584369577790631, tensor(0.4291, device='cuda:0')]\n",
            "9.691959083257801 train: [0.7583758520304165, tensor(0.4291, device='cuda:0')]\n",
            "9.692088566619189 train: [0.758314938625589, tensor(0.4292, device='cuda:0')]\n",
            "9.692218049980578 train: [0.7582541045571468, tensor(0.4292, device='cuda:0')]\n",
            "9.692347533341966 train: [0.7581932369025602, tensor(0.4292, device='cuda:0')]\n",
            "9.692477016703354 train: [0.7581323356807512, tensor(0.4292, device='cuda:0')]\n",
            "9.692606500064741 train: [0.75807128807519, tensor(0.4292, device='cuda:0')]\n",
            "9.69273598342613 train: [0.7582067294154597, tensor(0.4291, device='cuda:0')]\n",
            "9.692865466787518 train: [0.7581454087801744, tensor(0.4291, device='cuda:0')]\n",
            "9.692994950148906 train: [0.7580839420009527, tensor(0.4292, device='cuda:0')]\n",
            "9.693124433510294 train: [0.7580222727846732, tensor(0.4292, device='cuda:0')]\n",
            "9.693253916871681 train: [0.7578800813997951, tensor(0.4293, device='cuda:0')]\n",
            "9.69338340023307 train: [0.7577379433500202, tensor(0.4294, device='cuda:0')]\n",
            "9.693512883594458 train: [0.7575958586053455, tensor(0.4295, device='cuda:0')]\n",
            "9.693642366955846 train: [0.7574538271357907, tensor(0.4296, device='cuda:0')]\n",
            "9.693771850317233 train: [0.7573914889878163, tensor(0.4296, device='cuda:0')]\n",
            "9.693901333678623 train: [0.7573290052690002, tensor(0.4296, device='cuda:0')]\n",
            "9.69403081704001 train: [0.7573866359305862, tensor(0.4296, device='cuda:0')]\n",
            "9.694160300401398 train: [0.7572447500864629, tensor(0.4297, device='cuda:0')]\n",
            "9.694289783762786 train: [0.7571029173930584, tensor(0.4299, device='cuda:0')]\n",
            "9.694419267124175 train: [0.7572397296348314, tensor(0.4298, device='cuda:0')]\n",
            "9.694548750485563 train: [0.7573764343863869, tensor(0.4297, device='cuda:0')]\n",
            "9.69467823384695 train: [0.7573140236658699, tensor(0.4297, device='cuda:0')]\n",
            "9.694807717208338 train: [0.757251748783455, tensor(0.4297, device='cuda:0')]\n",
            "9.694937200569727 train: [0.7573086999078765, tensor(0.4297, device='cuda:0')]\n",
            "9.695066683931115 train: [0.7574448959307765, tensor(0.4297, device='cuda:0')]\n",
            "9.695196167292503 train: [0.7575808161745662, tensor(0.4296, device='cuda:0')]\n",
            "9.69532565065389 train: [0.757519268533038, tensor(0.4296, device='cuda:0')]\n",
            "9.69545513401528 train: [0.7574579686511133, tensor(0.4296, device='cuda:0')]\n",
            "9.695584617376667 train: [0.757316361253721, tensor(0.4297, device='cuda:0')]\n",
            "9.695714100738055 train: [0.7574515299245147, tensor(0.4296, device='cuda:0')]\n",
            "9.695843584099443 train: [0.7573099766578497, tensor(0.4297, device='cuda:0')]\n",
            "9.695973067460832 train: [0.7572493792758997, tensor(0.4297, device='cuda:0')]\n",
            "9.69610255082222 train: [0.7573840917745621, tensor(0.4297, device='cuda:0')]\n",
            "9.696232034183607 train: [0.7575185855830292, tensor(0.4296, device='cuda:0')]\n",
            "9.696361517544995 train: [0.7574584882029735, tensor(0.4296, device='cuda:0')]\n",
            "9.696491000906384 train: [0.7573985815691963, tensor(0.4296, device='cuda:0')]\n",
            "9.696620484267772 train: [0.7573387533923982, tensor(0.4296, device='cuda:0')]\n",
            "9.69674996762916 train: [0.7572789475478795, tensor(0.4296, device='cuda:0')]\n",
            "9.696879450990547 train: [0.7572190518825269, tensor(0.4297, device='cuda:0')]\n",
            "9.697008934351937 train: [0.757353313809558, tensor(0.4296, device='cuda:0')]\n",
            "9.697138417713324 train: [0.7572931463705107, tensor(0.4296, device='cuda:0')]\n",
            "9.697267901074712 train: [0.7574275125168565, tensor(0.4295, device='cuda:0')]\n",
            "9.6973973844361 train: [0.7572862804615671, tensor(0.4296, device='cuda:0')]\n",
            "9.697526867797489 train: [0.7574206538067172, tensor(0.4295, device='cuda:0')]\n",
            "9.697656351158876 train: [0.7573604626675747, tensor(0.4295, device='cuda:0')]\n",
            "9.697785834520264 train: [0.7574946601106683, tensor(0.4295, device='cuda:0')]\n",
            "9.697915317881652 train: [0.7576287515586705, tensor(0.4294, device='cuda:0')]\n",
            "9.698044801243041 train: [0.7575687791972372, tensor(0.4294, device='cuda:0')]\n",
            "9.698174284604429 train: [0.7577025830264911, tensor(0.4293, device='cuda:0')]\n",
            "9.698303767965816 train: [0.7575614838490188, tensor(0.4294, device='cuda:0')]\n",
            "9.698433251327204 train: [0.7575019491249302, tensor(0.4294, device='cuda:0')]\n",
            "9.698562734688592 train: [0.7574424925002864, tensor(0.4294, device='cuda:0')]\n",
            "9.698692218049981 train: [0.7573015205121046, tensor(0.4296, device='cuda:0')]\n",
            "9.698821701411369 train: [0.75743497001231, tensor(0.4295, device='cuda:0')]\n",
            "9.698951184772756 train: [0.7575683139534883, tensor(0.4294, device='cuda:0')]\n",
            "9.699080668134144 train: [0.7574273972284227, tensor(0.4295, device='cuda:0')]\n",
            "9.699210151495533 train: [0.7575604135670448, tensor(0.4294, device='cuda:0')]\n",
            "9.699339634856921 train: [0.7576931569499671, tensor(0.4293, device='cuda:0')]\n",
            "9.699469118218309 train: [0.7578256275294235, tensor(0.4293, device='cuda:0')]\n",
            "9.699598601579696 train: [0.7577675954389477, tensor(0.4293, device='cuda:0')]\n",
            "9.699728084941086 train: [0.7577098641230541, tensor(0.4293, device='cuda:0')]\n",
            "9.699857568302473 train: [0.7576523217527085, tensor(0.4293, device='cuda:0')]\n",
            "9.69998705166386 train: [0.7575948007616571, tensor(0.4293, device='cuda:0')]\n",
            "9.700116535025249 train: [0.7577265526774488, tensor(0.4292, device='cuda:0')]\n",
            "9.700246018386638 train: [0.7576689834654667, tensor(0.4292, device='cuda:0')]\n",
            "9.700375501748026 train: [0.757800672684167, tensor(0.4292, device='cuda:0')]\n",
            "9.700504985109413 train: [0.7577431110865188, tensor(0.4292, device='cuda:0')]\n",
            "9.7006344684708 train: [0.7578747934334132, tensor(0.4291, device='cuda:0')]\n",
            "9.70076395183219 train: [0.7580063711513482, tensor(0.4290, device='cuda:0')]\n",
            "9.700893435193578 train: [0.758137788550735, tensor(0.4289, device='cuda:0')]\n",
            "9.701022918554965 train: [0.7582689899833055, tensor(0.4289, device='cuda:0')]\n",
            "9.701152401916353 train: [0.7583998641149281, tensor(0.4288, device='cuda:0')]\n",
            "9.701281885277742 train: [0.7583433140716599, tensor(0.4288, device='cuda:0')]\n",
            "9.70141136863913 train: [0.7582027239133224, tensor(0.4289, device='cuda:0')]\n",
            "9.701540852000518 train: [0.7583328691986883, tensor(0.4288, device='cuda:0')]\n",
            "9.701670335361905 train: [0.7582771982985973, tensor(0.4288, device='cuda:0')]\n",
            "9.701799818723295 train: [0.758136698539787, tensor(0.4289, device='cuda:0')]\n",
            "9.701929302084682 train: [0.7582663384052498, tensor(0.4289, device='cuda:0')]\n",
            "9.70205878544607 train: [0.7583957076274809, tensor(0.4288, device='cuda:0')]\n",
            "9.702188268807458 train: [0.7583410679309117, tensor(0.4288, device='cuda:0')]\n",
            "9.702317752168847 train: [0.7584699859712589, tensor(0.4287, device='cuda:0')]\n",
            "9.702447235530235 train: [0.7585124166085211, tensor(0.4287, device='cuda:0')]\n",
            "9.702576718891622 train: [0.7586406990774356, tensor(0.4287, device='cuda:0')]\n",
            "9.70270620225301 train: [0.7585876669881284, tensor(0.4287, device='cuda:0')]\n",
            "9.7028356856144 train: [0.7586274950188572, tensor(0.4287, device='cuda:0')]\n",
            "9.702965168975787 train: [0.7585755410654828, tensor(0.4287, device='cuda:0')]\n",
            "9.703094652337175 train: [0.7585239953372409, tensor(0.4287, device='cuda:0')]\n",
            "9.703224135698562 train: [0.7586506568794095, tensor(0.4286, device='cuda:0')]\n",
            "9.703353619059952 train: [0.7586877773155851, tensor(0.4286, device='cuda:0')]\n",
            "9.70348310242134 train: [0.7585475392791128, tensor(0.4287, device='cuda:0')]\n",
            "9.703612585782727 train: [0.7585828880450081, tensor(0.4288, device='cuda:0')]\n",
            "9.703742069144115 train: [0.7585338870352208, tensor(0.4288, device='cuda:0')]\n",
            "9.703871552505504 train: [0.7584854592398641, tensor(0.4288, device='cuda:0')]\n",
            "9.704001035866892 train: [0.7584373823385241, tensor(0.4288, device='cuda:0')]\n",
            "9.70413051922828 train: [0.7585620094644506, tensor(0.4287, device='cuda:0')]\n",
            "9.704260002589667 train: [0.7585142690638847, tensor(0.4287, device='cuda:0')]\n",
            "9.704389485951054 train: [0.7584665462894591, tensor(0.4287, device='cuda:0')]\n",
            "9.704518969312444 train: [0.758498924968765, tensor(0.4288, device='cuda:0')]\n",
            "9.704648452673831 train: [0.7584512226390052, tensor(0.4288, device='cuda:0')]\n",
            "9.704777936035219 train: [0.7584834258799319, tensor(0.4288, device='cuda:0')]\n",
            "9.704907419396607 train: [0.75834351010316, tensor(0.4289, device='cuda:0')]\n",
            "9.705036902757996 train: [0.7582964170189825, tensor(0.4289, device='cuda:0')]\n",
            "9.705166386119384 train: [0.7582493967113009, tensor(0.4289, device='cuda:0')]\n",
            "9.705295869480771 train: [0.7582022275463751, tensor(0.4289, device='cuda:0')]\n",
            "9.705425352842159 train: [0.7580624667671039, tensor(0.4290, device='cuda:0')]\n",
            "9.705554836203548 train: [0.758094761422921, tensor(0.4290, device='cuda:0')]\n",
            "9.705684319564936 train: [0.7580472592521722, tensor(0.4291, device='cuda:0')]\n",
            "9.705813802926324 train: [0.7579076042670484, tensor(0.4292, device='cuda:0')]\n",
            "9.705943286287711 train: [0.7579400202969806, tensor(0.4292, device='cuda:0')]\n",
            "9.7060727696491 train: [0.7580642287328233, tensor(0.4291, device='cuda:0')]\n",
            "9.706202253010488 train: [0.7580957187548688, tensor(0.4291, device='cuda:0')]\n",
            "9.706331736371876 train: [0.7580492005175881, tensor(0.4291, device='cuda:0')]\n",
            "9.706461219733264 train: [0.7580030865508502, tensor(0.4291, device='cuda:0')]\n",
            "9.706590703094653 train: [0.7578635938959826, tensor(0.4292, device='cuda:0')]\n",
            "9.70672018645604 train: [0.7578932179251292, tensor(0.4293, device='cuda:0')]\n",
            "9.706849669817428 train: [0.7578478766910058, tensor(0.4293, device='cuda:0')]\n",
            "9.706979153178816 train: [0.7578027731993039, tensor(0.4293, device='cuda:0')]\n",
            "9.707108636540205 train: [0.7577576862958667, tensor(0.4293, device='cuda:0')]\n",
            "9.707238119901593 train: [0.7577866450634307, tensor(0.4293, device='cuda:0')]\n",
            "9.70736760326298 train: [0.7579095486602093, tensor(0.4292, device='cuda:0')]\n",
            "9.707497086624368 train: [0.7578646326679203, tensor(0.4292, device='cuda:0')]\n",
            "9.707626569985758 train: [0.7578928932377802, tensor(0.4293, device='cuda:0')]\n",
            "9.707756053347145 train: [0.7578483832445343, tensor(0.4293, device='cuda:0')]\n",
            "9.707885536708533 train: [0.7579708540277228, tensor(0.4292, device='cuda:0')]\n",
            "9.70801502006992 train: [0.7579266771738362, tensor(0.4292, device='cuda:0')]\n",
            "9.70814450343131 train: [0.7578825165435464, tensor(0.4292, device='cuda:0')]\n",
            "9.708273986792697 train: [0.7577433789418311, tensor(0.4293, device='cuda:0')]\n",
            "9.708403470154085 train: [0.757698937242319, tensor(0.4293, device='cuda:0')]\n",
            "9.708532953515473 train: [0.757654236133659, tensor(0.4293, device='cuda:0')]\n",
            "9.708662436876862 train: [0.7576831554340155, tensor(0.4294, device='cuda:0')]\n",
            "9.70879192023825 train: [0.7576379223819201, tensor(0.4294, device='cuda:0')]\n",
            "9.708921403599637 train: [0.7576673852044415, tensor(0.4294, device='cuda:0')]\n",
            "9.709050886961025 train: [0.7575284401493885, tensor(0.4295, device='cuda:0')]\n",
            "9.709180370322414 train: [0.7573895460459508, tensor(0.4296, device='cuda:0')]\n",
            "9.709309853683802 train: [0.7573442898187972, tensor(0.4296, device='cuda:0')]\n",
            "9.70943933704519 train: [0.7573736747123844, tensor(0.4296, device='cuda:0')]\n",
            "9.709568820406577 train: [0.7574027735195444, tensor(0.4296, device='cuda:0')]\n",
            "9.709698303767965 train: [0.7575252320165178, tensor(0.4296, device='cuda:0')]\n",
            "9.709827787129354 train: [0.7576474254759255, tensor(0.4295, device='cuda:0')]\n",
            "9.709957270490742 train: [0.757603814454776, tensor(0.4295, device='cuda:0')]\n",
            "9.71008675385213 train: [0.757725508588875, tensor(0.4294, device='cuda:0')]\n",
            "9.710216237213517 train: [0.7576826144093457, tensor(0.4294, device='cuda:0')]\n",
            "9.710345720574907 train: [0.7576399009420014, tensor(0.4294, device='cuda:0')]\n",
            "9.710475203936294 train: [0.7575012406380223, tensor(0.4295, device='cuda:0')]\n",
            "9.710604687297682 train: [0.7574585759905693, tensor(0.4296, device='cuda:0')]\n",
            "9.71073417065907 train: [0.7574157070632441, tensor(0.4296, device='cuda:0')]\n",
            "9.710863654020459 train: [0.757537302046545, tensor(0.4295, device='cuda:0')]\n",
            "9.710993137381847 train: [0.7576589624599066, tensor(0.4294, device='cuda:0')]\n",
            "9.711122620743234 train: [0.7576154210972333, tensor(0.4294, device='cuda:0')]\n",
            "9.711252104104622 train: [0.7576424289832654, tensor(0.4294, device='cuda:0')]\n",
            "9.711381587466011 train: [0.7577641133142584, tensor(0.4294, device='cuda:0')]\n",
            "9.711511070827399 train: [0.7576256330303925, tensor(0.4295, device='cuda:0')]\n",
            "9.711640554188786 train: [0.7575822393849527, tensor(0.4295, device='cuda:0')]\n",
            "9.711770037550174 train: [0.7576087395660606, tensor(0.4295, device='cuda:0')]\n",
            "9.711899520911563 train: [0.7574703635405691, tensor(0.4296, device='cuda:0')]\n",
            "9.712029004272951 train: [0.7574275158734618, tensor(0.4296, device='cuda:0')]\n",
            "9.712158487634339 train: [0.7574532068545385, tensor(0.4296, device='cuda:0')]\n",
            "9.712287970995726 train: [0.7575742217120229, tensor(0.4295, device='cuda:0')]\n",
            "9.712417454357116 train: [0.7575988345360608, tensor(0.4295, device='cuda:0')]\n",
            "9.712546937718503 train: [0.7576225062289444, tensor(0.4296, device='cuda:0')]\n",
            "9.712676421079891 train: [0.7575819724257224, tensor(0.4296, device='cuda:0')]\n",
            "9.712805904441279 train: [0.7575421111574945, tensor(0.4296, device='cuda:0')]\n",
            "9.712935387802668 train: [0.7575025932427503, tensor(0.4296, device='cuda:0')]\n",
            "9.713064871164056 train: [0.7575234708136958, tensor(0.4296, device='cuda:0')]\n",
            "9.713194354525443 train: [0.7574845185295561, tensor(0.4296, device='cuda:0')]\n",
            "9.713323837886831 train: [0.7576038723569085, tensor(0.4295, device='cuda:0')]\n",
            "9.71345332124822 train: [0.7576235700466838, tensor(0.4296, device='cuda:0')]\n",
            "9.713582804609608 train: [0.7576425487777528, tensor(0.4296, device='cuda:0')]\n",
            "9.713712287970996 train: [0.7577612064163292, tensor(0.4295, device='cuda:0')]\n",
            "9.713841771332383 train: [0.757724763993975, tensor(0.4295, device='cuda:0')]\n",
            "9.713971254693773 train: [0.7576888273468473, tensor(0.4295, device='cuda:0')]\n",
            "9.71410073805516 train: [0.7578069193302146, tensor(0.4294, device='cuda:0')]\n",
            "9.714230221416548 train: [0.7577715278361271, tensor(0.4295, device='cuda:0')]\n",
            "9.714359704777936 train: [0.7577362039182605, tensor(0.4295, device='cuda:0')]\n",
            "9.714489188139325 train: [0.7575983083397494, tensor(0.4296, device='cuda:0')]\n",
            "9.714618671500713 train: [0.75771633084551, tensor(0.4295, device='cuda:0')]\n",
            "9.7147481548621 train: [0.7578343104105736, tensor(0.4294, device='cuda:0')]\n",
            "9.714877638223488 train: [0.757696472231161, tensor(0.4295, device='cuda:0')]\n",
            "9.715007121584877 train: [0.7578144124980766, tensor(0.4294, device='cuda:0')]\n",
            "9.715136604946265 train: [0.7577789554195804, tensor(0.4295, device='cuda:0')]\n",
            "9.715266088307652 train: [0.7577946383000294, tensor(0.4295, device='cuda:0')]\n",
            "9.71539557166904 train: [0.757759306930347, tensor(0.4295, device='cuda:0')]\n",
            "9.715525055030428 train: [0.7578770408448539, tensor(0.4294, device='cuda:0')]\n",
            "9.715654538391817 train: [0.7578417073422127, tensor(0.4294, device='cuda:0')]\n",
            "9.715784021753205 train: [0.75780622292671, tensor(0.4294, device='cuda:0')]\n",
            "9.715913505114592 train: [0.7576685901219649, tensor(0.4295, device='cuda:0')]\n",
            "9.71604298847598 train: [0.7576324952682599, tensor(0.4295, device='cuda:0')]\n",
            "9.71617247183737 train: [0.7574949439800849, tensor(0.4296, device='cuda:0')]\n",
            "9.716301955198757 train: [0.7574579119657344, tensor(0.4297, device='cuda:0')]\n",
            "9.716431438560145 train: [0.7573204422902415, tensor(0.4298, device='cuda:0')]\n",
            "9.716560921921532 train: [0.7574391208841059, tensor(0.4297, device='cuda:0')]\n",
            "9.716690405282922 train: [0.7574006472765714, tensor(0.4297, device='cuda:0')]\n",
            "9.71681988864431 train: [0.7572632627949323, tensor(0.4298, device='cuda:0')]\n",
            "9.716949372005697 train: [0.7572238541405095, tensor(0.4298, device='cuda:0')]\n",
            "9.717078855367085 train: [0.7573432269509729, tensor(0.4297, device='cuda:0')]\n",
            "9.717208338728474 train: [0.7574627199022425, tensor(0.4297, device='cuda:0')]\n",
            "9.717337822089862 train: [0.7575822784644665, tensor(0.4296, device='cuda:0')]\n",
            "9.71746730545125 train: [0.75744498555427, tensor(0.4297, device='cuda:0')]\n",
            "9.717596788812637 train: [0.7574685178474362, tensor(0.4297, device='cuda:0')]\n",
            "9.717726272174026 train: [0.757427590666806, tensor(0.4297, device='cuda:0')]\n",
            "9.717855755535414 train: [0.7574508998857509, tensor(0.4297, device='cuda:0')]\n",
            "9.717985238896802 train: [0.757570352331931, tensor(0.4296, device='cuda:0')]\n",
            "9.71811472225819 train: [0.7575299729975348, tensor(0.4297, device='cuda:0')]\n",
            "9.718244205619579 train: [0.7576491502986966, tensor(0.4296, device='cuda:0')]\n",
            "9.718373688980966 train: [0.7576090976331361, tensor(0.4296, device='cuda:0')]\n",
            "9.718503172342354 train: [0.7574719986288594, tensor(0.4297, device='cuda:0')]\n",
            "9.718632655703741 train: [0.7574319381428234, tensor(0.4297, device='cuda:0')]\n",
            "9.71876213906513 train: [0.7575511012989814, tensor(0.4296, device='cuda:0')]\n",
            "9.718891622426518 train: [0.7575107692655508, tensor(0.4296, device='cuda:0')]\n",
            "9.719021105787906 train: [0.7573737872096258, tensor(0.4297, device='cuda:0')]\n",
            "9.719150589149294 train: [0.7573330672051236, tensor(0.4298, device='cuda:0')]\n",
            "9.719280072510683 train: [0.7571961667952889, tensor(0.4299, device='cuda:0')]\n",
            "9.71940955587207 train: [0.7571547876204313, tensor(0.4299, device='cuda:0')]\n",
            "9.719539039233458 train: [0.7572745775242556, tensor(0.4298, device='cuda:0')]\n",
            "9.719668522594846 train: [0.7573944870057675, tensor(0.4297, device='cuda:0')]\n",
            "9.719798005956235 train: [0.7572576744177968, tensor(0.4298, device='cuda:0')]\n",
            "9.719927489317623 train: [0.757377706443367, tensor(0.4297, device='cuda:0')]\n",
            "9.72005697267901 train: [0.7573351381712365, tensor(0.4298, device='cuda:0')]\n",
            "9.720186456040398 train: [0.7571984103976003, tensor(0.4299, device='cuda:0')]\n",
            "9.720315939401788 train: [0.7571555101881422, tensor(0.4299, device='cuda:0')]\n",
            "9.720445422763175 train: [0.7571823634653562, tensor(0.4299, device='cuda:0')]\n",
            "9.720574906124563 train: [0.7572092612705771, tensor(0.4299, device='cuda:0')]\n",
            "9.72070438948595 train: [0.7572357156982473, tensor(0.4299, device='cuda:0')]\n",
            "9.720833872847338 train: [0.7571932733065545, tensor(0.4299, device='cuda:0')]\n",
            "9.720963356208728 train: [0.7573129812027467, tensor(0.4298, device='cuda:0')]\n",
            "9.721092839570115 train: [0.7572711903416184, tensor(0.4299, device='cuda:0')]\n",
            "9.721222322931503 train: [0.7571346712880143, tensor(0.4300, device='cuda:0')]\n",
            "9.72135180629289 train: [0.7572540542156564, tensor(0.4299, device='cuda:0')]\n",
            "9.72148128965428 train: [0.7572128380720019, tensor(0.4299, device='cuda:0')]\n",
            "9.721610773015668 train: [0.7571716909216909, tensor(0.4299, device='cuda:0')]\n",
            "9.721740256377055 train: [0.7570352881670662, tensor(0.4300, device='cuda:0')]\n",
            "9.721869739738443 train: [0.7571546029843715, tensor(0.4299, device='cuda:0')]\n",
            "9.721999223099832 train: [0.7571789633808474, tensor(0.4299, device='cuda:0')]\n",
            "9.72212870646122 train: [0.7571377978622476, tensor(0.4300, device='cuda:0')]\n",
            "9.722258189822607 train: [0.7570967012566642, tensor(0.4300, device='cuda:0')]\n",
            "9.722387673183995 train: [0.7569604347517583, tensor(0.4301, device='cuda:0')]\n",
            "9.722517156545385 train: [0.7570796016112734, tensor(0.4300, device='cuda:0')]\n",
            "9.722646639906772 train: [0.7570383754705622, tensor(0.4300, device='cuda:0')]\n",
            "9.72277612326816 train: [0.7571575394889783, tensor(0.4299, device='cuda:0')]\n",
            "9.722905606629547 train: [0.7572767146859436, tensor(0.4299, device='cuda:0')]\n",
            "9.723035089990937 train: [0.7571405383301287, tensor(0.4300, device='cuda:0')]\n",
            "9.723164573352324 train: [0.7570991688103339, tensor(0.4300, device='cuda:0')]\n",
            "9.723294056713712 train: [0.7572182902314745, tensor(0.4299, device='cuda:0')]\n",
            "9.7234235400751 train: [0.7571768135990986, tensor(0.4299, device='cuda:0')]\n",
            "9.723553023436489 train: [0.757295986246458, tensor(0.4298, device='cuda:0')]\n",
            "9.723682506797877 train: [0.7574151160721689, tensor(0.4298, device='cuda:0')]\n",
            "9.723811990159264 train: [0.7572790616234403, tensor(0.4299, device='cuda:0')]\n",
            "9.723941473520652 train: [0.7572373880104719, tensor(0.4299, device='cuda:0')]\n",
            "9.724070956882041 train: [0.7571955674958907, tensor(0.4299, device='cuda:0')]\n",
            "9.724200440243429 train: [0.7571534383199834, tensor(0.4299, device='cuda:0')]\n",
            "9.724329923604817 train: [0.7571108927757757, tensor(0.4299, device='cuda:0')]\n",
            "9.724459406966204 train: [0.7570678232336131, tensor(0.4299, device='cuda:0')]\n",
            "9.724588890327594 train: [0.756931977580781, tensor(0.4300, device='cuda:0')]\n",
            "9.724718373688981 train: [0.7570522955135105, tensor(0.4299, device='cuda:0')]\n",
            "9.724847857050369 train: [0.7570075888237323, tensor(0.4300, device='cuda:0')]\n",
            "9.724977340411757 train: [0.7571282811465346, tensor(0.4299, device='cuda:0')]\n",
            "9.725106823773146 train: [0.7569925220859023, tensor(0.4300, device='cuda:0')]\n",
            "9.725236307134534 train: [0.7569466650405439, tensor(0.4300, device='cuda:0')]\n",
            "9.725365790495921 train: [0.7569003935603292, tensor(0.4300, device='cuda:0')]\n",
            "9.725495273857309 train: [0.7568536540184726, tensor(0.4300, device='cuda:0')]\n",
            "9.725624757218698 train: [0.7568063389866718, tensor(0.4300, device='cuda:0')]\n",
            "9.725754240580086 train: [0.7568409168033239, tensor(0.4300, device='cuda:0')]\n",
            "9.725883723941473 train: [0.7567926522306728, tensor(0.4301, device='cuda:0')]\n",
            "9.726013207302861 train: [0.7566571234605741, tensor(0.4302, device='cuda:0')]\n",
            "9.72614269066425 train: [0.7566934848667447, tensor(0.4302, device='cuda:0')]\n",
            "9.726272174025638 train: [0.7566443581481176, tensor(0.4302, device='cuda:0')]\n",
            "9.726401657387026 train: [0.756595087669177, tensor(0.4302, device='cuda:0')]\n",
            "9.726531140748413 train: [0.7565455121895821, tensor(0.4302, device='cuda:0')]\n",
            "9.726660624109801 train: [0.75666885589138, tensor(0.4301, device='cuda:0')]\n",
            "9.72679010747119 train: [0.7567923167228567, tensor(0.4301, device='cuda:0')]\n",
            "9.726919590832578 train: [0.756742033900637, tensor(0.4301, device='cuda:0')]\n",
            "9.727049074193966 train: [0.756606708071971, tensor(0.4302, device='cuda:0')]\n",
            "9.727178557555353 train: [0.7566458201529385, tensor(0.4302, device='cuda:0')]\n",
            "9.727308040916743 train: [0.7565105599062182, tensor(0.4303, device='cuda:0')]\n",
            "9.72743752427813 train: [0.7566342072248574, tensor(0.4302, device='cuda:0')]\n",
            "9.727567007639518 train: [0.7565838364972233, tensor(0.4302, device='cuda:0')]\n",
            "9.727696491000906 train: [0.7565335374548179, tensor(0.4302, device='cuda:0')]\n",
            "9.727825974362295 train: [0.7564831490298733, tensor(0.4302, device='cuda:0')]\n",
            "9.727955457723683 train: [0.7564326176034182, tensor(0.4303, device='cuda:0')]\n",
            "9.72808494108507 train: [0.7563817822802198, tensor(0.4303, device='cuda:0')]\n",
            "9.728214424446458 train: [0.7564218979612157, tensor(0.4303, device='cuda:0')]\n",
            "9.728343907807847 train: [0.7563706535955566, tensor(0.4303, device='cuda:0')]\n",
            "9.728473391169235 train: [0.7562356597255591, tensor(0.4304, device='cuda:0')]\n",
            "9.728602874530623 train: [0.7562765306717729, tensor(0.4304, device='cuda:0')]\n",
            "9.72873235789201 train: [0.7561416017635353, tensor(0.4305, device='cuda:0')]\n",
            "9.7288618412534 train: [0.7560902295617333, tensor(0.4305, device='cuda:0')]\n",
            "9.728991324614787 train: [0.7562143838917013, tensor(0.4304, device='cuda:0')]\n",
            "9.729120807976175 train: [0.7561630706134094, tensor(0.4305, device='cuda:0')]\n",
            "9.729250291337562 train: [0.7562871676872335, tensor(0.4304, device='cuda:0')]\n",
            "9.729379774698952 train: [0.756411166958042, tensor(0.4303, device='cuda:0')]\n",
            "9.72950925806034 train: [0.7563599531483487, tensor(0.4303, device='cuda:0')]\n",
            "9.729638741421727 train: [0.7563088111327375, tensor(0.4303, device='cuda:0')]\n",
            "9.729768224783115 train: [0.756257580273815, tensor(0.4303, device='cuda:0')]\n",
            "9.729897708144504 train: [0.7562062070955852, tensor(0.4304, device='cuda:0')]\n",
            "9.730027191505892 train: [0.7562473243030344, tensor(0.4304, device='cuda:0')]\n",
            "9.73015667486728 train: [0.7563714657126617, tensor(0.4303, device='cuda:0')]\n",
            "9.730286158228667 train: [0.7564955094253708, tensor(0.4302, device='cuda:0')]\n",
            "9.730415641590056 train: [0.7565362322685325, tensor(0.4302, device='cuda:0')]\n",
            "9.730545124951444 train: [0.7564015933234767, tensor(0.4303, device='cuda:0')]\n",
            "9.730674608312832 train: [0.7563508374965782, tensor(0.4303, device='cuda:0')]\n",
            "9.73080409167422 train: [0.7562162794397383, tensor(0.4304, device='cuda:0')]\n",
            "9.730933575035609 train: [0.756339438726295, tensor(0.4304, device='cuda:0')]\n",
            "9.731063058396996 train: [0.7562893622860778, tensor(0.4304, device='cuda:0')]\n",
            "9.731192541758384 train: [0.7561548869371649, tensor(0.4305, device='cuda:0')]\n",
            "9.731322025119772 train: [0.7560204594017094, tensor(0.4306, device='cuda:0')]\n",
            "9.731451508481161 train: [0.7560583780832125, tensor(0.4306, device='cuda:0')]\n",
            "9.731580991842549 train: [0.7560091347862641, tensor(0.4306, device='cuda:0')]\n",
            "9.731710475203936 train: [0.7560461877596906, tensor(0.4306, device='cuda:0')]\n",
            "9.731839958565324 train: [0.756168209871271, tensor(0.4305, device='cuda:0')]\n",
            "9.731969441926712 train: [0.7561199873616614, tensor(0.4306, device='cuda:0')]\n",
            "9.732098925288101 train: [0.7560721021508682, tensor(0.4306, device='cuda:0')]\n",
            "9.732228408649489 train: [0.7559378563940942, tensor(0.4307, device='cuda:0')]\n",
            "9.732357892010876 train: [0.7558902872325172, tensor(0.4307, device='cuda:0')]\n",
            "9.732487375372264 train: [0.7558427349574015, tensor(0.4307, device='cuda:0')]\n",
            "9.732616858733653 train: [0.7557086013753327, tensor(0.4308, device='cuda:0')]\n",
            "9.73274634209504 train: [0.7556608316386417, tensor(0.4308, device='cuda:0')]\n",
            "9.732875825456428 train: [0.7556128656302452, tensor(0.4308, device='cuda:0')]\n",
            "9.733005308817816 train: [0.755734663222774, tensor(0.4307, device='cuda:0')]\n",
            "9.733134792179206 train: [0.755770999870408, tensor(0.4308, device='cuda:0')]\n",
            "9.733264275540593 train: [0.7557225603518821, tensor(0.4308, device='cuda:0')]\n",
            "9.73339375890198 train: [0.7558443802585466, tensor(0.4307, device='cuda:0')]\n",
            "9.733523242263368 train: [0.7557959449049709, tensor(0.4307, device='cuda:0')]\n",
            "9.733652725624758 train: [0.7557474202211044, tensor(0.4307, device='cuda:0')]\n",
            "9.733782208986145 train: [0.7556135174180887, tensor(0.4308, device='cuda:0')]\n",
            "9.733911692347533 train: [0.7557355364686243, tensor(0.4307, device='cuda:0')]\n",
            "9.73404117570892 train: [0.755686675726859, tensor(0.4307, device='cuda:0')]\n",
            "9.73417065907031 train: [0.7558087450279931, tensor(0.4307, device='cuda:0')]\n",
            "9.734300142431698 train: [0.7559308243047232, tensor(0.4306, device='cuda:0')]\n",
            "9.734429625793085 train: [0.7560528071680488, tensor(0.4305, device='cuda:0')]\n",
            "9.734559109154473 train: [0.7560038716814159, tensor(0.4305, device='cuda:0')]\n",
            "9.734688592515862 train: [0.7558700893647142, tensor(0.4306, device='cuda:0')]\n",
            "9.73481807587725 train: [0.7558212566858566, tensor(0.4306, device='cuda:0')]\n",
            "9.734947559238638 train: [0.7558583916470493, tensor(0.4307, device='cuda:0')]\n",
            "9.735077042600025 train: [0.7559801731585535, tensor(0.4306, device='cuda:0')]\n",
            "9.735206525961415 train: [0.7559316125960688, tensor(0.4306, device='cuda:0')]\n",
            "9.735336009322802 train: [0.7557979613208574, tensor(0.4307, device='cuda:0')]\n",
            "9.73546549268419 train: [0.7558341711596253, tensor(0.4307, device='cuda:0')]\n",
            "9.735594976045578 train: [0.7557005843495935, tensor(0.4308, device='cuda:0')]\n",
            "9.735724459406967 train: [0.7556528508876262, tensor(0.4308, device='cuda:0')]\n",
            "9.735853942768355 train: [0.755773849466567, tensor(0.4307, device='cuda:0')]\n",
            "9.735983426129742 train: [0.7558946460600873, tensor(0.4307, device='cuda:0')]\n",
            "9.73611290949113 train: [0.7558475935215879, tensor(0.4307, device='cuda:0')]\n",
            "9.73624239285252 train: [0.7558006637213219, tensor(0.4307, device='cuda:0')]\n",
            "9.736371876213907 train: [0.7557537504923131, tensor(0.4307, device='cuda:0')]\n",
            "9.736501359575295 train: [0.7557067477425488, tensor(0.4307, device='cuda:0')]\n",
            "9.736630842936682 train: [0.7555733720369817, tensor(0.4308, device='cuda:0')]\n",
            "9.736760326298072 train: [0.7554400434024243, tensor(0.4309, device='cuda:0')]\n",
            "9.73688980965946 train: [0.7555610147725422, tensor(0.4308, device='cuda:0')]\n",
            "9.737019293020847 train: [0.7556819434644558, tensor(0.4308, device='cuda:0')]\n",
            "9.737148776382234 train: [0.7557171898317732, tensor(0.4308, device='cuda:0')]\n",
            "9.737278259743624 train: [0.7558378893798408, tensor(0.4307, device='cuda:0')]\n",
            "9.737407743105011 train: [0.7558720892779647, tensor(0.4307, device='cuda:0')]\n",
            "9.737537226466399 train: [0.7558256086523207, tensor(0.4307, device='cuda:0')]\n",
            "9.737666709827787 train: [0.7557795151127952, tensor(0.4307, device='cuda:0')]\n",
            "9.737796193189174 train: [0.7557336496103015, tensor(0.4307, device='cuda:0')]\n",
            "9.737925676550564 train: [0.7556005041470157, tensor(0.4308, device='cuda:0')]\n",
            "9.738055159911951 train: [0.755720196880801, tensor(0.4308, device='cuda:0')]\n",
            "9.738184643273339 train: [0.7556745777393178, tensor(0.4308, device='cuda:0')]\n",
            "9.738314126634727 train: [0.7556289746637409, tensor(0.4308, device='cuda:0')]\n",
            "9.738443609996116 train: [0.7554959413935536, tensor(0.4309, device='cuda:0')]\n",
            "9.738573093357504 train: [0.7556156211494455, tensor(0.4308, device='cuda:0')]\n",
            "9.738702576718891 train: [0.7554826370556142, tensor(0.4309, device='cuda:0')]\n",
            "9.738832060080279 train: [0.7553496997624494, tensor(0.4310, device='cuda:0')]\n",
            "9.738961543441668 train: [0.7554693420803335, tensor(0.4309, device='cuda:0')]\n",
            "9.739091026803056 train: [0.7555888894526758, tensor(0.4309, device='cuda:0')]\n",
            "9.739220510164444 train: [0.7557082890838497, tensor(0.4308, device='cuda:0')]\n",
            "9.739349993525831 train: [0.7556630612496787, tensor(0.4308, device='cuda:0')]\n",
            "9.73947947688722 train: [0.755617954972682, tensor(0.4308, device='cuda:0')]\n",
            "9.739608960248608 train: [0.7554851340981922, tensor(0.4309, device='cuda:0')]\n",
            "9.739738443609996 train: [0.7553523599094227, tensor(0.4310, device='cuda:0')]\n",
            "9.739867926971383 train: [0.7553839437776246, tensor(0.4310, device='cuda:0')]\n",
            "9.739997410332773 train: [0.7552512340194064, tensor(0.4311, device='cuda:0')]\n",
            "9.74012689369416 train: [0.7553701239038495, tensor(0.4311, device='cuda:0')]\n",
            "9.740256377055548 train: [0.7554888137141661, tensor(0.4310, device='cuda:0')]\n",
            "9.740385860416936 train: [0.755444901482407, tensor(0.4310, device='cuda:0')]\n",
            "9.740515343778325 train: [0.7554011629281007, tensor(0.4310, device='cuda:0')]\n",
            "9.740644827139713 train: [0.7555194683267846, tensor(0.4309, device='cuda:0')]\n",
            "9.7407743105011 train: [0.7555486637517888, tensor(0.4309, device='cuda:0')]\n",
            "9.740903793862488 train: [0.755505457266457, tensor(0.4310, device='cuda:0')]\n",
            "9.741033277223877 train: [0.7553729124493928, tensor(0.4311, device='cuda:0')]\n",
            "9.741162760585265 train: [0.7554907181432408, tensor(0.4310, device='cuda:0')]\n",
            "9.741292243946653 train: [0.7555184226013815, tensor(0.4310, device='cuda:0')]\n",
            "9.74142172730804 train: [0.7554763581751844, tensor(0.4310, device='cuda:0')]\n",
            "9.74155121066943 train: [0.7554346245718254, tensor(0.4310, device='cuda:0')]\n",
            "9.741680694030817 train: [0.7553929582687251, tensor(0.4310, device='cuda:0')]\n",
            "9.741810177392205 train: [0.755351253909515, tensor(0.4310, device='cuda:0')]\n",
            "9.741939660753593 train: [0.75530930090914, tensor(0.4310, device='cuda:0')]\n",
            "9.742069144114982 train: [0.7552669414721578, tensor(0.4311, device='cuda:0')]\n",
            "9.74219862747637 train: [0.7552951774862902, tensor(0.4311, device='cuda:0')]\n",
            "9.742328110837757 train: [0.7554129163579415, tensor(0.4310, device='cuda:0')]\n",
            "9.742457594199145 train: [0.7552806430404213, tensor(0.4311, device='cuda:0')]\n",
            "9.742587077560534 train: [0.7552375292063941, tensor(0.4311, device='cuda:0')]\n",
            "9.742716560921922 train: [0.7551053328946128, tensor(0.4312, device='cuda:0')]\n",
            "9.74284604428331 train: [0.7551345716324278, tensor(0.4312, device='cuda:0')]\n",
            "9.742975527644697 train: [0.7550912956793863, tensor(0.4312, device='cuda:0')]\n",
            "9.743105011006085 train: [0.7550479823000216, tensor(0.4312, device='cuda:0')]\n",
            "9.743234494367474 train: [0.7550044738364662, tensor(0.4313, device='cuda:0')]\n",
            "9.743363977728862 train: [0.755034340359055, tensor(0.4313, device='cuda:0')]\n",
            "9.74349346109025 train: [0.7551524124208105, tensor(0.4312, device='cuda:0')]\n",
            "9.743622944451637 train: [0.7552704431986283, tensor(0.4311, device='cuda:0')]\n",
            "9.743752427813027 train: [0.7552999324351579, tensor(0.4311, device='cuda:0')]\n",
            "9.743881911174414 train: [0.7553287812054688, tensor(0.4311, device='cuda:0')]\n",
            "9.744011394535802 train: [0.7554460892451511, tensor(0.4311, device='cuda:0')]\n",
            "9.74414087789719 train: [0.7554041917802237, tensor(0.4311, device='cuda:0')]\n",
            "9.744270361258579 train: [0.7554303829358414, tensor(0.4311, device='cuda:0')]\n",
            "9.744399844619966 train: [0.755546772145947, tensor(0.4310, device='cuda:0')]\n",
            "9.744529327981354 train: [0.7556628059058978, tensor(0.4309, device='cuda:0')]\n",
            "9.744658811342742 train: [0.7556858431591105, tensor(0.4310, device='cuda:0')]\n",
            "9.744788294704131 train: [0.7558010778495374, tensor(0.4309, device='cuda:0')]\n",
            "9.744917778065519 train: [0.7556691753926702, tensor(0.4310, device='cuda:0')]\n",
            "9.745047261426906 train: [0.7556326905460182, tensor(0.4310, device='cuda:0')]\n",
            "9.745176744788294 train: [0.7555008634890493, tensor(0.4311, device='cuda:0')]\n",
            "9.745306228149683 train: [0.7554656262159696, tensor(0.4311, device='cuda:0')]\n",
            "9.745435711511071 train: [0.7554826997699283, tensor(0.4311, device='cuda:0')]\n",
            "9.745565194872459 train: [0.7554483162598082, tensor(0.4311, device='cuda:0')]\n",
            "9.745694678233846 train: [0.7555618801798358, tensor(0.4310, device='cuda:0')]\n",
            "9.745824161595236 train: [0.7555772519978279, tensor(0.4311, device='cuda:0')]\n",
            "9.745953644956623 train: [0.7554455724488565, tensor(0.4312, device='cuda:0')]\n",
            "9.746083128318011 train: [0.7554593884454541, tensor(0.4312, device='cuda:0')]\n",
            "9.746212611679399 train: [0.7555720860694184, tensor(0.4311, device='cuda:0')]\n",
            "9.746342095040788 train: [0.755583676959254, tensor(0.4311, device='cuda:0')]\n",
            "9.746471578402176 train: [0.7556957903805964, tensor(0.4310, device='cuda:0')]\n",
            "9.746601061763563 train: [0.7558076031523326, tensor(0.4310, device='cuda:0')]\n",
            "9.74673054512495 train: [0.755919115431487, tensor(0.4309, device='cuda:0')]\n",
            "9.74686002848634 train: [0.7558925612572805, tensor(0.4309, device='cuda:0')]\n",
            "9.746989511847728 train: [0.7560037061735254, tensor(0.4308, device='cuda:0')]\n",
            "9.747118995209116 train: [0.7559784536413647, tensor(0.4308, device='cuda:0')]\n",
            "9.747248478570503 train: [0.7558469333815107, tensor(0.4309, device='cuda:0')]\n",
            "9.747377961931893 train: [0.7558222918367073, tensor(0.4309, device='cuda:0')]\n",
            "9.74750744529328 train: [0.755933110367893, tensor(0.4309, device='cuda:0')]\n",
            "9.747636928654668 train: [0.7560438903602049, tensor(0.4308, device='cuda:0')]\n",
            "9.747766412016055 train: [0.7561546318337434, tensor(0.4307, device='cuda:0')]\n",
            "9.747895895377445 train: [0.7561301628581744, tensor(0.4307, device='cuda:0')]\n",
            "9.748025378738832 train: [0.7561055457240448, tensor(0.4307, device='cuda:0')]\n",
            "9.74815486210022 train: [0.7562162709683887, tensor(0.4307, device='cuda:0')]\n",
            "9.748284345461608 train: [0.7561909165853691, tensor(0.4307, device='cuda:0')]\n",
            "9.748413828822997 train: [0.756164996876712, tensor(0.4307, device='cuda:0')]\n",
            "9.748543312184385 train: [0.75613830339728, tensor(0.4307, device='cuda:0')]\n",
            "9.748672795545772 train: [0.756145794375359, tensor(0.4307, device='cuda:0')]\n",
            "9.74880227890716 train: [0.7561177049946581, tensor(0.4307, device='cuda:0')]\n",
            "9.748931762268548 train: [0.7560888951570908, tensor(0.4307, device='cuda:0')]\n",
            "9.749061245629937 train: [0.7562005317497931, tensor(0.4307, device='cuda:0')]\n",
            "9.749190728991325 train: [0.7563122860189004, tensor(0.4306, device='cuda:0')]\n",
            "9.749320212352712 train: [0.7564241579031655, tensor(0.4305, device='cuda:0')]\n",
            "9.7494496957141 train: [0.7562929481619854, tensor(0.4306, device='cuda:0')]\n",
            "9.74957917907549 train: [0.7561617839323355, tensor(0.4307, device='cuda:0')]\n",
            "9.749708662436877 train: [0.7562739363387176, tensor(0.4306, device='cuda:0')]\n",
            "9.749838145798265 train: [0.7561428208851222, tensor(0.4307, device='cuda:0')]\n",
            "9.749967629159652 train: [0.7561105569222769, tensor(0.4308, device='cuda:0')]\n",
            "9.750097112521042 train: [0.7562228682009066, tensor(0.4307, device='cuda:0')]\n",
            "9.75022659588243 train: [0.7561899767404663, tensor(0.4307, device='cuda:0')]\n",
            "9.750356079243817 train: [0.7560589666959859, tensor(0.4308, device='cuda:0')]\n",
            "9.750485562605204 train: [0.7560252822322749, tensor(0.4308, device='cuda:0')]\n",
            "9.750615045966594 train: [0.7559910369927526, tensor(0.4308, device='cuda:0')]\n",
            "9.750744529327982 train: [0.7559561272061273, tensor(0.4308, device='cuda:0')]\n",
            "9.75087401268937 train: [0.7560694410225336, tensor(0.4307, device='cuda:0')]\n",
            "9.751003496050757 train: [0.7559385652321541, tensor(0.4308, device='cuda:0')]\n",
            "9.751132979412146 train: [0.7560523109040924, tensor(0.4308, device='cuda:0')]\n",
            "9.751262462773534 train: [0.7560726856689339, tensor(0.4308, device='cuda:0')]\n",
            "9.751391946134921 train: [0.7559418772458079, tensor(0.4309, device='cuda:0')]\n",
            "9.751521429496309 train: [0.7558111140772823, tensor(0.4310, device='cuda:0')]\n",
            "9.751650912857698 train: [0.7558317278590054, tensor(0.4310, device='cuda:0')]\n",
            "9.751780396219086 train: [0.7557945557436252, tensor(0.4310, device='cuda:0')]\n",
            "9.751909879580474 train: [0.7557573964816736, tensor(0.4310, device='cuda:0')]\n",
            "9.752039362941861 train: [0.755720094242404, tensor(0.4310, device='cuda:0')]\n",
            "9.75216884630325 train: [0.7555894824044777, tensor(0.4311, device='cuda:0')]\n",
            "9.752298329664638 train: [0.7557034749637782, tensor(0.4311, device='cuda:0')]\n",
            "9.752427813026026 train: [0.7556654745727234, tensor(0.4311, device='cuda:0')]\n",
            "9.752557296387414 train: [0.7557796222444424, tensor(0.4310, device='cuda:0')]\n",
            "9.752686779748803 train: [0.7557411028630264, tensor(0.4310, device='cuda:0')]\n",
            "9.75281626311019 train: [0.7557637721995669, tensor(0.4310, device='cuda:0')]\n",
            "9.752945746471578 train: [0.7557249057054823, tensor(0.4310, device='cuda:0')]\n",
            "9.753075229832966 train: [0.7557479330989656, tensor(0.4310, device='cuda:0')]\n",
            "9.753204713194355 train: [0.7558622791979767, tensor(0.4310, device='cuda:0')]\n",
            "9.753334196555743 train: [0.7558234676777063, tensor(0.4310, device='cuda:0')]\n",
            "9.75346367991713 train: [0.7557846695499548, tensor(0.4310, device='cuda:0')]\n",
            "9.753593163278518 train: [0.7557456774724327, tensor(0.4310, device='cuda:0')]\n",
            "9.753722646639908 train: [0.7556153315466871, tensor(0.4311, device='cuda:0')]\n",
            "9.753852130001295 train: [0.7555758121426771, tensor(0.4311, device='cuda:0')]\n",
            "9.753981613362683 train: [0.7554455404509284, tensor(0.4312, device='cuda:0')]\n",
            "9.75411109672407 train: [0.7554052869697532, tensor(0.4312, device='cuda:0')]\n",
            "9.754240580085458 train: [0.7553645294725957, tensor(0.4312, device='cuda:0')]\n",
            "9.754370063446848 train: [0.7553232164397725, tensor(0.4312, device='cuda:0')]\n",
            "9.754499546808235 train: [0.7554388882998463, tensor(0.4312, device='cuda:0')]\n",
            "9.754629030169623 train: [0.7553964379182403, tensor(0.4312, device='cuda:0')]\n",
            "9.75475851353101 train: [0.7553534328711677, tensor(0.4312, device='cuda:0')]\n",
            "9.7548879968924 train: [0.7554699194274814, tensor(0.4311, device='cuda:0')]\n",
            "9.755017480253787 train: [0.7553398454055414, tensor(0.4312, device='cuda:0')]\n",
            "9.755146963615175 train: [0.7554567597362183, tensor(0.4311, device='cuda:0')]\n",
            "9.755276446976563 train: [0.7554119120713624, tensor(0.4312, device='cuda:0')]\n",
            "9.755405930337952 train: [0.7555291357240247, tensor(0.4311, device='cuda:0')]\n",
            "9.75553541369934 train: [0.7553991410344645, tensor(0.4312, device='cuda:0')]\n",
            "9.755664897060727 train: [0.7553534993681271, tensor(0.4312, device='cuda:0')]\n",
            "9.755794380422115 train: [0.7552235796055939, tensor(0.4313, device='cuda:0')]\n",
            "9.755923863783504 train: [0.7551774670943846, tensor(0.4313, device='cuda:0')]\n",
            "9.756053347144892 train: [0.7552954569126283, tensor(0.4312, device='cuda:0')]\n",
            "9.75618283050628 train: [0.7554135094748813, tensor(0.4312, device='cuda:0')]\n",
            "9.756312313867667 train: [0.7555316247487902, tensor(0.4311, device='cuda:0')]\n",
            "9.756441797229057 train: [0.7556496994262826, tensor(0.4310, device='cuda:0')]\n",
            "9.756571280590444 train: [0.7556845592122654, tensor(0.4310, device='cuda:0')]\n",
            "9.756700763951832 train: [0.7556381053182774, tensor(0.4310, device='cuda:0')]\n",
            "9.75683024731322 train: [0.7557557395852601, tensor(0.4310, device='cuda:0')]\n",
            "9.756959730674609 train: [0.7557894795505885, tensor(0.4310, device='cuda:0')]\n",
            "9.757089214035997 train: [0.7558225372133875, tensor(0.4310, device='cuda:0')]\n",
            "9.757218697397384 train: [0.7559393570485309, tensor(0.4309, device='cuda:0')]\n",
            "9.757348180758772 train: [0.7559703661801209, tensor(0.4309, device='cuda:0')]\n",
            "9.757477664120161 train: [0.7560000754940529, tensor(0.4309, device='cuda:0')]\n",
            "9.757607147481549 train: [0.7561154642211341, tensor(0.4309, device='cuda:0')]\n",
            "9.757736630842937 train: [0.7561421485906014, tensor(0.4309, device='cuda:0')]\n",
            "9.757866114204324 train: [0.7560124501088534, tensor(0.4310, device='cuda:0')]\n",
            "9.757995597565714 train: [0.756126231399153, tensor(0.4309, device='cuda:0')]\n",
            "9.758125080927101 train: [0.7560880845566899, tensor(0.4309, device='cuda:0')]\n",
            "9.758254564288489 train: [0.7560507750168142, tensor(0.4309, device='cuda:0')]\n",
            "9.758384047649876 train: [0.7560140448234487, tensor(0.4309, device='cuda:0')]\n",
            "9.758513531011266 train: [0.7559776361973503, tensor(0.4309, device='cuda:0')]\n",
            "9.758643014372653 train: [0.7560901417593715, tensor(0.4309, device='cuda:0')]\n",
            "9.758772497734041 train: [0.7559606077278898, tensor(0.4310, device='cuda:0')]\n",
            "9.758901981095429 train: [0.7558311180725749, tensor(0.4311, device='cuda:0')]\n",
            "9.759031464456818 train: [0.7557953832485805, tensor(0.4311, device='cuda:0')]\n",
            "9.759160947818206 train: [0.7558139941714963, tensor(0.4311, device='cuda:0')]\n",
            "9.759290431179593 train: [0.7559261227825846, tensor(0.4310, device='cuda:0')]\n",
            "9.759419914540981 train: [0.7560381101374661, tensor(0.4309, device='cuda:0')]\n",
            "9.75954939790237 train: [0.7560032385892389, tensor(0.4309, device='cuda:0')]\n",
            "9.759678881263758 train: [0.7558738745853736, tensor(0.4310, device='cuda:0')]\n",
            "9.759808364625146 train: [0.755839300108574, tensor(0.4311, device='cuda:0')]\n",
            "9.759937847986533 train: [0.755951020092634, tensor(0.4310, device='cuda:0')]\n",
            "9.760067331347921 train: [0.7559163928576127, tensor(0.4310, device='cuda:0')]\n",
            "9.76019681470931 train: [0.7558815719378091, tensor(0.4310, device='cuda:0')]\n",
            "9.760326298070698 train: [0.7558464033135184, tensor(0.4310, device='cuda:0')]\n",
            "9.760455781432086 train: [0.7558107330703484, tensor(0.4310, device='cuda:0')]\n",
            "9.760585264793473 train: [0.7557744073991297, tensor(0.4310, device='cuda:0')]\n",
            "9.760714748154863 train: [0.7557948835703769, tensor(0.4310, device='cuda:0')]\n",
            "9.76084423151625 train: [0.7557574435858009, tensor(0.4311, device='cuda:0')]\n",
            "9.760973714877638 train: [0.7558703594353631, tensor(0.4310, device='cuda:0')]\n",
            "9.761103198239026 train: [0.755983390675294, tensor(0.4309, device='cuda:0')]\n",
            "9.761232681600415 train: [0.7560964859348729, tensor(0.4308, device='cuda:0')]\n",
            "9.761362164961803 train: [0.7560577374541968, tensor(0.4309, device='cuda:0')]\n",
            "9.76149164832319 train: [0.7560187457323319, tensor(0.4309, device='cuda:0')]\n",
            "9.761621131684578 train: [0.7560424892834167, tensor(0.4309, device='cuda:0')]\n",
            "9.761750615045967 train: [0.7560663785606458, tensor(0.4309, device='cuda:0')]\n",
            "9.761880098407355 train: [0.7560270464478365, tensor(0.4309, device='cuda:0')]\n",
            "9.762009581768742 train: [0.7561403773160906, tensor(0.4308, device='cuda:0')]\n",
            "9.76213906513013 train: [0.7561010972493735, tensor(0.4308, device='cuda:0')]\n",
            "9.76226854849152 train: [0.7562143768364991, tensor(0.4308, device='cuda:0')]\n",
            "9.762398031852907 train: [0.7561749950816447, tensor(0.4308, device='cuda:0')]\n",
            "9.762527515214295 train: [0.7562882746728212, tensor(0.4307, device='cuda:0')]\n",
            "9.762656998575682 train: [0.7562487401010869, tensor(0.4307, device='cuda:0')]\n",
            "9.762786481937072 train: [0.7563620709290284, tensor(0.4306, device='cuda:0')]\n",
            "9.76291596529846 train: [0.7563222300680237, tensor(0.4307, device='cuda:0')]\n",
            "9.763045448659847 train: [0.7562821468352772, tensor(0.4307, device='cuda:0')]\n",
            "9.763174932021235 train: [0.7563957211456572, tensor(0.4306, device='cuda:0')]\n",
            "9.763304415382624 train: [0.7563550761600032, tensor(0.4306, device='cuda:0')]\n",
            "9.763433898744012 train: [0.7563140868740913, tensor(0.4306, device='cuda:0')]\n",
            "9.7635633821054 train: [0.7562726511550247, tensor(0.4306, device='cuda:0')]\n",
            "9.763692865466787 train: [0.7563869680851064, tensor(0.4306, device='cuda:0')]\n",
            "9.763822348828176 train: [0.7563445624639996, tensor(0.4306, device='cuda:0')]\n",
            "9.763951832189564 train: [0.756215866775304, tensor(0.4307, device='cuda:0')]\n",
            "9.764081315550952 train: [0.7563307995753396, tensor(0.4306, device='cuda:0')]\n",
            "9.76421079891234 train: [0.7562871984867913, tensor(0.4306, device='cuda:0')]\n",
            "9.764340282273729 train: [0.7564024377779958, tensor(0.4305, device='cuda:0')]\n",
            "9.764469765635116 train: [0.7565177911592743, tensor(0.4305, device='cuda:0')]\n",
            "9.764599248996504 train: [0.7565489686592735, tensor(0.4305, device='cuda:0')]\n",
            "9.764728732357892 train: [0.7565046961420783, tensor(0.4305, device='cuda:0')]\n",
            "9.764858215719281 train: [0.7566200243979763, tensor(0.4304, device='cuda:0')]\n",
            "9.764987699080669 train: [0.7567352624011503, tensor(0.4303, device='cuda:0')]\n",
            "9.765117182442056 train: [0.7566911339488748, tensor(0.4303, device='cuda:0')]\n",
            "9.765246665803444 train: [0.7568062186401588, tensor(0.4303, device='cuda:0')]\n",
            "9.765376149164831 train: [0.7567621951916544, tensor(0.4303, device='cuda:0')]\n",
            "9.76550563252622 train: [0.7566336908284024, tensor(0.4304, device='cuda:0')]\n",
            "9.765635115887608 train: [0.7567487266553481, tensor(0.4303, device='cuda:0')]\n",
            "9.765764599248996 train: [0.7567792562481229, tensor(0.4303, device='cuda:0')]\n",
            "9.765894082610384 train: [0.7567355732512142, tensor(0.4303, device='cuda:0')]\n",
            "9.766023565971773 train: [0.7566920070585701, tensor(0.4303, device='cuda:0')]\n",
            "9.76615304933316 train: [0.7565636236165854, tensor(0.4304, device='cuda:0')]\n",
            "9.766282532694548 train: [0.7566783188980231, tensor(0.4304, device='cuda:0')]\n",
            "9.766412016055936 train: [0.7565499813269753, tensor(0.4305, device='cuda:0')]\n",
            "9.766541499417325 train: [0.7565795454174874, tensor(0.4305, device='cuda:0')]\n",
            "9.766670982778713 train: [0.7564512681123979, tensor(0.4306, device='cuda:0')]\n",
            "9.7668004661401 train: [0.7564086094285863, tensor(0.4306, device='cuda:0')]\n",
            "9.766929949501488 train: [0.7563661179921773, tensor(0.4306, device='cuda:0')]\n",
            "9.767059432862878 train: [0.7563945729537367, tensor(0.4306, device='cuda:0')]\n",
            "9.767188916224265 train: [0.7564226618910148, tensor(0.4306, device='cuda:0')]\n",
            "9.767318399585653 train: [0.756380851408671, tensor(0.4306, device='cuda:0')]\n",
            "9.76744788294704 train: [0.7563393095619658, tensor(0.4306, device='cuda:0')]\n",
            "9.76757736630843 train: [0.7563662232137042, tensor(0.4307, device='cuda:0')]\n",
            "9.767706849669818 train: [0.7564795681217276, tensor(0.4306, device='cuda:0')]\n",
            "9.767836333031205 train: [0.7565926711789142, tensor(0.4305, device='cuda:0')]\n",
            "9.767965816392593 train: [0.7564646087768866, tensor(0.4306, device='cuda:0')]\n",
            "9.768095299753982 train: [0.7564247151509431, tensor(0.4306, device='cuda:0')]\n",
            "9.76822478311537 train: [0.7564489477580372, tensor(0.4306, device='cuda:0')]\n",
            "9.768354266476758 train: [0.7565613186139271, tensor(0.4306, device='cuda:0')]\n",
            "9.768483749838145 train: [0.7566733973274695, tensor(0.4305, device='cuda:0')]\n",
            "9.768613233199535 train: [0.7566351723386541, tensor(0.4305, device='cuda:0')]\n",
            "9.768742716560922 train: [0.7565973159354595, tensor(0.4305, device='cuda:0')]\n",
            "9.76887219992231 train: [0.7565595739319851, tensor(0.4305, device='cuda:0')]\n",
            "9.769001683283697 train: [0.7566712216219379, tensor(0.4304, device='cuda:0')]\n",
            "9.769131166645087 train: [0.7565433407326998, tensor(0.4305, device='cuda:0')]\n",
            "9.769260650006474 train: [0.7566549026600723, tensor(0.4305, device='cuda:0')]\n",
            "9.769390133367862 train: [0.7567663761257749, tensor(0.4304, device='cuda:0')]\n",
            "9.76951961672925 train: [0.7568777104177494, tensor(0.4303, device='cuda:0')]\n",
            "9.76964910009064 train: [0.7569889056065113, tensor(0.4302, device='cuda:0')]\n",
            "9.769778583452027 train: [0.7570999617625283, tensor(0.4302, device='cuda:0')]\n",
            "9.769908066813414 train: [0.7572108282250419, tensor(0.4301, device='cuda:0')]\n",
            "9.770037550174802 train: [0.7573214543675012, tensor(0.4300, device='cuda:0')]\n",
            "9.770167033536191 train: [0.7571936364005193, tensor(0.4301, device='cuda:0')]\n",
            "9.770296516897579 train: [0.7573038731697345, tensor(0.4301, device='cuda:0')]\n",
            "9.770426000258967 train: [0.7571761012997884, tensor(0.4302, device='cuda:0')]\n",
            "9.770555483620354 train: [0.7571419433036177, tensor(0.4302, device='cuda:0')]\n",
            "9.770684966981744 train: [0.7571079995491522, tensor(0.4302, device='cuda:0')]\n",
            "9.770814450343131 train: [0.7570740672428331, tensor(0.4302, device='cuda:0')]\n",
            "9.770943933704519 train: [0.7571839272628821, tensor(0.4301, device='cuda:0')]\n",
            "9.771073417065907 train: [0.7571496390178433, tensor(0.4301, device='cuda:0')]\n",
            "9.771202900427294 train: [0.7570220223586459, tensor(0.4302, device='cuda:0')]\n",
            "9.771332383788684 train: [0.7568944487114672, tensor(0.4303, device='cuda:0')]\n",
            "9.771461867150071 train: [0.7570045687252932, tensor(0.4302, device='cuda:0')]\n",
            "9.771591350511459 train: [0.7571147022567645, tensor(0.4302, device='cuda:0')]\n",
            "9.771720833872847 train: [0.7570795435405087, tensor(0.4302, device='cuda:0')]\n",
            "9.771850317234236 train: [0.7571897285572713, tensor(0.4301, device='cuda:0')]\n",
            "9.771979800595624 train: [0.7572999270629606, tensor(0.4300, device='cuda:0')]\n",
            "9.772109283957011 train: [0.7573180725524475, tensor(0.4301, device='cuda:0')]\n",
            "9.772238767318399 train: [0.7573358073135835, tensor(0.4301, device='cuda:0')]\n",
            "9.772368250679788 train: [0.7573011466613158, tensor(0.4301, device='cuda:0')]\n",
            "9.772497734041176 train: [0.7574107972048564, tensor(0.4300, device='cuda:0')]\n",
            "9.772627217402563 train: [0.7573767927742261, tensor(0.4300, device='cuda:0')]\n",
            "9.772756700763951 train: [0.7572493955004205, tensor(0.4301, device='cuda:0')]\n",
            "9.77288618412534 train: [0.7573587972845351, tensor(0.4300, device='cuda:0')]\n",
            "9.773015667486728 train: [0.7573252734895423, tensor(0.4300, device='cuda:0')]\n",
            "9.773145150848116 train: [0.7572917104488904, tensor(0.4301, device='cuda:0')]\n",
            "9.773274634209503 train: [0.7572579061445363, tensor(0.4301, device='cuda:0')]\n",
            "9.773404117570893 train: [0.7571306359082094, tensor(0.4302, device='cuda:0')]\n",
            "9.77353360093228 train: [0.7570034084446053, tensor(0.4303, device='cuda:0')]\n",
            "9.773663084293668 train: [0.7570208099087572, tensor(0.4303, device='cuda:0')]\n",
            "9.773792567655056 train: [0.7569860138391761, tensor(0.4303, device='cuda:0')]\n",
            "9.773922051016445 train: [0.757003664714736, tensor(0.4303, device='cuda:0')]\n",
            "9.774051534377833 train: [0.7570211078279403, tensor(0.4303, device='cuda:0')]\n",
            "9.77418101773922 train: [0.7569866319354756, tensor(0.4303, device='cuda:0')]\n",
            "9.774310501100608 train: [0.7569523693844346, tensor(0.4303, device='cuda:0')]\n",
            "9.774439984461997 train: [0.7569180679015932, tensor(0.4303, device='cuda:0')]\n",
            "9.774569467823385 train: [0.7569351606974583, tensor(0.4304, device='cuda:0')]\n",
            "9.774698951184773 train: [0.7570446607188952, tensor(0.4303, device='cuda:0')]\n",
            "9.77482843454616 train: [0.757154073593744, tensor(0.4302, device='cuda:0')]\n",
            "9.77495791790755 train: [0.7572633993658555, tensor(0.4301, device='cuda:0')]\n",
            "9.775087401268937 train: [0.7572295783936841, tensor(0.4302, device='cuda:0')]\n",
            "9.775216884630325 train: [0.757195819145643, tensor(0.4302, device='cuda:0')]\n",
            "9.775346367991713 train: [0.7571619200947837, tensor(0.4302, device='cuda:0')]\n",
            "9.775475851353102 train: [0.7570350072687537, tensor(0.4303, device='cuda:0')]\n",
            "9.77560533471449 train: [0.757000542245169, tensor(0.4303, device='cuda:0')]\n",
            "9.775734818075877 train: [0.7571100859229996, tensor(0.4302, device='cuda:0')]\n",
            "9.775864301437265 train: [0.7570748647660348, tensor(0.4302, device='cuda:0')]\n",
            "9.775993784798654 train: [0.7571846612872053, tensor(0.4302, device='cuda:0')]\n",
            "9.776123268160042 train: [0.7572945216784973, tensor(0.4301, device='cuda:0')]\n",
            "9.77625275152143 train: [0.757167714156448, tensor(0.4302, device='cuda:0')]\n",
            "9.776382234882817 train: [0.7572776915188862, tensor(0.4301, device='cuda:0')]\n",
            "9.776511718244207 train: [0.7573876823607427, tensor(0.4300, device='cuda:0')]\n",
            "9.776641201605594 train: [0.7573512431606051, tensor(0.4300, device='cuda:0')]\n",
            "9.776770684966982 train: [0.7572245110248687, tensor(0.4301, device='cuda:0')]\n",
            "9.77690016832837 train: [0.7573345561028816, tensor(0.4301, device='cuda:0')]\n",
            "9.777029651689757 train: [0.7574445643642073, tensor(0.4300, device='cuda:0')]\n",
            "9.777159135051146 train: [0.75740788874844, tensor(0.4300, device='cuda:0')]\n",
            "9.777288618412534 train: [0.7573710746559043, tensor(0.4300, device='cuda:0')]\n",
            "9.777418101773922 train: [0.757481172350263, tensor(0.4299, device='cuda:0')]\n",
            "9.77754758513531 train: [0.7573545456079778, tensor(0.4300, device='cuda:0')]\n",
            "9.777677068496699 train: [0.7574647097063475, tensor(0.4300, device='cuda:0')]\n",
            "9.777806551858086 train: [0.7573381280369447, tensor(0.4301, device='cuda:0')]\n",
            "9.777936035219474 train: [0.7573007036822826, tensor(0.4301, device='cuda:0')]\n",
            "9.778065518580862 train: [0.7572630910425608, tensor(0.4301, device='cuda:0')]\n",
            "9.778195001942251 train: [0.757225139645514, tensor(0.4301, device='cuda:0')]\n",
            "9.778324485303639 train: [0.7571867492998818, tensor(0.4301, device='cuda:0')]\n",
            "9.778453968665026 train: [0.7571477697092105, tensor(0.4301, device='cuda:0')]\n",
            "9.778583452026414 train: [0.7571081510048799, tensor(0.4301, device='cuda:0')]\n",
            "9.778712935387803 train: [0.7570677931962045, tensor(0.4301, device='cuda:0')]\n",
            "9.778842418749191 train: [0.7571796449753517, tensor(0.4301, device='cuda:0')]\n",
            "9.778971902110579 train: [0.7571378848239613, tensor(0.4301, device='cuda:0')]\n",
            "9.779101385471966 train: [0.7570954367829368, tensor(0.4301, device='cuda:0')]\n",
            "9.779230868833356 train: [0.757208280538269, tensor(0.4300, device='cuda:0')]\n",
            "9.779360352194743 train: [0.7573214374486837, tensor(0.4300, device='cuda:0')]\n",
            "9.77948983555613 train: [0.7572772764587422, tensor(0.4300, device='cuda:0')]\n",
            "9.779619318917518 train: [0.7572326292257676, tensor(0.4300, device='cuda:0')]\n",
            "9.779748802278908 train: [0.7571874459044456, tensor(0.4300, device='cuda:0')]\n",
            "9.779878285640295 train: [0.7572212540064103, tensor(0.4300, device='cuda:0')]\n",
            "9.780007769001683 train: [0.7570950714944945, tensor(0.4301, device='cuda:0')]\n",
            "9.78013725236307 train: [0.7570487822168251, tensor(0.4301, device='cuda:0')]\n",
            "9.78026673572446 train: [0.7569226704756596, tensor(0.4302, device='cuda:0')]\n",
            "9.780396219085848 train: [0.7567966007437349, tensor(0.4303, device='cuda:0')]\n",
            "9.780525702447235 train: [0.7569117081918914, tensor(0.4302, device='cuda:0')]\n",
            "9.780655185808623 train: [0.75686447967097, tensor(0.4302, device='cuda:0')]\n",
            "9.780784669170012 train: [0.7569797876035651, tensor(0.4302, device='cuda:0')]\n",
            "9.7809141525314 train: [0.7570951071648059, tensor(0.4301, device='cuda:0')]\n",
            "9.781043635892788 train: [0.7570475216662186, tensor(0.4301, device='cuda:0')]\n",
            "9.781173119254175 train: [0.7569998520094714, tensor(0.4301, device='cuda:0')]\n",
            "9.781302602615565 train: [0.756951998259601, tensor(0.4301, device='cuda:0')]\n",
            "9.781432085976952 train: [0.7569039105283024, tensor(0.4301, device='cuda:0')]\n",
            "9.78156156933834 train: [0.7568554889886017, tensor(0.4302, device='cuda:0')]\n",
            "9.781691052699728 train: [0.7569716135107826, tensor(0.4301, device='cuda:0')]\n",
            "9.781820536061117 train: [0.7568457661934906, tensor(0.4302, device='cuda:0')]\n",
            "9.781950019422505 train: [0.7567965293672003, tensor(0.4302, device='cuda:0')]\n",
            "9.782079502783892 train: [0.7566707529787398, tensor(0.4303, device='cuda:0')]\n",
            "9.78220898614528 train: [0.7567114861345451, tensor(0.4303, device='cuda:0')]\n",
            "9.782338469506668 train: [0.7568282869471034, tensor(0.4302, device='cuda:0')]\n",
            "9.782467952868057 train: [0.756944999041656, tensor(0.4301, device='cuda:0')]\n",
            "9.782597436229445 train: [0.75689543728361, tensor(0.4302, device='cuda:0')]\n",
            "9.782726919590832 train: [0.757011949773906, tensor(0.4301, device='cuda:0')]\n",
            "9.78285640295222 train: [0.7569625430241765, tensor(0.4301, device='cuda:0')]\n",
            "9.78298588631361 train: [0.7570026384845234, tensor(0.4301, device='cuda:0')]\n",
            "9.783115369674997 train: [0.7569534491701245, tensor(0.4301, device='cuda:0')]\n",
            "9.783244853036384 train: [0.75699303419158, tensor(0.4301, device='cuda:0')]\n",
            "9.783374336397772 train: [0.756867433887251, tensor(0.4302, device='cuda:0')]\n",
            "9.783503819759162 train: [0.7569831870342248, tensor(0.4302, device='cuda:0')]\n",
            "9.78363330312055 train: [0.7570987024254564, tensor(0.4301, device='cuda:0')]\n",
            "9.783762786481937 train: [0.7570508834034954, tensor(0.4301, device='cuda:0')]\n",
            "9.783892269843324 train: [0.7570033293528309, tensor(0.4301, device='cuda:0')]\n",
            "9.784021753204714 train: [0.7568778314534024, tensor(0.4302, device='cuda:0')]\n",
            "9.784151236566101 train: [0.7568305210763876, tensor(0.4302, device='cuda:0')]\n",
            "9.784280719927489 train: [0.7567050934129675, tensor(0.4303, device='cuda:0')]\n",
            "9.784410203288877 train: [0.7568199425626155, tensor(0.4302, device='cuda:0')]\n",
            "9.784539686650266 train: [0.7567728146346281, tensor(0.4303, device='cuda:0')]\n",
            "9.784669170011654 train: [0.7567257023196697, tensor(0.4303, device='cuda:0')]\n",
            "9.784798653373041 train: [0.7567623600211482, tensor(0.4303, device='cuda:0')]\n",
            "9.784928136734429 train: [0.7567152650400601, tensor(0.4303, device='cuda:0')]\n",
            "9.785057620095818 train: [0.7566681856533367, tensor(0.4303, device='cuda:0')]\n",
            "9.785187103457206 train: [0.7566210223727605, tensor(0.4303, device='cuda:0')]\n",
            "9.785316586818594 train: [0.7566580212550608, tensor(0.4303, device='cuda:0')]\n",
            "9.785446070179981 train: [0.7566106763706258, tensor(0.4303, device='cuda:0')]\n",
            "9.78557555354137 train: [0.7564854926055083, tensor(0.4304, device='cuda:0')]\n",
            "9.785705036902758 train: [0.7565226446681936, tensor(0.4304, device='cuda:0')]\n",
            "9.785834520264146 train: [0.7566374144380265, tensor(0.4304, device='cuda:0')]\n",
            "9.785964003625534 train: [0.7565903527337141, tensor(0.4304, device='cuda:0')]\n",
            "9.786093486986923 train: [0.7567048746247965, tensor(0.4303, device='cuda:0')]\n",
            "9.78622297034831 train: [0.7567409226890649, tensor(0.4303, device='cuda:0')]\n",
            "9.786352453709698 train: [0.7566945128734901, tensor(0.4303, device='cuda:0')]\n",
            "9.786481937071086 train: [0.7567295575747175, tensor(0.4303, device='cuda:0')]\n",
            "9.786611420432475 train: [0.7568431863751335, tensor(0.4303, device='cuda:0')]\n",
            "9.786740903793863 train: [0.7567978747823711, tensor(0.4303, device='cuda:0')]\n",
            "9.78687038715525 train: [0.7567528759593148, tensor(0.4303, device='cuda:0')]\n",
            "9.786999870516638 train: [0.7568658987327701, tensor(0.4302, device='cuda:0')]\n",
            "9.787129353878028 train: [0.7569787353292349, tensor(0.4302, device='cuda:0')]\n",
            "9.787258837239415 train: [0.7570913858409215, tensor(0.4301, device='cuda:0')]\n",
            "9.787388320600803 train: [0.7570474594941209, tensor(0.4301, device='cuda:0')]\n",
            "9.78751780396219 train: [0.7570784818674064, tensor(0.4301, device='cuda:0')]\n",
            "9.78764728732358 train: [0.7570351671585428, tensor(0.4301, device='cuda:0')]\n",
            "9.787776770684967 train: [0.7571469903735103, tensor(0.4300, device='cuda:0')]\n",
            "9.787906254046355 train: [0.7571042239010989, tensor(0.4301, device='cuda:0')]\n",
            "9.788035737407743 train: [0.7571334818539946, tensor(0.4301, device='cuda:0')]\n",
            "9.78816522076913 train: [0.7570912767816369, tensor(0.4301, device='cuda:0')]\n",
            "9.78829470413052 train: [0.7572024720178832, tensor(0.4300, device='cuda:0')]\n",
            "9.788424187491907 train: [0.757160715304725, tensor(0.4300, device='cuda:0')]\n",
            "9.788553670853295 train: [0.7571191209379874, tensor(0.4300, device='cuda:0')]\n",
            "9.788683154214683 train: [0.7572300585353177, tensor(0.4300, device='cuda:0')]\n",
            "9.788812637576072 train: [0.7571884664499284, tensor(0.4300, device='cuda:0')]\n",
            "9.78894212093746 train: [0.7571467890634901, tensor(0.4300, device='cuda:0')]\n",
            "9.789071604298847 train: [0.7571750115619021, tensor(0.4300, device='cuda:0')]\n",
            "9.789201087660235 train: [0.7572860153320411, tensor(0.4299, device='cuda:0')]\n",
            "9.789330571021624 train: [0.7573968835894058, tensor(0.4299, device='cuda:0')]\n",
            "9.789460054383012 train: [0.7573553477463844, tensor(0.4299, device='cuda:0')]\n",
            "9.7895895377444 train: [0.7573828248654637, tensor(0.4299, device='cuda:0')]\n",
            "9.789719021105787 train: [0.7573416511843571, tensor(0.4299, device='cuda:0')]\n",
            "9.789848504467177 train: [0.7574520911918836, tensor(0.4298, device='cuda:0')]\n",
            "9.789977987828564 train: [0.7575623959836232, tensor(0.4297, device='cuda:0')]\n",
            "9.790107471189952 train: [0.7576725656263049, tensor(0.4297, device='cuda:0')]\n",
            "9.79023695455134 train: [0.7577825013442561, tensor(0.4296, device='cuda:0')]\n",
            "9.790366437912729 train: [0.7577425805314156, tensor(0.4296, device='cuda:0')]\n",
            "9.790495921274116 train: [0.7578521721568057, tensor(0.4295, device='cuda:0')]\n",
            "9.790625404635504 train: [0.7578127469840287, tensor(0.4296, device='cuda:0')]\n",
            "9.790754887996892 train: [0.757773433548905, tensor(0.4296, device='cuda:0')]\n",
            "9.790884371358281 train: [0.7577977352095316, tensor(0.4296, device='cuda:0')]\n",
            "9.791013854719669 train: [0.757821732649334, tensor(0.4296, device='cuda:0')]\n",
            "9.791143338081056 train: [0.7577829801215705, tensor(0.4296, device='cuda:0')]\n",
            "9.791272821442444 train: [0.7577444377495451, tensor(0.4296, device='cuda:0')]\n",
            "9.791402304803833 train: [0.7577059573853229, tensor(0.4296, device='cuda:0')]\n",
            "9.791531788165221 train: [0.7578149176613617, tensor(0.4296, device='cuda:0')]\n",
            "9.791661271526609 train: [0.7577762903653562, tensor(0.4296, device='cuda:0')]\n",
            "9.791790754887996 train: [0.7576519016111924, tensor(0.4297, device='cuda:0')]\n",
            "9.791920238249386 train: [0.757613017854663, tensor(0.4297, device='cuda:0')]\n",
            "9.792049721610773 train: [0.7576370634104163, tensor(0.4297, device='cuda:0')]\n",
            "9.792179204972161 train: [0.7575979483498454, tensor(0.4297, device='cuda:0')]\n",
            "9.792308688333549 train: [0.7577072134312538, tensor(0.4296, device='cuda:0')]\n",
            "9.792438171694938 train: [0.7576679025624203, tensor(0.4296, device='cuda:0')]\n",
            "9.792567655056326 train: [0.7576284074854303, tensor(0.4296, device='cuda:0')]\n",
            "9.792697138417713 train: [0.7575885804892353, tensor(0.4297, device='cuda:0')]\n",
            "9.792826621779101 train: [0.7576982187894074, tensor(0.4296, device='cuda:0')]\n",
            "9.79295610514049 train: [0.7578079689016933, tensor(0.4295, device='cuda:0')]\n",
            "9.793085588501878 train: [0.7579177815281245, tensor(0.4294, device='cuda:0')]\n",
            "9.793215071863266 train: [0.7580275581681141, tensor(0.4294, device='cuda:0')]\n",
            "9.793344555224653 train: [0.7579868123204204, tensor(0.4294, device='cuda:0')]\n",
            "9.79347403858604 train: [0.7580965909090909, tensor(0.4293, device='cuda:0')]\n",
            "9.79360352194743 train: [0.7581230689706215, tensor(0.4293, device='cuda:0')]\n",
            "9.793733005308818 train: [0.7582326908906551, tensor(0.4293, device='cuda:0')]\n",
            "9.793862488670205 train: [0.7581923316992847, tensor(0.4293, device='cuda:0')]\n",
            "9.793991972031593 train: [0.7581521332806578, tensor(0.4293, device='cuda:0')]\n",
            "9.794121455392983 train: [0.7582614999055772, tensor(0.4292, device='cuda:0')]\n",
            "9.79425093875437 train: [0.7583707815666578, tensor(0.4291, device='cuda:0')]\n",
            "9.794380422115758 train: [0.7582467025775271, tensor(0.4292, device='cuda:0')]\n",
            "9.794509905477145 train: [0.7582717002856459, tensor(0.4292, device='cuda:0')]\n",
            "9.794639388838535 train: [0.7582321606621625, tensor(0.4293, device='cuda:0')]\n",
            "9.794768872199922 train: [0.7583409825303479, tensor(0.4292, device='cuda:0')]\n",
            "9.79489835556131 train: [0.7583018866812145, tensor(0.4292, device='cuda:0')]\n",
            "9.795027838922698 train: [0.7584105142037952, tensor(0.4291, device='cuda:0')]\n",
            "9.795157322284087 train: [0.7583716653412377, tensor(0.4291, device='cuda:0')]\n",
            "9.795286805645475 train: [0.7582477281512816, tensor(0.4292, device='cuda:0')]\n",
            "9.795416289006862 train: [0.7582089185834591, tensor(0.4292, device='cuda:0')]\n",
            "9.79554577236825 train: [0.7583174903076421, tensor(0.4292, device='cuda:0')]\n",
            "9.79567525572964 train: [0.7582784856947202, tensor(0.4292, device='cuda:0')]\n",
            "9.795804739091027 train: [0.7582392975257227, tensor(0.4292, device='cuda:0')]\n",
            "9.795934222452415 train: [0.7581154831401045, tensor(0.4293, device='cuda:0')]\n",
            "9.796063705813802 train: [0.7579917091836734, tensor(0.4294, device='cuda:0')]\n",
            "9.796193189175192 train: [0.7579517531674578, tensor(0.4294, device='cuda:0')]\n",
            "9.79632267253658 train: [0.7579114178572773, tensor(0.4294, device='cuda:0')]\n",
            "9.796452155897967 train: [0.75787065440475, tensor(0.4294, device='cuda:0')]\n",
            "9.796581639259355 train: [0.7578293649673055, tensor(0.4294, device='cuda:0')]\n",
            "9.796711122620744 train: [0.7579393587652152, tensor(0.4294, device='cuda:0')]\n",
            "9.796840605982132 train: [0.7578157346649436, tensor(0.4295, device='cuda:0')]\n",
            "9.79697008934352 train: [0.757692150885644, tensor(0.4295, device='cuda:0')]\n",
            "9.797099572704907 train: [0.7578027991696873, tensor(0.4295, device='cuda:0')]\n",
            "9.797229056066296 train: [0.7577595460202904, tensor(0.4295, device='cuda:0')]\n",
            "9.797358539427684 train: [0.7577904598457776, tensor(0.4295, device='cuda:0')]\n",
            "9.797488022789071 train: [0.7577468800145422, tensor(0.4295, device='cuda:0')]\n",
            "9.79761750615046 train: [0.757703118536995, tensor(0.4295, device='cuda:0')]\n",
            "9.797746989511849 train: [0.7577348097131363, tensor(0.4295, device='cuda:0')]\n",
            "9.797876472873236 train: [0.7576907707813851, tensor(0.4295, device='cuda:0')]\n",
            "9.798005956234624 train: [0.7578019293410173, tensor(0.4295, device='cuda:0')]\n",
            "9.798135439596011 train: [0.7578338825266494, tensor(0.4295, device='cuda:0')]\n",
            "9.7982649229574 train: [0.757944883744959, tensor(0.4294, device='cuda:0')]\n",
            "9.798394406318788 train: [0.7578215002379194, tensor(0.4295, device='cuda:0')]\n",
            "9.798523889680176 train: [0.7579322228064904, tensor(0.4294, device='cuda:0')]\n",
            "9.798653373041564 train: [0.757808881517181, tensor(0.4295, device='cuda:0')]\n",
            "9.798782856402953 train: [0.7579192278749155, tensor(0.4295, device='cuda:0')]\n",
            "9.79891233976434 train: [0.7579485400163932, tensor(0.4295, device='cuda:0')]\n",
            "9.799041823125728 train: [0.757906583519969, tensor(0.4295, device='cuda:0')]\n",
            "9.799171306487116 train: [0.7580161271532582, tensor(0.4294, device='cuda:0')]\n",
            "9.799300789848504 train: [0.758125439727955, tensor(0.4293, device='cuda:0')]\n",
            "9.799430273209893 train: [0.7580021873397697, tensor(0.4294, device='cuda:0')]\n",
            "9.79955975657128 train: [0.7581109782153396, tensor(0.4294, device='cuda:0')]\n",
            "9.799689239932668 train: [0.757987768240008, tensor(0.4295, device='cuda:0')]\n",
            "9.799818723294056 train: [0.7579484829285518, tensor(0.4295, device='cuda:0')]\n",
            "9.799948206655445 train: [0.7580566436761857, tensor(0.4294, device='cuda:0')]\n",
            "9.800077690016833 train: [0.7580801797495876, tensor(0.4294, device='cuda:0')]\n",
            "9.80020717337822 train: [0.7579570548219038, tensor(0.4295, device='cuda:0')]\n",
            "9.800336656739608 train: [0.7580645271473005, tensor(0.4294, device='cuda:0')]\n",
            "9.800466140100998 train: [0.7579414447431526, tensor(0.4295, device='cuda:0')]\n",
            "9.800595623462385 train: [0.7578184023008242, tensor(0.4296, device='cuda:0')]\n",
            "9.800725106823773 train: [0.7576953998008565, tensor(0.4297, device='cuda:0')]\n",
            "9.80085459018516 train: [0.7576598214397173, tensor(0.4297, device='cuda:0')]\n",
            "9.80098407354655 train: [0.7576244984023764, tensor(0.4297, device='cuda:0')]\n",
            "9.801113556907938 train: [0.7575015872248291, tensor(0.4298, device='cuda:0')]\n",
            "9.801243040269325 train: [0.7575204999532098, tensor(0.4298, device='cuda:0')]\n",
            "9.801372523630713 train: [0.7576268802708401, tensor(0.4298, device='cuda:0')]\n",
            "9.801502006992102 train: [0.7577330799166782, tensor(0.4297, device='cuda:0')]\n",
            "9.80163149035349 train: [0.757698845389978, tensor(0.4297, device='cuda:0')]\n",
            "9.801760973714877 train: [0.7576648167948926, tensor(0.4297, device='cuda:0')]\n",
            "9.801890457076265 train: [0.7576819832315173, tensor(0.4297, device='cuda:0')]\n",
            "9.802019940437654 train: [0.7577877642633659, tensor(0.4297, device='cuda:0')]\n",
            "9.802149423799042 train: [0.757893413648487, tensor(0.4296, device='cuda:0')]\n",
            "9.80227890716043 train: [0.75777063810764, tensor(0.4297, device='cuda:0')]\n",
            "9.802408390521817 train: [0.7578760126990357, tensor(0.4296, device='cuda:0')]\n",
            "9.802537873883207 train: [0.7577532797415135, tensor(0.4297, device='cuda:0')]\n",
            "9.802667357244594 train: [0.7576305865291202, tensor(0.4298, device='cuda:0')]\n",
            "9.802796840605982 train: [0.7576445284772294, tensor(0.4298, device='cuda:0')]\n",
            "9.80292632396737 train: [0.7577492716089349, tensor(0.4298, device='cuda:0')]\n",
            "9.803055807328759 train: [0.7578537863202908, tensor(0.4297, device='cuda:0')]\n",
            "9.803185290690147 train: [0.7577311562577794, tensor(0.4298, device='cuda:0')]\n",
            "9.803314774051534 train: [0.7578352997865668, tensor(0.4297, device='cuda:0')]\n",
            "9.803444257412922 train: [0.7578068131268197, tensor(0.4297, device='cuda:0')]\n",
            "9.803573740774311 train: [0.7577786272689384, tensor(0.4297, device='cuda:0')]\n",
            "9.803703224135699 train: [0.7578824210586874, tensor(0.4297, device='cuda:0')]\n",
            "9.803832707497087 train: [0.7579861812853679, tensor(0.4296, device='cuda:0')]\n",
            "9.803962190858474 train: [0.7579583201211172, tensor(0.4296, device='cuda:0')]\n",
            "9.804091674219864 train: [0.757967427049272, tensor(0.4296, device='cuda:0')]\n",
            "9.804221157581251 train: [0.7579761911236388, tensor(0.4296, device='cuda:0')]\n",
            "9.804350640942639 train: [0.7579490247896392, tensor(0.4296, device='cuda:0')]\n",
            "9.804480124304026 train: [0.7580523991860321, tensor(0.4296, device='cuda:0')]\n",
            "9.804739091026804 train: [0.7581556916522744, tensor(0.4295, device='cuda:0')]\n",
            "9.804868574388191 train: [0.758129382981763, tensor(0.4295, device='cuda:0')]\n",
            "9.804998057749579 train: [0.7581031313269324, tensor(0.4295, device='cuda:0')]\n",
            "9.805127541110966 train: [0.758076645590646, tensor(0.4295, device='cuda:0')]\n",
            "9.805257024472356 train: [0.7581799159526914, tensor(0.4295, device='cuda:0')]\n",
            "9.805386507833743 train: [0.7582832014761385, tensor(0.4294, device='cuda:0')]\n",
            "9.805515991195131 train: [0.7583865506417498, tensor(0.4293, device='cuda:0')]\n",
            "9.805645474556519 train: [0.7584898664581626, tensor(0.4293, device='cuda:0')]\n",
            "9.805774957917908 train: [0.7584984337579262, tensor(0.4293, device='cuda:0')]\n",
            "9.805904441279296 train: [0.7586016497363524, tensor(0.4292, device='cuda:0')]\n",
            "9.806033924640683 train: [0.7587047355110218, tensor(0.4291, device='cuda:0')]\n",
            "9.806163408002071 train: [0.7588077395939276, tensor(0.4291, device='cuda:0')]\n",
            "9.80629289136346 train: [0.7589106135833777, tensor(0.4290, device='cuda:0')]\n",
            "9.806422374724848 train: [0.7589169266571195, tensor(0.4290, device='cuda:0')]\n",
            "9.806551858086236 train: [0.7588917126386909, tensor(0.4290, device='cuda:0')]\n",
            "9.806681341447623 train: [0.7588668940882273, tensor(0.4290, device='cuda:0')]\n",
            "9.806810824809013 train: [0.7589693533820376, tensor(0.4290, device='cuda:0')]\n",
            "9.8069403081704 train: [0.7589447239294211, tensor(0.4290, device='cuda:0')]\n",
            "9.807069791531788 train: [0.7590471376847504, tensor(0.4289, device='cuda:0')]\n",
            "9.807199274893176 train: [0.7590521646228168, tensor(0.4289, device='cuda:0')]\n",
            "9.807328758254565 train: [0.7590275821123813, tensor(0.4289, device='cuda:0')]\n",
            "9.807458241615953 train: [0.7591298846989697, tensor(0.4288, device='cuda:0')]\n",
            "9.80758772497734 train: [0.7591345573487353, tensor(0.4289, device='cuda:0')]\n",
            "9.807717208338728 train: [0.7592367614381916, tensor(0.4288, device='cuda:0')]\n",
            "9.807846691700117 train: [0.7593388359428183, tensor(0.4287, device='cuda:0')]\n",
            "9.807976175061505 train: [0.7593421192054004, tensor(0.4287, device='cuda:0')]\n",
            "9.808105658422893 train: [0.7593193504008859, tensor(0.4287, device='cuda:0')]\n",
            "9.80823514178428 train: [0.7592969271902912, tensor(0.4288, device='cuda:0')]\n",
            "9.80836462514567 train: [0.7592745111908914, tensor(0.4288, device='cuda:0')]\n",
            "9.808494108507057 train: [0.7592519091639871, tensor(0.4288, device='cuda:0')]\n",
            "9.808623591868445 train: [0.759129862562289, tensor(0.4289, device='cuda:0')]\n",
            "9.808753075229832 train: [0.759133224538239, tensor(0.4289, device='cuda:0')]\n",
            "9.808882558591222 train: [0.7592351361728822, tensor(0.4288, device='cuda:0')]\n",
            "9.80901204195261 train: [0.7592116377206101, tensor(0.4288, device='cuda:0')]\n",
            "9.809141525313997 train: [0.759187905468026, tensor(0.4288, device='cuda:0')]\n",
            "9.809271008675385 train: [0.759289904000593, tensor(0.4288, device='cuda:0')]\n",
            "9.809400492036774 train: [0.7591679688947635, tensor(0.4289, device='cuda:0')]\n",
            "9.809529975398162 train: [0.7590460729460007, tensor(0.4289, device='cuda:0')]\n",
            "9.80965945875955 train: [0.7591481898409425, tensor(0.4289, device='cuda:0')]\n",
            "9.809788942120937 train: [0.7591228951876775, tensor(0.4289, device='cuda:0')]\n",
            "9.809918425482326 train: [0.7592251116470995, tensor(0.4288, device='cuda:0')]\n",
            "9.810047908843714 train: [0.7593273435185642, tensor(0.4288, device='cuda:0')]\n",
            "9.810177392205102 train: [0.7594295907946538, tensor(0.4287, device='cuda:0')]\n",
            "9.81030687556649 train: [0.7593077701994028, tensor(0.4288, device='cuda:0')]\n",
            "9.810436358927877 train: [0.7593147110758127, tensor(0.4288, device='cuda:0')]\n",
            "9.810565842289266 train: [0.7592884985444318, tensor(0.4288, device='cuda:0')]\n",
            "9.810695325650654 train: [0.7592952475764976, tensor(0.4288, device='cuda:0')]\n",
            "9.810824809012042 train: [0.7591735266326732, tensor(0.4289, device='cuda:0')]\n",
            "9.81095429237343 train: [0.7591796658272406, tensor(0.4289, device='cuda:0')]\n",
            "9.811083775734819 train: [0.759281629453279, tensor(0.4288, device='cuda:0')]\n",
            "9.811213259096206 train: [0.7591599692018044, tensor(0.4289, device='cuda:0')]\n",
            "9.811342742457594 train: [0.7590383479315062, tensor(0.4290, device='cuda:0')]\n",
            "9.811472225818981 train: [0.7590420983039465, tensor(0.4290, device='cuda:0')]\n",
            "9.811601709180371 train: [0.7589205348673188, tensor(0.4291, device='cuda:0')]\n",
            "9.811731192541759 train: [0.7587990103621358, tensor(0.4292, device='cuda:0')]\n",
            "9.811860675903146 train: [0.7587773001644129, tensor(0.4292, device='cuda:0')]\n",
            "9.811990159264534 train: [0.758655837494305, tensor(0.4293, device='cuda:0')]\n",
            "9.812119642625923 train: [0.7586346861764995, tensor(0.4293, device='cuda:0')]\n",
            "9.81224912598731 train: [0.7586134935435823, tensor(0.4293, device='cuda:0')]\n",
            "9.812378609348698 train: [0.7585920192307692, tensor(0.4294, device='cuda:0')]\n",
            "9.812508092710086 train: [0.7584706639245413, tensor(0.4295, device='cuda:0')]\n",
            "9.812637576071475 train: [0.7584482100343275, tensor(0.4295, device='cuda:0')]\n",
            "9.812767059432863 train: [0.7585496942236957, tensor(0.4294, device='cuda:0')]\n",
            "9.81289654279425 train: [0.758651242051241, tensor(0.4293, device='cuda:0')]\n",
            "9.813026026155638 train: [0.7586271367521368, tensor(0.4293, device='cuda:0')]\n",
            "9.813155509517028 train: [0.7586323379555626, tensor(0.4293, device='cuda:0')]\n",
            "9.813284992878415 train: [0.7587341120253009, tensor(0.4293, device='cuda:0')]\n",
            "9.813414476239803 train: [0.7588359015844335, tensor(0.4292, device='cuda:0')]\n",
            "9.81354395960119 train: [0.7589376586177443, tensor(0.4291, device='cuda:0')]\n",
            "9.81367344296258 train: [0.7589123748156795, tensor(0.4292, device='cuda:0')]\n",
            "9.813802926323968 train: [0.759014135122185, tensor(0.4291, device='cuda:0')]\n",
            "9.813932409685355 train: [0.7589884153195097, tensor(0.4291, device='cuda:0')]\n",
            "9.814061893046743 train: [0.7590902749204731, tensor(0.4290, device='cuda:0')]\n",
            "9.814191376408132 train: [0.7590638796019992, tensor(0.4290, device='cuda:0')]\n",
            "9.81432085976952 train: [0.7590370130916569, tensor(0.4291, device='cuda:0')]\n",
            "9.814450343130908 train: [0.7590095317525596, tensor(0.4291, device='cuda:0')]\n",
            "9.814579826492295 train: [0.7588884196523916, tensor(0.4292, device='cuda:0')]\n",
            "9.814709309853685 train: [0.7588594846841098, tensor(0.4292, device='cuda:0')]\n",
            "9.814838793215072 train: [0.7589622259868462, tensor(0.4291, device='cuda:0')]\n",
            "9.81496827657646 train: [0.7589318028462765, tensor(0.4291, device='cuda:0')]\n",
            "9.815097759937847 train: [0.7590349310930657, tensor(0.4290, device='cuda:0')]\n",
            "9.815227243299237 train: [0.7589139114930828, tensor(0.4291, device='cuda:0')]\n",
            "9.815356726660625 train: [0.7588815945781064, tensor(0.4291, device='cuda:0')]\n",
            "9.815486210022012 train: [0.7589853041244697, tensor(0.4291, device='cuda:0')]\n",
            "9.8156156933834 train: [0.7588643502911431, tensor(0.4292, device='cuda:0')]\n",
            "9.815745176744787 train: [0.7589683646798548, tensor(0.4291, device='cuda:0')]\n",
            "9.815874660106177 train: [0.7589341448787392, tensor(0.4291, device='cuda:0')]\n",
            "9.816004143467564 train: [0.7590384021889627, tensor(0.4290, device='cuda:0')]\n",
            "9.816133626828952 train: [0.7590034164553395, tensor(0.4290, device='cuda:0')]\n",
            "9.81626311019034 train: [0.759022557110485, tensor(0.4291, device='cuda:0')]\n",
            "9.816392593551729 train: [0.7591271332651587, tensor(0.4290, device='cuda:0')]\n",
            "9.816522076913117 train: [0.759091480466167, tensor(0.4290, device='cuda:0')]\n",
            "9.816651560274504 train: [0.7589706637415982, tensor(0.4291, device='cuda:0')]\n",
            "9.816781043635892 train: [0.7588498854692014, tensor(0.4292, device='cuda:0')]\n",
            "9.816910526997281 train: [0.7589546615874182, tensor(0.4291, device='cuda:0')]\n",
            "9.817040010358669 train: [0.7589748433637632, tensor(0.4291, device='cuda:0')]\n",
            "9.817169493720057 train: [0.7588541220589495, tensor(0.4292, device='cuda:0')]\n",
            "9.817298977081444 train: [0.7588184033384713, tensor(0.4292, device='cuda:0')]\n",
            "9.817428460442834 train: [0.7589229744853652, tensor(0.4292, device='cuda:0')]\n",
            "9.817557943804221 train: [0.7588023190045249, tensor(0.4293, device='cuda:0')]\n",
            "9.817687427165609 train: [0.758821649211939, tensor(0.4293, device='cuda:0')]\n",
            "9.817816910526997 train: [0.7587865314318548, tensor(0.4293, device='cuda:0')]\n",
            "9.817946393888386 train: [0.7587515680579154, tensor(0.4293, device='cuda:0')]\n",
            "9.818075877249774 train: [0.7587165680532131, tensor(0.4293, device='cuda:0')]\n",
            "9.818205360611161 train: [0.7586813882354738, tensor(0.4293, device='cuda:0')]\n",
            "9.818334843972549 train: [0.7587858171549702, tensor(0.4292, device='cuda:0')]\n",
            "9.818464327333938 train: [0.7588903083428006, tensor(0.4292, device='cuda:0')]\n",
            "9.818593810695326 train: [0.7589101756204656, tensor(0.4292, device='cuda:0')]\n",
            "9.818723294056714 train: [0.7587896945638501, tensor(0.4293, device='cuda:0')]\n",
            "9.818852777418101 train: [0.75889403998779, tensor(0.4292, device='cuda:0')]\n",
            "9.81898226077949 train: [0.7587735997338639, tensor(0.4293, device='cuda:0')]\n",
            "9.819111744140878 train: [0.7587384499426312, tensor(0.4293, device='cuda:0')]\n",
            "9.819241227502266 train: [0.75870335897741, tensor(0.4293, device='cuda:0')]\n",
            "9.819370710863653 train: [0.7586681361498194, tensor(0.4293, device='cuda:0')]\n",
            "9.819500194225043 train: [0.758632590892454, tensor(0.4293, device='cuda:0')]\n",
            "9.81962967758643 train: [0.7585122875954524, tensor(0.4294, device='cuda:0')]\n",
            "9.819759160947818 train: [0.7584760160413948, tensor(0.4294, device='cuda:0')]\n",
            "9.819888644309206 train: [0.7583557757091117, tensor(0.4295, device='cuda:0')]\n",
            "9.820018127670595 train: [0.7584607554683785, tensor(0.4295, device='cuda:0')]\n",
            "9.820147611031983 train: [0.7585658448128734, tensor(0.4294, device='cuda:0')]\n",
            "9.82027709439337 train: [0.758670996078276, tensor(0.4293, device='cuda:0')]\n",
            "9.820406577754758 train: [0.7587761616304719, tensor(0.4293, device='cuda:0')]\n",
            "9.820536061116147 train: [0.7587384548367837, tensor(0.4293, device='cuda:0')]\n",
            "9.820665544477535 train: [0.7587006648077532, tensor(0.4293, device='cuda:0')]\n",
            "9.820795027838923 train: [0.7588059184481394, tensor(0.4292, device='cuda:0')]\n",
            "9.82092451120031 train: [0.7587677015333463, tensor(0.4292, device='cuda:0')]\n",
            "9.8210539945617 train: [0.7587292113162285, tensor(0.4292, device='cuda:0')]\n",
            "9.821183477923087 train: [0.7588347909361531, tensor(0.4292, device='cuda:0')]\n",
            "9.821312961284475 train: [0.7587956841089754, tensor(0.4292, device='cuda:0')]\n",
            "9.821442444645863 train: [0.7589015526107595, tensor(0.4291, device='cuda:0')]\n",
            "9.82157192800725 train: [0.7590074826889611, tensor(0.4290, device='cuda:0')]\n",
            "9.82170141136864 train: [0.7591134743143602, tensor(0.4290, device='cuda:0')]\n",
            "9.821830894730027 train: [0.759073587802163, tensor(0.4290, device='cuda:0')]\n",
            "9.821960378091415 train: [0.7590335238468837, tensor(0.4290, device='cuda:0')]\n",
            "9.822089861452802 train: [0.7589135185466708, tensor(0.4291, device='cuda:0')]\n",
            "9.822219344814192 train: [0.7589403716195676, tensor(0.4291, device='cuda:0')]\n",
            "9.82234882817558 train: [0.7588998727978992, tensor(0.4291, device='cuda:0')]\n",
            "9.822478311536967 train: [0.7588592918074735, tensor(0.4291, device='cuda:0')]\n",
            "9.822607794898355 train: [0.7589657118635827, tensor(0.4291, device='cuda:0')]\n",
            "9.822737278259744 train: [0.758924801008628, tensor(0.4291, device='cuda:0')]\n",
            "9.822866761621132 train: [0.7590313669459193, tensor(0.4290, device='cuda:0')]\n",
            "9.82299624498252 train: [0.758990126463871, tensor(0.4290, device='cuda:0')]\n",
            "9.823125728343907 train: [0.758870279609858, tensor(0.4291, device='cuda:0')]\n",
            "9.823255211705296 train: [0.7589770883176264, tensor(0.4290, device='cuda:0')]\n",
            "9.823384695066684 train: [0.759083910737053, tensor(0.4290, device='cuda:0')]\n",
            "9.823514178428072 train: [0.759042166329764, tensor(0.4290, device='cuda:0')]\n",
            "9.82364366178946 train: [0.7590003402635317, tensor(0.4290, device='cuda:0')]\n",
            "9.823773145150849 train: [0.7591072980890599, tensor(0.4289, device='cuda:0')]\n",
            "9.823902628512236 train: [0.7592142695705462, tensor(0.4289, device='cuda:0')]\n",
            "9.824032111873624 train: [0.7590945196857559, tensor(0.4289, device='cuda:0')]\n",
            "9.824161595235012 train: [0.7591238869748765, tensor(0.4290, device='cuda:0')]\n",
            "9.824291078596401 train: [0.7592307104801931, tensor(0.4289, device='cuda:0')]\n",
            "9.824420561957789 train: [0.7593373108150717, tensor(0.4288, device='cuda:0')]\n",
            "9.824550045319176 train: [0.7592960053866767, tensor(0.4288, device='cuda:0')]\n",
            "9.824679528680564 train: [0.7592548550494029, tensor(0.4288, device='cuda:0')]\n",
            "9.824809012041953 train: [0.7592825166973745, tensor(0.4289, device='cuda:0')]\n",
            "9.824938495403341 train: [0.759241712847378, tensor(0.4289, device='cuda:0')]\n",
            "9.825067978764729 train: [0.7593477541381901, tensor(0.4288, device='cuda:0')]\n",
            "9.825197462126116 train: [0.7593072368301489, tensor(0.4288, device='cuda:0')]\n",
            "9.825326945487506 train: [0.7594130924439734, tensor(0.4287, device='cuda:0')]\n",
            "9.825456428848893 train: [0.7595188674103412, tensor(0.4287, device='cuda:0')]\n",
            "9.82558591221028 train: [0.7594786734341697, tensor(0.4287, device='cuda:0')]\n",
            "9.825715395571669 train: [0.7595842628860986, tensor(0.4286, device='cuda:0')]\n",
            "9.825844878933058 train: [0.7595442604295296, tensor(0.4286, device='cuda:0')]\n",
            "9.825974362294446 train: [0.7596497590479937, tensor(0.4286, device='cuda:0')]\n",
            "9.826103845655833 train: [0.7597551771947766, tensor(0.4285, device='cuda:0')]\n",
            "9.82623332901722 train: [0.7598605149078544, tensor(0.4284, device='cuda:0')]\n",
            "9.82636281237861 train: [0.7598209195108525, tensor(0.4284, device='cuda:0')]\n",
            "9.826492295739998 train: [0.7597813838200249, tensor(0.4284, device='cuda:0')]\n",
            "9.826621779101385 train: [0.7597417660709966, tensor(0.4285, device='cuda:0')]\n",
            "9.826751262462773 train: [0.7596223285979466, tensor(0.4285, device='cuda:0')]\n",
            "9.82688074582416 train: [0.7595823704598216, tensor(0.4286, device='cuda:0')]\n",
            "9.82701022918555 train: [0.7595421415424509, tensor(0.4286, device='cuda:0')]\n",
            "9.827139712546938 train: [0.7594227917401972, tensor(0.4287, device='cuda:0')]\n",
            "9.827269195908325 train: [0.7595286629856789, tensor(0.4286, device='cuda:0')]\n",
            "9.827398679269713 train: [0.7594875174454433, tensor(0.4286, device='cuda:0')]\n",
            "9.827528162631102 train: [0.7594461016690628, tensor(0.4286, device='cuda:0')]\n",
            "9.82765764599249 train: [0.7595524384240916, tensor(0.4285, device='cuda:0')]\n",
            "9.827787129353878 train: [0.7595816990651835, tensor(0.4286, device='cuda:0')]\n",
            "9.827916612715265 train: [0.7595395804401642, tensor(0.4286, device='cuda:0')]\n",
            "9.828046096076655 train: [0.7595690697330452, tensor(0.4286, device='cuda:0')]\n",
            "9.828175579438042 train: [0.7595269663099377, tensor(0.4286, device='cuda:0')]\n",
            "9.82830506279943 train: [0.7594077874355756, tensor(0.4287, device='cuda:0')]\n",
            "9.828434546160818 train: [0.7593656753849775, tensor(0.4287, device='cuda:0')]\n",
            "9.828564029522207 train: [0.7594721907993967, tensor(0.4286, device='cuda:0')]\n",
            "9.828693512883595 train: [0.7595018560436975, tensor(0.4286, device='cuda:0')]\n",
            "9.828822996244982 train: [0.7593827558624142, tensor(0.4287, device='cuda:0')]\n",
            "9.82895247960637 train: [0.759340862595581, tensor(0.4287, device='cuda:0')]\n",
            "9.82908196296776 train: [0.7594470795850568, tensor(0.4287, device='cuda:0')]\n",
            "9.829211446329147 train: [0.7594053306607186, tensor(0.4287, device='cuda:0')]\n",
            "9.829340929690535 train: [0.7595114571655034, tensor(0.4286, device='cuda:0')]\n",
            "9.829470413051922 train: [0.759392448789263, tensor(0.4287, device='cuda:0')]\n",
            "9.829599896413312 train: [0.7592734777021897, tensor(0.4288, device='cuda:0')]\n",
            "9.8297293797747 train: [0.7592320645363408, tensor(0.4288, device='cuda:0')]\n",
            "9.829858863136087 train: [0.7592605961237275, tensor(0.4288, device='cuda:0')]\n",
            "9.829988346497474 train: [0.759141701573755, tensor(0.4289, device='cuda:0')]\n",
            "9.830117829858864 train: [0.7591006107658586, tensor(0.4289, device='cuda:0')]\n",
            "9.830247313220251 train: [0.7590595798612784, tensor(0.4289, device='cuda:0')]\n",
            "9.830376796581639 train: [0.7591653454103808, tensor(0.4289, device='cuda:0')]\n",
            "9.830506279943027 train: [0.7591242231702179, tensor(0.4289, device='cuda:0')]\n",
            "9.830635763304416 train: [0.7592299925225378, tensor(0.4288, device='cuda:0')]\n",
            "9.830765246665804 train: [0.7593357287805671, tensor(0.4287, device='cuda:0')]\n",
            "9.830894730027191 train: [0.759216952661565, tensor(0.4288, device='cuda:0')]\n",
            "9.831024213388579 train: [0.7593226108912201, tensor(0.4288, device='cuda:0')]\n",
            "9.831153696749968 train: [0.7592816371714681, tensor(0.4288, device='cuda:0')]\n",
            "9.831283180111356 train: [0.7591629252206908, tensor(0.4289, device='cuda:0')]\n",
            "9.831412663472744 train: [0.7590442503847957, tensor(0.4290, device='cuda:0')]\n",
            "9.831542146834131 train: [0.7589256126463799, tensor(0.4290, device='cuda:0')]\n",
            "9.83167163019552 train: [0.758807011988051, tensor(0.4291, device='cuda:0')]\n",
            "9.831801113556908 train: [0.7589124474158654, tensor(0.4291, device='cuda:0')]\n",
            "9.831930596918296 train: [0.758939830990951, tensor(0.4291, device='cuda:0')]\n",
            "9.832060080279684 train: [0.7590449780567371, tensor(0.4290, device='cuda:0')]\n",
            "9.832189563641073 train: [0.7590051313086413, tensor(0.4290, device='cuda:0')]\n",
            "9.83231904700246 train: [0.7589655316088503, tensor(0.4290, device='cuda:0')]\n",
            "9.832448530363848 train: [0.7589259911877739, tensor(0.4290, device='cuda:0')]\n",
            "9.832578013725236 train: [0.758951850278585, tensor(0.4291, device='cuda:0')]\n",
            "9.832707497086624 train: [0.7590564913225919, tensor(0.4290, device='cuda:0')]\n",
            "9.832836980448013 train: [0.7591609590325795, tensor(0.4289, device='cuda:0')]\n",
            "9.8329664638094 train: [0.759265253489684, tensor(0.4289, device='cuda:0')]\n",
            "9.833095947170788 train: [0.7592267284441377, tensor(0.4289, device='cuda:0')]\n",
            "9.833225430532176 train: [0.7591083028118738, tensor(0.4290, device='cuda:0')]\n",
            "9.833354913893565 train: [0.7591319536086184, tensor(0.4290, device='cuda:0')]\n",
            "9.833484397254953 train: [0.7591549879151723, tensor(0.4290, device='cuda:0')]\n",
            "9.83361388061634 train: [0.7591178626682018, tensor(0.4290, device='cuda:0')]\n",
            "9.833743363977728 train: [0.7591393930991066, tensor(0.4290, device='cuda:0')]\n",
            "9.833872847339117 train: [0.7591600269908162, tensor(0.4290, device='cuda:0')]\n",
            "9.834002330700505 train: [0.7591795306337733, tensor(0.4290, device='cuda:0')]\n",
            "9.834131814061893 train: [0.759197623645636, tensor(0.4290, device='cuda:0')]\n",
            "9.83426129742328 train: [0.7591644996225149, tensor(0.4290, device='cuda:0')]\n",
            "9.83439078078467 train: [0.7591322751917086, tensor(0.4290, device='cuda:0')]\n",
            "9.834520264146057 train: [0.7592333374264733, tensor(0.4290, device='cuda:0')]\n",
            "9.834649747507445 train: [0.7592023288335769, tensor(0.4290, device='cuda:0')]\n",
            "9.834779230868833 train: [0.7591717041521455, tensor(0.4290, device='cuda:0')]\n",
            "9.834908714230222 train: [0.7591412293293179, tensor(0.4290, device='cuda:0')]\n",
            "9.83503819759161 train: [0.7591542109398384, tensor(0.4290, device='cuda:0')]\n",
            "9.835167680952997 train: [0.7591239353647442, tensor(0.4290, device='cuda:0')]\n",
            "9.835297164314385 train: [0.759136635109095, tensor(0.4290, device='cuda:0')]\n",
            "9.835426647675774 train: [0.759106652161816, tensor(0.4291, device='cuda:0')]\n",
            "9.835556131037162 train: [0.7592070785024588, tensor(0.4290, device='cuda:0')]\n",
            "9.83568561439855 train: [0.7593074268752243, tensor(0.4289, device='cuda:0')]\n",
            "9.835815097759937 train: [0.7594076973164838, tensor(0.4289, device='cuda:0')]\n",
            "9.835944581121327 train: [0.7592896301993638, tensor(0.4289, device='cuda:0')]\n",
            "9.836074064482714 train: [0.7593008910635067, tensor(0.4290, device='cuda:0')]\n",
            "9.836203547844102 train: [0.7592721715017575, tensor(0.4290, device='cuda:0')]\n",
            "9.83633303120549 train: [0.7592436943398482, tensor(0.4290, device='cuda:0')]\n",
            "9.836462514566879 train: [0.7592152260272744, tensor(0.4290, device='cuda:0')]\n",
            "9.836591997928267 train: [0.759186579838912, tensor(0.4290, device='cuda:0')]\n",
            "9.836721481289654 train: [0.759157569165651, tensor(0.4290, device='cuda:0')]\n",
            "9.836850964651042 train: [0.7590396692480915, tensor(0.4291, device='cuda:0')]\n",
            "9.836980448012431 train: [0.7590096639094601, tensor(0.4291, device='cuda:0')]\n",
            "9.837109931373819 train: [0.7590228669550835, tensor(0.4291, device='cuda:0')]\n",
            "9.837239414735206 train: [0.75899203394789, tensor(0.4291, device='cuda:0')]\n",
            "9.837368898096594 train: [0.7588742329182535, tensor(0.4292, device='cuda:0')]\n",
            "9.837498381457983 train: [0.7587564684500788, tensor(0.4293, device='cuda:0')]\n",
            "9.837627864819371 train: [0.7588573525243182, tensor(0.4292, device='cuda:0')]\n",
            "9.837757348180759 train: [0.7589582985274111, tensor(0.4292, device='cuda:0')]\n",
            "9.837886831542146 train: [0.7590592598226963, tensor(0.4291, device='cuda:0')]\n",
            "9.838016314903534 train: [0.758941539714163, tensor(0.4292, device='cuda:0')]\n",
            "9.838145798264923 train: [0.7590424722974343, tensor(0.4291, device='cuda:0')]\n",
            "9.838275281626311 train: [0.7591433269976148, tensor(0.4291, device='cuda:0')]\n",
            "9.838404764987699 train: [0.7590256486024827, tensor(0.4292, device='cuda:0')]\n",
            "9.838534248349086 train: [0.7590406429580572, tensor(0.4292, device='cuda:0')]\n",
            "9.838663731710476 train: [0.7590091612875347, tensor(0.4292, device='cuda:0')]\n",
            "9.838793215071863 train: [0.7591096792984673, tensor(0.4291, device='cuda:0')]\n",
            "9.838922698433251 train: [0.7589920790383126, tensor(0.4292, device='cuda:0')]\n",
            "9.839052181794639 train: [0.7589611780335526, tensor(0.4292, device='cuda:0')]\n",
            "9.839181665156028 train: [0.7590615171668196, tensor(0.4291, device='cuda:0')]\n",
            "9.839311148517416 train: [0.7590307080365438, tensor(0.4292, device='cuda:0')]\n",
            "9.839440631878803 train: [0.7589131928317077, tensor(0.4292, device='cuda:0')]\n",
            "9.83957011524019 train: [0.7587957140092879, tensor(0.4293, device='cuda:0')]\n",
            "9.83969959860158 train: [0.7586782715523913, tensor(0.4294, device='cuda:0')]\n",
            "9.839829081962968 train: [0.7586471688034188, tensor(0.4294, device='cuda:0')]\n",
            "9.839958565324356 train: [0.7585297856734786, tensor(0.4295, device='cuda:0')]\n",
            "9.840088048685743 train: [0.7586303617966965, tensor(0.4295, device='cuda:0')]\n",
            "9.840217532047133 train: [0.7585987231542626, tensor(0.4295, device='cuda:0')]\n",
            "9.84034701540852 train: [0.7585668154726498, tensor(0.4295, device='cuda:0')]\n",
            "9.840476498769908 train: [0.7586676179955038, tensor(0.4294, device='cuda:0')]\n",
            "9.840605982131295 train: [0.758634966224252, tensor(0.4294, device='cuda:0')]\n",
            "9.840735465492685 train: [0.7585176938535263, tensor(0.4295, device='cuda:0')]\n",
            "9.840864948854072 train: [0.7584004577339198, tensor(0.4296, device='cuda:0')]\n",
            "9.84099443221546 train: [0.7582832578486264, tensor(0.4297, device='cuda:0')]\n",
            "9.841123915576848 train: [0.7583846762978986, tensor(0.4296, device='cuda:0')]\n",
            "9.841253398938237 train: [0.758403202578165, tensor(0.4296, device='cuda:0')]\n",
            "9.841382882299625 train: [0.7582860565783845, tensor(0.4297, device='cuda:0')]\n",
            "9.841512365661012 train: [0.7582521068458569, tensor(0.4297, device='cuda:0')]\n",
            "9.8416418490224 train: [0.7582704594182069, tensor(0.4297, device='cuda:0')]\n",
            "9.84177133238379 train: [0.7583717551602712, tensor(0.4297, device='cuda:0')]\n",
            "9.841900815745177 train: [0.7583894805940817, tensor(0.4297, device='cuda:0')]\n",
            "9.842030299106565 train: [0.7583563706560842, tensor(0.4297, device='cuda:0')]\n",
            "9.842159782467952 train: [0.7583730728424739, tensor(0.4297, device='cuda:0')]\n",
            "9.842289265829342 train: [0.7583407174670338, tensor(0.4297, device='cuda:0')]\n",
            "9.84241874919073 train: [0.7584412752474308, tensor(0.4297, device='cuda:0')]\n",
            "9.842548232552117 train: [0.7585416629587441, tensor(0.4296, device='cuda:0')]\n",
            "9.842677715913505 train: [0.7586419270215442, tensor(0.4295, device='cuda:0')]\n",
            "9.842807199274894 train: [0.7587420211582943, tensor(0.4295, device='cuda:0')]\n",
            "9.842936682636282 train: [0.7587555444863493, tensor(0.4295, device='cuda:0')]\n",
            "9.84306616599767 train: [0.758725615061484, tensor(0.4295, device='cuda:0')]\n",
            "9.843195649359057 train: [0.758825140570165, tensor(0.4294, device='cuda:0')]\n",
            "9.843325132720446 train: [0.7587960431558732, tensor(0.4294, device='cuda:0')]\n",
            "9.843454616081834 train: [0.7588953419461894, tensor(0.4294, device='cuda:0')]\n",
            "9.843584099443222 train: [0.7589945175568539, tensor(0.4293, device='cuda:0')]\n",
            "9.84371358280461 train: [0.7588776052775013, tensor(0.4294, device='cuda:0')]\n",
            "9.843843066165997 train: [0.7588495820943264, tensor(0.4294, device='cuda:0')]\n",
            "9.843972549527386 train: [0.758821613812158, tensor(0.4294, device='cuda:0')]\n",
            "9.844102032888774 train: [0.7588319602356842, tensor(0.4294, device='cuda:0')]\n",
            "9.844231516250161 train: [0.75893093049865, tensor(0.4293, device='cuda:0')]\n",
            "9.844360999611549 train: [0.7589031013574312, tensor(0.4294, device='cuda:0')]\n",
            "9.844490482972938 train: [0.7588752345396217, tensor(0.4294, device='cuda:0')]\n",
            "9.844619966334326 train: [0.758885473874679, tensor(0.4294, device='cuda:0')]\n",
            "9.844749449695714 train: [0.758895663831361, tensor(0.4294, device='cuda:0')]\n",
            "9.844878933057101 train: [0.7589944557346207, tensor(0.4293, device='cuda:0')]\n",
            "9.84500841641849 train: [0.7589671003596526, tensor(0.4293, device='cuda:0')]\n",
            "9.845137899779878 train: [0.7589398920172938, tensor(0.4293, device='cuda:0')]\n",
            "9.845267383141266 train: [0.7589125996428233, tensor(0.4294, device='cuda:0')]\n",
            "9.845396866502654 train: [0.7588850385058831, tensor(0.4294, device='cuda:0')]\n",
            "9.845526349864043 train: [0.7588952191320438, tensor(0.4294, device='cuda:0')]\n",
            "9.84565583322543 train: [0.7589055351633153, tensor(0.4294, device='cuda:0')]\n",
            "9.845785316586818 train: [0.7590043116312467, tensor(0.4293, device='cuda:0')]\n",
            "9.845914799948206 train: [0.7591029654206601, tensor(0.4293, device='cuda:0')]\n",
            "9.846044283309595 train: [0.7591125062773248, tensor(0.4293, device='cuda:0')]\n",
            "9.846173766670983 train: [0.758995917042756, tensor(0.4294, device='cuda:0')]\n",
            "9.84630325003237 train: [0.7589692955903894, tensor(0.4294, device='cuda:0')]\n",
            "9.846432733393758 train: [0.7588527641462637, tensor(0.4294, device='cuda:0')]\n",
            "9.846562216755148 train: [0.7588265879998111, tensor(0.4295, device='cuda:0')]\n",
            "9.846691700116535 train: [0.7588003737676368, tensor(0.4295, device='cuda:0')]\n",
            "9.846821183477923 train: [0.7587739370100817, tensor(0.4295, device='cuda:0')]\n",
            "9.84695066683931 train: [0.7587470934006917, tensor(0.4295, device='cuda:0')]\n",
            "9.8470801502007 train: [0.7587197048262799, tensor(0.4295, device='cuda:0')]\n",
            "9.847209633562088 train: [0.7586033189227938, tensor(0.4296, device='cuda:0')]\n",
            "9.847339116923475 train: [0.758574670392874, tensor(0.4296, device='cuda:0')]\n",
            "9.847468600284863 train: [0.7585452933864556, tensor(0.4296, device='cuda:0')]\n",
            "9.847598083646252 train: [0.7585151421667492, tensor(0.4296, device='cuda:0')]\n",
            "9.84772756700764 train: [0.7586147187024611, tensor(0.4296, device='cuda:0')]\n",
            "9.847857050369027 train: [0.7586300250848936, tensor(0.4296, device='cuda:0')]\n",
            "9.847986533730415 train: [0.7585978945623342, tensor(0.4296, device='cuda:0')]\n",
            "9.848116017091805 train: [0.7585652674067045, tensor(0.4296, device='cuda:0')]\n",
            "9.848245500453192 train: [0.7584490478161718, tensor(0.4297, device='cuda:0')]\n",
            "9.84837498381458 train: [0.7584153487491752, tensor(0.4297, device='cuda:0')]\n",
            "9.848504467175967 train: [0.7583810156903519, tensor(0.4297, device='cuda:0')]\n",
            "9.848633950537357 train: [0.7583460489309695, tensor(0.4297, device='cuda:0')]\n",
            "9.848763433898744 train: [0.7583103567453446, tensor(0.4297, device='cuda:0')]\n",
            "9.848892917260132 train: [0.7582738934653069, tensor(0.4297, device='cuda:0')]\n",
            "9.84902240062152 train: [0.7581578252128248, tensor(0.4298, device='cuda:0')]\n",
            "9.849151883982909 train: [0.7580417924878152, tensor(0.4299, device='cuda:0')]\n",
            "9.849281367344297 train: [0.7581445232034607, tensor(0.4298, device='cuda:0')]\n",
            "9.849410850705684 train: [0.758105487139276, tensor(0.4299, device='cuda:0')]\n",
            "9.849540334067072 train: [0.7582087282745555, tensor(0.4298, device='cuda:0')]\n",
            "9.84966981742846 train: [0.7583121216644705, tensor(0.4297, device='cuda:0')]\n",
            "9.849799300789849 train: [0.7581961540667239, tensor(0.4298, device='cuda:0')]\n",
            "9.849928784151237 train: [0.758155755631028, tensor(0.4298, device='cuda:0')]\n",
            "9.850058267512624 train: [0.758115047981372, tensor(0.4298, device='cuda:0')]\n",
            "9.850187750874012 train: [0.7580739853285281, tensor(0.4298, device='cuda:0')]\n",
            "9.850317234235401 train: [0.7579581250220435, tensor(0.4299, device='cuda:0')]\n",
            "9.850446717596789 train: [0.7579886375658266, tensor(0.4299, device='cuda:0')]\n",
            "9.850576200958177 train: [0.757946648939296, tensor(0.4299, device='cuda:0')]\n",
            "9.850705684319564 train: [0.7579044436267597, tensor(0.4300, device='cuda:0')]\n",
            "9.850835167680954 train: [0.7580093018235011, tensor(0.4299, device='cuda:0')]\n",
            "9.850964651042341 train: [0.7580411645804943, tensor(0.4299, device='cuda:0')]\n",
            "9.851094134403729 train: [0.7581461075237558, tensor(0.4298, device='cuda:0')]\n",
            "9.851223617765116 train: [0.7582509266735173, tensor(0.4298, device='cuda:0')]\n",
            "9.851353101126506 train: [0.7582084777867149, tensor(0.4298, device='cuda:0')]\n",
            "9.851482584487893 train: [0.7583131636992815, tensor(0.4297, device='cuda:0')]\n",
            "9.851612067849281 train: [0.7583442679659346, tensor(0.4297, device='cuda:0')]\n",
            "9.851741551210669 train: [0.7584486261326026, tensor(0.4297, device='cuda:0')]\n",
            "9.851871034572058 train: [0.7584786917649475, tensor(0.4297, device='cuda:0')]\n",
            "9.852000517933446 train: [0.75843752383313, tensor(0.4297, device='cuda:0')]\n",
            "9.852130001294833 train: [0.7585411326415692, tensor(0.4296, device='cuda:0')]\n",
            "9.852259484656221 train: [0.7586444807575011, tensor(0.4296, device='cuda:0')]\n",
            "9.85238896801761 train: [0.7586044516782577, tensor(0.4296, device='cuda:0')]\n",
            "9.852518451378998 train: [0.7586314475111398, tensor(0.4296, device='cuda:0')]\n",
            "9.852647934740386 train: [0.7585921653887189, tensor(0.4296, device='cuda:0')]\n",
            "9.852777418101773 train: [0.7586946642821139, tensor(0.4295, device='cuda:0')]\n",
            "9.852906901463163 train: [0.7586560254749821, tensor(0.4295, device='cuda:0')]\n",
            "9.85303638482455 train: [0.7587582087464257, tensor(0.4295, device='cuda:0')]\n",
            "9.853165868185938 train: [0.7587200297322632, tensor(0.4295, device='cuda:0')]\n",
            "9.853295351547326 train: [0.7588219890783523, tensor(0.4294, device='cuda:0')]\n",
            "9.853424834908715 train: [0.7589238258600696, tensor(0.4293, device='cuda:0')]\n",
            "9.853554318270103 train: [0.7588861423100347, tensor(0.4294, device='cuda:0')]\n",
            "9.85368380163149 train: [0.7588485617176247, tensor(0.4294, device='cuda:0')]\n",
            "9.853813284992878 train: [0.7588109468299965, tensor(0.4294, device='cuda:0')]\n",
            "9.853942768354267 train: [0.758773206206174, tensor(0.4294, device='cuda:0')]\n",
            "9.854072251715655 train: [0.7587352027394775, tensor(0.4294, device='cuda:0')]\n",
            "9.854201735077043 train: [0.7586197706380414, tensor(0.4295, device='cuda:0')]\n",
            "9.85433121843843 train: [0.7587219411112541, tensor(0.4294, device='cuda:0')]\n",
            "9.85446070179982 train: [0.7587476235741445, tensor(0.4294, device='cuda:0')]\n",
            "9.854590185161207 train: [0.7588498349183511, tensor(0.4294, device='cuda:0')]\n",
            "9.854719668522595 train: [0.7589519694945088, tensor(0.4293, device='cuda:0')]\n",
            "9.854849151883982 train: [0.7590539816579741, tensor(0.4292, device='cuda:0')]\n",
            "9.85497863524537 train: [0.7590156562401347, tensor(0.4292, device='cuda:0')]\n",
            "9.85510811860676 train: [0.759117445054945, tensor(0.4292, device='cuda:0')]\n",
            "9.855237601968147 train: [0.7590793499351279, tensor(0.4292, device='cuda:0')]\n",
            "9.855367085329535 train: [0.7591810068397494, tensor(0.4291, device='cuda:0')]\n",
            "9.855496568690922 train: [0.7592052190081678, tensor(0.4291, device='cuda:0')]\n",
            "9.855626052052312 train: [0.7591675842952612, tensor(0.4291, device='cuda:0')]\n",
            "9.8557555354137 train: [0.7591300979060802, tensor(0.4292, device='cuda:0')]\n",
            "9.855885018775087 train: [0.7590926229005583, tensor(0.4292, device='cuda:0')]\n",
            "9.856014502136475 train: [0.7591939725391506, tensor(0.4291, device='cuda:0')]\n",
            "9.856143985497864 train: [0.7592177082603568, tensor(0.4291, device='cuda:0')]\n",
            "9.856273468859252 train: [0.7591802826243039, tensor(0.4291, device='cuda:0')]\n",
            "9.85640295222064 train: [0.7591429139430372, tensor(0.4291, device='cuda:0')]\n",
            "9.856532435582027 train: [0.759244148853915, tensor(0.4291, device='cuda:0')]\n",
            "9.856661918943416 train: [0.7592676346474748, tensor(0.4291, device='cuda:0')]\n",
            "9.856791402304804 train: [0.759290794286481, tensor(0.4291, device='cuda:0')]\n",
            "9.856920885666192 train: [0.7592539327710506, tensor(0.4291, device='cuda:0')]\n",
            "9.85705036902758 train: [0.7592761306642561, tensor(0.4291, device='cuda:0')]\n",
            "9.857179852388969 train: [0.7593766308689416, tensor(0.4290, device='cuda:0')]\n",
            "9.857309335750356 train: [0.7594769184127984, tensor(0.4290, device='cuda:0')]\n",
            "9.857438819111744 train: [0.7594416905181057, tensor(0.4290, device='cuda:0')]\n",
            "9.857568302473132 train: [0.7595415735338688, tensor(0.4289, device='cuda:0')]\n",
            "9.857697785834521 train: [0.7596412441724941, tensor(0.4289, device='cuda:0')]\n",
            "9.857827269195909 train: [0.7595261644506077, tensor(0.4290, device='cuda:0')]\n",
            "9.857956752557296 train: [0.7594111195908, tensor(0.4290, device='cuda:0')]\n",
            "9.858086235918684 train: [0.7593777486049464, tensor(0.4290, device='cuda:0')]\n",
            "9.858215719280073 train: [0.7592627610597307, tensor(0.4291, device='cuda:0')]\n",
            "9.85834520264146 train: [0.7593618525446922, tensor(0.4291, device='cuda:0')]\n",
            "9.858474686002848 train: [0.7593290500040756, tensor(0.4291, device='cuda:0')]\n",
            "9.858604169364236 train: [0.7592962573930913, tensor(0.4291, device='cuda:0')]\n",
            "9.858733652725626 train: [0.7593132213721131, tensor(0.4291, device='cuda:0')]\n",
            "9.858863136087013 train: [0.7593299983559715, tensor(0.4291, device='cuda:0')]\n",
            "9.8589926194484 train: [0.7594287319620622, tensor(0.4290, device='cuda:0')]\n",
            "9.859122102809788 train: [0.7595272993437511, tensor(0.4290, device='cuda:0')]\n",
            "9.859251586171178 train: [0.7594956831111266, tensor(0.4290, device='cuda:0')]\n",
            "9.859381069532565 train: [0.759510513964336, tensor(0.4290, device='cuda:0')]\n",
            "9.859510552893953 train: [0.7594795912952711, tensor(0.4290, device='cuda:0')]\n",
            "9.85964003625534 train: [0.7594489050962265, tensor(0.4290, device='cuda:0')]\n",
            "9.85976951961673 train: [0.7594182735908288, tensor(0.4290, device='cuda:0')]\n",
            "9.859899002978118 train: [0.7593875151125888, tensor(0.4290, device='cuda:0')]\n",
            "9.860028486339505 train: [0.7593564935083804, tensor(0.4291, device='cuda:0')]\n",
            "9.860157969700893 train: [0.75924176975955, tensor(0.4291, device='cuda:0')]\n",
            "9.860287453062282 train: [0.7592572587438996, tensor(0.4292, device='cuda:0')]\n",
            "9.86041693642367 train: [0.7593556577701486, tensor(0.4291, device='cuda:0')]\n",
            "9.860546419785058 train: [0.7593712610064354, tensor(0.4291, device='cuda:0')]\n",
            "9.860675903146445 train: [0.7593396301060408, tensor(0.4291, device='cuda:0')]\n",
            "9.860805386507833 train: [0.7593548227889261, tensor(0.4291, device='cuda:0')]\n",
            "9.860934869869222 train: [0.7594529662554427, tensor(0.4291, device='cuda:0')]\n",
            "9.86106435323061 train: [0.7595509440519863, tensor(0.4290, device='cuda:0')]\n",
            "9.861323319953385 train: [0.7595203479936391, tensor(0.4290, device='cuda:0')]\n",
            "9.861452803314775 train: [0.7594898971728332, tensor(0.4290, device='cuda:0')]\n",
            "9.861582286676162 train: [0.7595876437448507, tensor(0.4289, device='cuda:0')]\n",
            "9.86171177003755 train: [0.7596853608307228, tensor(0.4289, device='cuda:0')]\n",
            "9.861841253398937 train: [0.7596550801596232, tensor(0.4289, device='cuda:0')]\n",
            "9.861970736760327 train: [0.7597527576087965, tensor(0.4288, device='cuda:0')]\n",
            "9.862100220121715 train: [0.7596382162613506, tensor(0.4289, device='cuda:0')]\n",
            "9.862229703483102 train: [0.7596516651544492, tensor(0.4289, device='cuda:0')]\n",
            "9.86235918684449 train: [0.7597492083792244, tensor(0.4289, device='cuda:0')]\n",
            "9.86248867020588 train: [0.7596347193484259, tensor(0.4289, device='cuda:0')]\n",
            "9.862618153567267 train: [0.7596052433328311, tensor(0.4290, device='cuda:0')]\n",
            "9.862747636928654 train: [0.7595759119985167, tensor(0.4290, device='cuda:0')]\n",
            "9.862877120290042 train: [0.7595464084604957, tensor(0.4290, device='cuda:0')]\n",
            "9.863006603651431 train: [0.7594320189411492, tensor(0.4291, device='cuda:0')]\n",
            "9.863136087012819 train: [0.759402093492639, tensor(0.4291, device='cuda:0')]\n",
            "9.863265570374207 train: [0.7592877601452297, tensor(0.4292, device='cuda:0')]\n",
            "9.863395053735594 train: [0.759257141699186, tensor(0.4292, device='cuda:0')]\n",
            "9.863524537096984 train: [0.7591428645857454, tensor(0.4293, device='cuda:0')]\n",
            "9.863654020458371 train: [0.7590286218672223, tensor(0.4293, device='cuda:0')]\n",
            "9.863783503819759 train: [0.7591267303641288, tensor(0.4293, device='cuda:0')]\n",
            "9.863912987181147 train: [0.7592248997523463, tensor(0.4292, device='cuda:0')]\n",
            "9.864042470542536 train: [0.7591927770353143, tensor(0.4292, device='cuda:0')]\n",
            "9.864171953903924 train: [0.7590785955377906, tensor(0.4293, device='cuda:0')]\n",
            "9.864301437265311 train: [0.7591769989878543, tensor(0.4292, device='cuda:0')]\n",
            "9.864430920626699 train: [0.7592753728473451, tensor(0.4292, device='cuda:0')]\n",
            "9.864560403988088 train: [0.7591612304280957, tensor(0.4293, device='cuda:0')]\n",
            "9.864689887349476 train: [0.7590471223219137, tensor(0.4294, device='cuda:0')]\n",
            "9.864819370710864 train: [0.7590142424452614, tensor(0.4294, device='cuda:0')]\n",
            "9.864948854072251 train: [0.7590317611107901, tensor(0.4294, device='cuda:0')]\n",
            "9.86507833743364 train: [0.7591301731809357, tensor(0.4293, device='cuda:0')]\n",
            "9.865207820795028 train: [0.7592285556845888, tensor(0.4292, device='cuda:0')]\n",
            "9.865337304156416 train: [0.7593268183735009, tensor(0.4292, device='cuda:0')]\n",
            "9.865466787517803 train: [0.759343286847182, tensor(0.4292, device='cuda:0')]\n",
            "9.865596270879193 train: [0.759441232097482, tensor(0.4291, device='cuda:0')]\n",
            "9.86572575424058 train: [0.7594098613629278, tensor(0.4291, device='cuda:0')]\n",
            "9.865855237601968 train: [0.7595074063863936, tensor(0.4291, device='cuda:0')]\n",
            "9.865984720963356 train: [0.7594765762996571, tensor(0.4291, device='cuda:0')]\n",
            "9.866114204324743 train: [0.7595739918563579, tensor(0.4290, device='cuda:0')]\n",
            "9.866243687686133 train: [0.7596712880143113, tensor(0.4290, device='cuda:0')]\n",
            "9.86637317104752 train: [0.7596410782905214, tensor(0.4290, device='cuda:0')]\n",
            "9.866502654408908 train: [0.7596108776291954, tensor(0.4290, device='cuda:0')]\n",
            "9.866632137770296 train: [0.7596244873621429, tensor(0.4290, device='cuda:0')]\n",
            "9.866761621131685 train: [0.7595942982456141, tensor(0.4290, device='cuda:0')]\n",
            "9.866891104493073 train: [0.7596078162841656, tensor(0.4290, device='cuda:0')]\n",
            "9.86702058785446 train: [0.7594939491253762, tensor(0.4291, device='cuda:0')]\n",
            "9.867150071215848 train: [0.7593801160994281, tensor(0.4292, device='cuda:0')]\n",
            "9.867279554577237 train: [0.7594770544905417, tensor(0.4291, device='cuda:0')]\n",
            "9.867409037938625 train: [0.7595738737869113, tensor(0.4291, device='cuda:0')]\n",
            "9.867538521300013 train: [0.7595447997695188, tensor(0.4291, device='cuda:0')]\n",
            "9.8676680046614 train: [0.7596414898949163, tensor(0.4290, device='cuda:0')]\n",
            "9.86779748802279 train: [0.7596532766039562, tensor(0.4290, device='cuda:0')]\n",
            "9.867926971384177 train: [0.7596247437049324, tensor(0.4290, device='cuda:0')]\n",
            "9.868056454745565 train: [0.759635809569604, tensor(0.4290, device='cuda:0')]\n",
            "9.868185938106953 train: [0.7596463323353293, tensor(0.4290, device='cuda:0')]\n",
            "9.868315421468342 train: [0.7596189826488434, tensor(0.4291, device='cuda:0')]\n",
            "9.86844490482973 train: [0.7595920008979348, tensor(0.4291, device='cuda:0')]\n",
            "9.868574388191117 train: [0.7596010867125542, tensor(0.4291, device='cuda:0')]\n",
            "9.868703871552505 train: [0.759487442025733, tensor(0.4292, device='cuda:0')]\n",
            "9.868833354913894 train: [0.7594613011334216, tensor(0.4292, device='cuda:0')]\n",
            "9.868962838275282 train: [0.7594353478278377, tensor(0.4292, device='cuda:0')]\n",
            "9.86909232163667 train: [0.7595310864363691, tensor(0.4291, device='cuda:0')]\n",
            "9.869221804998057 train: [0.7595050406008466, tensor(0.4291, device='cuda:0')]\n",
            "9.869351288359447 train: [0.7593914952217763, tensor(0.4292, device='cuda:0')]\n",
            "9.869480771720834 train: [0.7594001523513856, tensor(0.4292, device='cuda:0')]\n",
            "9.869610255082222 train: [0.7593737784969476, tensor(0.4292, device='cuda:0')]\n",
            "9.86973973844361 train: [0.7593825254896777, tensor(0.4292, device='cuda:0')]\n",
            "9.869869221804999 train: [0.7593562519394546, tensor(0.4293, device='cuda:0')]\n",
            "9.869998705166386 train: [0.759329986239112, tensor(0.4293, device='cuda:0')]\n",
            "9.870128188527774 train: [0.7594257159476073, tensor(0.4292, device='cuda:0')]\n",
            "9.870257671889162 train: [0.7593989989718316, tensor(0.4292, device='cuda:0')]\n",
            "9.870387155250551 train: [0.7593720207670484, tensor(0.4292, device='cuda:0')]\n",
            "9.870516638611939 train: [0.7594679704906172, tensor(0.4292, device='cuda:0')]\n",
            "9.870646121973326 train: [0.7594401826621654, tensor(0.4292, device='cuda:0')]\n",
            "9.870775605334714 train: [0.7594119546498278, tensor(0.4292, device='cuda:0')]\n",
            "9.870905088696103 train: [0.7595083038696865, tensor(0.4291, device='cuda:0')]\n",
            "9.871034572057491 train: [0.759604714006152, tensor(0.4291, device='cuda:0')]\n",
            "9.871164055418879 train: [0.7597012746875681, tensor(0.4290, device='cuda:0')]\n",
            "9.871293538780266 train: [0.7596713213695613, tensor(0.4290, device='cuda:0')]\n",
            "9.871423022141656 train: [0.7597680225721333, tensor(0.4289, device='cuda:0')]\n",
            "9.871552505503043 train: [0.7598647845500012, tensor(0.4289, device='cuda:0')]\n",
            "9.871681988864431 train: [0.7598791733091719, tensor(0.4289, device='cuda:0')]\n",
            "9.871811472225819 train: [0.7598933786007522, tensor(0.4289, device='cuda:0')]\n",
            "9.871940955587206 train: [0.7598628815196579, tensor(0.4289, device='cuda:0')]\n",
            "9.872070438948596 train: [0.759832572652757, tensor(0.4289, device='cuda:0')]\n",
            "9.872199922309983 train: [0.7598021832697179, tensor(0.4289, device='cuda:0')]\n",
            "9.87232940567137 train: [0.7597716238711378, tensor(0.4289, device='cuda:0')]\n",
            "9.872458889032758 train: [0.7597407154888907, tensor(0.4289, device='cuda:0')]\n",
            "9.872588372394148 train: [0.7596275578011503, tensor(0.4290, device='cuda:0')]\n",
            "9.872717855755536 train: [0.7597246584855948, tensor(0.4290, device='cuda:0')]\n",
            "9.872847339116923 train: [0.7596926076361845, tensor(0.4290, device='cuda:0')]\n",
            "9.87297682247831 train: [0.7597899381305757, tensor(0.4289, device='cuda:0')]\n",
            "9.8731063058397 train: [0.759887329104358, tensor(0.4288, device='cuda:0')]\n",
            "9.873235789201088 train: [0.75985437393385, tensor(0.4289, device='cuda:0')]\n",
            "9.873365272562475 train: [0.7598211602850274, tensor(0.4289, device='cuda:0')]\n",
            "9.873494755923863 train: [0.7598394598445745, tensor(0.4289, device='cuda:0')]\n",
            "9.873624239285252 train: [0.759858022166022, tensor(0.4289, device='cuda:0')]\n",
            "9.87375372264664 train: [0.7599557775260587, tensor(0.4288, device='cuda:0')]\n",
            "9.873883206008028 train: [0.759973959525008, tensor(0.4288, device='cuda:0')]\n",
            "9.874012689369415 train: [0.760071400486131, tensor(0.4288, device='cuda:0')]\n",
            "9.874142172730805 train: [0.7601687231238135, tensor(0.4287, device='cuda:0')]\n",
            "9.874271656092192 train: [0.7602658381550811, tensor(0.4286, device='cuda:0')]\n",
            "9.87440113945358 train: [0.7603627456725053, tensor(0.4286, device='cuda:0')]\n",
            "9.874530622814968 train: [0.7603311977719858, tensor(0.4286, device='cuda:0')]\n",
            "9.874660106176357 train: [0.7602999271345297, tensor(0.4286, device='cuda:0')]\n",
            "9.874789589537745 train: [0.7602687550712547, tensor(0.4286, device='cuda:0')]\n",
            "9.874919072899132 train: [0.7603653367669911, tensor(0.4286, device='cuda:0')]\n",
            "9.87504855626052 train: [0.7602524056312765, tensor(0.4286, device='cuda:0')]\n",
            "9.87517803962191 train: [0.7603488718272372, tensor(0.4286, device='cuda:0')]\n",
            "9.875307522983297 train: [0.7604453093769631, tensor(0.4285, device='cuda:0')]\n",
            "9.875437006344685 train: [0.7605417182932122, tensor(0.4284, device='cuda:0')]\n",
            "9.875566489706072 train: [0.7605109841175598, tensor(0.4285, device='cuda:0')]\n",
            "9.875695973067462 train: [0.7604802590645477, tensor(0.4285, device='cuda:0')]\n",
            "9.87582545642885 train: [0.7605765306996016, tensor(0.4284, device='cuda:0')]\n",
            "9.875954939790237 train: [0.7604636855170053, tensor(0.4285, device='cuda:0')]\n",
            "9.876084423151624 train: [0.7604327137037418, tensor(0.4285, device='cuda:0')]\n",
            "9.876213906513014 train: [0.7605290386897291, tensor(0.4284, device='cuda:0')]\n",
            "9.876343389874402 train: [0.760625424229115, tensor(0.4284, device='cuda:0')]\n",
            "9.87647287323579 train: [0.7607217811844147, tensor(0.4283, device='cuda:0')]\n",
            "9.876602356597177 train: [0.7606089981182642, tensor(0.4284, device='cuda:0')]\n",
            "9.876731839958566 train: [0.7604962484891331, tensor(0.4285, device='cuda:0')]\n",
            "9.876861323319954 train: [0.7604651212504703, tensor(0.4285, device='cuda:0')]\n",
            "9.876990806681341 train: [0.7604339141797, tensor(0.4285, device='cuda:0')]\n",
            "9.877120290042729 train: [0.7605303171694952, tensor(0.4284, device='cuda:0')]\n",
            "9.877249773404117 train: [0.7606267806267806, tensor(0.4284, device='cuda:0')]\n",
            "9.877379256765506 train: [0.7605141118694666, tensor(0.4285, device='cuda:0')]\n",
            "9.877508740126894 train: [0.7604014764855997, tensor(0.4285, device='cuda:0')]\n",
            "9.877638223488281 train: [0.7604171116256023, tensor(0.4286, device='cuda:0')]\n",
            "9.877767706849669 train: [0.7604324751998816, tensor(0.4286, device='cuda:0')]\n",
            "9.877897190211058 train: [0.7605287038091442, tensor(0.4285, device='cuda:0')]\n",
            "9.878026673572446 train: [0.7604979690417635, tensor(0.4285, device='cuda:0')]\n",
            "9.878156156933834 train: [0.7605938926583259, tensor(0.4284, device='cuda:0')]\n",
            "9.878285640295221 train: [0.7606896989607759, tensor(0.4284, device='cuda:0')]\n",
            "9.87841512365661 train: [0.7607853880011836, tensor(0.4283, device='cuda:0')]\n",
            "9.878544607017998 train: [0.7606728457840237, tensor(0.4284, device='cuda:0')]\n",
            "9.878674090379386 train: [0.7607682423514955, tensor(0.4283, device='cuda:0')]\n",
            "9.878803573740774 train: [0.7607798031419926, tensor(0.4283, device='cuda:0')]\n",
            "9.878933057102163 train: [0.7607516400038672, tensor(0.4284, device='cuda:0')]\n",
            "9.87906254046355 train: [0.76076195597166, tensor(0.4284, device='cuda:0')]\n",
            "9.879192023824938 train: [0.7607346921371312, tensor(0.4284, device='cuda:0')]\n",
            "9.879321507186326 train: [0.7607438528900157, tensor(0.4284, device='cuda:0')]\n",
            "9.879450990547715 train: [0.7607174878653192, tensor(0.4284, device='cuda:0')]\n",
            "9.879580473909103 train: [0.7606913970153665, tensor(0.4284, device='cuda:0')]\n",
            "9.87970995727049 train: [0.7607857902826233, tensor(0.4283, device='cuda:0')]\n",
            "9.879839440631878 train: [0.7608800668958073, tensor(0.4283, device='cuda:0')]\n",
            "9.879968923993268 train: [0.7608544073708008, tensor(0.4283, device='cuda:0')]\n",
            "9.880098407354655 train: [0.7609486460084511, tensor(0.4282, device='cuda:0')]\n",
            "9.880227890716043 train: [0.7609561685822667, tensor(0.4282, device='cuda:0')]\n",
            "9.88035737407743 train: [0.7608438337478141, tensor(0.4283, device='cuda:0')]\n",
            "9.88048685743882 train: [0.7608187269372694, tensor(0.4283, device='cuda:0')]\n",
            "9.880616340800207 train: [0.7607064455430933, tensor(0.4284, device='cuda:0')]\n",
            "9.880745824161595 train: [0.7606814550913157, tensor(0.4284, device='cuda:0')]\n",
            "9.880875307522983 train: [0.7606562946864289, tensor(0.4284, device='cuda:0')]\n",
            "9.881004790884372 train: [0.760630787102704, tensor(0.4285, device='cuda:0')]\n",
            "9.88113427424576 train: [0.7607250361640572, tensor(0.4284, device='cuda:0')]\n",
            "9.881263757607147 train: [0.7608193460517509, tensor(0.4283, device='cuda:0')]\n",
            "9.881393240968535 train: [0.7607926737631286, tensor(0.4283, device='cuda:0')]\n",
            "9.881522724329924 train: [0.7608871230678507, tensor(0.4283, device='cuda:0')]\n",
            "9.881652207691312 train: [0.7608596513856132, tensor(0.4283, device='cuda:0')]\n",
            "9.8817816910527 train: [0.7607475128960943, tensor(0.4284, device='cuda:0')]\n",
            "9.881911174414087 train: [0.7607191842934549, tensor(0.4284, device='cuda:0')]\n",
            "9.882040657775477 train: [0.7608141200371752, tensor(0.4283, device='cuda:0')]\n",
            "9.882170141136864 train: [0.7607848161064775, tensor(0.4283, device='cuda:0')]\n",
            "9.882299624498252 train: [0.7606727547106745, tensor(0.4284, device='cuda:0')]\n",
            "9.88242910785964 train: [0.7606425066557154, tensor(0.4284, device='cuda:0')]\n",
            "9.882558591221029 train: [0.7606116480522864, tensor(0.4284, device='cuda:0')]\n",
            "9.882688074582417 train: [0.7604996616494518, tensor(0.4285, device='cuda:0')]\n",
            "9.882817557943804 train: [0.7604675946109684, tensor(0.4285, device='cuda:0')]\n",
            "9.882947041305192 train: [0.7603556623774371, tensor(0.4286, device='cuda:0')]\n",
            "9.88307652466658 train: [0.7603223877851362, tensor(0.4286, device='cuda:0')]\n",
            "9.883206008027969 train: [0.7602884155555304, tensor(0.4286, device='cuda:0')]\n",
            "9.883335491389357 train: [0.7603855738108442, tensor(0.4286, device='cuda:0')]\n",
            "9.883464974750744 train: [0.7604829686898862, tensor(0.4285, device='cuda:0')]\n",
            "9.883594458112132 train: [0.7604473084277099, tensor(0.4285, device='cuda:0')]\n",
            "9.883723941473521 train: [0.7604112167703619, tensor(0.4285, device='cuda:0')]\n",
            "9.883853424834909 train: [0.7605092718265414, tensor(0.4285, device='cuda:0')]\n",
            "9.883982908196296 train: [0.7603974651120711, tensor(0.4286, device='cuda:0')]\n",
            "9.884112391557684 train: [0.7603599832935696, tensor(0.4286, device='cuda:0')]\n",
            "9.884241874919073 train: [0.7602482313853841, tensor(0.4286, device='cuda:0')]\n",
            "9.884371358280461 train: [0.7602735721754366, tensor(0.4287, device='cuda:0')]\n",
            "9.884500841641849 train: [0.7602991704152444, tensor(0.4287, device='cuda:0')]\n",
            "9.884630325003236 train: [0.7603245845622719, tensor(0.4287, device='cuda:0')]\n",
            "9.884759808364626 train: [0.760286523066754, tensor(0.4287, device='cuda:0')]\n",
            "9.884889291726013 train: [0.7603850990487703, tensor(0.4286, device='cuda:0')]\n",
            "9.885018775087401 train: [0.7603473045860161, tensor(0.4286, device='cuda:0')]\n",
            "9.885148258448789 train: [0.7602356693922727, tensor(0.4287, device='cuda:0')]\n",
            "9.885277741810178 train: [0.760334032984778, tensor(0.4287, device='cuda:0')]\n",
            "9.885407225171566 train: [0.7604323677020176, tensor(0.4286, device='cuda:0')]\n",
            "9.885536708532953 train: [0.7603207691743243, tensor(0.4287, device='cuda:0')]\n",
            "9.885666191894341 train: [0.7602836291551442, tensor(0.4287, device='cuda:0')]\n",
            "9.88579567525573 train: [0.7603816634784669, tensor(0.4286, device='cuda:0')]\n",
            "9.885925158617118 train: [0.7604796690400695, tensor(0.4286, device='cuda:0')]\n",
            "9.886054641978506 train: [0.760442874630503, tensor(0.4286, device='cuda:0')]\n",
            "9.886184125339893 train: [0.7605406662097984, tensor(0.4285, device='cuda:0')]\n",
            "9.886313608701283 train: [0.7604291499830814, tensor(0.4286, device='cuda:0')]\n",
            "9.88644309206267 train: [0.7603176664542758, tensor(0.4287, device='cuda:0')]\n",
            "9.886572575424058 train: [0.7604152571995579, tensor(0.4286, device='cuda:0')]\n",
            "9.886702058785446 train: [0.7603791157453861, tensor(0.4286, device='cuda:0')]\n",
            "9.886831542146835 train: [0.7603429848836685, tensor(0.4286, device='cuda:0')]\n",
            "9.886961025508223 train: [0.7604405290222598, tensor(0.4286, device='cuda:0')]\n",
            "9.88709050886961 train: [0.7605380445806756, tensor(0.4285, device='cuda:0')]\n",
            "9.887219992230998 train: [0.7605019063165486, tensor(0.4285, device='cuda:0')]\n",
            "9.887349475592387 train: [0.7604656906234509, tensor(0.4285, device='cuda:0')]\n",
            "9.887478958953775 train: [0.760354332343963, tensor(0.4286, device='cuda:0')]\n",
            "9.887608442315162 train: [0.7602430066730488, tensor(0.4287, device='cuda:0')]\n",
            "9.88773792567655 train: [0.7601317135963875, tensor(0.4288, device='cuda:0')]\n",
            "9.88786740903794 train: [0.7602294526042604, tensor(0.4287, device='cuda:0')]\n",
            "9.887996892399327 train: [0.7601927755856759, tensor(0.4287, device='cuda:0')]\n",
            "9.888126375760715 train: [0.7601559334267576, tensor(0.4287, device='cuda:0')]\n",
            "9.888255859122102 train: [0.7600447182206966, tensor(0.4288, device='cuda:0')]\n",
            "9.88838534248349 train: [0.7600074689427015, tensor(0.4288, device='cuda:0')]\n",
            "9.88851482584488 train: [0.7598963079848337, tensor(0.4289, device='cuda:0')]\n",
            "9.888644309206267 train: [0.7597851795396765, tensor(0.4290, device='cuda:0')]\n",
            "9.888773792567655 train: [0.7598835721596725, tensor(0.4289, device='cuda:0')]\n",
            "9.888903275929042 train: [0.75990901231444, tensor(0.4289, device='cuda:0')]\n",
            "9.889032759290432 train: [0.7598710194753354, tensor(0.4290, device='cuda:0')]\n",
            "9.88916224265182 train: [0.7598330377420007, tensor(0.4290, device='cuda:0')]\n",
            "9.889291726013207 train: [0.7597948914668555, tensor(0.4290, device='cuda:0')]\n",
            "9.889421209374595 train: [0.7598207687530909, tensor(0.4290, device='cuda:0')]\n",
            "9.889550692735984 train: [0.7597823720289937, tensor(0.4290, device='cuda:0')]\n",
            "9.889680176097372 train: [0.7598809278017483, tensor(0.4289, device='cuda:0')]\n",
            "9.88980965945876 train: [0.759979542556538, tensor(0.4289, device='cuda:0')]\n",
            "9.889939142820147 train: [0.7599410517107746, tensor(0.4289, device='cuda:0')]\n",
            "9.890068626181536 train: [0.7599671519986073, tensor(0.4289, device='cuda:0')]\n",
            "9.890198109542924 train: [0.7599930692026952, tensor(0.4289, device='cuda:0')]\n",
            "9.890327592904312 train: [0.7600913468555967, tensor(0.4288, device='cuda:0')]\n",
            "9.8904570762657 train: [0.7599804170034578, tensor(0.4289, device='cuda:0')]\n",
            "9.890586559627089 train: [0.7599430941249762, tensor(0.4289, device='cuda:0')]\n",
            "9.890716042988476 train: [0.7599059574981482, tensor(0.4289, device='cuda:0')]\n",
            "9.890845526349864 train: [0.7600036645065364, tensor(0.4289, device='cuda:0')]\n",
            "9.890975009711251 train: [0.7601012553574634, tensor(0.4288, device='cuda:0')]\n",
            "9.89110449307264 train: [0.7600645501228391, tensor(0.4288, device='cuda:0')]\n",
            "9.891233976434028 train: [0.7601620160060121, tensor(0.4288, device='cuda:0')]\n",
            "9.891363459795416 train: [0.7602593658528379, tensor(0.4287, device='cuda:0')]\n",
            "9.891492943156804 train: [0.7602230040367796, tensor(0.4287, device='cuda:0')]\n",
            "9.891622426518193 train: [0.7601122005090085, tensor(0.4288, device='cuda:0')]\n",
            "9.89175190987958 train: [0.7600759583155842, tensor(0.4288, device='cuda:0')]\n",
            "9.891881393240968 train: [0.7601731763974041, tensor(0.4287, device='cuda:0')]\n",
            "9.892010876602356 train: [0.7601368483279541, tensor(0.4288, device='cuda:0')]\n",
            "9.892140359963745 train: [0.7601004433021458, tensor(0.4288, device='cuda:0')]\n",
            "9.892269843325133 train: [0.7600637862992673, tensor(0.4288, device='cuda:0')]\n",
            "9.89239932668652 train: [0.7601612120677488, tensor(0.4287, device='cuda:0')]\n",
            "9.892528810047908 train: [0.7601240318814121, tensor(0.4287, device='cuda:0')]\n",
            "9.892658293409298 train: [0.7600866000537532, tensor(0.4287, device='cuda:0')]\n",
            "9.892787776770685 train: [0.7601845048146904, tensor(0.4287, device='cuda:0')]\n",
            "9.892917260132073 train: [0.7602825560046125, tensor(0.4286, device='cuda:0')]\n",
            "9.89304674349346 train: [0.7602442429423748, tensor(0.4286, device='cuda:0')]\n",
            "9.89317622685485 train: [0.7603424317843512, tensor(0.4286, device='cuda:0')]\n",
            "9.893305710216238 train: [0.7603037714576666, tensor(0.4286, device='cuda:0')]\n",
            "9.893435193577625 train: [0.7602648601398602, tensor(0.4286, device='cuda:0')]\n",
            "9.893564676939013 train: [0.7603634401429722, tensor(0.4285, device='cuda:0')]\n",
            "9.893694160300402 train: [0.7602528739891052, tensor(0.4286, device='cuda:0')]\n",
            "9.89382364366179 train: [0.760213288047733, tensor(0.4286, device='cuda:0')]\n",
            "9.893953127023178 train: [0.7601734515302985, tensor(0.4286, device='cuda:0')]\n",
            "9.894082610384565 train: [0.7601332771970036, tensor(0.4286, device='cuda:0')]\n",
            "9.894212093745953 train: [0.7600927651951304, tensor(0.4286, device='cuda:0')]\n",
            "9.894341577107342 train: [0.7599823187020768, tensor(0.4287, device='cuda:0')]\n",
            "9.89447106046873 train: [0.759940967294002, tensor(0.4287, device='cuda:0')]\n",
            "9.894600543830117 train: [0.7600410511554105, tensor(0.4287, device='cuda:0')]\n",
            "9.894730027191505 train: [0.7599306602983074, tensor(0.4288, device='cuda:0')]\n",
            "9.894859510552894 train: [0.7598883744051476, tensor(0.4288, device='cuda:0')]\n",
            "9.894988993914282 train: [0.7597780377746256, tensor(0.4289, device='cuda:0')]\n",
            "9.89511847727567 train: [0.7598113427476995, tensor(0.4289, device='cuda:0')]\n",
            "9.895247960637057 train: [0.7597010493317106, tensor(0.4289, device='cuda:0')]\n",
            "9.895377443998447 train: [0.7596581235346657, tensor(0.4290, device='cuda:0')]\n",
            "9.895506927359834 train: [0.7597591060803948, tensor(0.4289, device='cuda:0')]\n",
            "9.895636410721222 train: [0.7598600593218447, tensor(0.4288, device='cuda:0')]\n",
            "9.89576589408261 train: [0.7598937641587341, tensor(0.4288, device='cuda:0')]\n",
            "9.895895377443999 train: [0.7599271105308965, tensor(0.4289, device='cuda:0')]\n",
            "9.896024860805387 train: [0.7598168963016678, tensor(0.4289, device='cuda:0')]\n",
            "9.896154344166774 train: [0.7599171725805373, tensor(0.4289, device='cuda:0')]\n",
            "9.896283827528162 train: [0.7598753917533821, tensor(0.4289, device='cuda:0')]\n",
            "9.896413310889551 train: [0.7599065434239579, tensor(0.4289, device='cuda:0')]\n",
            "9.896542794250939 train: [0.7598654731176202, tensor(0.4289, device='cuda:0')]\n",
            "9.896672277612327 train: [0.7597553476867336, tensor(0.4290, device='cuda:0')]\n",
            "9.896801760973714 train: [0.7597850227949127, tensor(0.4290, device='cuda:0')]\n",
            "9.896931244335104 train: [0.7598839975313733, tensor(0.4289, device='cuda:0')]\n",
            "9.897060727696491 train: [0.759982595359877, tensor(0.4289, device='cuda:0')]\n",
            "9.897190211057879 train: [0.7600809034896159, tensor(0.4288, device='cuda:0')]\n",
            "9.897319694419267 train: [0.7601074681111792, tensor(0.4288, device='cuda:0')]\n",
            "9.897449177780656 train: [0.7602050335271447, tensor(0.4288, device='cuda:0')]\n",
            "9.897578661142044 train: [0.7600949705427047, tensor(0.4288, device='cuda:0')]\n",
            "9.897708144503431 train: [0.760118389771057, tensor(0.4289, device='cuda:0')]\n",
            "9.897837627864819 train: [0.7600825671921797, tensor(0.4289, device='cuda:0')]\n",
            "9.897967111226208 train: [0.7600473637704553, tensor(0.4289, device='cuda:0')]\n",
            "9.898096594587596 train: [0.7601432151085783, tensor(0.4288, device='cuda:0')]\n",
            "9.898226077948983 train: [0.760108882545406, tensor(0.4288, device='cuda:0')]\n",
            "9.898355561310371 train: [0.7600749076433475, tensor(0.4288, device='cuda:0')]\n",
            "9.89848504467176 train: [0.7599649749115507, tensor(0.4289, device='cuda:0')]\n",
            "9.898614528033148 train: [0.7599843046053729, tensor(0.4289, device='cuda:0')]\n",
            "9.898744011394536 train: [0.7600795743982738, tensor(0.4289, device='cuda:0')]\n",
            "9.898873494755923 train: [0.7601746428809733, tensor(0.4288, device='cuda:0')]\n",
            "9.8991324614787 train: [0.7601419860675607, tensor(0.4288, device='cuda:0')]\n",
            "9.899261944840088 train: [0.7601593681556917, tensor(0.4288, device='cuda:0')]\n",
            "9.899391428201476 train: [0.7601273308970654, tensor(0.4288, device='cuda:0')]\n",
            "9.899650394924253 train: [0.7600955633912396, tensor(0.4288, device='cuda:0')]\n",
            "9.89977987828564 train: [0.7599857547285134, tensor(0.4289, device='cuda:0')]\n",
            "9.899909361647028 train: [0.7599541036567073, tensor(0.4289, device='cuda:0')]\n",
            "9.900038845008416 train: [0.7599223749333422, tensor(0.4289, device='cuda:0')]\n",
            "9.900168328369805 train: [0.7599391662038323, tensor(0.4290, device='cuda:0')]\n",
            "9.900297811731193 train: [0.7599071884926364, tensor(0.4290, device='cuda:0')]\n",
            "9.90042729509258 train: [0.7598751332578205, tensor(0.4290, device='cuda:0')]\n",
            "9.900556778453968 train: [0.759969820072393, tensor(0.4289, device='cuda:0')]\n",
            "9.900686261815357 train: [0.7600645662877316, tensor(0.4288, device='cuda:0')]\n",
            "9.900815745176745 train: [0.7599548888611388, tensor(0.4289, device='cuda:0')]\n",
            "9.900945228538133 train: [0.7600496098909026, tensor(0.4289, device='cuda:0')]\n",
            "9.90107471189952 train: [0.7600169503750721, tensor(0.4289, device='cuda:0')]\n",
            "9.90120419526091 train: [0.7599842135993964, tensor(0.4289, device='cuda:0')]\n",
            "9.901333678622297 train: [0.7600024475272348, tensor(0.4289, device='cuda:0')]\n",
            "9.901463161983685 train: [0.7599694623149021, tensor(0.4289, device='cuda:0')]\n",
            "9.901592645345072 train: [0.7599879530432082, tensor(0.4289, device='cuda:0')]\n",
            "9.901722128706462 train: [0.75987839733425, tensor(0.4290, device='cuda:0')]\n",
            "9.90185161206785 train: [0.7599732070592279, tensor(0.4289, device='cuda:0')]\n",
            "9.901981095429237 train: [0.76006790285122, tensor(0.4289, device='cuda:0')]\n",
            "9.902110578790625 train: [0.7600353649412547, tensor(0.4289, device='cuda:0')]\n",
            "9.902240062152014 train: [0.7600528804594772, tensor(0.4289, device='cuda:0')]\n",
            "9.902369545513402 train: [0.760020700363451, tensor(0.4289, device='cuda:0')]\n",
            "9.90249902887479 train: [0.759988616093686, tensor(0.4289, device='cuda:0')]\n",
            "9.902628512236177 train: [0.7600056980569834, tensor(0.4289, device='cuda:0')]\n",
            "9.902757995597566 train: [0.7600225155064518, tensor(0.4289, device='cuda:0')]\n",
            "9.902887478958954 train: [0.7599909639471527, tensor(0.4290, device='cuda:0')]\n",
            "9.903016962320342 train: [0.7599595944846143, tensor(0.4290, device='cuda:0')]\n",
            "9.90314644568173 train: [0.7600535641136353, tensor(0.4289, device='cuda:0')]\n",
            "9.903275929043119 train: [0.760022367634524, tensor(0.4289, device='cuda:0')]\n",
            "9.903405412404506 train: [0.7601163011898173, tensor(0.4288, device='cuda:0')]\n",
            "9.903534895765894 train: [0.7600850182043536, tensor(0.4289, device='cuda:0')]\n",
            "9.903664379127282 train: [0.7600535713297778, tensor(0.4289, device='cuda:0')]\n",
            "9.903793862488671 train: [0.7600218742048258, tensor(0.4289, device='cuda:0')]\n",
            "9.903923345850059 train: [0.7600388404017611, tensor(0.4289, device='cuda:0')]\n",
            "9.904052829211446 train: [0.7601330496875518, tensor(0.4288, device='cuda:0')]\n",
            "9.904182312572834 train: [0.7601502542077675, tensor(0.4288, device='cuda:0')]\n",
            "9.904311795934223 train: [0.7601671082528941, tensor(0.4288, device='cuda:0')]\n",
            "9.904441279295611 train: [0.760057857446879, tensor(0.4289, device='cuda:0')]\n",
            "9.904570762656999 train: [0.760026618822333, tensor(0.4289, device='cuda:0')]\n",
            "9.904700246018386 train: [0.7600421881907604, tensor(0.4290, device='cuda:0')]\n",
            "9.904829729379776 train: [0.760057235090007, tensor(0.4290, device='cuda:0')]\n",
            "9.904959212741163 train: [0.7601505701279473, tensor(0.4289, device='cuda:0')]\n",
            "9.90508869610255 train: [0.760243705741336, tensor(0.4288, device='cuda:0')]\n",
            "9.905218179463938 train: [0.7602563009488358, tensor(0.4288, device='cuda:0')]\n",
            "9.905347662825326 train: [0.7601471471367828, tensor(0.4289, device='cuda:0')]\n",
            "9.905477146186715 train: [0.7601198092658848, tensor(0.4289, device='cuda:0')]\n",
            "9.905606629548103 train: [0.7602120332391162, tensor(0.4289, device='cuda:0')]\n",
            "9.90573611290949 train: [0.7601856426079661, tensor(0.4289, device='cuda:0')]\n",
            "9.905865596270878 train: [0.7600765615859245, tensor(0.4290, device='cuda:0')]\n",
            "9.905995079632268 train: [0.7600507152908067, tensor(0.4290, device='cuda:0')]\n",
            "9.906124562993655 train: [0.7599416849199431, tensor(0.4291, device='cuda:0')]\n",
            "9.906254046355043 train: [0.7600336097135796, tensor(0.4290, device='cuda:0')]\n",
            "9.90638352971643 train: [0.7600079530662225, tensor(0.4290, device='cuda:0')]\n",
            "9.90651301307782 train: [0.7599822176049502, tensor(0.4290, device='cuda:0')]\n",
            "9.906642496439208 train: [0.7599562310449407, tensor(0.4290, device='cuda:0')]\n",
            "9.906771979800595 train: [0.7598472923650318, tensor(0.4291, device='cuda:0')]\n",
            "9.906901463161983 train: [0.7599394232147385, tensor(0.4291, device='cuda:0')]\n",
            "9.907030946523372 train: [0.7599124204918756, tensor(0.4291, device='cuda:0')]\n",
            "9.90716042988476 train: [0.7598849949573997, tensor(0.4291, device='cuda:0')]\n",
            "9.907289913246148 train: [0.7598570606953934, tensor(0.4291, device='cuda:0')]\n",
            "9.907419396607535 train: [0.7599497399535001, tensor(0.4290, device='cuda:0')]\n",
            "9.907548879968925 train: [0.7600425648095102, tensor(0.4290, device='cuda:0')]\n",
            "9.907678363330312 train: [0.7600130708919464, tensor(0.4290, device='cuda:0')]\n",
            "9.9078078466917 train: [0.7599830691305401, tensor(0.4290, device='cuda:0')]\n",
            "9.907937330053088 train: [0.7599980727933484, tensor(0.4290, device='cuda:0')]\n",
            "9.908066813414477 train: [0.7598892840626308, tensor(0.4291, device='cuda:0')]\n",
            "9.908196296775865 train: [0.7598581947517918, tensor(0.4291, device='cuda:0')]\n",
            "9.908325780137252 train: [0.7599518129981067, tensor(0.4290, device='cuda:0')]\n",
            "9.90845526349864 train: [0.7600454904410227, tensor(0.4290, device='cuda:0')]\n",
            "9.90858474686003 train: [0.7599367571805876, tensor(0.4290, device='cuda:0')]\n",
            "9.908714230221417 train: [0.7600305819020059, tensor(0.4290, device='cuda:0')]\n",
            "9.908843713582804 train: [0.7599985491660799, tensor(0.4290, device='cuda:0')]\n",
            "9.908973196944192 train: [0.7598898692648692, tensor(0.4291, device='cuda:0')]\n",
            "9.909102680305582 train: [0.7599075306306504, tensor(0.4291, device='cuda:0')]\n",
            "9.90923216366697 train: [0.759875185572112, tensor(0.4291, device='cuda:0')]\n",
            "9.909361647028357 train: [0.7598928439877732, tensor(0.4291, device='cuda:0')]\n",
            "9.909491130389744 train: [0.7598605961620915, tensor(0.4291, device='cuda:0')]\n",
            "9.909620613751134 train: [0.759752013624772, tensor(0.4292, device='cuda:0')]\n",
            "9.909750097112521 train: [0.7597198809994834, tensor(0.4292, device='cuda:0')]\n",
            "9.909879580473909 train: [0.7596875858516483, tensor(0.4292, device='cuda:0')]\n",
            "9.910009063835297 train: [0.7597814838264864, tensor(0.4292, device='cuda:0')]\n",
            "9.910138547196686 train: [0.7597487599696789, tensor(0.4292, device='cuda:0')]\n",
            "9.910268030558074 train: [0.7598428798372127, tensor(0.4291, device='cuda:0')]\n",
            "9.910397513919461 train: [0.7597343928469446, tensor(0.4292, device='cuda:0')]\n",
            "9.910526997280849 train: [0.7598285736836325, tensor(0.4291, device='cuda:0')]\n",
            "9.910656480642237 train: [0.7597952613419267, tensor(0.4291, device='cuda:0')]\n",
            "9.910785964003626 train: [0.7597617869767596, tensor(0.4291, device='cuda:0')]\n",
            "9.910915447365014 train: [0.7597280649038461, tensor(0.4292, device='cuda:0')]\n",
            "9.911044930726401 train: [0.759693923746392, tensor(0.4292, device='cuda:0')]\n",
            "9.911174414087789 train: [0.759788643284319, tensor(0.4291, device='cuda:0')]\n",
            "9.911303897449178 train: [0.759883507235882, tensor(0.4290, device='cuda:0')]\n",
            "9.911433380810566 train: [0.759775138224582, tensor(0.4291, device='cuda:0')]\n",
            "9.911562864171954 train: [0.7597972241112659, tensor(0.4291, device='cuda:0')]\n",
            "9.911692347533341 train: [0.7598193037002917, tensor(0.4291, device='cuda:0')]\n",
            "9.91182183089473 train: [0.7599141948571742, tensor(0.4291, device='cuda:0')]\n",
            "9.911951314256118 train: [0.7598793759867556, tensor(0.4291, device='cuda:0')]\n",
            "9.912080797617506 train: [0.7599740602492847, tensor(0.4290, device='cuda:0')]\n",
            "9.912210280978893 train: [0.7599949032159063, tensor(0.4290, device='cuda:0')]\n",
            "9.912339764340283 train: [0.7598866264096353, tensor(0.4291, device='cuda:0')]\n",
            "9.91246924770167 train: [0.7598528585908394, tensor(0.4291, device='cuda:0')]\n",
            "9.912598731063058 train: [0.7598723403963933, tensor(0.4291, device='cuda:0')]\n",
            "9.912728214424446 train: [0.7599662735797384, tensor(0.4291, device='cuda:0')]\n",
            "9.912857697785835 train: [0.7600600088719482, tensor(0.4290, device='cuda:0')]\n",
            "9.912987181147223 train: [0.7601535463575434, tensor(0.4290, device='cuda:0')]\n",
            "9.91311666450861 train: [0.7601216465918423, tensor(0.4290, device='cuda:0')]\n",
            "9.913246147869998 train: [0.7600900980424358, tensor(0.4290, device='cuda:0')]\n",
            "9.913375631231387 train: [0.7601832492255147, tensor(0.4289, device='cuda:0')]\n",
            "9.913505114592775 train: [0.7601519574175825, tensor(0.4289, device='cuda:0')]\n",
            "9.913634597954163 train: [0.7601206745132801, tensor(0.4289, device='cuda:0')]\n",
            "9.91376408131555 train: [0.7600125492395229, tensor(0.4290, device='cuda:0')]\n",
            "9.91389356467694 train: [0.7601056584575998, tensor(0.4290, device='cuda:0')]\n",
            "9.914023048038327 train: [0.7600741391003764, tensor(0.4290, device='cuda:0')]\n",
            "9.914152531399715 train: [0.7600424578087915, tensor(0.4290, device='cuda:0')]\n",
            "9.914282014761103 train: [0.7600596553006277, tensor(0.4290, device='cuda:0')]\n",
            "9.914411498122492 train: [0.7600768479033404, tensor(0.4290, device='cuda:0')]\n",
            "9.91454098148388 train: [0.76004500891022, tensor(0.4290, device='cuda:0')]\n",
            "9.914670464845267 train: [0.7600132643663712, tensor(0.4290, device='cuda:0')]\n",
            "9.914799948206655 train: [0.7599813580671957, tensor(0.4290, device='cuda:0')]\n",
            "9.914929431568044 train: [0.7599492900816331, tensor(0.4290, device='cuda:0')]\n",
            "9.915058914929432 train: [0.7598413427392919, tensor(0.4291, device='cuda:0')]\n",
            "9.91518839829082 train: [0.7599348561447784, tensor(0.4291, device='cuda:0')]\n",
            "9.915317881652207 train: [0.7600284283311123, tensor(0.4290, device='cuda:0')]\n",
            "9.915447365013597 train: [0.7599205157330247, tensor(0.4291, device='cuda:0')]\n",
            "9.915576848374984 train: [0.7598126337745162, tensor(0.4292, device='cuda:0')]\n",
            "9.915706331736372 train: [0.7597047824425397, tensor(0.4292, device='cuda:0')]\n",
            "9.91583581509776 train: [0.7597238749754361, tensor(0.4293, device='cuda:0')]\n",
            "9.915965298459149 train: [0.7596908565838163, tensor(0.4293, device='cuda:0')]\n",
            "9.916094781820536 train: [0.7596578475617742, tensor(0.4293, device='cuda:0')]\n",
            "9.916224265181924 train: [0.7596247626504578, tensor(0.4293, device='cuda:0')]\n",
            "9.916353748543312 train: [0.7596441114293508, tensor(0.4293, device='cuda:0')]\n",
            "9.9164832319047 train: [0.759610782158559, tensor(0.4293, device='cuda:0')]\n",
            "9.916612715266089 train: [0.7596302978696714, tensor(0.4293, device='cuda:0')]\n",
            "9.916742198627476 train: [0.7597240229198704, tensor(0.4292, device='cuda:0')]\n",
            "9.916871681988864 train: [0.7596908668840374, tensor(0.4293, device='cuda:0')]\n",
            "9.917001165350252 train: [0.7596577202475059, tensor(0.4293, device='cuda:0')]\n",
            "9.917130648711641 train: [0.7596244978359934, tensor(0.4293, device='cuda:0')]\n",
            "9.917260132073029 train: [0.7595910293652783, tensor(0.4293, device='cuda:0')]\n",
            "9.917389615434416 train: [0.7594834080803017, tensor(0.4294, device='cuda:0')]\n",
            "9.917519098795804 train: [0.7595774148114246, tensor(0.4293, device='cuda:0')]\n",
            "9.917648582157193 train: [0.7594698259424711, tensor(0.4294, device='cuda:0')]\n",
            "9.917778065518581 train: [0.7594354621267417, tensor(0.4294, device='cuda:0')]\n",
            "9.917907548879969 train: [0.7594567620852668, tensor(0.4294, device='cuda:0')]\n",
            "9.918037032241356 train: [0.7594221545921868, tensor(0.4294, device='cuda:0')]\n",
            "9.918166515602746 train: [0.7595164437505445, tensor(0.4294, device='cuda:0')]\n",
            "9.918295998964133 train: [0.759610791278785, tensor(0.4293, device='cuda:0')]\n",
            "9.918425482325521 train: [0.759632394565525, tensor(0.4293, device='cuda:0')]\n",
            "9.918554965686909 train: [0.7596536515875522, tensor(0.4293, device='cuda:0')]\n",
            "9.918684449048298 train: [0.7596194658482435, tensor(0.4293, device='cuda:0')]\n",
            "9.918813932409686 train: [0.7597133203477807, tensor(0.4293, device='cuda:0')]\n",
            "9.918943415771073 train: [0.7596796458492003, tensor(0.4293, device='cuda:0')]\n",
            "9.91907289913246 train: [0.7596461508545196, tensor(0.4293, device='cuda:0')]\n",
            "9.91920238249385 train: [0.7596126653324051, tensor(0.4293, device='cuda:0')]\n",
            "9.919331865855238 train: [0.7595052692253315, tensor(0.4294, device='cuda:0')]\n",
            "9.919461349216625 train: [0.7595989885768034, tensor(0.4293, device='cuda:0')]\n",
            "9.919590832578013 train: [0.7594916247621636, tensor(0.4294, device='cuda:0')]\n",
            "9.919720315939403 train: [0.7593842912934295, tensor(0.4295, device='cuda:0')]\n",
            "9.91984979930079 train: [0.7594779880109999, tensor(0.4294, device='cuda:0')]\n",
            "9.919979282662178 train: [0.7593706867976612, tensor(0.4295, device='cuda:0')]\n",
            "9.920108766023565 train: [0.759390586458322, tensor(0.4295, device='cuda:0')]\n",
            "9.920238249384955 train: [0.7593572597511952, tensor(0.4295, device='cuda:0')]\n",
            "9.920367732746342 train: [0.7592500210476574, tensor(0.4296, device='cuda:0')]\n",
            "9.92049721610773 train: [0.7592691655985924, tensor(0.4296, device='cuda:0')]\n",
            "9.920626699469118 train: [0.7593623749714918, tensor(0.4295, device='cuda:0')]\n",
            "9.920756182830507 train: [0.7593300042348955, tensor(0.4296, device='cuda:0')]\n",
            "9.920885666191895 train: [0.7594229242440693, tensor(0.4295, device='cuda:0')]\n",
            "9.921015149553282 train: [0.7595157332171779, tensor(0.4294, device='cuda:0')]\n",
            "9.92114463291467 train: [0.7594841177236761, tensor(0.4294, device='cuda:0')]\n",
            "9.92127411627606 train: [0.7595767223042195, tensor(0.4294, device='cuda:0')]\n",
            "9.921403599637447 train: [0.7595453614483978, tensor(0.4294, device='cuda:0')]\n",
            "9.921533082998835 train: [0.75951400943908, tensor(0.4294, device='cuda:0')]\n",
            "9.921662566360222 train: [0.7596064858759207, tensor(0.4293, device='cuda:0')]\n",
            "9.92179204972161 train: [0.7596990209716257, tensor(0.4293, device='cuda:0')]\n",
            "9.921921533083 train: [0.7596675758331616, tensor(0.4293, device='cuda:0')]\n",
            "9.922051016444387 train: [0.759684511287979, tensor(0.4293, device='cuda:0')]\n",
            "9.922180499805775 train: [0.7596530770586003, tensor(0.4293, device='cuda:0')]\n",
            "9.922309983167162 train: [0.7597454687364495, tensor(0.4293, device='cuda:0')]\n",
            "9.922439466528552 train: [0.7596384170993161, tensor(0.4293, device='cuda:0')]\n",
            "9.92256894988994 train: [0.759607087316037, tensor(0.4293, device='cuda:0')]\n",
            "9.922698433251327 train: [0.7596994464279909, tensor(0.4293, device='cuda:0')]\n",
            "9.922827916612714 train: [0.7595924465059588, tensor(0.4294, device='cuda:0')]\n",
            "9.922957399974104 train: [0.7596848662972713, tensor(0.4293, device='cuda:0')]\n",
            "9.923086883335491 train: [0.7596534630006715, tensor(0.4293, device='cuda:0')]\n",
            "9.92321636669688 train: [0.7596219839396138, tensor(0.4293, device='cuda:0')]\n",
            "9.923345850058267 train: [0.7597144451392498, tensor(0.4293, device='cuda:0')]\n",
            "9.923475333419656 train: [0.7596826280246847, tensor(0.4293, device='cuda:0')]\n",
            "9.923604816781044 train: [0.759700378472147, tensor(0.4293, device='cuda:0')]\n",
            "9.923734300142431 train: [0.7597181239244082, tensor(0.4293, device='cuda:0')]\n",
            "9.923863783503819 train: [0.759686235173802, tensor(0.4293, device='cuda:0')]\n",
            "9.923993266865208 train: [0.7597786223043379, tensor(0.4292, device='cuda:0')]\n",
            "9.924122750226596 train: [0.7597469875851997, tensor(0.4293, device='cuda:0')]\n",
            "9.924252233587984 train: [0.7597152772519282, tensor(0.4293, device='cuda:0')]\n",
            "9.924381716949371 train: [0.7596834068367656, tensor(0.4293, device='cuda:0')]\n",
            "9.92451120031076 train: [0.7597759113865187, tensor(0.4292, device='cuda:0')]\n",
            "9.924640683672148 train: [0.7597939666637832, tensor(0.4292, device='cuda:0')]\n",
            "9.924770167033536 train: [0.7598865141358992, tensor(0.4292, device='cuda:0')]\n",
            "9.924899650394924 train: [0.7599789511447659, tensor(0.4291, device='cuda:0')]\n",
            "9.925029133756313 train: [0.7599469816311972, tensor(0.4291, device='cuda:0')]\n",
            "9.9251586171177 train: [0.7599644961581689, tensor(0.4291, device='cuda:0')]\n",
            "9.925288100479088 train: [0.7599327909062422, tensor(0.4291, device='cuda:0')]\n",
            "9.925417583840476 train: [0.7598260587726879, tensor(0.4292, device='cuda:0')]\n",
            "9.925547067201865 train: [0.7597193566158599, tensor(0.4293, device='cuda:0')]\n",
            "9.925676550563253 train: [0.7598114860778088, tensor(0.4292, device='cuda:0')]\n",
            "9.92580603392464 train: [0.7599035053024331, tensor(0.4292, device='cuda:0')]\n",
            "9.925935517286028 train: [0.7599954143361551, tensor(0.4291, device='cuda:0')]\n",
            "9.926065000647418 train: [0.7600113866396762, tensor(0.4291, device='cuda:0')]\n",
            "9.926194484008805 train: [0.7599809709568428, tensor(0.4291, device='cuda:0')]\n",
            "9.926323967370193 train: [0.7600724931463233, tensor(0.4291, device='cuda:0')]\n",
            "9.92645345073158 train: [0.7600425832847708, tensor(0.4291, device='cuda:0')]\n",
            "9.92658293409297 train: [0.7601339025594268, tensor(0.4290, device='cuda:0')]\n",
            "9.926712417454358 train: [0.7602251119322473, tensor(0.4290, device='cuda:0')]\n",
            "9.926841900815745 train: [0.7602390159973248, tensor(0.4290, device='cuda:0')]\n",
            "9.926971384177133 train: [0.7602101107144398, tensor(0.4290, device='cuda:0')]\n",
            "9.927100867538522 train: [0.7601814662888633, tensor(0.4290, device='cuda:0')]\n",
            "9.92723035089991 train: [0.7601528298936836, tensor(0.4290, device='cuda:0')]\n",
            "9.927359834261297 train: [0.7602437200150935, tensor(0.4289, device='cuda:0')]\n",
            "9.927489317622685 train: [0.7602149144909883, tensor(0.4290, device='cuda:0')]\n",
            "9.927618800984073 train: [0.7603058546469643, tensor(0.4289, device='cuda:0')]\n",
            "9.927748284345462 train: [0.76039676932237, tensor(0.4288, device='cuda:0')]\n",
            "9.92787776770685 train: [0.7604876585279128, tensor(0.4288, device='cuda:0')]\n",
            "9.928007251068237 train: [0.7604585824714502, tensor(0.4288, device='cuda:0')]\n",
            "9.928136734429625 train: [0.7604294304019045, tensor(0.4288, device='cuda:0')]\n",
            "9.928266217791014 train: [0.7604000340617797, tensor(0.4288, device='cuda:0')]\n",
            "9.928395701152402 train: [0.760370225287802, tensor(0.4288, device='cuda:0')]\n",
            "9.92852518451379 train: [0.7604614752024291, tensor(0.4288, device='cuda:0')]\n",
            "9.928654667875177 train: [0.7605528677935081, tensor(0.4287, device='cuda:0')]\n",
            "9.928784151236567 train: [0.7605687992475618, tensor(0.4287, device='cuda:0')]\n",
            "9.928913634597954 train: [0.7605378904273983, tensor(0.4287, device='cuda:0')]\n",
            "9.929043117959342 train: [0.7605068221073135, tensor(0.4287, device='cuda:0')]\n",
            "9.92917260132073 train: [0.7604755102919182, tensor(0.4287, device='cuda:0')]\n",
            "9.929302084682119 train: [0.7604438710328133, tensor(0.4287, device='cuda:0')]\n",
            "9.929431568043507 train: [0.7605357776749889, tensor(0.4287, device='cuda:0')]\n",
            "9.929561051404894 train: [0.7606278266703235, tensor(0.4286, device='cuda:0')]\n",
            "9.929690534766282 train: [0.760521489772984, tensor(0.4287, device='cuda:0')]\n",
            "9.929820018127671 train: [0.7604886017236189, tensor(0.4287, device='cuda:0')]\n",
            "9.929949501489059 train: [0.7605078817932591, tensor(0.4287, device='cuda:0')]\n",
            "9.930078984850446 train: [0.7606003031345402, tensor(0.4287, device='cuda:0')]\n",
            "9.930208468211834 train: [0.7606926986489827, tensor(0.4286, device='cuda:0')]\n",
            "9.930337951573224 train: [0.7606594692329185, tensor(0.4286, device='cuda:0')]\n",
            "9.930467434934611 train: [0.7607517467254773, tensor(0.4286, device='cuda:0')]\n",
            "9.930596918295999 train: [0.7607710605124623, tensor(0.4286, device='cuda:0')]\n",
            "9.930726401657386 train: [0.7607900332194687, tensor(0.4286, device='cuda:0')]\n",
            "9.930855885018776 train: [0.7606838073002814, tensor(0.4287, device='cuda:0')]\n",
            "9.930985368380163 train: [0.760651609096962, tensor(0.4287, device='cuda:0')]\n",
            "9.931114851741551 train: [0.7606195876551561, tensor(0.4287, device='cuda:0')]\n",
            "9.931244335102939 train: [0.7607112901927103, tensor(0.4286, device='cuda:0')]\n",
            "9.931373818464328 train: [0.7606794370853818, tensor(0.4286, device='cuda:0')]\n",
            "9.931503301825716 train: [0.7606475928668792, tensor(0.4286, device='cuda:0')]\n",
            "9.931632785187103 train: [0.7605414757361779, tensor(0.4287, device='cuda:0')]\n",
            "9.931762268548491 train: [0.7605094081622799, tensor(0.4287, device='cuda:0')]\n",
            "9.93189175190988 train: [0.7604770980849694, tensor(0.4287, device='cuda:0')]\n",
            "9.932021235271268 train: [0.7605690789826545, tensor(0.4287, device='cuda:0')]\n",
            "9.932150718632656 train: [0.7605361830462483, tensor(0.4287, device='cuda:0')]\n",
            "9.932280201994043 train: [0.7605555756630098, tensor(0.4287, device='cuda:0')]\n",
            "9.932409685355433 train: [0.7604495601102271, tensor(0.4288, device='cuda:0')]\n",
            "9.93253916871682 train: [0.7604161920396677, tensor(0.4288, device='cuda:0')]\n",
            "9.932668652078208 train: [0.760382582030915, tensor(0.4288, device='cuda:0')]\n",
            "9.932798135439596 train: [0.7604750016076998, tensor(0.4287, device='cuda:0')]\n",
            "9.932927618800985 train: [0.7604409741571468, tensor(0.4287, device='cuda:0')]\n",
            "9.933057102162373 train: [0.7604620380490105, tensor(0.4288, device='cuda:0')]\n",
            "9.93318658552376 train: [0.7604831797728734, tensor(0.4288, device='cuda:0')]\n",
            "9.933316068885148 train: [0.7604489143359078, tensor(0.4288, device='cuda:0')]\n",
            "9.933445552246535 train: [0.7605414276878093, tensor(0.4287, device='cuda:0')]\n",
            "9.933575035607925 train: [0.7605073310112552, tensor(0.4287, device='cuda:0')]\n",
            "9.933704518969313 train: [0.7605281200477557, tensor(0.4287, device='cuda:0')]\n",
            "9.9338340023307 train: [0.7605486523740699, tensor(0.4287, device='cuda:0')]\n",
            "9.933963485692088 train: [0.7605149870742255, tensor(0.4288, device='cuda:0')]\n",
            "9.934092969053477 train: [0.7606070923997389, tensor(0.4287, device='cuda:0')]\n",
            "9.934222452414865 train: [0.7606990884915029, tensor(0.4286, device='cuda:0')]\n",
            "9.934351935776252 train: [0.7607908918005072, tensor(0.4286, device='cuda:0')]\n",
            "9.93448141913764 train: [0.7606850794372526, tensor(0.4287, device='cuda:0')]\n",
            "9.93461090249903 train: [0.7607766084475253, tensor(0.4286, device='cuda:0')]\n",
            "9.934740385860417 train: [0.7607446107320099, tensor(0.4286, device='cuda:0')]\n",
            "9.934869869221805 train: [0.7608358553722102, tensor(0.4285, device='cuda:0')]\n",
            "9.934999352583192 train: [0.760730095592481, tensor(0.4286, device='cuda:0')]\n",
            "9.935128835944582 train: [0.7608211498369595, tensor(0.4286, device='cuda:0')]\n",
            "9.93525831930597 train: [0.7607900823641339, tensor(0.4286, device='cuda:0')]\n",
            "9.935387802667357 train: [0.7608062019698378, tensor(0.4286, device='cuda:0')]\n",
            "9.935517286028745 train: [0.7608218996462692, tensor(0.4286, device='cuda:0')]\n",
            "9.935646769390134 train: [0.7609124731533226, tensor(0.4285, device='cuda:0')]\n",
            "9.935776252751522 train: [0.760882829193376, tensor(0.4285, device='cuda:0')]\n",
            "9.93590573611291 train: [0.7607771656981402, tensor(0.4286, device='cuda:0')]\n",
            "9.936035219474297 train: [0.7607481328637344, tensor(0.4286, device='cuda:0')]\n",
            "9.936164702835686 train: [0.7608381657215476, tensor(0.4286, device='cuda:0')]\n",
            "9.936294186197074 train: [0.7608512598502969, tensor(0.4286, device='cuda:0')]\n",
            "9.936423669558462 train: [0.7607456593978541, tensor(0.4287, device='cuda:0')]\n",
            "9.93655315291985 train: [0.7607177312175751, tensor(0.4287, device='cuda:0')]\n",
            "9.936682636281239 train: [0.7606898941733998, tensor(0.4287, device='cuda:0')]\n",
            "9.936812119642626 train: [0.7607795391605481, tensor(0.4286, device='cuda:0')]\n",
            "9.936941603004014 train: [0.7607517846281892, tensor(0.4286, device='cuda:0')]\n",
            "9.937071086365401 train: [0.7607238710924997, tensor(0.4286, device='cuda:0')]\n",
            "9.937200569726791 train: [0.7606957152800743, tensor(0.4287, device='cuda:0')]\n",
            "9.937330053088179 train: [0.7605902388913777, tensor(0.4287, device='cuda:0')]\n",
            "9.937459536449566 train: [0.7606801688191194, tensor(0.4287, device='cuda:0')]\n",
            "9.937589019810954 train: [0.7606937665276918, tensor(0.4287, device='cuda:0')]\n",
            "9.937718503172343 train: [0.7607837404712404, tensor(0.4286, device='cuda:0')]\n",
            "9.93784798653373 train: [0.7608736894774433, tensor(0.4286, device='cuda:0')]\n",
            "9.937977469895118 train: [0.7608447868814018, tensor(0.4286, device='cuda:0')]\n",
            "9.938106953256506 train: [0.7608158922938381, tensor(0.4286, device='cuda:0')]\n",
            "9.938236436617895 train: [0.7609057994661523, tensor(0.4285, device='cuda:0')]\n",
            "9.938365919979283 train: [0.7608766547251226, tensor(0.4285, device='cuda:0')]\n",
            "9.93849540334067 train: [0.7608906281625174, tensor(0.4285, device='cuda:0')]\n",
            "9.938624886702058 train: [0.7609805708518842, tensor(0.4285, device='cuda:0')]\n",
            "9.938754370063446 train: [0.7609512614617834, tensor(0.4285, device='cuda:0')]\n",
            "9.938883853424835 train: [0.76092187699655, tensor(0.4285, device='cuda:0')]\n",
            "9.939013336786223 train: [0.7608923343092894, tensor(0.4285, device='cuda:0')]\n",
            "9.93914282014761 train: [0.7608624671325768, tensor(0.4285, device='cuda:0')]\n",
            "9.939272303508998 train: [0.7607571865919469, tensor(0.4286, device='cuda:0')]\n",
            "9.939401786870388 train: [0.7607730753267209, tensor(0.4286, device='cuda:0')]\n",
            "9.939531270231775 train: [0.760863529108186, tensor(0.4286, device='cuda:0')]\n",
            "9.939660753593163 train: [0.7607582921055431, tensor(0.4286, device='cuda:0')]\n",
            "9.93979023695455 train: [0.7608488060221482, tensor(0.4286, device='cuda:0')]\n",
            "9.93991972031594 train: [0.7608179724727706, tensor(0.4286, device='cuda:0')]\n",
            "9.940049203677328 train: [0.760787064363122, tensor(0.4286, device='cuda:0')]\n",
            "9.940178687038715 train: [0.7607559155749559, tensor(0.4286, device='cuda:0')]\n",
            "9.940308170400103 train: [0.7607729519961725, tensor(0.4286, device='cuda:0')]\n",
            "9.940437653761492 train: [0.7607413985095888, tensor(0.4286, device='cuda:0')]\n",
            "9.94056713712288 train: [0.7607588474293429, tensor(0.4286, device='cuda:0')]\n",
            "9.940696620484267 train: [0.7607271385529364, tensor(0.4286, device='cuda:0')]\n",
            "9.940826103845655 train: [0.7608179718299383, tensor(0.4286, device='cuda:0')]\n",
            "9.940955587207045 train: [0.7607860975350617, tensor(0.4286, device='cuda:0')]\n",
            "9.941085070568432 train: [0.7608769805753561, tensor(0.4285, device='cuda:0')]\n",
            "9.94121455392982 train: [0.7607719160930895, tensor(0.4286, device='cuda:0')]\n",
            "9.941344037291207 train: [0.7607898441731539, tensor(0.4286, device='cuda:0')]\n",
            "9.941473520652597 train: [0.760757908401648, tensor(0.4286, device='cuda:0')]\n",
            "9.941603004013984 train: [0.7607259814460902, tensor(0.4286, device='cuda:0')]\n",
            "9.941732487375372 train: [0.7607438255058494, tensor(0.4287, device='cuda:0')]\n",
            "9.94186197073676 train: [0.7606388518856609, tensor(0.4287, device='cuda:0')]\n",
            "9.941991454098149 train: [0.7605339072317032, tensor(0.4288, device='cuda:0')]\n",
            "9.942120937459537 train: [0.7605021945997856, tensor(0.4288, device='cuda:0')]\n",
            "9.942250420820924 train: [0.7604704907161803, tensor(0.4288, device='cuda:0')]\n",
            "9.942379904182312 train: [0.7604386298176379, tensor(0.4288, device='cuda:0')]\n",
            "9.942509387543701 train: [0.7605295057862023, tensor(0.4288, device='cuda:0')]\n",
            "9.942638870905089 train: [0.7604972312517897, tensor(0.4288, device='cuda:0')]\n",
            "9.942768354266477 train: [0.7605882397775233, tensor(0.4287, device='cuda:0')]\n",
            "9.942897837627864 train: [0.7604834033557759, tensor(0.4288, device='cuda:0')]\n",
            "9.943027320989254 train: [0.7605745543475956, tensor(0.4287, device='cuda:0')]\n",
            "9.943156804350641 train: [0.7605938828293107, tensor(0.4288, device='cuda:0')]\n",
            "9.943286287712029 train: [0.760612957585264, tensor(0.4288, device='cuda:0')]\n",
            "9.943415771073417 train: [0.7607038874818528, tensor(0.4287, device='cuda:0')]\n",
            "9.943545254434806 train: [0.7605991073320619, tensor(0.4288, device='cuda:0')]\n",
            "9.943674737796194 train: [0.7605672725996631, tensor(0.4288, device='cuda:0')]\n",
            "9.943804221157581 train: [0.7604625401192721, tensor(0.4289, device='cuda:0')]\n",
            "9.943933704518969 train: [0.7605529441902583, tensor(0.4288, device='cuda:0')]\n",
            "9.944063187880358 train: [0.7606432406387665, tensor(0.4288, device='cuda:0')]\n",
            "9.944192671241746 train: [0.7606123272804277, tensor(0.4288, device='cuda:0')]\n",
            "9.944322154603134 train: [0.7607024252842534, tensor(0.4287, device='cuda:0')]\n",
            "9.944451637964521 train: [0.7607924984916006, tensor(0.4287, device='cuda:0')]\n",
            "9.944581121325909 train: [0.76088238154079, tensor(0.4286, device='cuda:0')]\n",
            "9.944710604687298 train: [0.7608521136914399, tensor(0.4286, device='cuda:0')]\n",
            "9.944840088048686 train: [0.7608220194952915, tensor(0.4286, device='cuda:0')]\n",
            "9.944969571410073 train: [0.7609117787469717, tensor(0.4286, device='cuda:0')]\n",
            "9.945099054771461 train: [0.761001513312389, tensor(0.4285, device='cuda:0')]\n",
            "9.94522853813285 train: [0.7609714109879533, tensor(0.4285, device='cuda:0')]\n",
            "9.945358021494238 train: [0.7610611126826844, tensor(0.4284, device='cuda:0')]\n",
            "9.945487504855626 train: [0.7611507897171557, tensor(0.4284, device='cuda:0')]\n",
            "9.945616988217013 train: [0.7612404421015351, tensor(0.4283, device='cuda:0')]\n",
            "9.945746471578403 train: [0.7611358329985941, tensor(0.4284, device='cuda:0')]\n",
            "9.94587595493979 train: [0.761225297656795, tensor(0.4283, device='cuda:0')]\n",
            "9.946005438301178 train: [0.7613146551724138, tensor(0.4283, device='cuda:0')]\n",
            "9.946134921662566 train: [0.761285281725486, tensor(0.4283, device='cuda:0')]\n",
            "9.946264405023955 train: [0.7612993315056047, tensor(0.4283, device='cuda:0')]\n",
            "9.946393888385343 train: [0.7611947861428602, tensor(0.4284, device='cuda:0')]\n",
            "9.94652337174673 train: [0.7612838512236082, tensor(0.4283, device='cuda:0')]\n",
            "9.946652855108118 train: [0.7612554056836903, tensor(0.4283, device='cuda:0')]\n",
            "9.946782338469507 train: [0.7611509094028827, tensor(0.4284, device='cuda:0')]\n",
            "9.946911821830895 train: [0.7611634833136257, tensor(0.4284, device='cuda:0')]\n",
            "9.947041305192283 train: [0.761135560824862, tensor(0.4284, device='cuda:0')]\n",
            "9.94717078855367 train: [0.7612241606328632, tensor(0.4284, device='cuda:0')]\n",
            "9.94730027191506 train: [0.7613127361303123, tensor(0.4283, device='cuda:0')]\n",
            "9.947429755276447 train: [0.7612853817136225, tensor(0.4283, device='cuda:0')]\n",
            "9.947559238637835 train: [0.7612581172256628, tensor(0.4283, device='cuda:0')]\n",
            "9.947688721999222 train: [0.761230695387991, tensor(0.4283, device='cuda:0')]\n",
            "9.947818205360612 train: [0.7613192214083051, tensor(0.4283, device='cuda:0')]\n",
            "9.947947688722 train: [0.761291386756238, tensor(0.4283, device='cuda:0')]\n",
            "9.948077172083387 train: [0.7613038435176886, tensor(0.4283, device='cuda:0')]\n",
            "9.948206655444775 train: [0.7613924878489794, tensor(0.4282, device='cuda:0')]\n",
            "9.948336138806164 train: [0.7614050096984009, tensor(0.4283, device='cuda:0')]\n",
            "9.948465622167552 train: [0.7613770962012775, tensor(0.4283, device='cuda:0')]\n",
            "9.94859510552894 train: [0.7613892050544332, tensor(0.4283, device='cuda:0')]\n",
            "9.948724588890327 train: [0.7614008989726028, tensor(0.4283, device='cuda:0')]\n",
            "9.948854072251716 train: [0.7614891400545762, tensor(0.4282, device='cuda:0')]\n",
            "9.948983555613104 train: [0.7615771923656321, tensor(0.4282, device='cuda:0')]\n",
            "9.949113038974492 train: [0.7615510847754874, tensor(0.4282, device='cuda:0')]\n",
            "9.94924252233588 train: [0.7616388576596597, tensor(0.4281, device='cuda:0')]\n",
            "9.949372005697269 train: [0.7616134069130732, tensor(0.4281, device='cuda:0')]\n",
            "9.949501489058656 train: [0.7617010649834699, tensor(0.4281, device='cuda:0')]\n",
            "9.949630972420044 train: [0.7616758594235243, tensor(0.4281, device='cuda:0')]\n",
            "9.949760455781432 train: [0.7616506607616521, tensor(0.4281, device='cuda:0')]\n",
            "9.94988993914282 train: [0.7616252223286359, tensor(0.4281, device='cuda:0')]\n",
            "9.950019422504209 train: [0.7615994620119962, tensor(0.4281, device='cuda:0')]\n",
            "9.950148905865596 train: [0.7616873086392475, tensor(0.4281, device='cuda:0')]\n",
            "9.950278389226984 train: [0.761660724993688, tensor(0.4281, device='cuda:0')]\n",
            "9.950407872588372 train: [0.7616336555554387, tensor(0.4281, device='cuda:0')]\n",
            "9.950537355949761 train: [0.7617218723049578, tensor(0.4280, device='cuda:0')]\n",
            "9.950666839311149 train: [0.7616177408118198, tensor(0.4281, device='cuda:0')]\n",
            "9.950796322672536 train: [0.7615892919102494, tensor(0.4281, device='cuda:0')]\n",
            "9.950925806033924 train: [0.7615603579914004, tensor(0.4281, device='cuda:0')]\n",
            "9.951055289395313 train: [0.7614562912575945, tensor(0.4282, device='cuda:0')]\n",
            "9.9511847727567 train: [0.7615453751826121, tensor(0.4281, device='cuda:0')]\n",
            "9.951314256118089 train: [0.7614413389291719, tensor(0.4282, device='cuda:0')]\n",
            "9.951443739479476 train: [0.7614105530192387, tensor(0.4282, device='cuda:0')]\n",
            "9.951573222840866 train: [0.7613065635965373, tensor(0.4283, device='cuda:0')]\n",
            "9.951702706202253 train: [0.7613962758274772, tensor(0.4282, device='cuda:0')]\n",
            "9.95183218956364 train: [0.7614139203829349, tensor(0.4282, device='cuda:0')]\n",
            "9.951961672925028 train: [0.7613099730900499, tensor(0.4283, device='cuda:0')]\n",
            "9.952091156286418 train: [0.7613997301497302, tensor(0.4283, device='cuda:0')]\n",
            "9.952220639647805 train: [0.7613679088670985, tensor(0.4283, device='cuda:0')]\n",
            "9.952350123009193 train: [0.7614577155326251, tensor(0.4282, device='cuda:0')]\n",
            "9.95247960637058 train: [0.7615474976909432, tensor(0.4282, device='cuda:0')]\n",
            "9.95260908973197 train: [0.7615156692727464, tensor(0.4282, device='cuda:0')]\n",
            "9.952738573093358 train: [0.7614837675624062, tensor(0.4282, device='cuda:0')]\n",
            "9.952868056454745 train: [0.7614517106257082, tensor(0.4282, device='cuda:0')]\n",
            "9.952997539816133 train: [0.7614193346201051, tensor(0.4282, device='cuda:0')]\n",
            "9.953127023177522 train: [0.7613865577342619, tensor(0.4282, device='cuda:0')]\n",
            "9.95325650653891 train: [0.7614768496670337, tensor(0.4282, device='cuda:0')]\n",
            "9.953385989900298 train: [0.7614433366013758, tensor(0.4282, device='cuda:0')]\n",
            "9.953515473261685 train: [0.761533923816064, tensor(0.4281, device='cuda:0')]\n",
            "9.953644956623075 train: [0.7614996750319727, tensor(0.4281, device='cuda:0')]\n",
            "9.953774439984462 train: [0.7615906393136772, tensor(0.4281, device='cuda:0')]\n",
            "9.95390392334585 train: [0.761681660684343, tensor(0.4280, device='cuda:0')]\n",
            "9.954033406707238 train: [0.7617727391206396, tensor(0.4279, device='cuda:0')]\n",
            "9.954162890068627 train: [0.7616689836399639, tensor(0.4280, device='cuda:0')]\n",
            "9.954292373430015 train: [0.7616338395279649, tensor(0.4280, device='cuda:0')]\n",
            "9.954421856791402 train: [0.7615985413262527, tensor(0.4280, device='cuda:0')]\n",
            "9.95455134015279 train: [0.7616217534167671, tensor(0.4280, device='cuda:0')]\n",
            "9.95468082351418 train: [0.761586139238518, tensor(0.4281, device='cuda:0')]\n",
            "9.954810306875567 train: [0.761677565280439, tensor(0.4280, device='cuda:0')]\n",
            "9.954939790236955 train: [0.7616417896287844, tensor(0.4280, device='cuda:0')]\n",
            "9.955069273598342 train: [0.7616058601641249, tensor(0.4280, device='cuda:0')]\n",
            "9.955198756959732 train: [0.7616974914965986, tensor(0.4280, device='cuda:0')]\n",
            "9.95532824032112 train: [0.7617891796511203, tensor(0.4279, device='cuda:0')]\n",
            "9.955457723682507 train: [0.761685563059764, tensor(0.4280, device='cuda:0')]\n",
            "9.955587207043894 train: [0.761649238536861, tensor(0.4280, device='cuda:0')]\n",
            "9.955716690405282 train: [0.761545669154411, tensor(0.4281, device='cuda:0')]\n",
            "9.955846173766671 train: [0.7615091284055849, tensor(0.4281, device='cuda:0')]\n",
            "9.955975657128059 train: [0.7614724341981428, tensor(0.4281, device='cuda:0')]\n",
            "9.956105140489447 train: [0.7614355049089826, tensor(0.4281, device='cuda:0')]\n",
            "9.956234623850834 train: [0.7613320208773287, tensor(0.4282, device='cuda:0')]\n",
            "9.956364107212224 train: [0.7612944673973261, tensor(0.4282, device='cuda:0')]\n",
            "9.956493590573611 train: [0.761387078020485, tensor(0.4281, device='cuda:0')]\n",
            "9.956623073934999 train: [0.7613489557752395, tensor(0.4281, device='cuda:0')]\n",
            "9.956752557296387 train: [0.7614418603588072, tensor(0.4281, device='cuda:0')]\n",
            "9.956882040657776 train: [0.7614032513137413, tensor(0.4281, device='cuda:0')]\n",
            "9.957011524019164 train: [0.7614963681161994, tensor(0.4280, device='cuda:0')]\n",
            "9.957141007380551 train: [0.7613929741761972, tensor(0.4281, device='cuda:0')]\n",
            "9.957270490741939 train: [0.7614862302627456, tensor(0.4280, device='cuda:0')]\n",
            "9.957399974103328 train: [0.7614470651345396, tensor(0.4281, device='cuda:0')]\n",
            "9.957529457464716 train: [0.7613437199845485, tensor(0.4281, device='cuda:0')]\n",
            "9.957658940826104 train: [0.7612404028831801, tensor(0.4282, device='cuda:0')]\n",
            "9.957788424187491 train: [0.7613338736822879, tensor(0.4282, device='cuda:0')]\n",
            "9.95791790754888 train: [0.761363399183912, tensor(0.4282, device='cuda:0')]\n",
            "9.958047390910268 train: [0.7613241957615092, tensor(0.4282, device='cuda:0')]\n",
            "9.958176874271656 train: [0.7612850844818412, tensor(0.4282, device='cuda:0')]\n",
            "9.958306357633044 train: [0.7612459023126995, tensor(0.4282, device='cuda:0')]\n",
            "9.958435840994433 train: [0.7613392275097783, tensor(0.4281, device='cuda:0')]\n",
            "9.95856532435582 train: [0.7614325274017604, tensor(0.4281, device='cuda:0')]\n",
            "9.958694807717208 train: [0.7613933411799668, tensor(0.4281, device='cuda:0')]\n",
            "9.958824291078596 train: [0.7613540841274475, tensor(0.4281, device='cuda:0')]\n",
            "9.958953774439985 train: [0.7613835748798565, tensor(0.4281, device='cuda:0')]\n",
            "9.959083257801373 train: [0.7613443297894518, tensor(0.4281, device='cuda:0')]\n",
            "9.95921274116276 train: [0.7612411805779913, tensor(0.4282, device='cuda:0')]\n",
            "9.959342224524148 train: [0.7612018840005835, tensor(0.4282, device='cuda:0')]\n",
            "9.959471707885537 train: [0.7611625166703133, tensor(0.4282, device='cuda:0')]\n",
            "9.959601191246925 train: [0.7611229972289357, tensor(0.4282, device='cuda:0')]\n",
            "9.959730674608313 train: [0.7612166195771054, tensor(0.4282, device='cuda:0')]\n",
            "9.9598601579697 train: [0.7611767780520319, tensor(0.4282, device='cuda:0')]\n",
            "9.95998964133109 train: [0.7611367846060126, tensor(0.4282, device='cuda:0')]\n",
            "9.960119124692477 train: [0.761096557957811, tensor(0.4282, device='cuda:0')]\n",
            "9.960248608053865 train: [0.7610560168701916, tensor(0.4282, device='cuda:0')]\n",
            "9.960378091415253 train: [0.7610151614708025, tensor(0.4282, device='cuda:0')]\n",
            "9.960507574776642 train: [0.7609739918872225, tensor(0.4282, device='cuda:0')]\n",
            "9.96063705813803 train: [0.760932426948052, tensor(0.4282, device='cuda:0')]\n",
            "9.960766541499417 train: [0.7609665522999928, tensor(0.4282, device='cuda:0')]\n",
            "9.960896024860805 train: [0.7610009935290568, tensor(0.4283, device='cuda:0')]\n",
            "9.961025508222193 train: [0.7610355067093151, tensor(0.4283, device='cuda:0')]\n",
            "9.961154991583582 train: [0.7609934684028788, tensor(0.4283, device='cuda:0')]\n",
            "9.96128447494497 train: [0.7610886625035097, tensor(0.4282, device='cuda:0')]\n",
            "9.961413958306357 train: [0.7610467096096658, tensor(0.4282, device='cuda:0')]\n",
            "9.961543441667745 train: [0.7611417895609593, tensor(0.4282, device='cuda:0')]\n",
            "9.961672925029134 train: [0.7610389325623701, tensor(0.4282, device='cuda:0')]\n",
            "9.961802408390522 train: [0.7611339066706162, tensor(0.4282, device='cuda:0')]\n",
            "9.96193189175191 train: [0.7610310785286721, tensor(0.4283, device='cuda:0')]\n",
            "9.962061375113297 train: [0.760989567638899, tensor(0.4283, device='cuda:0')]\n",
            "9.962190858474687 train: [0.7609481491293687, tensor(0.4283, device='cuda:0')]\n",
            "9.962320341836074 train: [0.7609067418064717, tensor(0.4283, device='cuda:0')]\n",
            "9.962449825197462 train: [0.7610015073537049, tensor(0.4282, device='cuda:0')]\n",
            "9.96257930855885 train: [0.7609600228733734, tensor(0.4282, device='cuda:0')]\n",
            "9.962708791920239 train: [0.7609184684696378, tensor(0.4283, device='cuda:0')]\n",
            "9.962838275281626 train: [0.7608767630584424, tensor(0.4283, device='cuda:0')]\n",
            "9.962967758643014 train: [0.7608349067009239, tensor(0.4283, device='cuda:0')]\n",
            "9.963097242004402 train: [0.7609300234578537, tensor(0.4282, device='cuda:0')]\n",
            "9.963226725365791 train: [0.760887846890697, tensor(0.4282, device='cuda:0')]\n",
            "9.963356208727179 train: [0.7609831740497462, tensor(0.4282, device='cuda:0')]\n",
            "9.963485692088566 train: [0.7609407585181881, tensor(0.4282, device='cuda:0')]\n",
            "9.963615175449954 train: [0.7610362149229731, tensor(0.4281, device='cuda:0')]\n",
            "9.963744658811343 train: [0.7611316455843914, tensor(0.4281, device='cuda:0')]\n",
            "9.963874142172731 train: [0.7610889841165306, tensor(0.4281, device='cuda:0')]\n",
            "9.964003625534119 train: [0.7611844629487525, tensor(0.4280, device='cuda:0')]\n",
            "9.964133108895506 train: [0.7611418058622871, tensor(0.4280, device='cuda:0')]\n",
            "9.964262592256896 train: [0.7610991602736886, tensor(0.4280, device='cuda:0')]\n",
            "9.964392075618283 train: [0.7611946801177532, tensor(0.4280, device='cuda:0')]\n",
            "9.964521558979671 train: [0.7612304181435648, tensor(0.4280, device='cuda:0')]\n",
            "9.964651042341059 train: [0.7611877778526203, tensor(0.4280, device='cuda:0')]\n",
            "9.964780525702448 train: [0.7611451490488229, tensor(0.4280, device='cuda:0')]\n",
            "9.964910009063836 train: [0.7610426379176379, tensor(0.4281, device='cuda:0')]\n",
            "9.965039492425223 train: [0.7610000401396342, tensor(0.4281, device='cuda:0')]\n",
            "9.96516897578661 train: [0.760957372916904, tensor(0.4281, device='cuda:0')]\n",
            "9.965298459148 train: [0.7608549284671307, tensor(0.4282, device='cuda:0')]\n",
            "9.965427942509388 train: [0.7608909212338342, tensor(0.4282, device='cuda:0')]\n",
            "9.965557425870776 train: [0.7609864342840874, tensor(0.4281, device='cuda:0')]\n",
            "9.965686909232163 train: [0.760943791859466, tensor(0.4281, device='cuda:0')]\n",
            "9.965816392593553 train: [0.7608414043740167, tensor(0.4282, device='cuda:0')]\n",
            "9.96594587595494 train: [0.7609367238354945, tensor(0.4282, device='cuda:0')]\n",
            "9.966075359316328 train: [0.7608942669853687, tensor(0.4282, device='cuda:0')]\n",
            "9.966204842677715 train: [0.7607919274740055, tensor(0.4282, device='cuda:0')]\n",
            "9.966334326039105 train: [0.7608270866522531, tensor(0.4283, device='cuda:0')]\n",
            "9.966463809400492 train: [0.7607247836958658, tensor(0.4283, device='cuda:0')]\n",
            "9.96659329276188 train: [0.7606827821529775, tensor(0.4283, device='cuda:0')]\n",
            "9.966722776123268 train: [0.760580526099455, tensor(0.4284, device='cuda:0')]\n",
            "9.966852259484655 train: [0.7605387975599669, tensor(0.4284, device='cuda:0')]\n",
            "9.966981742846045 train: [0.7604970802363206, tensor(0.4284, device='cuda:0')]\n",
            "9.967111226207432 train: [0.7604552933713021, tensor(0.4284, device='cuda:0')]\n",
            "9.96724070956882 train: [0.7604134369929412, tensor(0.4285, device='cuda:0')]\n",
            "9.967370192930208 train: [0.7603714303982557, tensor(0.4285, device='cuda:0')]\n",
            "9.967499676291597 train: [0.7603291929276231, tensor(0.4285, device='cuda:0')]\n",
            "9.967629159652985 train: [0.7602868053833757, tensor(0.4285, device='cuda:0')]\n",
            "9.967758643014372 train: [0.7602441064290215, tensor(0.4285, device='cuda:0')]\n",
            "9.96788812637576 train: [0.7602010961899942, tensor(0.4285, device='cuda:0')]\n",
            "9.96801760973715 train: [0.7602970229612648, tensor(0.4284, device='cuda:0')]\n",
            "9.968147093098537 train: [0.7601949696695921, tensor(0.4285, device='cuda:0')]\n",
            "9.968276576459925 train: [0.7602911941350154, tensor(0.4285, device='cuda:0')]\n",
            "9.968406059821312 train: [0.7602473942204467, tensor(0.4285, device='cuda:0')]\n",
            "9.968535543182702 train: [0.7603438277307022, tensor(0.4284, device='cuda:0')]\n",
            "9.96866502654409 train: [0.7604402353666591, tensor(0.4284, device='cuda:0')]\n",
            "9.968794509905477 train: [0.7603962718619409, tensor(0.4284, device='cuda:0')]\n",
            "9.968923993266865 train: [0.7604927272047293, tensor(0.4283, device='cuda:0')]\n",
            "9.969053476628254 train: [0.7604486878616891, tensor(0.4283, device='cuda:0')]\n",
            "9.969182959989642 train: [0.7605451103100439, tensor(0.4283, device='cuda:0')]\n",
            "9.96931244335103 train: [0.7605010757525756, tensor(0.4283, device='cuda:0')]\n",
            "9.969441926712417 train: [0.7604570530006187, tensor(0.4283, device='cuda:0')]\n",
            "9.969571410073806 train: [0.7604129615023765, tensor(0.4283, device='cuda:0')]\n",
            "9.969700893435194 train: [0.7603688012854875, tensor(0.4283, device='cuda:0')]\n",
            "9.969830376796581 train: [0.7602669161452912, tensor(0.4284, device='cuda:0')]\n",
            "9.969959860157969 train: [0.7602225457838652, tensor(0.4284, device='cuda:0')]\n",
            "9.970089343519358 train: [0.760120707532588, tensor(0.4285, device='cuda:0')]\n",
            "9.970218826880746 train: [0.7600760466679717, tensor(0.4285, device='cuda:0')]\n",
            "9.970348310242134 train: [0.7600312368008983, tensor(0.4285, device='cuda:0')]\n",
            "9.970477793603521 train: [0.7601284712207985, tensor(0.4284, device='cuda:0')]\n",
            "9.97060727696491 train: [0.7602258405254539, tensor(0.4284, device='cuda:0')]\n",
            "9.970736760326298 train: [0.7601807068015652, tensor(0.4284, device='cuda:0')]\n",
            "9.970866243687686 train: [0.7602781234877424, tensor(0.4283, device='cuda:0')]\n",
            "9.970995727049074 train: [0.760232914418959, tensor(0.4283, device='cuda:0')]\n",
            "9.971125210410463 train: [0.7601876370317759, tensor(0.4283, device='cuda:0')]\n",
            "9.97125469377185 train: [0.7601422913536157, tensor(0.4284, device='cuda:0')]\n",
            "9.971384177133238 train: [0.7600967970156933, tensor(0.4284, device='cuda:0')]\n",
            "9.971513660494626 train: [0.7600512344631024, tensor(0.4284, device='cuda:0')]\n",
            "9.971643143856015 train: [0.7600054429738378, tensor(0.4284, device='cuda:0')]\n",
            "9.971772627217403 train: [0.7601035151829983, tensor(0.4283, device='cuda:0')]\n",
            "9.97190211057879 train: [0.760001883478869, tensor(0.4284, device='cuda:0')]\n",
            "9.972031593940178 train: [0.7599557152406418, tensor(0.4284, device='cuda:0')]\n",
            "9.972161077301566 train: [0.7600540760953389, tensor(0.4284, device='cuda:0')]\n",
            "9.972290560662955 train: [0.7600077525805523, tensor(0.4284, device='cuda:0')]\n",
            "9.97254952738573 train: [0.7599613611365248, tensor(0.4284, device='cuda:0')]\n",
            "9.972679010747118 train: [0.7598598163261111, tensor(0.4284, device='cuda:0')]\n",
            "9.972808494108508 train: [0.759903541056472, tensor(0.4285, device='cuda:0')]\n",
            "9.972937977469895 train: [0.7598020310990773, tensor(0.4285, device='cuda:0')]\n",
            "9.973067460831283 train: [0.7599006547245996, tensor(0.4285, device='cuda:0')]\n",
            "9.97319694419267 train: [0.7599441157133465, tensor(0.4285, device='cuda:0')]\n",
            "9.97332642755406 train: [0.7599871638659778, tensor(0.4285, device='cuda:0')]\n",
            "9.973455910915447 train: [0.7598856969549143, tensor(0.4286, device='cuda:0')]\n",
            "9.973585394276835 train: [0.7598399329195034, tensor(0.4286, device='cuda:0')]\n",
            "9.973714877638223 train: [0.7599376033153312, tensor(0.4285, device='cuda:0')]\n",
            "9.973844360999612 train: [0.759892245583057, tensor(0.4285, device='cuda:0')]\n",
            "9.973973844361 train: [0.7597908454969103, tensor(0.4286, device='cuda:0')]\n",
            "9.974103327722387 train: [0.7596894724688253, tensor(0.4287, device='cuda:0')]\n",
            "9.974232811083775 train: [0.7596446470168705, tensor(0.4287, device='cuda:0')]\n",
            "9.974362294445164 train: [0.7597415568791619, tensor(0.4286, device='cuda:0')]\n",
            "9.974491777806552 train: [0.7598382805927735, tensor(0.4286, device='cuda:0')]\n",
            "9.97462126116794 train: [0.7597939340630032, tensor(0.4286, device='cuda:0')]\n",
            "9.974750744529327 train: [0.7598903846153846, tensor(0.4285, device='cuda:0')]\n",
            "9.974880227890717 train: [0.7598462833160706, tensor(0.4285, device='cuda:0')]\n",
            "9.975009711252104 train: [0.7598023539876546, tensor(0.4286, device='cuda:0')]\n",
            "9.975139194613492 train: [0.7597584363690422, tensor(0.4286, device='cuda:0')]\n",
            "9.97526867797488 train: [0.7597145304555519, tensor(0.4286, device='cuda:0')]\n",
            "9.975398161336269 train: [0.7598106871060318, tensor(0.4285, device='cuda:0')]\n",
            "9.975527644697657 train: [0.7597667058660764, tensor(0.4285, device='cuda:0')]\n",
            "9.975657128059044 train: [0.759862910001947, tensor(0.4285, device='cuda:0')]\n",
            "9.975786611420432 train: [0.7598189335221918, tensor(0.4285, device='cuda:0')]\n",
            "9.975916094781821 train: [0.7597177457563744, tensor(0.4286, device='cuda:0')]\n",
            "9.976045578143209 train: [0.7596165849380313, tensor(0.4286, device='cuda:0')]\n",
            "9.976175061504597 train: [0.7595154510563993, tensor(0.4287, device='cuda:0')]\n",
            "9.976304544865984 train: [0.759414344100721, tensor(0.4288, device='cuda:0')]\n",
            "9.976434028227374 train: [0.7595105183067299, tensor(0.4287, device='cuda:0')]\n",
            "9.976563511588761 train: [0.759549402013677, tensor(0.4287, device='cuda:0')]\n",
            "9.976692994950149 train: [0.7595057481191463, tensor(0.4287, device='cuda:0')]\n",
            "9.976822478311536 train: [0.7594046962633562, tensor(0.4288, device='cuda:0')]\n",
            "9.976951961672926 train: [0.7595003408939737, tensor(0.4288, device='cuda:0')]\n",
            "9.977081445034313 train: [0.7595380062209671, tensor(0.4288, device='cuda:0')]\n",
            "9.977210928395701 train: [0.759436990393567, tensor(0.4288, device='cuda:0')]\n",
            "9.977340411757089 train: [0.7593360014320786, tensor(0.4289, device='cuda:0')]\n",
            "9.977469895118478 train: [0.7592936892086772, tensor(0.4289, device='cuda:0')]\n",
            "9.977599378479866 train: [0.7592515480232344, tensor(0.4289, device='cuda:0')]\n",
            "9.977728861841253 train: [0.759287224306997, tensor(0.4290, device='cuda:0')]\n",
            "9.977858345202641 train: [0.7591863089395984, tensor(0.4290, device='cuda:0')]\n",
            "9.977987828564029 train: [0.7591447578584206, tensor(0.4290, device='cuda:0')]\n",
            "9.978117311925418 train: [0.7592388054743555, tensor(0.4290, device='cuda:0')]\n",
            "9.978246795286806 train: [0.7591975778224035, tensor(0.4290, device='cuda:0')]\n",
            "9.978376278648193 train: [0.759291353945271, tensor(0.4289, device='cuda:0')]\n",
            "9.978505762009581 train: [0.7593850253379242, tensor(0.4289, device='cuda:0')]\n",
            "9.97863524537097 train: [0.7594785122331188, tensor(0.4288, device='cuda:0')]\n",
            "9.978764728732358 train: [0.7594380726331165, tensor(0.4288, device='cuda:0')]\n",
            "9.978894212093746 train: [0.7593978033467462, tensor(0.4288, device='cuda:0')]\n",
            "9.979023695455133 train: [0.7593576245289955, tensor(0.4288, device='cuda:0')]\n",
            "9.979153178816523 train: [0.7593174563772437, tensor(0.4289, device='cuda:0')]\n",
            "9.97928266217791 train: [0.7593500363687408, tensor(0.4289, device='cuda:0')]\n",
            "9.979412145539298 train: [0.7594430547474685, tensor(0.4288, device='cuda:0')]\n",
            "9.979541628900686 train: [0.7594029709841704, tensor(0.4288, device='cuda:0')]\n",
            "9.979671112262075 train: [0.7593629775802601, tensor(0.4288, device='cuda:0')]\n",
            "9.979800595623463 train: [0.7592622529513198, tensor(0.4289, device='cuda:0')]\n",
            "9.97993007898485 train: [0.7593550742195471, tensor(0.4288, device='cuda:0')]\n",
            "9.980059562346238 train: [0.7593871451450022, tensor(0.4289, device='cuda:0')]\n",
            "9.980189045707627 train: [0.7593474140964446, tensor(0.4289, device='cuda:0')]\n",
            "9.980318529069015 train: [0.7593788401625552, tensor(0.4289, device='cuda:0')]\n",
            "9.980448012430402 train: [0.7593395190523289, tensor(0.4289, device='cuda:0')]\n",
            "9.98057749579179 train: [0.7593003676658001, tensor(0.4289, device='cuda:0')]\n",
            "9.98070697915318 train: [0.7592613062957451, tensor(0.4289, device='cuda:0')]\n",
            "9.980836462514567 train: [0.759353484191375, tensor(0.4288, device='cuda:0')]\n",
            "9.980965945875955 train: [0.7594455580439037, tensor(0.4288, device='cuda:0')]\n",
            "9.981095429237342 train: [0.7595375278946779, tensor(0.4287, device='cuda:0')]\n",
            "9.981224912598732 train: [0.7595674668874172, tensor(0.4287, device='cuda:0')]\n",
            "9.98135439596012 train: [0.7596590778857615, tensor(0.4287, device='cuda:0')]\n",
            "9.981483879321507 train: [0.7596211141215776, tensor(0.4287, device='cuda:0')]\n",
            "9.981613362682895 train: [0.7597122163633401, tensor(0.4286, device='cuda:0')]\n",
            "9.981742846044284 train: [0.759611645511293, tensor(0.4287, device='cuda:0')]\n",
            "9.981872329405672 train: [0.7597023271648934, tensor(0.4287, device='cuda:0')]\n",
            "9.98200181276706 train: [0.7596655707893879, tensor(0.4287, device='cuda:0')]\n",
            "9.982131296128447 train: [0.7596290627131238, tensor(0.4287, device='cuda:0')]\n",
            "9.982260779489836 train: [0.759592643810939, tensor(0.4287, device='cuda:0')]\n",
            "9.982390262851224 train: [0.7596828824783498, tensor(0.4286, device='cuda:0')]\n",
            "9.982519746212612 train: [0.7596464660917785, tensor(0.4286, device='cuda:0')]\n",
            "9.982649229574 train: [0.7596100593378979, tensor(0.4286, device='cuda:0')]\n",
            "9.982778712935389 train: [0.7597004188452383, tensor(0.4286, device='cuda:0')]\n",
            "9.982908196296776 train: [0.7595999692328034, tensor(0.4287, device='cuda:0')]\n",
            "9.983037679658164 train: [0.7595632652646137, tensor(0.4287, device='cuda:0')]\n",
            "9.983167163019552 train: [0.7594628603386039, tensor(0.4288, device='cuda:0')]\n",
            "9.98329664638094 train: [0.7595534298176051, tensor(0.4287, device='cuda:0')]\n",
            "9.983426129742329 train: [0.7596439753585914, tensor(0.4286, device='cuda:0')]\n",
            "9.983555613103716 train: [0.7595435995690356, tensor(0.4287, device='cuda:0')]\n",
            "9.983685096465104 train: [0.7595067684990396, tensor(0.4287, device='cuda:0')]\n",
            "9.983814579826491 train: [0.7594698677725841, tensor(0.4287, device='cuda:0')]\n",
            "9.98394406318788 train: [0.7594328180404987, tensor(0.4287, device='cuda:0')]\n",
            "9.984073546549268 train: [0.7593955399955301, tensor(0.4288, device='cuda:0')]\n",
            "9.984203029910656 train: [0.7593579543723146, tensor(0.4288, device='cuda:0')]\n",
            "9.984332513272044 train: [0.7592576958623631, tensor(0.4288, device='cuda:0')]\n",
            "9.984461996633433 train: [0.7591574638233054, tensor(0.4289, device='cuda:0')]\n",
            "9.98459147999482 train: [0.759187270911177, tensor(0.4289, device='cuda:0')]\n",
            "9.984720963356208 train: [0.7590870746236079, tensor(0.4290, device='cuda:0')]\n",
            "9.984850446717596 train: [0.7590485235601031, tensor(0.4290, device='cuda:0')]\n",
            "9.984979930078985 train: [0.7590098240837537, tensor(0.4290, device='cuda:0')]\n",
            "9.985109413440373 train: [0.7589708969707732, tensor(0.4290, device='cuda:0')]\n",
            "9.98523889680176 train: [0.759062858309742, tensor(0.4290, device='cuda:0')]\n",
            "9.985368380163148 train: [0.7590235381622467, tensor(0.4290, device='cuda:0')]\n",
            "9.985497863524538 train: [0.7589234427464268, tensor(0.4291, device='cuda:0')]\n",
            "9.985627346885925 train: [0.7588233737270772, tensor(0.4291, device='cuda:0')]\n",
            "9.985756830247313 train: [0.7587233310937579, tensor(0.4292, device='cuda:0')]\n",
            "9.9858863136087 train: [0.7588158982133079, tensor(0.4291, device='cuda:0')]\n",
            "9.98601579697009 train: [0.7588484794334438, tensor(0.4292, device='cuda:0')]\n",
            "9.986145280331478 train: [0.7588085850381169, tensor(0.4292, device='cuda:0')]\n",
            "9.986274763692865 train: [0.758901025142666, tensor(0.4291, device='cuda:0')]\n",
            "9.986404247054253 train: [0.7589331072007702, tensor(0.4291, device='cuda:0')]\n",
            "9.986533730415642 train: [0.7589647058003911, tensor(0.4291, device='cuda:0')]\n",
            "9.98666321377703 train: [0.7588647367927778, tensor(0.4292, device='cuda:0')]\n",
            "9.986792697138418 train: [0.7589563293367373, tensor(0.4291, device='cuda:0')]\n",
            "9.986922180499805 train: [0.7590475812129008, tensor(0.4291, device='cuda:0')]\n",
            "9.987051663861195 train: [0.759076378690434, tensor(0.4291, device='cuda:0')]\n",
            "9.987181147222582 train: [0.7591668786962774, tensor(0.4290, device='cuda:0')]\n",
            "9.98731063058397 train: [0.7591303120665039, tensor(0.4291, device='cuda:0')]\n",
            "9.987440113945357 train: [0.7591562398758782, tensor(0.4291, device='cuda:0')]\n",
            "9.987569597306747 train: [0.759120791450292, tensor(0.4291, device='cuda:0')]\n",
            "9.987699080668134 train: [0.7590209071356275, tensor(0.4291, device='cuda:0')]\n",
            "9.987828564029522 train: [0.7589210491028509, tensor(0.4292, device='cuda:0')]\n",
            "9.98795804739091 train: [0.7588869104537268, tensor(0.4292, device='cuda:0')]\n",
            "9.9880875307523 train: [0.7587870963131962, tensor(0.4293, device='cuda:0')]\n",
            "9.988217014113687 train: [0.7588093342825638, tensor(0.4293, device='cuda:0')]\n",
            "9.988346497475074 train: [0.7588309342284933, tensor(0.4293, device='cuda:0')]\n",
            "9.988475980836462 train: [0.7587311668166832, tensor(0.4294, device='cuda:0')]\n",
            "9.988605464197851 train: [0.7587510333346816, tensor(0.4294, device='cuda:0')]\n",
            "9.988734947559239 train: [0.7586513026520667, tensor(0.4295, device='cuda:0')]\n",
            "9.988864430920627 train: [0.7587382287675526, tensor(0.4294, device='cuda:0')]\n",
            "9.988993914282014 train: [0.7587550066966542, tensor(0.4294, device='cuda:0')]\n",
            "9.989123397643402 train: [0.7588411857079328, tensor(0.4294, device='cuda:0')]\n",
            "9.989252881004791 train: [0.7589270262793565, tensor(0.4293, device='cuda:0')]\n",
            "9.989382364366179 train: [0.7590125285442917, tensor(0.4293, device='cuda:0')]\n",
            "9.989511847727567 train: [0.7590243680669213, tensor(0.4293, device='cuda:0')]\n",
            "9.989641331088954 train: [0.7589990340421233, tensor(0.4293, device='cuda:0')]\n",
            "9.989770814450344 train: [0.7590836251868536, tensor(0.4292, device='cuda:0')]\n",
            "9.989900297811731 train: [0.7591679574282223, tensor(0.4292, device='cuda:0')]\n",
            "9.990029781173119 train: [0.7590683029313166, tensor(0.4292, device='cuda:0')]\n",
            "9.990159264534507 train: [0.7591522206629177, tensor(0.4292, device='cuda:0')]\n",
            "9.990288747895896 train: [0.7591306720674339, tensor(0.4292, device='cuda:0')]\n",
            "9.990418231257284 train: [0.7590310616918837, tensor(0.4293, device='cuda:0')]\n",
            "9.990547714618671 train: [0.7590103231031629, tensor(0.4293, device='cuda:0')]\n",
            "9.990677197980059 train: [0.7590938102301739, tensor(0.4292, device='cuda:0')]\n",
            "9.990806681341448 train: [0.758994243885705, tensor(0.4293, device='cuda:0')]\n",
            "9.990936164702836 train: [0.7590776324085751, tensor(0.4292, device='cuda:0')]\n",
            "9.991065648064223 train: [0.7590574502209042, tensor(0.4293, device='cuda:0')]\n",
            "9.991195131425611 train: [0.759037194531573, tensor(0.4293, device='cuda:0')]\n",
            "9.991324614787 train: [0.7589376878201767, tensor(0.4293, device='cuda:0')]\n",
            "9.991454098148388 train: [0.7589169017262066, tensor(0.4293, device='cuda:0')]\n",
            "9.991583581509776 train: [0.7588174368635952, tensor(0.4294, device='cuda:0')]\n",
            "9.991713064871163 train: [0.7589010980010685, tensor(0.4294, device='cuda:0')]\n",
            "9.991842548232553 train: [0.7589848159571037, tensor(0.4293, device='cuda:0')]\n",
            "9.99197203159394 train: [0.7589626961372179, tensor(0.4293, device='cuda:0')]\n",
            "9.992101514955328 train: [0.7589401885038592, tensor(0.4293, device='cuda:0')]\n",
            "9.992230998316716 train: [0.7590241832905144, tensor(0.4293, device='cuda:0')]\n",
            "9.992360481678105 train: [0.7590006503858242, tensor(0.4293, device='cuda:0')]\n",
            "9.992489965039493 train: [0.7590848513310704, tensor(0.4292, device='cuda:0')]\n",
            "9.99261944840088 train: [0.7589854686587306, tensor(0.4293, device='cuda:0')]\n",
            "9.992748931762268 train: [0.7590698855569094, tensor(0.4292, device='cuda:0')]\n",
            "9.992878415123657 train: [0.7590446284736206, tensor(0.4293, device='cuda:0')]\n",
            "9.993007898485045 train: [0.7590556354635418, tensor(0.4293, device='cuda:0')]\n",
            "9.993137381846433 train: [0.7591403245978701, tensor(0.4292, device='cuda:0')]\n",
            "9.99326686520782 train: [0.7592249915709699, tensor(0.4292, device='cuda:0')]\n",
            "9.99339634856921 train: [0.7592361278831059, tensor(0.4292, device='cuda:0')]\n",
            "9.993525831930597 train: [0.7591368164209891, tensor(0.4292, device='cuda:0')]\n",
            "9.993655315291985 train: [0.759111570403831, tensor(0.4292, device='cuda:0')]\n",
            "9.993784798653373 train: [0.7590123012040921, tensor(0.4293, device='cuda:0')]\n",
            "9.993914282014762 train: [0.7589871566472883, tensor(0.4293, device='cuda:0')]\n",
            "9.99404376537615 train: [0.7589618615304162, tensor(0.4293, device='cuda:0')]\n",
            "9.994173248737537 train: [0.7589362587983911, tensor(0.4293, device='cuda:0')]\n",
            "9.994302732098925 train: [0.7589102700250344, tensor(0.4294, device='cuda:0')]\n",
            "9.994432215460312 train: [0.758883659752101, tensor(0.4294, device='cuda:0')]\n",
            "9.994561698821702 train: [0.7588564282232206, tensor(0.4294, device='cuda:0')]\n",
            "9.99469118218309 train: [0.7589417957679243, tensor(0.4293, device='cuda:0')]\n",
            "9.994820665544477 train: [0.7590273765261518, tensor(0.4293, device='cuda:0')]\n",
            "9.994950148905865 train: [0.7590429954384695, tensor(0.4293, device='cuda:0')]\n",
            "9.995079632267254 train: [0.7590588457268864, tensor(0.4293, device='cuda:0')]\n",
            "9.995209115628642 train: [0.7590297257016293, tensor(0.4293, device='cuda:0')]\n",
            "9.99533859899003 train: [0.759045573583617, tensor(0.4293, device='cuda:0')]\n",
            "9.995468082351417 train: [0.7591312418407311, tensor(0.4292, device='cuda:0')]\n",
            "9.995597565712806 train: [0.7592168092888054, tensor(0.4292, device='cuda:0')]\n",
            "9.995727049074194 train: [0.7593022759673113, tensor(0.4291, device='cuda:0')]\n",
            "9.995856532435582 train: [0.759203189150664, tensor(0.4292, device='cuda:0')]\n",
            "9.99598601579697 train: [0.7592172789615786, tensor(0.4292, device='cuda:0')]\n",
            "9.996115499158359 train: [0.7591182290882633, tensor(0.4293, device='cuda:0')]\n",
            "9.996244982519746 train: [0.7592030368861507, tensor(0.4292, device='cuda:0')]\n",
            "9.996374465881134 train: [0.7591765188720891, tensor(0.4292, device='cuda:0')]\n",
            "9.996503949242522 train: [0.7590775130662895, tensor(0.4293, device='cuda:0')]\n",
            "9.996633432603911 train: [0.7590514885101859, tensor(0.4293, device='cuda:0')]\n",
            "9.996762915965299 train: [0.7590255490923679, tensor(0.4293, device='cuda:0')]\n",
            "9.996892399326686 train: [0.7589995380955246, tensor(0.4293, device='cuda:0')]\n",
            "9.997021882688074 train: [0.7590114464686774, tensor(0.4294, device='cuda:0')]\n",
            "9.997151366049463 train: [0.7590960341707687, tensor(0.4293, device='cuda:0')]\n",
            "9.997280849410851 train: [0.7590697892233516, tensor(0.4293, device='cuda:0')]\n",
            "9.997410332772239 train: [0.7591543472813831, tensor(0.4293, device='cuda:0')]\n",
            "9.997539816133626 train: [0.759127944993386, tensor(0.4293, device='cuda:0')]\n",
            "9.997669299495016 train: [0.7590290615825492, tensor(0.4293, device='cuda:0')]\n",
            "9.997798782856403 train: [0.7590023694070972, tensor(0.4293, device='cuda:0')]\n",
            "9.99792826621779 train: [0.7589753711420758, tensor(0.4294, device='cuda:0')]\n",
            "9.998057749579178 train: [0.759060277694311, tensor(0.4293, device='cuda:0')]\n",
            "9.998187232940568 train: [0.7591452403783562, tensor(0.4292, device='cuda:0')]\n",
            "9.998316716301956 train: [0.7592302591722909, tensor(0.4292, device='cuda:0')]\n",
            "9.998446199663343 train: [0.7593153340542056, tensor(0.4291, device='cuda:0')]\n",
            "9.99857568302473 train: [0.7592872176951108, tensor(0.4291, device='cuda:0')]\n",
            "9.99870516638612 train: [0.7591884164956709, tensor(0.4292, device='cuda:0')]\n",
            "9.998834649747508 train: [0.7590896410056246, tensor(0.4293, device='cuda:0')]\n",
            "9.998964133108895 train: [0.7591748462689255, tensor(0.4292, device='cuda:0')]\n",
            "9.999093616470283 train: [0.7591462156307532, tensor(0.4292, device='cuda:0')]\n",
            "9.999223099831672 train: [0.7591174361225327, tensor(0.4292, device='cuda:0')]\n",
            "9.99935258319306 train: [0.759202838976693, tensor(0.4292, device='cuda:0')]\n",
            "9.999482066554448 train: [0.7591735126221457, tensor(0.4292, device='cuda:0')]\n",
            "9.999611549915835 train: [0.7591438813802552, tensor(0.4292, device='cuda:0')]\n",
            "9.999741033277225 train: [0.7592296380825726, tensor(0.4292, device='cuda:0')]\n",
            "9.999870516638612 train: [0.7592471843694387, tensor(0.4292, device='cuda:0')]\n",
            "1002.987012987013 \n",
            "1002.987012987013 valid: [1.420224849994366, tensor(0., device='cuda:0')]\n",
            "1002.987012987013 valid: [0.9728068571824294, tensor(0.2500, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.823667477338742, tensor(0.3333, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.9728067838228666, tensor(0.2500, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.957212653526893, tensor(0.3000, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.9468165666629107, tensor(0.3333, device='cuda:0')]\n",
            "1002.987012987013 valid: [1.014446300464672, tensor(0.2857, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8876405129065881, tensor(0.3750, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8473903297359108, tensor(0.3889, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7626512967623197, tensor(0.4500, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8224306973544034, tensor(0.4091, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7538948059082031, tensor(0.4583, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8051509518595137, tensor(0.4231, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8115570571396377, tensor(0.4286, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8521349002153445, tensor(0.4000, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.83171323629526, tensor(0.4063, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8136941210716558, tensor(0.4118, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7976771297617855, tensor(0.4167, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8304427915256516, tensor(0.3947, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.859931887113131, tensor(0.3750, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8440012390360291, tensor(0.3810, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.84631192934263, tensor(0.3864, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8323587270883414, tensor(0.3913, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8195682916885767, tensor(0.3958, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8435945951021635, tensor(0.3800, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8313558905787722, tensor(0.3846, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8200237567608173, tensor(0.3889, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8095010610727164, tensor(0.3929, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7997040685355189, tensor(0.3966, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8203880896935096, tensor(0.3833, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7939239577679126, tensor(0.4032, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8134958560650165, tensor(0.3906, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.804765323381046, tensor(0.3939, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8228670698485223, tensor(0.3824, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.81436767578125, tensor(0.3857, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8063404702732706, tensor(0.3889, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8229319360300805, tensor(0.3784, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8386501667470585, tensor(0.3684, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8400908400556275, tensor(0.3718, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8545941866361177, tensor(0.3625, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8683900528956086, tensor(0.3537, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8602233439574748, tensor(0.3571, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8524364819466961, tensor(0.3605, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.865340759704163, tensor(0.3523, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8577862600994925, tensor(0.3556, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8505602169993729, tensor(0.3587, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8324631911057693, tensor(0.3723, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8260658459785657, tensor(0.3750, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8092073593259419, tensor(0.3878, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.803531024639423, tensor(0.3900, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8053213266225961, tensor(0.3922, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8171464367025703, tensor(0.3846, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8116416100666727, tensor(0.3868, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8131822548021278, tensor(0.3889, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7983971228966347, tensor(0.4000, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7935220068627662, tensor(0.4018, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7796005681458755, tensor(0.4123, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.790645852329244, tensor(0.4052, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.801316720099617, tensor(0.3983, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7879614414312901, tensor(0.4083, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7983264514206336, tensor(0.4016, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.799883063910321, tensor(0.4032, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8097297938606532, tensor(0.3968, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8052869943472055, tensor(0.3984, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8066646779077293, tensor(0.4000, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8024029498333698, tensor(0.4015, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8116242050713978, tensor(0.3955, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8074148877174067, tensor(0.3971, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.795713222678024, tensor(0.4058, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.7971292684366414, tensor(0.4071, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8059052935400867, tensor(0.4014, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8020092564770299, tensor(0.4028, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8032808615359919, tensor(0.4041, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8116179722014683, tensor(0.3986, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8078016075721154, tensor(0.4000, device='cuda:0')]\n",
            "1002.987012987013 valid: [0.8040856735909033, tensor(0.4013, device='cuda:0')]\n",
            "train: [0.7593330615534563, tensor(0.4291, device='cuda:0')]\n",
            "valid: [0.8004662573754371, tensor(0.4026, device='cuda:0')]\n",
            "model parameters succesfully saved to /gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/checkpoints/ser-cnn-ffc-loss-bce_9.pt!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "rEqE3jYKufvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- look into model behavior"
      ],
      "metadata": {
        "id": "L9dvEdppuioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.recorder.plot()"
      ],
      "metadata": {
        "id": "xtPwjfXxQ2t2",
        "outputId": "3596506a-138c-46e3-88c9-7cc1038698d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.recorder.plot_lr()"
      ],
      "metadata": {
        "id": "utaoN0_qVEKR",
        "outputId": "00149dd4-9a20-46c3-b48b-1f8535a0e86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5f338fd3JnsCWUjYEpawCIQdwiaKGyqogAsKKBatLbVq3Z5a96W29efSqsUdd60KqAjWYnHDIiBCCEvYCSGQhC1sYUlCtvv5Yw7pkIIMMMk5M/N9XddczJw5Z+YDM8xnzjL3EWMMSimlFIDL7gBKKaWcQ0tBKaVULS0FpZRStbQUlFJK1dJSUEopVSvM7gB1JScnm7Zt29odQymlAsqSJUt2GWNSTvdxHFcKbdu2JSsry+4YSikVUERksz8eRzcfKaWUqqWloJRSqpaWglJKqVpaCkoppWppKSillKrlUymIyDARWSciuSJy3zHuv1lEckRkmYjME5EMr/vut5ZbJyIX+zO8Ukop/zphKYiIG3gJGA5kAOO8P/QtHxpjuhtjegFPA89ay2YAY4GuwDDgZevxlFJKOZAvv1PoD+QaY/IARGQKMApYfWQGY8x+r/ljgSPjcY8CphhjDgObRCTXerwf/ZBdNbCq6hqWF5aQu/MAO/Yfxhhwu6BxdDjx1qVlQjStk2KICtfuVyoQ+VIKqUCB1+1CYEDdmUTkVuBuIAI432vZhXWWTT3GshOBiQCtW7f2JbdqQOu2H+DNeXl8mbOdA4erfFqmWeNIOjZtRPe0eHqmxdO7dSLNGkfVc1Kl1Ony2y+ajTEvAS+JyLXAQ8CEk1h2MjAZIDMzU8/64xA79pfzxKw1zFy2lehwNyN6tuDcTk3pnhpP8/go3CJU1tRwoLyKkrJK9pVWULi3jC27S8nfXcra7ft5fW4eVTWel7Rj0ziGnJHCOWekMLBdEyLC9DgHpZzGl1IoAlp53U6zph3PFOCVU1xWOcSsnG3c+8kKDlfXcNt5HfjV2ekkxET8z3yRLjeRcW6S4yIB6Nvm6PvLK6tZvW0/Wfl7mLt+F+//uJk3520iPjqc4d2aM6JnSwa2a4LbJQ3x11JKnYCc6HScIhIGrAcuwPOBvhi41hizymuejsaYDdb1EcCjxphMEekKfIhnP0JL4FugozGm+njPl5mZaXTsI/tU1xiemLWGN+dtonfrBJ67phdtk2P99vhlFdXMz93Fv3K28dWq7RyqqCY1IZprB7TmmsxWpDSK9NtzKRVKRGSJMSbzdB/nhGsKxpgqEbkNmA24gbeMMatE5HEgyxjzOXCbiAwFKoG9WJuOrPmm4dkpXQXc+nOFoOxVUVXD3dOW8cWKbdxwZlseuKSL3zfxREe4GZrRjKEZzSivrObbNTv5cNFmnpm9jue/Wc+l3Vvw23M70Kl5I78+r1LKNydcU2houqZgj8rqGn7z/hK+W7uTBy7pzMQh7Rv0+XN3HuQfCzczLauA0opqLu7ajNvO60j3tPgGzaFUoPLXmoKWgqKmxnDXtGXMXLaVP1/ejfED25x4oXqy91AFby/I5535m9hfXsWwrs25d3hn0v24CUupYKSloPzmz1+s5o15m7jn4k7cel4Hu+MAcKC8krfm5fPa3I1UVNUwfmAbbr+gI0mx/7uzWynlv1LQYwJD3GdLC3lj3iYmDGrDLec27Cajn9MoKpw7hnbk+3vO5Zp+rXjvx3zOfWYOHy3aQk2Ns77IKBVMtBRC2MqiEu77NIcB6Uk8dFkGIs47LLRpoyieuKI7/75zCF1aNOb+6Tlc89qPrN9xwO5oSgUlLYUQdfBwFbd8kE1iTAQvXtuHcLez3wpnNGvElIkDeWZ0D3KLD3LJ33/g2a/XU1ldY3c0pYKKsz8JVL350z9XU7C3lEnjegfMbwNEhKszW/Ht3ecwomdLJn27gdGvLGBj8UG7oykVNLQUQtBXq7YzNauAm89pT//0JLvjnLQmcZE8N6YXL1/Xh817Srl00g+8/2M+TjtoQqlApKUQYvYcquD+6TlktGjMXUPPsDvOabmkewu+unMIA9Kb8PDMVfzm/SWUlFXaHUupgKalEGKe/HINJWWVPDumZ1AMSNe0cRTv3NiPhy/L4Lu1Oxn54jxWbS2xO5ZSASvwPxWUzxZt2sO0rEJuOjudzs0b2x3Hb0SEm85KZ+pvBnK4soYrXl7A1MVb7I6lVEDSUggRFVU1PDQjh9SEaO64oKPdcepF3zZJ/Ov2sxiQnsS9n+bw0IwcPTpJqZOkpRAi3p6/ifU7DvLHkV2JifDbaTQcp0lcJO/c2J+bz2nPPxZu4ca3F1NSqvsZlPKVlkII2HOoghe/y+X8zk0ZmtHM7jj1zu0S7hvemWdG9+CnTbu54uX5bNp1yO5YSgUELYUQMOnbDRyqqOL+4Z3tjtKgrs5sxYe/Hsi+skouf2k+izbtsTuSUo6npRDk8oo9Q1KP7d+ajs1C7xwF/domMfPWwTSJi+D6N3/iq1Xb7Y6klKNpKQS5p/69lsgwF3cODc6dy75olRTDJzefSecWjbn5H0uYskiPTFLqeLQUgtiSzXuZvWoHvzmnPU0bRdkdx1ZJsRF89OsBnN0xhfum5/Didxv0F9BKHYOWQhB7/pv1JMVG8Kuz0+2O4ggxEWG8MSGTK3qn8tev1vPkl2u1GJSqI3iPTQxxWfl7+GHDLu4f3jmoD0E9WeFuF3+7uidxkWG8NjePiuoaHnHosOFK2UE/LYLU899sIDkugusH2XdqTadyuYTHR3Ul3O3irfmbqKyu4fGR3XC5tBiU0lIIQovz9zAvdxcPXtJF1xKOQ0R4+LIuRIS5ePU/G6msMjxxZXfcWgwqxOknRhB67uv1JMdFMn6griX8HBHh3mGdiHALk77LpdoYnr6qh64xqJCmpRBksrfsZcHG3Tx0aReiI9x2x3E8EeHuizohIvz92w1Eh7t5fFRX3cegQpaWQpCZ/J884qPDGde/td1RAsqdQztSXlnNa3PziI5wc//wzloMKiRpKQSRvOKDzF69nVvP7UBspL60J0PEM15SWWU1k+fmER3u5q4LA/skREqdCv3kCCKv/7CJcLeLCWe2tTtKQBIRHhvRlbKKas+mpAg3N5/T3u5YSjUoLYUgsfNAOZ9mFzK6bxopjSLtjhOwXC7hyat6UF5Vw5NfrqVxVDjXDtBNcSp0aCkEiXcX5FNZXcOvz25nd5SA53YJz17TkwPllTw0I4fkuAgu6trc7lhKNQgd5iIIHDpcxfs/bmZY1+akJ8faHScohLtdvHxdH7qnJfC7j5aSla/DbqvQoKUQBD7NLmR/eRW/HqJrCf4UExHG2zf0IzUhmpvezWL9jgN2R1Kq3mkpBLiaGsO7C/LpmRZPn9aJdscJOkmxEbz7y/5EhLmY8NYitpWU2R1JqXrlUymIyDARWSciuSJy3zHuv1tEVovIChH5VkTaeN1XLSLLrMvn/gyvYF7uLjYWH+KGwW3tjhK0WiXF8O6N/TlYXsUNby1mf7me81kFrxOWgoi4gZeA4UAGME5EMurMthTINMb0AD4Bnva6r8wY08u6jPRTbmV5d0E+yXERXNK9hd1RglpGy8a8en1fNhYf5LYPl1JVXWN3JKXqhS9rCv2BXGNMnjGmApgCjPKewRgzxxhTat1cCKT5N6Y6li27S/lu3U6u7d+ayDAd0qK+De6QzJ8v78bc9cU89s9Vei4GFZR8KYVUoMDrdqE17XhuAr70uh0lIlkislBELj/WAiIy0Zonq7i42IdICuC9H/Nxi3CdDnzXYMb2b81vzmnHPxZu4e35+XbHUcrv/Po7BREZD2QC53hNbmOMKRKRdsB3IpJjjNnovZwxZjIwGSAzM1O/fvng0OEqpmYVMKxbc5o1Du1TbTa0ey/uzOZdpfzpX6tpnRTD0IxmdkdSym98WVMoAlp53U6zph1FRIYCDwIjjTGHj0w3xhRZf+YB3wO9TyOvsny2tIgD5VXcqDuYG5zLJTw3phfdU+O5fcpSVhaV2B1JKb/xpRQWAx1FJF1EIoCxwFFHEYlIb+A1PIWw02t6oohEWteTgcHAan+FD1XGGN7/cTNdWzbWw1BtEh3h5o1fZJIQHc7E97LYdfDwiRdSKgCcsBSMMVXAbcBsYA0wzRizSkQeF5EjRxM9A8QBH9c59LQLkCUiy4E5wJPGGC2F05S9ZR/rdhxg/MA2OryzjZo2jmLyLzLZU1rBLf/IpqJKj0hSgc+nfQrGmFnArDrTHvG6PvQ4yy0Aup9OQPW/Plq0hdgINyN7trQ7SsjrlhrPU1f14I4py3j8i1X8+XJ9u6vApgPiBZiSskq+WLGVK/uk6TkTHGJUr1RWb93Pa3Pz6NoyXk9wpAKaDnMRYGYsLaK8soZr9YPHUf4wrDNDzkjhkZkrdfA8FdC0FAKIMYaPFm2he2o83VLj7Y6jvLhdwgtje5OaEM3N/8jWMZJUwNJSCCBLC/axdvsB3TzhUPEx4Uz+RSZlFVX85v0llFdW2x1JqZOmpRBAPvrJ2sHcS3cwO9UZzRrx7JherCgs4bHPV9kdR6mTpqUQIErKKvnniq2M7JVKnO5gdrSLuzbnlnPbM2VxAR9nFZx4AaUcREshQMxcpjuYA8ndF57BoHZNeGjGSlZv3W93HKV8pqUQAIwxfPjTFrqlNqZ7mu5gDgRhbheTxvUmPjqcWz5YoudgUAFDSyEArCzaz9rtBxjTT9cSAklKo0heuq4PBXvL+P205TrUtgoIWgoB4OMlBUSEuRjZQ3cwB5p+bZO4f3hnvlq9g9d/yLM7jlInpKXgcIerqpm5bCsXd21OfEy43XHUKbjprHQu6d6cp/69jp/ydtsdR6mfpaXgcN+s3klJWSWj++rJ7AKViPDUVT1okxTDbR8tZeeBcrsjKXVcWgoO9/GSAlrER3FWh2S7o6jT0CgqnFfG9+VAeSV3TV1GdY3uX1DOpKXgYNtLypm7vpgr+6TidukQ2YGuU/NG/HFkV+bn7uaV73PtjqPUMWkpONhnS4uoMTC6b6sTz6wCwjWZrRjZsyXPfr2exTpwnnIgLQWHMsbw8ZICMtskkp4ca3cc5Sciwl+u6EarpBhu/2gpew9V2B1JqaNoKThU9pZ95BUf4upM3cEcbBpFhfPiuD7sOniYez5Zob9fUI6ipeBQnywpIDrczaX624Sg1D0tnvuHd+GbNTt4e36+3XGUqqWl4EBlFdX8c/k2hndvroPfBbEbB7dlaJdm/N+Xa8gpLLE7jlKAloIjzV61nYOHq7hadzAHNRHhmdE9SI6L5LaPsjmg4yMpB9BScKCPlxSQlhjNgPQku6OoepYYG8Gkcb0p3FvGg5+t1P0LynZaCg5TuLeUBRt3M7pvGi79bUJI6Nc2ibuGduTz5Vv5bGmR3XFUiNNScJjp2UUYA1f10aOOQslvz+1A//QkHpm5ii27S+2Oo0KYloKDGGP4NLuQQe2a0Copxu44qgG5XcJzY3ohAndMXUpldY3dkVSI0lJwkCWb97J5dylX6eB3ISk1IZonrujO0i37eOE7HQZD2UNLwUE+zS4kOtzNsG7N7Y6ibDKiZ0uu6pPGi99t0GEwlC20FByivLKaL1ZsY3g3/W1CqPvjqK6kJcZw55RlehpP1eC0FBzi69U7OFBepZuOFHGRYTw/thfb95fz8IyVdsdRIUZLwSGmZxfSIj6Kge2a2B1FOUCf1onccUFHZi7bymdLC+2Oo0KIloID7DxQztwNu7iit543Qf3Xred1oF/bRB6esYqCPXqYqmoYPpWCiAwTkXUikisi9x3j/rtFZLWIrBCRb0Wkjdd9E0Rkg3WZ4M/wwWLm0q1U1xiu1N8mKC+1h6kCd0xZSpUepqoawAlLQUTcwEvAcCADGCciGXVmWwpkGmN6AJ8AT1vLJgGPAgOA/sCjIpLov/jB4dPsQnq2SqBD0zi7oyiHSUuM4c9XdCN7yz5enKOHqar658uaQn8g1xiTZ4ypAKYAo7xnMMbMMcYcWb9dCBz5ynsx8LUxZo8xZi/wNTDMP9GDw6qtJazdfoCr+qTaHUU51KheqVzeqyUvfJfL8oJ9dsdRQc6XUkgFCrxuF1rTjucm4MuTWVZEJopIlohkFRcX+xApeEzPLiLcLYzQ8yaon/HHUd1o2iiSu6Yto6yi2u44Koj5dUeziIwHMoFnTmY5Y8xkY0ymMSYzJSXFn5EcrbK6hpnLiji/c1MSYyPsjqMcLD46nL9e3ZO84kM89e+1dsdRQcyXUigCvAf2T7OmHUVEhgIPAiONMYdPZtlQ9cOGYnYdrNDB75RPBndI5sbBbXlnQT4/bAitNWrVcHwphcVARxFJF5EIYCzwufcMItIbeA1PIez0ums2cJGIJFo7mC+yping0yVFJMaEc26npnZHUQHi3mGd6dA0jns+XkFJqf7aWfnfCUvBGFMF3Ibnw3wNMM0Ys0pEHheRkdZszwBxwMciskxEPreW3QP8CU+xLAYet6aFvJLSSr5es4NRvVKJCNOfiyjfRIW7ee6aXuw6eJiHZ+qvnZX/+TTIjjFmFjCrzrRHvK4P/Zll3wLeOtWAweqLnK1UVNVwpR51pE5S97R4br+gI89+vZ4LM5oxoqcepKD8R7+i2mR6dhEdm8bRPTXe7igqAN1ybnt6tUrgoRkr2V5SbnccFUS0FGywadchlmzey1V90xDRYS3UyQtzu3j2mp5UVNXwh09X6Lmdld9oKdjgs+xCXAKX99JNR+rUtUuJ44FLuzB3fTH/WLjZ7jgqSGgpNLCaGsOn2UUM7pBM8/gou+OoADd+QGvOOSOFv8xaQ17xQbvjqCCgpdDAftq0h6J9ZfrbBOUXIsLTo3sQFe7mrmnLddA8ddq0FBrY9OxCYiPcXNxVT7mp/KNZ4yj+fHk3lhfs46U5G+2OowKclkIDKq2oYlbONi7p3oLoCLfdcVQQuaxHSy7v1ZJJ321gRaEOmqdOnZZCA/pq1Q4OVVTrKTdVvagdNG/qMsorddA8dWq0FBrQp9mFpCZE079tkt1RVBA6MmjexuJDPPmlDpqnTo2WQgMp2lfGvNxdXNU3DZeeclPVk8EdkrnhTM+gefM27LI7jgpAWgoN5NMlhRgDV+umI1XP7hvemfYpsdzzyXJKynTQPHVytBQaQE2N4ZMlhQxq14RWSTF2x1FBLirczXNjelF84DCP6qB56iRpKTSAnzbtYcueUq7pp2sJqmH0SEvg9gs6MmPZVr5YsdXuOCqAaCk0gI+XFNAoMoxhXVvYHUWFkCOD5j342Up27NdB85RvtBTq2YHySmblbOOyni31twmqQR0ZNO9wVTX3fKKD5infaCnUs3+t2EZ5ZQ3XZOqmI9Xw2qXE8eAl1qB5P22xO44KAFoK9WxaVgEdmsbRq1WC3VFUiBo/sA1DzkjhiX/poHnqxLQU6lHuzoNkb9nHNZl63gRlHxHhmdE9iAx36aB56oS0FOrRx0sKcLuEy3vreROUvbwHzXv5ex00Tx2flkI9qaquYXp2Eed1akrTRnreBGW/y3q0ZFSvlkz6dgM5hSV2x1EOpaVQT/6zvpjiA4e5WncwKwd5fGQ3kuMiuXPqUh00Tx2TlkI9+WjRFlIaRXJ+56Z2R1GqVnzMfwfNe+rfOmie+l9aCvVg674yvlu7k2sy0wh36z+xcpazOnoGzXt7vg6ap/6XfmLVg2lZBRhgbL/WdkdR6ph00Dx1PFoKflZVXcPUxQWc3TFFB79TjqWD5qnj0VLws+/XFbOtpJxr++tagnK2HmkJ/O58HTRPHU1Lwc+O7GC+oIvuYFbOd+t57empg+YpL1oKfrR1Xxlz1u1kTGYr3cGsAkKY28VzOmie8qKfXH40dbFnB/OYfq3sjqKUz3TQPOVNS8FPjuxgHqI7mFUA8h40b9OuQ3bHUTbSUvCTb9fuZPv+cq4doDuYVeA5MmheRJiLu6Yu00HzQphPpSAiw0RknYjkish9x7h/iIhki0iViIyuc1+1iCyzLp/7K7jTvLsgn9SEaC7QXzCrANWscRR/uaIby3TQvJB2wlIQETfwEjAcyADGiUhGndm2ADcAHx7jIcqMMb2sy8jTzOtI63ccYMHG3Ywf2IYw3cGsApgOmqd8+QTrD+QaY/KMMRXAFGCU9wzGmHxjzAogJNc531mQT2SYi7G6g1kFAR00L7T5UgqpQIHX7UJrmq+iRCRLRBaKyOXHmkFEJlrzZBUXF5/EQ9uvpLSSz7KLuLxXKomxEXbHUeq06aB5oa0htnW0McZkAtcCz4tI+7ozGGMmG2MyjTGZKSkpDRDJf6ZlFVBWWc2EM9vaHUUpv9FB80KXL6VQBHhvF0mzpvnEGFNk/ZkHfA/0Pol8jlZdY3hvYT792yaR0bKx3XGU8qt7h3kNmleqg+aFCl9KYTHQUUTSRSQCGAv4dBSRiCSKSKR1PRkYDKw+1bBOM2ftTgr2lHHD4LZ2R1HK76Ij/jto3kMzV+qvnUPECUvBGFMF3AbMBtYA04wxq0TkcREZCSAi/USkELgaeE1EVlmLdwGyRGQ5MAd40hgTNKXw1vxNtIiP4qKMZnZHUape9EhL4K4Lz+Cfy7cyPdvnDQQqgIX5MpMxZhYwq860R7yuL8azWanucguA7qeZ0ZFyCktYsHE3D1zSWQ9DVUHt5nPaM3d9MY/MXElm20TaNIm1O5KqR/ppdopem7uRRpFhjNMhslWQc7uE58b0Iszt4vYpy6jUXzsHNS2FU7BldymzcrZx7cDWNIoKtzuOUvWuZUI0/3dld5YX7OP5b9bbHUfVIy2FU/DGvDzcLuGXg9PtjqJUg7mkewvGZLbi5e83sjBvt91xVD3RUjhJuw8eZlpWAVf0TqVZ4yi74yjVoB4ZkUHbJrHcNXUZ+0or7I6j6oGWwkl698fNlFfWMHFIO7ujKNXgYiPDmDS2N7sOHuaBz3L0MNUgpKVwEkrKKnln/iYuzGhGh6aN7I6jlC26p8Xz/y7qxKyc7UzLKjjxAiqgaCmchHfm57O/vIo7LuhodxSlbDXx7Hac2b4Jj32+mo3FB+2Oo/xIS8FHJWWVvDkvjwszmtEtNd7uOErZyuUSnr2mF1HhLn73oY6mGky0FHykawlKHa15fBR/u6Ynq7ft5y//WmN3HOUnWgo+2F/uWUsY2kXXEpTydn7nZvz67HTeX7iZWTnb7I6j/EBLwQdvzM3TtQSljuOeizvTq1UC936ygi27S+2Oo06TlsIJ7Nhfzus/bOLSHi3onqZrCUrVFRHm4oVxvUHgdx9lU1Glw2AEMi2FE3j+m/VU1dTwh4s72R1FKcdqlRTDM6N7sLywRM/WFuC0FH7Ghh0HmLq4gOsGtNGRIZU6gWHdWjBhUBvenLeJr1fvsDuOOkVaCj/jyS/XEhsRxu26L0EpnzxwaRe6pTbm9x8vp2hfmd1x1CnQUjiOOWt38u3andxyXgeSYiPsjqNUQIgMc/PiuD5U1xh+92G2DrMdgLQUjqG8sprH/rmKdimx3HSWjoSq1MlomxzLE1d2J3vLPp6Zvc7uOOokaSkcw6v/2cjm3aX8aVQ3IsL0n0ipkzWyZ0uuG9CayXPz+PdK/f1CINFPvDrydx3i5e83clmPFgzukGx3HKUC1iMjMujZKoHff7xCx0cKIFoKXqprDPd8spzIMBcPX5ZhdxylAlpkmJuXr+tDRJiLm99fwqHDVXZHUj7QUvDy9vxNLM7fy2MjuuoJdJTyg9SEaCaN7c3G4oPc++kKPf9CANBSsOTuPMDTs9dxYUYzruyTanccpYLGWR2T+X8XdeKLFdt4e36+3XHUCWgpAGUV1dz6wVLiIsN44oruiIjdkZQKKr89pz1DuzTjiVlryMrfY3cc9TNCvhSMMTw4I4f1Ow/w/JhepDSKtDuSUkHH5RL+dk1PUhOjueWDbHYeKLc7kjqOkC+FD37awvTsIu64oCNDzkixO45SQSs+OpxXx/dlf3klt32wVAfOc6iQLoU563by6OerOLdTCr87X4eyUKq+dWnRmKeu6sGi/D08+vkq3fHsQGF2B7DL8oJ93PpBNp2bN+LFa/vgdul+BKUawqheqazdfoBXvt9IRotGXD+ord2RlJeQXFNYumUv49/8iaTYCN6+oR9xkSHbjUrZ4p6LOjG0S1Me++dqFuTusjuO8hJypTA/dxfXv7mIxJgIpkwcSFP9PYJSDc7lEp4b04t2ybHc8mE2m3cfsjuSsoRMKRhjeGveJn7x1iJaJkQx7TeDSEuMsTuWUiGrUVQ4b0zIxBj41btZHCivtDuSwsdSEJFhIrJORHJF5L5j3D9ERLJFpEpERte5b4KIbLAuE/wV/GQU7i3lF28t4vEvVnNB56ZMv2UwzeN1DUEpu7VpEssr1/Uhb9ch7pq6jJoa3fFstxOWgoi4gZeA4UAGME5E6g4MtAW4AfiwzrJJwKPAAKA/8KiIJJ5+bN9s3n2Ixz5fxfl/+w9LNu/lT6O68ur4vroPQSkHObNDMo+OyOCbNTv1VJ4O4MunY38g1xiTByAiU4BRwOojMxhj8q376h54fDHwtTFmj3X/18Aw4KPTTl5HaUUVs1dtZ++hSgr2lpKVv5ecohLcLuGqPqncfkFH3VyklENdP7ANG3Yc5LW5ebRKimH8wDZ2RwpZvpRCKlDgdbsQzzd/Xxxr2f8ZWEhEJgITAVq3bu3jQx+tvLKGu6YuByAq3EWP1ATuHdaZy3u3pEV89Ck9plKqYYgIj47IoGhfGY/MXElqQjTndW5qd6yQ5IjtKMaYycBkgMzMzFPaqJgQHc6c359LQnQ4jaPD9XcHSgWYMLeLF8b1ZszkH7n1w2ym/WYQ3VLj7Y4VcnzZ0VwEtPK6nWZN88XpLHtSXC4hPTmWxNgILQSlAlRsZBhvTehHYkwEN76zmKJ9ZXZHCjm+lMJioKOIpItIBDAW+NzHx58NXCQiidYO5ousaUopdUxNG0fx9o39KK+s5sa3F1FSpoeqNqQTloIxpgq4Dc+H+RpgmjFmlYg8LiIjAUSkn4gUAlcDr4nIKmvZPcCf8BTLYuDxIzudlVLqeM5o1ojXxvdl065D3Pz+Esorq+2OFDLEaVh6EKIAAAvzSURBVANSZWZmmqysLLtjKKUcYMbSIu6cuoyLMprx8nV9CHOHzO9tT5qILDHGZJ7u4+i/sFLKsS7vncpjIzL4avUO7p+eo6OqNgBHHH2klFLHc8PgdPaWVvL3bzeQEBPOA5d00bMj1iMtBaWU4905tCP7Sit4/YdNJMREcOt5HeyOFLS0FJRSjuf5cVtXSsoqeWb2OhpHh3O9/uq5XmgpKKUCgsslPHN1Tw4eruLhGSsJcwnj+p/aCAjq+HRHs1IqYIS7Xbx0XR/O65TC/dNzmLp4i92Rgo6WglIqoESGuXllfF/OOSOF+6bnMG1xwYkXUj7TUlBKBZyocDevXd+Xszokc+/0FXycpcXgL1oKSqmAFBXu5vVfZDK4fTJ/+HQFUxbppiR/0FJQSgWsI8UwpKNnU9Lrc/PsjhTwtBSUUgEtOsJTDJd2b8FfZq3hb1+t018+nwY9JFUpFfAiwlxMGtebuMgwXvgul/1llTw6oisuHUb/pGkpKKWCgtslPHlVdxpHh/H6D5vYU1rJM6N7EBXutjtaQNFSUEoFDRHhgUu60CQukie/XMv2kjImX59JYmyE3dEChu5TUEoFFRHh5nPa88K43iwvLOHKVxaQv+uQ3bEChpaCUioojejZkg9/NYB9pRVc+coCsvL1/F6+0FJQSgWtzLZJTL9lMI2jwhj3+kI+/El/y3AiWgpKqaCWnhzLjFsHM6h9Mg98lsN9n67Q03v+DC0FpVTQS4iJ4O0b+nHbeR2YsriAMZMXsnVfmd2xHElLQSkVEtwu4fcXd+LV8X3ZuPMgl076ga9X77A7luNoKSilQsqwbs2ZedtgWiZE8+v3snh4xkrdnORFS0EpFXLap8Qx/ZYz+fXZ6by/cDMjXpjH6q377Y7lCFoKSqmQFBnm5sFLM3jvl/3ZW1rJyBfn8exX6zhcFdprDVoKSqmQNuSMFL66awgjerZk0ne5XDppHks277U7lm20FJRSIS8pNoLnxvTi7Rv7UXq4itGvLuCBz3LYffCw3dEanJaCUkpZzuvUlK/uPocbzmzL1MUFnPvX73njhzwqqmrsjtZgtBSUUspLXGQYj47oyuw7z6ZP60T+/K81XPz8XGYuK6K6JvjP06CloJRSx9ChaSPe/WV/3r6xHxFuF3dMWcbFz8/l8+Vbg7ocxGlnKMrMzDRZWVl2x1BKqVo1NYYvV27n79+uZ/2Og6QnxzJhUBuu6ptGo6hwu+MBICJLjDGZp/04WgpKKeWbI+Xwxrw8lm7ZR1xkGKP7pjG6bxpdWzZGxL4zvWkpKKWUjZYV7OOd+ZuYlbOdiuoaOjSN44reqQzv1pz05NgGL4gGLQURGQb8HXADbxhjnqxzfyTwHtAX2A2MMcbki0hbYA2wzpp1oTHm5p97Li0FpVQg2Vdawayc7Xy2tJDF+Z7fN7RpEsN5nZpydsdkerdOJKkBzvzWYKUgIm5gPXAhUAgsBsYZY1Z7zXML0MMYc7OIjAWuMMaMsUrhC2NMN18DaSkopQJV4d5S5qzdyZx1xSzYuIvySs+hrOnJsfRMi6dD0zjapcSRnhxL00aRJMRE4Hb5Z43CX6Xgyzma+wO5xpg864mnAKOA1V7zjAIes65/Arwodm5cU0opG6QlxnD9oLZcP6gt5ZXVLC/YR/aWfWRv2cvCvD3MWLb1qPlFIDEmgpgINxFuFxktG/PitX1sSu/hSymkAgVetwuBAcebxxhTJSIlQBPrvnQRWQrsBx4yxvxQ9wlEZCIwEaB169Yn9RdQSiknigp3M6BdEwa0a1I77dDhKjbtOkT+7kPsOnCYPYcq2H2ogrLKaiqrDa0So21M7OFLKZyObUBrY8xuEekLzBCRrsaYo4YjNMZMBiaDZ/NRPWdSSilbxEaG0S01nm6p8XZHOS5ffrxWBLTyup1mTTvmPCISBsQDu40xh40xuwGMMUuAjcAZpxtaKaVU/fClFBYDHUUkXUQigLHA53Xm+RyYYF0fDXxnjDEikmLtqEZE2gEdgTz/RFdKKeVvJ9x8ZO0juA2YjeeQ1LeMMatE5HEgyxjzOfAm8L6I5AJ78BQHwBDgcRGpBGqAm40xe+rjL6KUUur06Y/XlFIqCPjrkFQdEE8ppVQtLQWllFK1tBSUUkrV0lJQSilVy3E7mkWkGNh8Gg+RDOzyUxx/02ynzsn5nJwNnJ3PydnA2fnqZmtjjEk53Qd1XCmcLhHJ8sce+Pqg2U6dk/M5ORs4O5+Ts4Gz89VXNt18pJRSqpaWglJKqVrBWAqT7Q7wMzTbqXNyPidnA2fnc3I2cHa+eskWdPsUlFJKnbpgXFNQSil1irQUlFJK1QqaUhCRYSKyTkRyReS+en6ut0Rkp4is9JqWJCJfi8gG689Ea7qIyCQr1woR6eO1zARr/g0iMsFrel8RybGWmXQypzYVkVYiMkdEVovIKhG5wyn5RCRKRBaJyHIr2x+t6eki8pP1eFOtIdoRkUjrdq51f1uvx7rfmr5ORC72mn5a7wMRcYvIUhH5woHZ8q1/92UikmVNs/11tZZNEJFPRGStiKwRkUEOytbJ+jc7ctkvInc6KN9d1v+HlSLykXj+n9j3vjPGBPwFz5DeG4F2QASwHMiox+cbAvQBVnpNexq4z7p+H/CUdf0S4EtAgIHAT9b0JDznlkgCEq3ridZ9i6x5xVp2+ElkawH0sa43AtYDGU7IZ80fZ10PB36yHmcaMNaa/irwW+v6LcCr1vWxwFTreob1GkcC6dZr7/bH+wC4G/gQ+MK67aRs+UBynWm2v67Wsu8Cv7KuRwAJTsl2jM+K7UAbJ+TDcyrjTUC01/vtBjvfd7Z/oPvjAgwCZnvdvh+4v56fsy1Hl8I6oIV1vQWwzrr+GjCu7nzAOOA1r+mvWdNaAGu9ph813ynknAlc6LR8QAyQjed837uAsLqvJZ5zeAyyrodZ80nd1/fIfKf7PsBzVsFvgfOBL6znckQ2a5l8/rcUbH9d8ZxpcRPWgStOynaMrBcB852Sj/+e3z7Jeh99AVxs5/suWDYfHfmHPaLQmtaQmhljtlnXtwPNrOvHy/Zz0wuPMf2kWauWvfF8I3dEPvFsnlkG7AS+xvMtZp8xpuoYj1ebwbq/BGhyCpl99TzwBzwnhMJ6LqdkAzDAVyKyREQmWtOc8LqmA8XA2+LZ9PaGiMQ6JFtdY4GPrOu25zPGFAF/BbbgOad9CbAEG993wVIKjmI8lWzrsb4iEgd8CtxpjNnvfZ+d+Ywx1caYXni+lfcHOtuRoy4RuQzYaTznEneqs4wxfYDhwK0iMsT7Thtf1zA8m1NfMcb0Bg7h2RzjhGy1rO3yI4GP695nVz5rP8YoPMXaEogFhjV0Dm/BUgpFQCuv22nWtIa0Q0RaAFh/7jxBtp+bnnaM6T4TkXA8hfCBMWa60/IBGGP2AXPwrN4miMiRU8N6P15tBuv+eGD3KWT2xWBgpIjkA1PwbEL6u0OyAbXfKjHG7AQ+w1OqTnhdC4FCY8xP1u1P8JSEE7J5Gw5kG2N2WLedkG8osMkYU2yMqQSm43kv2ve+O5Xtck674PmmkoenbY/sTOlaz8/ZlqP3KTzD0TutnrauX8rRO60WWdOT8GyHTbQum4Ak6766O60uOYlcArwHPF9nuu35gBQgwboeDfwAXIbnm5v3TrVbrOu3cvROtWnW9a4cvVMtD88ONb+8D4Bz+e+OZkdkw/MNspHX9QV4vlHa/rpay/4AdLKuP2blckQ2r4xTgBsd9n9iALAKzz42wbPD/nd2vu9s/TD35wXPEQPr8WyjfrCen+sjPNv/KvF8S7oJz3a9b4ENwDdebxYBXrJy5QCZXo/zSyDXuni/WTOBldYyL1JnB94Jsp2FZzV4BbDMulzihHxAD2CplW0l8Ig1vZ31nyrX+s8QaU2Psm7nWve383qsB63nX4fXkR7+eB9wdCk4IpuVY7l1WXVkeSe8rtayvYAs67WdgedD0xHZrOVj8Xyjjvea5oh8wB+Btdby7+P5YLftfafDXCillKoVLPsUlFJK+YGWglJKqVpaCkoppWppKSillKqlpaCUUqqWloJSSqlaWgpKKaVq/X8FYU5uxSiPOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This should be same with following plot"
      ],
      "metadata": {
        "id": "XxY-cX9huqMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([sched(o) for o in torch.arange(0., 1., 0.01)[1:]])"
      ],
      "metadata": {
        "id": "_yh0Vr3CuxdM",
        "outputId": "12c78431-68b6-428b-f2a4-ccec632d49ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f60631928d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 202
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "gE6PAbXNVFNq",
        "outputId": "599d6cb3-56e9-49fa-96d5-8420b591996f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}