{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pooling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Emotion Recognition with `CNN + Transformer`\n",
        "\n",
        "- The major architecture of this model is motivated by this paper [Self-attention for Speech Emotion Recognition](https://publications.idiap.ch/attachments/papers/2019/Tarantino_INTERSPEECH_2019.pdf)\n",
        "\n",
        "- This is my individual notebook to understand transformer and speech emotion recognition task."
      ],
      "metadata": {
        "id": "7kPMSMvg_d-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "from pathlib import Path\n",
        "drive_path = Path('/gdrive/Shareddrives/Dion-Account/2122WS/4-dl4slp/coding-project/ser/')"
      ],
      "metadata": {
        "id": "4bMB_Fg6l4ub",
        "outputId": "6d71bdbb-6f0b-42fe-a1f3-1a0dd0964509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from exp.nb_08 import *"
      ],
      "metadata": {
        "id": "dK23Yp19bAT_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_data_path = drive_path/'data/v1'\n",
        "(drive_data_path).ls()"
      ],
      "metadata": {
        "id": "xw7rlEPZpuNv",
        "outputId": "3bfe43fa-40e8-4a51-9764-2f7b16209309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/4-dl4slp/coding-project/ser/data/v1/train'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/4-dl4slp/coding-project/ser/data/v1/dev'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/4-dl4slp/coding-project/ser/data/v1/ser.tar-v1.gz')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemList(ListContainer):\n",
        "    def __init__(self, items, path='.', tfms=None):\n",
        "        super().__init__(items)\n",
        "        self.path,self.tfms = Path(path),tfms\n",
        "\n",
        "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
        "\n",
        "    def new(self, items, cls=None):\n",
        "        if cls is None: cls=self.__class__\n",
        "        return cls(items, self.path, tfms=self.tfms)\n",
        "\n",
        "    def  get(self, i): return i\n",
        "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        res = super().__getitem__(idx)\n",
        "        if isinstance(res,list): return [self._get(o) for o in res]\n",
        "        return self._get(res)\n"
      ],
      "metadata": {
        "id": "G7UTFPBDeSRS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions = None, recurse=True, include=None, **kwargs):\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "    \n",
        "    def get(self, fn):\n",
        "        return torch.load(fn)\n",
        "\n",
        "class Reshape():\n",
        "    \"transpose to [n_features, n_frames]\"\n",
        "    _order=12\n",
        "    def __call__(self, item):\n",
        "        w, h = item.shape\n",
        "        return item.view(h, w)\n",
        "\n",
        "class DummyChannel():\n",
        "    \"insert pseudo axis in height [n_features, 1, n_frames]\"\n",
        "    _order = 30\n",
        "    def __call__(self, item):\n",
        "        return item.unsqueeze(1)\n",
        "\n",
        "def re_labeler(fn, pat, subcl='act'):\n",
        "    assert subcl in ['act', 'val', 'all']\n",
        "    if subcl=='all': return tuple(int(i) for i in re.findall(pat, str(fn)))\n",
        "    else:\n",
        "        return re.findall(pat, str(fn))[0] if pat == 'act' else re.findall(pat, str(fn))[1]\n"
      ],
      "metadata": {
        "id": "PHB8bfNz-KiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def random_splitter(fn, p_valid): return random.random() < p_valid"
      ],
      "metadata": {
        "id": "s72NONpGdFf0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CategoryProcessor(Processor):\n",
        "    \"convert string to float, which was retrieved from the file name\"\n",
        "    def __init__(self): self.vocab=None\n",
        "\n",
        "    def __call__(self, items):\n",
        "        #The vocab is defined on the first use.\n",
        "        if self.vocab is None:\n",
        "            # set_trace()\n",
        "            self.vocab = uniqueify(items)\n",
        "            # self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
        "        return [torch.tensor(o).float() for o in items]\n",
        "    def proc1(self, item):  return self.otoi[item]\n",
        "\n",
        "    def deprocess(self, idxs):\n",
        "        assert self.vocab is not None\n",
        "        return [self.deproc1(idx) for idx in idxs]\n",
        "    def deproc1(self, idx): return self.vocab[idx]\n"
      ],
      "metadata": {
        "id": "Lo9Q2I_gfl-_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_files(p, fs, extensions=None):\n",
        "    p = Path(p)\n",
        "    res = [p/f for f in fs if not f.startswith('.')\n",
        "        #    and '_0_0' in f\n",
        "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
        "    return res\n",
        "\n",
        "def get_files(path, extensions=None, recurse=False, include=None):\n",
        "    path = Path(path)\n",
        "    extensions = setify(extensions)\n",
        "    extensions = {e.lower() for e in extensions}\n",
        "    if recurse:\n",
        "        res = []\n",
        "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
        "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
        "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
        "            res += _get_files(p, f, extensions)\n",
        "        return res\n",
        "    else:\n",
        "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
        "        return _get_files(path, f, extensions)"
      ],
      "metadata": {
        "id": "Jb_86tKdlyYU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs, **kwargs))"
      ],
      "metadata": {
        "id": "npt7ZXfs59Yo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = drive_data_path/'train'\n",
        "tfms = [Reshape(), DummyChannel()]\n",
        "al=AudioList.from_files(train_path, tfms=tfms)"
      ],
      "metadata": {
        "id": "V1-WeGWbceda"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al[0].shape, al.items.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzgHtq8lcpwG",
        "outputId": "c5d71551-1944-48bb-ee4d-474538b92cee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([26, 1, 614]), 7800)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def databunchify(sd, bs, c_in=None, c_out=None, **kwargs):\n",
        "    dls = get_dls(sd.train, sd.valid, bs, **kwargs)\n",
        "    return DataBunch(*dls, c_in=c_in, c_out=c_out)\n",
        "\n",
        "SplitData.to_databunch = databunchify"
      ],
      "metadata": {
        "id": "ucopmUtS6Wet"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pat = r'_(\\d+)'\n",
        "emotion_labeler = partial(re_labeler, pat=label_pat, subcl='all')\n",
        "sd = SplitData.split_by_func(al, partial(random_splitter, p_valid=0.00))\n",
        "ll = label_by_func(sd, emotion_labeler, proc_y=CategoryProcessor())"
      ],
      "metadata": {
        "id": "7t-IrdLscir_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll.train.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbBLDyZkc4Rt",
        "outputId": "d606e7b2-da7e-4a5e-ac9e-ca4ba096b46f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ItemList (7800 items)\n",
              "[tensor([1., 1.]), tensor([0., 0.]), tensor([0., 0.]), tensor([1., 0.]), tensor([1., 1.]), tensor([1., 0.]), tensor([1., 1.]), tensor([1., 0.]), tensor([1., 0.]), tensor([1., 1.])...]\n",
              "Path: /gdrive/Shareddrives/Dion-Account/2122WS/4-dl4slp/coding-project/ser/data/v1/train"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs=1"
      ],
      "metadata": {
        "id": "5oN7RbWZCeb6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_in = ll.train[0][0].shape[0]\n",
        "c_out = 2\n",
        "data = ll.to_databunch(bs,c_in=c_in,c_out=c_out)"
      ],
      "metadata": {
        "id": "DAO3200FesZw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.train_dl.batch_size, data.valid_dl.batch_size"
      ],
      "metadata": {
        "id": "UDN3bG_o5Zh_",
        "outputId": "914190b2-bc3f-4ec6-81b8-2817a985f90a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.c_in, data.c_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ5YJvE6e5KW",
        "outputId": "79d6084b-8ffb-440c-8dfc-172a8a087fd8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(data.train_dl))"
      ],
      "metadata": {
        "id": "9DmN6vGxe8_o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "id": "SCtBT8F5892Y",
        "outputId": "9c6d249a-d50b-4612-a078-2b065ca2fc4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 26, 1, 153])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "id": "Y4bcsqEw8-pV",
        "outputId": "29c22e26-f620-4acb-9c35-c1b7c648e4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigate label distribution"
      ],
      "metadata": {
        "id": "pa4YQhtFECd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.researchgate.net/profile/Lung-Hao-Lee-2/publication/304124018/figure/fig1/AS:374864755085312@1466386130906/Two-dimensional-valence-arousal-space.png)"
      ],
      "metadata": {
        "id": "nKxwP1x0EFWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(str(i.tolist()) for i in data.train_ds.y)"
      ],
      "metadata": {
        "id": "7a2ObaN1CIIr",
        "outputId": "0de60ea5-496f-4ca8-b857-35368d3f2996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'[0.0, 0.0]': 1240,\n",
              "         '[0.0, 1.0]': 1023,\n",
              "         '[1.0, 0.0]': 3194,\n",
              "         '[1.0, 1.0]': 2343})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "EsHcnnmQlGo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class RunningBatchNorm(nn.Module):\n",
        "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.mom, self.eps = mom, eps\n",
        "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
        "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
        "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
        "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
        "        self.register_buffer('count', tensor(0.))\n",
        "        self.register_buffer('factor', tensor(0.))\n",
        "        self.register_buffer('offset', tensor(0.))\n",
        "        self.batch = 0\n",
        "\n",
        "    def update_stats(self, x):\n",
        "        bs,nc,*_ = x.shape\n",
        "        self.sums.detach_()\n",
        "        self.sqrs.detach_()\n",
        "        dims = (0,2,3)\n",
        "        s    = x    .sum(dims, keepdim=True)\n",
        "        ss   = (x*x).sum(dims, keepdim=True)\n",
        "        c    = s.new_tensor(x.numel()/nc)\n",
        "        mom1 = s.new_tensor(1 - (1-self.mom)/math.sqrt(bs-1))\n",
        "        self.sums .lerp_(s , mom1)\n",
        "        self.sqrs .lerp_(ss, mom1)\n",
        "        self.count.lerp_(c , mom1)\n",
        "        self.batch += bs\n",
        "        means = self.sums/self.count\n",
        "        varns = (self.sqrs/self.count).sub_(means*means)\n",
        "        if bool(self.batch < 20): varns.clamp_min_(0.01)\n",
        "        self.factor = self.mults / (varns+self.eps).sqrt()\n",
        "        self.offset = self.adds - means*self.factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training: self.update_stats(x)\n",
        "        return x*self.factor + self.offset"
      ],
      "metadata": {
        "id": "WwIGJW5fs54s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, steppers, **defaults):\n",
        "        self.steppers = listify(steppers)\n",
        "        maybe_update(self.steppers, defaults, get_defaults)\n",
        "        # might be a generator\n",
        "        self.param_groups = list(params)\n",
        "        # ensure params is a list of lists\n",
        "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
        "        self.hypers = [{**defaults} for p in self.param_groups]\n",
        "\n",
        "    def grad_params(self):\n",
        "        return [(p,hyper) for pg,hyper in zip(self.param_groups,self.hypers)\n",
        "            for p in pg if p.grad is not None]\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p,hyper in self.grad_params():\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "\n",
        "    def step(self):\n",
        "        for p,hyper in self.grad_params(): compose(p, self.steppers, **hyper)\n",
        "def maybe_update(os, dest, f):\n",
        "    for o in os:\n",
        "        for k,v in f(o).items():\n",
        "            if k not in dest: dest[k] = v\n",
        "\n",
        "class Stat():\n",
        "    _defaults = {}\n",
        "    def init_state(self, p): raise NotImplementedError\n",
        "    def update(self, p, state, **kwargs): raise NotImplementedError\n",
        "\n",
        "class AverageGrad(Stat):\n",
        "    _defaults = dict(mom=0.9)\n",
        "\n",
        "    def __init__(self, dampening:bool=False): self.dampening=dampening\n",
        "    def init_state(self, p): return {'grad_avg': torch.zeros_like(p.grad.data)}\n",
        "    def update(self, p, state, mom, **kwargs):\n",
        "        state['mom_damp'] = 1-mom if self.dampening else 1.\n",
        "        state['grad_avg'].mul_(mom).add_(state['mom_damp'], p.grad.data)\n",
        "        return state\n",
        "\n",
        "class AverageSqrGrad(Stat):\n",
        "    _defaults = dict(sqr_mom=0.99)\n",
        "\n",
        "    def __init__(self, dampening:bool=True): self.dampening=dampening\n",
        "    def init_state(self, p): return {'sqr_avg': torch.zeros_like(p.grad.data)}\n",
        "    def update(self, p, state, sqr_mom, **kwargs):\n",
        "        state['sqr_damp'] = 1-sqr_mom if self.dampening else 1.\n",
        "        state['sqr_avg'].mul_(sqr_mom).addcmul_(state['sqr_damp'], p.grad.data, p.grad.data)\n",
        "        return state\n",
        "\n",
        "class StepCount(Stat):\n",
        "    def init_state(self, p): return {'step': 0}\n",
        "    def update(self, p, state, **kwargs):\n",
        "        state['step'] += 1\n",
        "        return state\n",
        "\n",
        "def debias(mom, damp, step): return damp * (1 - mom**step) / (1-mom)\n",
        "\n",
        "class StatefulOptimizer(Optimizer):\n",
        "    def __init__(self, params, steppers, stats=None, **defaults):\n",
        "        self.stats = listify(stats)\n",
        "        maybe_update(self.stats, defaults, get_defaults)\n",
        "        super().__init__(params, steppers, **defaults)\n",
        "        self.state = {}\n",
        "\n",
        "    def step(self):\n",
        "        for p,hyper in self.grad_params():\n",
        "            if p not in self.state:\n",
        "                #Create a state for p and call all the statistics to initialize it.\n",
        "                self.state[p] = {}\n",
        "                maybe_update(self.stats, self.state[p], lambda o: o.init_state(p))\n",
        "            state = self.state[p]\n",
        "            for stat in self.stats: state = stat.update(p, state, **hyper)\n",
        "            compose(p, self.steppers, **state, **hyper)\n",
        "            self.state[p] = state\n",
        "\n",
        "def adam_step(p, lr, mom, mom_damp, step, sqr_mom, sqr_damp, grad_avg, sqr_avg, eps, **kwargs):\n",
        "    debias1 = debias(mom,     mom_damp, step)\n",
        "    debias2 = debias(sqr_mom, sqr_damp, step)\n",
        "    p.data.addcdiv_(-lr / debias1, grad_avg, (sqr_avg/debias2).sqrt() + eps)\n",
        "    return p\n",
        "adam_step._defaults = dict(eps=1e-5)\n",
        "\n",
        "def weight_decay(p, lr, wd, **kwargs):\n",
        "    p.data.mul_(1 - lr*wd)\n",
        "    return p\n",
        "weight_decay._defaults = dict(wd=0.)\n",
        "\n",
        "def adam_opt(xtra_step=None, **kwargs):\n",
        "    return partial(StatefulOptimizer, steppers=[adam_step,weight_decay]+listify(xtra_step),\n",
        "                   stats=[AverageGrad(dampening=True), AverageSqrGrad(), StepCount()], **kwargs)\n",
        "    \n",
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-1, )    "
      ],
      "metadata": {
        "id": "M1yJTG9lji3X"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_defaults(d): return getattr(d,'_defaults',{})"
      ],
      "metadata": {
        "id": "bzPopnue3D0t"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback():\n",
        "    _order=0\n",
        "    def set_runner(self, run): self.run=run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
        "        return camel2snake(name or 'callback')\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        f = getattr(self, cb_name, None)\n",
        "        if f and f(): return True\n",
        "        return False\n",
        "\n",
        "class TrainEvalCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.run.n_epochs=0.\n",
        "        self.run.n_iter=0\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.run.n_epochs += 1./self.iters\n",
        "        self.run.n_iter   += 1\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        self.run.n_epochs=self.epoch\n",
        "        self.model.train()\n",
        "        self.run.in_train=True\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.model.eval()\n",
        "        self.run.in_train=False\n",
        "\n",
        "class CancelTrainException(Exception): pass\n",
        "class CancelEpochException(Exception): pass\n",
        "class CancelBatchException(Exception): pass\n",
        "\n",
        "class Runner():\n",
        "    def __init__(self, cbs=None, cb_funcs=None):\n",
        "        self.in_train = False\n",
        "        cbs = listify(cbs)\n",
        "        for cbf in listify(cb_funcs):\n",
        "            cb = cbf()\n",
        "            setattr(self, cb.name, cb)\n",
        "            cbs.append(cb)\n",
        "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
        "\n",
        "    @property\n",
        "    def opt(self):       return self.learn.opt\n",
        "    @property\n",
        "    def model(self):     return self.learn.model\n",
        "    @property\n",
        "    def loss_func(self): return self.learn.loss_func\n",
        "    @property\n",
        "    def data(self):      return self.learn.data\n",
        "\n",
        "    def one_batch(self, xb, yb):\n",
        "        try:\n",
        "            self.xb,self.yb = xb,yb\n",
        "            self('begin_batch')\n",
        "            # print(self.xb.shape)\n",
        "            self.pred = self.model(self.xb)\n",
        "            self('after_pred')\n",
        "            # print(self.pred.shape, self.yb.shape)\n",
        "            self.loss = self.loss_func(self.pred, self.yb)\n",
        "            self('after_loss')\n",
        "            if not self.in_train: return\n",
        "            self.loss.backward()\n",
        "            self('after_backward')\n",
        "            self.opt.step()\n",
        "            self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException: self('after_cancel_batch')\n",
        "        finally: self('after_batch')\n",
        "\n",
        "    def all_batches(self, dl):\n",
        "        self.iters = len(dl)\n",
        "        try:\n",
        "            for xb,yb in dl: self.one_batch(xb, yb)\n",
        "        except CancelEpochException: self('after_cancel_epoch')\n",
        "\n",
        "    def fit(self, epochs, learn):\n",
        "        self.epochs,self.learn,self.loss = epochs,learn,tensor(0.)\n",
        "\n",
        "        try:\n",
        "            for cb in self.cbs: cb.set_runner(self)\n",
        "            self('begin_fit')\n",
        "            for epoch in range(epochs):\n",
        "                self.epoch = epoch\n",
        "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
        "                self('after_epoch')\n",
        "\n",
        "        except CancelTrainException: self('after_cancel_train')\n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.learn = None\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        res = False\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
        "            # print(cb_name, cb)\n",
        "            res = cb(cb_name) and res\n",
        "        return res\n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
        "\n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "\n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "        # print stats based on thousand iteration\n",
        "        if (self.run.n_iter % 1000) ==0:\n",
        "            print(f\"iteration: {self.run.n_iter}, accuracy:  {self.train_stats}\")\n",
        "    def after_epoch(self):\n",
        "        print(f\"epoch {self.run.n_epoch} done!\")\n",
        "\n",
        "class Recorder(Callback):\n",
        "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.lrs.append(self.opt.hypers[-1]['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())\n",
        "\n",
        "    def plot_lr  (self): plt.plot(self.lrs)\n",
        "    def plot_loss(self): plt.plot(self.losses)\n",
        "\n",
        "    def plot(self, skip_last=0):\n",
        "        losses = [o.item() for o in self.losses]\n",
        "        n = len(losses)-skip_last\n",
        "        plt.xscale('log')\n",
        "        plt.plot(self.lrs[:n], losses[:n])\n",
        "\n",
        "class ParamScheduler(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, pname, sched_funcs):\n",
        "        self.pname,self.sched_funcs = pname,listify(sched_funcs)\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        fs = self.sched_funcs\n",
        "        if len(fs)==1: fs = fs*len(self.opt.param_groups)\n",
        "        pos = self.n_epochs/self.epochs\n",
        "        for f,h in zip(fs,self.opt.hypers): h[self.pname] = f(pos)\n",
        "\n",
        "class LR_Find(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
        "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        pos = self.n_iter/self.max_iter\n",
        "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
        "        for pg in self.opt.hypers: pg['lr'] = lr\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
        "            raise CancelTrainException()\n",
        "        if self.loss < self.best_loss: self.best_loss = self.loss\n",
        "\n",
        "def get_runner(model, data, lr=0.6, cbs=None, opt_func=None, loss_func = F.cross_entropy):\n",
        "    if opt_func is None: opt_func = optim.SGD\n",
        "    opt = opt_func(model.parameters(), lr=lr)\n",
        "    learn = Learner(model, opt, loss_func, data)\n",
        "    return learn, Runner(cb_funcs=listify(cbs))"
      ],
      "metadata": {
        "id": "Ds8HJcRt4Xv6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    \"remove last (pooled) dimension and reshape tensor tp (seq_len x d_model)\"\n",
        "    def __init__(self): super().__init__()\n",
        "    def forward(self, x):\n",
        "        return x.squeeze(-1).permute(1,0)"
      ],
      "metadata": {
        "id": "OxniMMCvy9qh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here, the Author mentioned that they use '6-block' for raw data. but in our case, as it is log mel, it's not 100% raw data."
      ],
      "metadata": {
        "id": "TvHhUxCmOrl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO Fix the length, cnn 1d"
      ],
      "metadata": {
        "id": "PUY5uRaEmxxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.module = nn.Sequential(\n",
        "            nn.Conv1d(1,8, kernel_size=10, stride=1), GeneralRelu(),\n",
        "            nn.Conv1d(8,16, kernel_size=10), GeneralRelu(),\n",
        "            nn.Conv1d(16,32, kernel_size=5), GeneralRelu(),\n",
        "            nn.Conv1d(32,64, kernel_size=5), GeneralRelu(),\n",
        "            nn.Conv1d(64,128, kernel_size=3), GeneralRelu(),\n",
        "            nn.AdaptiveMaxPool1d(1), #26, 128, 1\n",
        "            Flatten()) #128, 26\n",
        "    def forward(self, x):\n",
        "        return self.module(x)"
      ],
      "metadata": {
        "id": "1EwucPjayOua"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_filter = CNN1d()\n",
        "# n_frames = [xb.shape[-1] for xb, yb in iter(data.train_dl)]\n",
        "# len_dist = [sd.train[idx].shape[0] for idx, item in enumerate(sd.train)]"
      ],
      "metadata": {
        "id": "oGl_NHURHCl7"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(n_frames)"
      ],
      "metadata": {
        "id": "0wOYHvd4KKF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape, CNN1d()(xb.squeeze(0)).shape"
      ],
      "metadata": {
        "id": "Wve9XSpGrvjR",
        "outputId": "f0ebd5db-7dcb-4140-cd02-4dd25df894f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 26, 1, 67]), torch.Size([128, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 128 : Time frame, which corresponds to `seq_len`\n",
        "- 26 : d_model, which corresponds to `d_model` "
      ],
      "metadata": {
        "id": "lc6Fm508utl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let us introduce transformer\n",
        "- embedding is composed of two parts\n",
        "    - positional encoding - equal to original one\n",
        "    - embedding - learn from CNN 1d model"
      ],
      "metadata": {
        "id": "oExrKQXOwKG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor"
      ],
      "metadata": {
        "id": "frEqAixDXr7Q"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq ipdb\n",
        "from ipdb import set_trace"
      ],
      "metadata": {
        "id": "2C7E9Ge0b7Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"Encode the position with a sinusoid.\"\n",
        "    def __init__(self, d:int):\n",
        "        super().__init__()\n",
        "        self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
        "\n",
        "    def forward(self, pos:Tensor):\n",
        "        inp = torch.ger(pos, self.freq)\n",
        "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
        "        return enc\n",
        "\n",
        "class TransformerEmbedding(nn.Module):\n",
        "    \"Embedding from CNN + positional encoding + dropout\"\n",
        "    def __init__(self, emb_sz:int, inp_p:float=0.):\n",
        "        super().__init__()\n",
        "        self.emb_sz = emb_sz\n",
        "        # (seq_len x d_model)\n",
        "        self.embed = CNN1d()\n",
        "        self.pos_enc = PositionalEncoding(emb_sz)\n",
        "        self.drop = nn.Dropout(inp_p)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Need to insert the batch dimension as you removed it when it is used for conv1d\n",
        "        # 1,       26,       1,       75 -> 128    , 26\n",
        "        # bs, d_model, seq_len, n_frames -> seq_len, d_model\n",
        "        inp = self.embed(inp)\n",
        "        pos = torch.arange(0, inp.size(0), device=inp.device).float()     \n",
        "        # reconstruct pseudo batch dimension (1 x 128 x 26)\n",
        "        return self.drop(inp * math.sqrt(self.emb_sz) + self.pos_enc(pos)).unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "2YUXXcXKwLxe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_inp = torch.randn(128, 26)\n",
        "dummy_pos_emb = PositionalEncoding(26)\n",
        "dummy_pos = torch.arange(0, dummy_inp.size(0)).float()\n",
        "dummy_pos_emb(dummy_pos)"
      ],
      "metadata": {
        "id": "XIqFVq4Vc5u7",
        "outputId": "c1eea03e-5054-4654-a2ba-f99d8a8bba57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.8415,  0.4727,  0.2401,  ...,  1.0000,  1.0000,  1.0000],\n",
              "        [ 0.9093,  0.8331,  0.4661,  ...,  1.0000,  1.0000,  1.0000],\n",
              "        ...,\n",
              "        [-0.6160, -0.9590, -0.8958,  ...,  0.9945,  0.9987,  0.9997],\n",
              "        [ 0.3300, -0.7110, -0.7628,  ...,  0.9944,  0.9986,  0.9997],\n",
              "        [ 0.9726, -0.2941, -0.5853,  ...,  0.9943,  0.9986,  0.9997]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `emb_sz`: 26\n",
        "- Transformer-embedding: 1 x 128 x 26 (bs, seq_len, d_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "gcDh8QESsOAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., double_drop:bool=True):\n",
        "    layers = [nn.Linear(d_model, d_ff), nn.ReLU()]\n",
        "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
        "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
        "\n",
        "class MergeLayer(nn.Module):\n",
        "    \"Merge a shortcut with the result of the module by adding them or concatenating them if `dense=True`.\"\n",
        "    def __init__(self, dense:bool=False):\n",
        "        super().__init__()\n",
        "        self.dense=dense\n",
        "    def forward(self, x):\n",
        "        return torch.cat([x,x.orig], dim=1) if self.dense else (x+x.orig)\n",
        "\n",
        "class SequentialEx(nn.Module):\n",
        "    \"Like `nn.Sequential`, but with ModuleList semantics, and can access module input\"\n",
        "    def __init__(self, *layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        for l in self.layers:\n",
        "            res.orig = x\n",
        "            nres = l(res)\n",
        "            # We have to remove res.orig to avoid hanging refs and therefore memory leaks\n",
        "            res.orig, nres.orig = None, None\n",
        "            res = nres\n",
        "        return res\n",
        "\n",
        "    def __getitem__(self,i): return self.layers[i]\n",
        "    def append(self,l):      return self.layers.append(l)\n",
        "    def extend(self,l):      return self.layers.extend(l)\n",
        "    def insert(self,i,l):    return self.layers.insert(i,l)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"MutiHeadAttention.\"\n",
        "\n",
        "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
        "                 scale:bool=True):\n",
        "        super().__init__()\n",
        "        # d_head = ifnone(d_head, d_model//n_heads)\n",
        "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
        "        self.q_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.k_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.v_wgt = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
        "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
        "        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
        "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask))))\n",
        "\n",
        "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
        "        bs,seq_len = q.size(0),q.size(1)\n",
        "        wq,wk,wv = self.q_wgt(q),self.k_wgt(k),self.v_wgt(v)\n",
        "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
        "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
        "        attn_score = torch.matmul(wq, wk)\n",
        "        if self.scale: attn_score = attn_score.div_(self.d_head ** 0.5)\n",
        "        if mask is not None:\n",
        "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
        "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
        "        attn_vec = torch.matmul(attn_prob, wv)\n",
        "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, seq_len, -1)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"Encoder block of a Transformer model.\"\n",
        "    #Can't use Sequential directly cause more than one input...\n",
        "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
        "                 bias:bool=True, scale:bool=True, double_drop:bool=True):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
        "        self.ff  = feed_forward(d_model, d_inner, ff_p=ff_p, double_drop=double_drop)\n",
        "\n",
        "    def forward(self, x:Tensor, mask:Tensor=None): return self.ff(self.mha(x, x, x, mask=mask))"
      ],
      "metadata": {
        "id": "t6DdCZWvb1MB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "pA8dCOmKNn4_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Tarantino (2019) applied 2d-convolution here.\n",
        "        self.conv = nn.Conv2d(1, 5, 20)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1) # (bs, 5, 109, 1)\n",
        "        self.lin_out = nn.Linear(5*109, 2) # I might need to make this two.         \n",
        "    \n",
        "    def forward(self, inp):\n",
        "        conv_out = self.conv(inp.unsqueeze(1)) # (bs, 128, 26) -> (bs, 1, 128, 26) -> (bs, 5, 109, 7), insert dummy channel, channel 1 to 5, kerner size = 20\n",
        "        pool_out = self.pool(conv_out.squeeze(0)) # (bs, 5, 109, 7) -> (5, 109, 7) -> (5, 109, 1)\n",
        "        out = pool_out.squeeze(-1).unsqueeze(0) # (5, 109, 1) -> (5, 109) -> (1, 5, 109)\n",
        "        return self.lin_out(out.view(1, -1)) # (1, 5*109) -> (1, 2)    "
      ],
      "metadata": {
        "id": "Ii_1JOnyM2Z9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNTransformer(nn.Module):\n",
        "    \"CNN Transformer model\"\n",
        "    \n",
        "    def __init__(self, out_vsz:int=4, n_layers:int=1, n_heads:int=3, d_model:int=26, d_head:int=9, \n",
        "                 d_inner:int=3 * 9,\n",
        "                 inp_p:float=0.1, resid_p:float=0.1, attn_p:float=0.1,\n",
        "                 ff_p:float=0.1,\n",
        "                 bias:bool=True, \n",
        "                 scale:bool=True, double_drop:bool=True):\n",
        "        super().__init__()\n",
        "        self.enc_emb = TransformerEmbedding(d_model, inp_p)\n",
        "        self.encoder = nn.ModuleList([EncoderBlock(n_heads, d_model, d_head, d_inner, resid_p, attn_p, ff_p, bias, scale, double_drop) for _ in range(0, n_layers)])\n",
        "        self.out_layer = OutLayer()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        # torch.Size([1, 26, 1, 75]) => torch.Size([1, 128, 26])\n",
        "        enc = self.enc_emb(inp.squeeze(0))\n",
        "        # torch.Size([1, 128, 26])\n",
        "        for enc_block in self.encoder: enc = enc_block(enc)\n",
        "        \n",
        "        return self.out_layer(enc)"
      ],
      "metadata": {
        "id": "tXXWpd88wq4i"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = CNNTransformer()"
      ],
      "metadata": {
        "id": "8TgmEL4PPhxN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = xb.squeeze(0); z1.shape"
      ],
      "metadata": {
        "id": "4kYK46FiPv3m",
        "outputId": "0cfbb331-436e-4028-8c66-2acc096a569c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([26, 1, 67])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z2 = m1.enc_emb(z1); z2. # embedding. i.e., cnn feature extraction -> add with PE"
      ],
      "metadata": {
        "id": "ruvH8IZmQAPS",
        "outputId": "7090ddcd-a6df-4ba2-c69a-0ac1dc26bcc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder block\n",
        "for enc_block in m1.encoder:\n",
        "    print(\"n_block\")\n",
        "    z3 = enc_block(z2)"
      ],
      "metadata": {
        "id": "4tMGODz4QL8M",
        "outputId": "1cbbee65-deaf-4a70-8649-91d183c187d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z3.shape"
      ],
      "metadata": {
        "id": "foyyqWVDQTV1",
        "outputId": "ce877464-aa0f-4114-b0c5-17635b08ecc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# out layer. projection (dim * n_frames -> n_out)\n",
        "m1.out_layer(z3).shape"
      ],
      "metadata": {
        "id": "mCx-HWmrQ-Tk",
        "outputId": "3b8ca04e-0d37-4059-d779-1d5b2a31b6fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
        "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
        "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
        "\n",
        "    def forward(self, input, target):\n",
        "\n",
        "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight) \n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
        "        return focal_loss"
      ],
      "metadata": {
        "id": "030LU6V7tKJB"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbfs = [partial(AvgStatsCallback,accuracy),\n",
        "        CudaCallback]"
      ],
      "metadata": {
        "id": "NMqTlV_2kvsn"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_chan(x, mean, std):\n",
        "    return (x-mean[...,None,None]) / std[...,None,None]\n",
        "\n",
        "_m = tensor([4.6458, 5.4130, 6.5964, 6.8884, 6.8241, 7.1415, 7.2152, 7.1492, 6.6828,\n",
        "        6.7434, 6.8610, 6.9456, 7.2149, 7.3144, 7.3993, 7.1714, 7.3913, 7.5860,\n",
        "        7.3430, 7.3854, 7.4977, 7.4650, 7.3808, 7.0497, 6.7768, 6.4319])\n",
        "_s = tensor([1.6839, 2.3302, 2.6372, 2.6552, 2.7861, 2.7495, 2.7446, 2.6085, 2.5018,\n",
        "        2.3586, 2.3367, 2.3888, 2.4452, 2.4944, 2.4172, 2.4300, 2.3737, 2.4037,\n",
        "        2.4891, 2.4774, 2.4399, 2.3689, 2.2110, 2.2310, 2.2802, 2.2686])\n",
        "norm_ser = partial(normalize_chan, mean=_m.cuda(), std=_s.cuda())\n",
        "\n",
        "class BatchTransformXCallback(Callback):\n",
        "    _order=2\n",
        "    def __init__(self, tfm): self.tfm = tfm\n",
        "    def begin_batch(self):\n",
        "        self.run.xb = self.tfm(self.xb).squeeze(0)\n",
        "        # self.run.yb = self.yb.squeeze(0)"
      ],
      "metadata": {
        "id": "eAce3l3fkefR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbfs.append(partial(BatchTransformXCallback, norm_ser))"
      ],
      "metadata": {
        "id": "40BHfbmWsfBE"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inspect.getsource(cos_1cycle_anneal))"
      ],
      "metadata": {
        "id": "3yqhHwYPUbXo",
        "outputId": "54600f30-6fb7-4bb2-e97d-77db801eb5ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def cos_1cycle_anneal(start, high, end):\n",
            "    return [sched_cos(start, high), sched_cos(high, end)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sched = combine_scheds([0.3,0.7], cos_1cycle_anneal(0.1,0.3,0.05))"
      ],
      "metadata": {
        "id": "VDx9rJ1S7evB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect; inspect.getsource(init_cnn)"
      ],
      "metadata": {
        "id": "gc588jyHSq8s",
        "outputId": "5ab1c2e7-d2b2-4c1f-8d99-050f30a4a43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def init_cnn(m, uniform=False):\\n    f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\\n    init_cnn_(m, f)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_learn_run(model, data, lr, cbs=None, opt_func=None, **kwargs):\n",
        "    init_cnn(model)\n",
        "    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)"
      ],
      "metadata": {
        "id": "YRndPhvA10xj"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNTransformer()"
      ],
      "metadata": {
        "id": "1eE97evZS09y"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn,run = get_learn_run(model, data, 0.2, cbs=cbfs+[\n",
        "    partial(ParamScheduler, 'lr', sched)], opt_func=opt_func, loss_func = FocalLoss()\n",
        ")"
      ],
      "metadata": {
        "id": "D_CtaxjgIxIg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.fit(10, learn)"
      ],
      "metadata": {
        "id": "bV8Qls7_S7Ov",
        "outputId": "d45f309b-55a8-4403-f70b-8cb8f5c862ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/exp/nb_04.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.tot_mets[i] += torch.tensor(m(run.pred, run.yb)) * bn\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0, accuracy:  train: [1.3878704951359675, tensor(0., device='cuda:0')]\n",
            "iteration: 1000, accuracy:  train: [108.02894221163452, tensor(0.4680, device='cuda:0')]\n",
            "iteration: 2000, accuracy:  train: [95.20179333410218, tensor(0.4570, device='cuda:0')]\n",
            "iteration: 3000, accuracy:  train: [93.45566862327942, tensor(0.4503, device='cuda:0')]\n",
            "iteration: 4000, accuracy:  train: [98.27458519985389, tensor(0.4538, device='cuda:0')]\n",
            "iteration: 5000, accuracy:  train: [85.58152215710705, tensor(0.4543, device='cuda:0')]\n",
            "iteration: 6000, accuracy:  train: [154.42100675528437, tensor(0.4563, device='cuda:0')]\n",
            "iteration: 7000, accuracy:  train: [181.03646731785568, tensor(0.4582, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-3dee63044f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-57cb71cb4316>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, learn)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-57cb71cb4316>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# print(cb_name, cb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-57cb71cb4316>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-57cb71cb4316>\u001b[0m in \u001b[0;36mafter_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"iteration: {self.run.n_iter}, accuracy:  {self.train_stats}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {self.run.n_epoch} done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Runner' object has no attribute 'n_epoch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_summary(run, learn, data, find_all=False):\n",
        "    xb,yb = get_batch(data.valid_dl, run)\n",
        "    device = next(learn.model.parameters()).device#Model may not be on the GPU yet\n",
        "    xb,yb = xb.to(device),yb.to(device)\n",
        "    mods = learn.model.children()\n",
        "    f = lambda hook,mod,inp,out: print(f\"{mod}\\n{out.shape}\\n\")\n",
        "    with Hooks(mods, f) as hooks: learn.model(xb)"
      ],
      "metadata": {
        "id": "ZhGMUtaJ3JP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.cbs"
      ],
      "metadata": {
        "id": "Ly5Uu4pSJLDk",
        "outputId": "7072ba33-013d-4efd-9bb7-5499874e9441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.TrainEvalCallback at 0x7f4cc4c13f90>,\n",
              " <__main__.AvgStatsCallback at 0x7f4cc4c13450>,\n",
              " <exp.nb_06.CudaCallback at 0x7f4cc7ae7a90>,\n",
              " <__main__.BatchTransformXCallback at 0x7f4cc7ae7210>,\n",
              " <__main__.ParamScheduler at 0x7f4cc4c15c90>]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    }
  ]
}