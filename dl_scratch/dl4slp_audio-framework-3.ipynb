{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "dl4slp-audio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2021-12-23 Update Note\n",
        "\n",
        "- Being discouraged by the low performance of transformer, and research, I will move back to \"more\" epoch of xresnet."
      ],
      "metadata": {
        "id": "7Nfe54aqpQ1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmq1O0Lup1h2",
        "outputId": "0f96fb0f-b7df-4f45-b348-cafdc9c46900"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I will use xresnet and their datablock, optimizer from fastai."
      ],
      "metadata": {
        "id": "DxHqVglwqH0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NOTE: if you do not have installed [nvidia/apex](https://github.com/nvidia/apex),  change `from exp.nb_10c import *` to `from exp.nb_10b import *` in `exp.nb_11`"
      ],
      "metadata": {
        "id": "nb6S4CPyqS_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from exp.nb_12a import *"
      ],
      "metadata": {
        "id": "77V-bw0pqR2J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Local data (which is divided into separate dataset) is saved to `Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/data/v1/ser'`\n"
      ],
      "metadata": {
        "id": "_U7CK3KXqnr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1'); root_path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V93zJPFhqnpC",
        "outputId": "68afbc66-8932-4aaf-8542-e240650b1cb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/train'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/dev'),\n",
              " PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/data/v1/ser.tar-v1.gz')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1FVouZFT7-5"
      },
      "source": [
        "features-entry contains a list of a list with 26 items.\n",
        "- length of inner list: 26 (float numbers - represent one preprocessed speech frame (logMel))\n",
        "\n",
        "- length of outer list: number of frames per data-point, e.g. 10 or 15, ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = root_path/'train'\n",
        "\n",
        "audios = get_files(train_path)\n",
        "class AudioList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions = None, recurse=True, include=None, **kwargs):\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "    \n",
        "    def get(self, fn):\n",
        "        return torch.load(fn)\n",
        "        \n",
        "# al=AudioList.from_files(train_path); al\n",
        "\n",
        "class Reshape():\n",
        "    _order=12\n",
        "    def __call__(self, item):\n",
        "        w, h = item.shape\n",
        "        return item.view(h, w)\n",
        "\n",
        "# Mutants of input tensor\n",
        "class PadorTrim():\n",
        "    \n",
        "    _order = 20\n",
        "    def __init__(self, max_len):\n",
        "        self.max_len = max_len\n",
        "    def __call__(self, ad):\n",
        "        # h - logmel, here 27, w - frames / various\n",
        "        h, w = ad.shape\n",
        "        pad_size = self.max_len - w\n",
        "        if pad_size >0: return torch.cat((ad, torch.zeros(h, pad_size).to(ad.device)), dim=1)\n",
        "        else: return ad[:, :self.max_len]\n",
        "class DummyChannel():\n",
        "    _order = 30\n",
        "    def __call__(self, item):\n",
        "        return item.unsqueeze(0)        "
      ],
      "metadata": {
        "id": "kswbnzhkRxvu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpecAugment():\n",
        "    _order=99\n",
        "    def __init__(self, max_mask_pct=0.2, freq_masks=1, time_masks=1, replace_with_zero=False):\n",
        "        self.max_mask_pct, self.freq_masks, self.time_masks, self.replace_with_zero = \\\n",
        "        max_mask_pct, freq_masks, time_masks, replace_with_zero\n",
        "        if not 0 <= self.max_mask_pct <= 1.0: \n",
        "            raise ValueError( f\"max_mask_pct must be between 0.0 and 1.0, but it's {self.max_mask_pct}\")\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        _, n_mels, n_steps = spec.shape\n",
        "        F = math.ceil(n_mels * self.max_mask_pct) # rounding up in case of small %\n",
        "        T = math.ceil(n_steps * self.max_mask_pct)\n",
        "        fill = 0 if self.replace_with_zero else spec.mean()\n",
        "        for i in range(0, self.freq_masks):\n",
        "            f = random.randint(0, F)\n",
        "            f0 = random.randint(0, n_mels-f)\n",
        "            spec[0][f0:f0+f] = fill\n",
        "        for i in range(0, self.time_masks):\n",
        "            t = random.randint(0, T)\n",
        "            t0 = random.randint(0, n_steps-t)\n",
        "            spec[0][:,t0:t0+t] = fill\n",
        "        return spec"
      ],
      "metadata": {
        "id": "0_CAJYm3S1XY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masker = SpecAugment(freq_masks=1, time_masks=2, max_mask_pct=0.1)\n",
        "tfms = [Reshape(), PadorTrim(250), DummyChannel(), masker]\n",
        "al=AudioList.from_files(train_path, tfms=tfms)"
      ],
      "metadata": {
        "id": "7gXNkyc7PFr-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(al[3].squeeze(0))"
      ],
      "metadata": {
        "id": "o2e8rcQdFerM",
        "outputId": "4e7448a7-65db-440c-caf9-3db69d84f4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f335ef3abd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def re_labeler(fn, pat, subcl='act'):\n",
        "    assert subcl in ['act', 'val', 'all']\n",
        "    if subcl=='all': return ''.join(re.findall(pat, str(fn)))\n",
        "    else:\n",
        "        return re.findall(pat, str(fn))[0] if pat == 'act' else re.findall(pat, str(fn))[1]\n",
        "\n",
        "label_pat = r'_(\\d+)'\n",
        "emotion_labeler = partial(re_labeler, pat=label_pat, subcl='val')"
      ],
      "metadata": {
        "id": "src5ZbMFRx39"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd = SplitData.split_by_func(al, partial(random_splitter, p_valid=0.01))\n",
        "ll = label_by_func(sd, emotion_labeler, proc_y=CategoryProcessor())"
      ],
      "metadata": {
        "id": "DOSpH2pqRyAk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=64\n",
        "c_in = ll.train[0][0].shape[0]\n",
        "c_out = len(uniqueify(ll.train.y))\n",
        "data = ll.to_databunch(bs,c_in=c_in,c_out=c_out)"
      ],
      "metadata": {
        "id": "ZkTlju1wRx7S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll.train[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS5NB5DvUCBN",
        "outputId": "a6f1d60d-e602-4677-b03d-a394e33298b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 26, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_in, c_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUR1bKqURyDQ",
        "outputId": "915b3aa6-1a57-490a-b4fa-21dff6f4ffed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-1, )\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "lr = 1e-2\n",
        "pct_start = 0.5\n",
        "phases = create_phases(pct_start)\n",
        "sched_lr  = combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
        "sched_mom = combine_scheds(phases, cos_1cycle_anneal(0.95,0.85, 0.95))\n",
        "cbscheds = [ParamScheduler('lr', sched_lr), \n",
        "            ParamScheduler('mom', sched_mom)]"
      ],
      "metadata": {
        "id": "u7pqps96UTU6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def multi_f1score(input, target):\n",
        "    with torch.no_grad():\n",
        "        label_convert = {0:[1, 1], 1:[0, 0], 2:[1,0], 3:[0, 1]}\n",
        "        pred_np = np.array(list(map(lambda o: label_convert[int(o)], input.argmax(1))))\n",
        "        targ_np = np.array(list(map(lambda o: label_convert[int(o)], target)))\n",
        "        # print(targ_np)\n",
        "        return f1_score(targ_np[:, 0], pred_np[:, 0]) , f1_score(targ_np[:, 1], pred_np[:, 1])\n",
        "multi_f1score.__name__ = 'fscore'        \n",
        "# multi_f1score.__name__ = 'f1-score'"
      ],
      "metadata": {
        "id": "AkSyVQ81DXkn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_learner(arch, data, loss_func, opt_func, c_in=None, c_out=None,\n",
        "                lr=1e-2, cuda=True, norm=None, progress=False, mixup=0, xtra_cb=None, **kwargs):\n",
        "    cbfs = [partial(AvgStatsCallback,multi_f1score)]+listify(xtra_cb)\n",
        "    if progress: cbfs.append(ProgressCallback)\n",
        "    if cuda:     cbfs.append(CudaCallback)\n",
        "    if norm:     cbfs.append(partial(BatchTransformXCallback, norm))\n",
        "    if mixup:    cbfs.append(partial(MixUp, mixup))\n",
        "    arch_args = {}\n",
        "    if not c_in : c_in  = data.c_in\n",
        "    if not c_out: c_out = data.c_out\n",
        "    if c_in:  arch_args['c_in' ]=c_in\n",
        "    if c_out: arch_args['c_out']=c_out\n",
        "    return Learner(arch(**arch_args), data, loss_func, opt_func=opt_func, lr=lr, cb_funcs=cbfs, **kwargs)\n"
      ],
      "metadata": {
        "id": "GqDPmafBkbCx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = cnn_learner(xresnet34, data, loss_func, opt_func)\n",
        "learn.fit(7, cbs=cbscheds)"
      ],
      "metadata": {
        "id": "HknjfDCWf5_R",
        "outputId": "23e93b17-6c99-4556-9d75-42c32621459d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['epoch', 'train_loss', 'train_fscore', 'valid_loss', 'valid_fscore', 'time']\n",
            "\n",
            "train: [0.8947077393531799, tensor([0.0667, 0.0667], dtype=torch.float64)]\n",
            "train: [0.8995749950408936, tensor([0.1496, 0.1496], dtype=torch.float64)]\n",
            "train: [0.8661493460337321, tensor([0.2086, 0.2086], dtype=torch.float64)]\n",
            "train: [0.853609025478363, tensor([0.2872, 0.2872], dtype=torch.float64)]\n",
            "train: [0.84774808883667, tensor([0.3173, 0.3173], dtype=torch.float64)]\n",
            "train: [0.8335094451904297, tensor([0.3401, 0.3401], dtype=torch.float64)]\n",
            "train: [0.8138457706996373, tensor([0.3830, 0.3830], dtype=torch.float64)]\n",
            "train: [0.8126154541969299, tensor([0.4071, 0.4071], dtype=torch.float64)]\n",
            "train: [0.7991580433315701, tensor([0.4200, 0.4200], dtype=torch.float64)]\n",
            "train: [0.7941384315490723, tensor([0.4317, 0.4317], dtype=torch.float64)]\n",
            "train: [0.7880243821577593, tensor([0.4234, 0.4234], dtype=torch.float64)]\n",
            "train: [0.7803444862365723, tensor([0.4101, 0.4101], dtype=torch.float64)]\n",
            "train: [0.7716338817889874, tensor([0.3956, 0.3956], dtype=torch.float64)]\n",
            "train: [0.7676434516906738, tensor([0.3757, 0.3757], dtype=torch.float64)]\n",
            "train: [0.7654098510742188, tensor([0.3694, 0.3694], dtype=torch.float64)]\n",
            "train: [0.7619519233703613, tensor([0.3743, 0.3743], dtype=torch.float64)]\n",
            "train: [0.7625124314252067, tensor([0.3790, 0.3790], dtype=torch.float64)]\n",
            "train: [0.7592105865478516, tensor([0.3805, 0.3805], dtype=torch.float64)]\n",
            "train: [0.7582969163593493, tensor([0.3864, 0.3864], dtype=torch.float64)]\n",
            "train: [0.7560273170471191, tensor([0.3929, 0.3929], dtype=torch.float64)]\n",
            "train: [0.7524548031034923, tensor([0.4000, 0.4000], dtype=torch.float64)]\n",
            "train: [0.7496109875765714, tensor([0.4111, 0.4111], dtype=torch.float64)]\n",
            "train: [0.7431818091351053, tensor([0.4227, 0.4227], dtype=torch.float64)]\n",
            "train: [0.7405142784118652, tensor([0.4273, 0.4273], dtype=torch.float64)]\n",
            "train: [0.7407216644287109, tensor([0.4273, 0.4273], dtype=torch.float64)]\n",
            "train: [0.7419415987454928, tensor([0.4314, 0.4314], dtype=torch.float64)]\n",
            "train: [0.7401762361879702, tensor([0.4313, 0.4313], dtype=torch.float64)]\n",
            "train: [0.7377262115478516, tensor([0.4313, 0.4313], dtype=torch.float64)]\n",
            "train: [0.7390916100863753, tensor([0.4334, 0.4334], dtype=torch.float64)]\n",
            "train: [0.7398871739705404, tensor([0.4362, 0.4362], dtype=torch.float64)]\n",
            "train: [0.7370822045110887, tensor([0.4385, 0.4385], dtype=torch.float64)]\n",
            "train: [0.7356663942337036, tensor([0.4343, 0.4343], dtype=torch.float64)]\n",
            "train: [0.7355070981112394, tensor([0.4281, 0.4281], dtype=torch.float64)]\n",
            "train: [0.7355016820571002, tensor([0.4174, 0.4174], dtype=torch.float64)]\n",
            "train: [0.7358742850167411, tensor([0.4055, 0.4055], dtype=torch.float64)]\n",
            "train: [0.7338328891330295, tensor([0.3942, 0.3942], dtype=torch.float64)]\n",
            "train: [0.7312313801533467, tensor([0.3903, 0.3903], dtype=torch.float64)]\n",
            "train: [0.7319917176899157, tensor([0.3877, 0.3877], dtype=torch.float64)]\n",
            "train: [0.7307521135379107, tensor([0.3853, 0.3853], dtype=torch.float64)]\n",
            "train: [0.7303172588348389, tensor([0.3869, 0.3869], dtype=torch.float64)]\n",
            "train: [0.7292332998136195, tensor([0.3914, 0.3914], dtype=torch.float64)]\n",
            "train: [0.7314006714593797, tensor([0.3938, 0.3938], dtype=torch.float64)]\n",
            "train: [0.7296599454657976, tensor([0.4001, 0.4001], dtype=torch.float64)]\n",
            "train: [0.7275483391501687, tensor([0.4066, 0.4066], dtype=torch.float64)]\n",
            "train: [0.728255123562283, tensor([0.4104, 0.4104], dtype=torch.float64)]\n",
            "train: [0.728476151176121, tensor([0.4141, 0.4141], dtype=torch.float64)]\n",
            "train: [0.7294985994379571, tensor([0.4165, 0.4165], dtype=torch.float64)]\n",
            "train: [0.7290444374084473, tensor([0.4198, 0.4198], dtype=torch.float64)]\n",
            "train: [0.7308523217026068, tensor([0.4208, 0.4208], dtype=torch.float64)]\n",
            "train: [0.7308260345458985, tensor([0.4230, 0.4230], dtype=torch.float64)]\n",
            "train: [0.7309978709501379, tensor([0.4247, 0.4247], dtype=torch.float64)]\n",
            "train: [0.7301919643695538, tensor([0.4286, 0.4286], dtype=torch.float64)]\n",
            "train: [0.7305347514602373, tensor([0.4314, 0.4314], dtype=torch.float64)]\n",
            "train: [0.7300568333378544, tensor([0.4325, 0.4325], dtype=torch.float64)]\n",
            "train: [0.7293705333362926, tensor([0.4311, 0.4311], dtype=torch.float64)]\n",
            "train: [0.7294529506138393, tensor([0.4314, 0.4314], dtype=torch.float64)]\n",
            "train: [0.727402268794545, tensor([0.4290, 0.4290], dtype=torch.float64)]\n",
            "train: [0.7257164922253839, tensor([0.4231, 0.4231], dtype=torch.float64)]\n",
            "train: [0.7244071960449219, tensor([0.4159, 0.4159], dtype=torch.float64)]\n",
            "train: [0.726033083597819, tensor([0.4090, 0.4090], dtype=torch.float64)]\n",
            "train: [0.7281514152151639, tensor([0.4023, 0.4023], dtype=torch.float64)]\n",
            "train: [0.7277264748850176, tensor([0.3958, 0.3958], dtype=torch.float64)]\n",
            "train: [0.7277397882370722, tensor([0.3908, 0.3908], dtype=torch.float64)]\n",
            "train: [0.7274190187454224, tensor([0.3859, 0.3859], dtype=torch.float64)]\n",
            "train: [0.7269481365497296, tensor([0.3846, 0.3846], dtype=torch.float64)]\n",
            "train: [0.7258046468098959, tensor([0.3822, 0.3822], dtype=torch.float64)]\n",
            "train: [0.7242453845579233, tensor([0.3842, 0.3842], dtype=torch.float64)]\n",
            "train: [0.7231036915498621, tensor([0.3875, 0.3875], dtype=torch.float64)]\n",
            "train: [0.7240350142769192, tensor([0.3882, 0.3882], dtype=torch.float64)]\n",
            "train: [0.7227408272879464, tensor([0.3921, 0.3921], dtype=torch.float64)]\n",
            "train: [0.7217815023073009, tensor([0.3957, 0.3957], dtype=torch.float64)]\n",
            "train: [0.7219393518235948, tensor([0.3980, 0.3980], dtype=torch.float64)]\n",
            "train: [0.7220276610492027, tensor([0.4012, 0.4012], dtype=torch.float64)]\n",
            "train: [0.7228338396227038, tensor([0.4021, 0.4021], dtype=torch.float64)]\n",
            "train: [0.7231383260091145, tensor([0.4043, 0.4043], dtype=torch.float64)]\n",
            "train: [0.7228865372507196, tensor([0.4064, 0.4064], dtype=torch.float64)]\n",
            "train: [0.7220550636192421, tensor([0.4072, 0.4072], dtype=torch.float64)]\n",
            "train: [0.7216661404340695, tensor([0.4088, 0.4088], dtype=torch.float64)]\n",
            "train: [0.7212302775322637, tensor([0.4088, 0.4088], dtype=torch.float64)]\n",
            "train: [0.7222016811370849, tensor([0.4089, 0.4089], dtype=torch.float64)]\n",
            "train: [0.7232982965163243, tensor([0.4078, 0.4078], dtype=torch.float64)]\n",
            "train: [0.7258928810677877, tensor([0.4068, 0.4068], dtype=torch.float64)]\n",
            "train: [0.7246394789362528, tensor([0.4076, 0.4076], dtype=torch.float64)]\n",
            "train: [0.7244999749319894, tensor([0.4076, 0.4076], dtype=torch.float64)]\n",
            "train: [0.7242790222167969, tensor([0.4067, 0.4067], dtype=torch.float64)]\n",
            "train: [0.7236505109210347, tensor([0.4062, 0.4062], dtype=torch.float64)]\n",
            "train: [0.7225995995532507, tensor([0.4042, 0.4042], dtype=torch.float64)]\n",
            "train: [0.7221942814913663, tensor([0.4032, 0.4032], dtype=torch.float64)]\n",
            "train: [0.7226355906282917, tensor([0.4042, 0.4042], dtype=torch.float64)]\n",
            "train: [0.7214047749837239, tensor([0.4057, 0.4057], dtype=torch.float64)]\n",
            "train: [0.7211315448467548, tensor([0.4064, 0.4064], dtype=torch.float64)]\n",
            "train: [0.7217375713845958, tensor([0.4079, 0.4079], dtype=torch.float64)]\n",
            "train: [0.7213508031701529, tensor([0.4100, 0.4100], dtype=torch.float64)]\n",
            "train: [0.7219507744971742, tensor([0.4115, 0.4115], dtype=torch.float64)]\n",
            "train: [0.7224490517064145, tensor([0.4130, 0.4130], dtype=torch.float64)]\n",
            "train: [0.7220718065897623, tensor([0.4143, 0.4143], dtype=torch.float64)]\n",
            "train: [0.7216678894672197, tensor([0.4150, 0.4150], dtype=torch.float64)]\n",
            "train: [0.721602303641183, tensor([0.4144, 0.4144], dtype=torch.float64)]\n",
            "train: [0.7216944839015151, tensor([0.4134, 0.4134], dtype=torch.float64)]\n",
            "train: [0.7211795806884765, tensor([0.4136, 0.4136], dtype=torch.float64)]\n",
            "train: [0.7208759572246287, tensor([0.4123, 0.4123], dtype=torch.float64)]\n",
            "train: [0.7196314942603018, tensor([0.4091, 0.4091], dtype=torch.float64)]\n",
            "train: [0.7194523487276244, tensor([0.4051, 0.4051], dtype=torch.float64)]\n",
            "train: [0.7188856418316181, tensor([0.4019, 0.4019], dtype=torch.float64)]\n",
            "train: [0.7181100754510789, tensor([0.3981, 0.3981], dtype=torch.float64)]\n",
            "train: [0.7174118329893868, tensor([0.3943, 0.3943], dtype=torch.float64)]\n",
            "train: [0.7172077214606455, tensor([0.3906, 0.3906], dtype=torch.float64)]\n",
            "train: [0.7163965437147353, tensor([0.3870, 0.3870], dtype=torch.float64)]\n",
            "train: [0.7162390192714306, tensor([0.3850, 0.3850], dtype=torch.float64)]\n",
            "train: [0.7154164400967684, tensor([0.3846, 0.3846], dtype=torch.float64)]\n",
            "train: [0.7157071775144285, tensor([0.3844, 0.3844], dtype=torch.float64)]\n",
            "train: [0.7152482441493443, tensor([0.3852, 0.3852], dtype=torch.float64)]\n",
            "train: [0.7151528417536642, tensor([0.3862, 0.3862], dtype=torch.float64)]\n",
            "train: [0.7150279262609649, tensor([0.3877, 0.3877], dtype=torch.float64)]\n",
            "train: [0.7141283781632133, tensor([0.3898, 0.3898], dtype=torch.float64)]\n",
            "train: [0.7138254231420057, tensor([0.3910, 0.3910], dtype=torch.float64)]\n",
            "train: [0.7143015413202791, tensor([0.3906, 0.3906], dtype=torch.float64)]\n",
            "train: [0.7140212624759997, tensor([0.3924, 0.3924], dtype=torch.float64)]\n",
            "train: [0.7130405201631433, tensor([0.3944, 0.3944], dtype=torch.float64)]\n",
            "train: [0.7131299336751302, tensor([0.3940, 0.3940], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.7364692687988281, tensor([0.2000, 0.2000], dtype=torch.float64)]\n",
            "\n",
            "train: [0.7001473903656006, tensor([0.4528, 0.4528], dtype=torch.float64)]\n",
            "train: [0.6768007278442383, tensor([0.3728, 0.3728], dtype=torch.float64)]\n",
            "train: [0.6786244710286459, tensor([0.3279, 0.3279], dtype=torch.float64)]\n",
            "train: [0.6657595634460449, tensor([0.3622, 0.3622], dtype=torch.float64)]\n",
            "train: [0.6617291927337646, tensor([0.3593, 0.3593], dtype=torch.float64)]\n",
            "train: [0.6533636252085367, tensor([0.3794, 0.3794], dtype=torch.float64)]\n",
            "train: [0.6637083462306431, tensor([0.3791, 0.3791], dtype=torch.float64)]\n",
            "train: [0.6600230932235718, tensor([0.3978, 0.3978], dtype=torch.float64)]\n",
            "train: [0.661876360575358, tensor([0.3914, 0.3914], dtype=torch.float64)]\n",
            "train: [0.6608906745910644, tensor([0.3931, 0.3931], dtype=torch.float64)]\n",
            "train: [0.6614219058643688, tensor([0.3973, 0.3973], dtype=torch.float64)]\n",
            "train: [0.6583233674367269, tensor([0.3920, 0.3920], dtype=torch.float64)]\n",
            "train: [0.6556298916156476, tensor([0.3951, 0.3951], dtype=torch.float64)]\n",
            "train: [0.6547824314662388, tensor([0.3913, 0.3913], dtype=torch.float64)]\n",
            "train: [0.6579125086466472, tensor([0.3857, 0.3857], dtype=torch.float64)]\n",
            "train: [0.657745897769928, tensor([0.3884, 0.3884], dtype=torch.float64)]\n",
            "train: [0.6592324761783376, tensor([0.3812, 0.3812], dtype=torch.float64)]\n",
            "train: [0.6561918788486056, tensor([0.3939, 0.3939], dtype=torch.float64)]\n",
            "train: [0.6564996117039731, tensor([0.3965, 0.3965], dtype=torch.float64)]\n",
            "train: [0.6571676731109619, tensor([0.3992, 0.3992], dtype=torch.float64)]\n",
            "train: [0.6585198356991723, tensor([0.4040, 0.4040], dtype=torch.float64)]\n",
            "train: [0.6582980155944824, tensor([0.4079, 0.4079], dtype=torch.float64)]\n",
            "train: [0.6571229022482167, tensor([0.4127, 0.4127], dtype=torch.float64)]\n",
            "train: [0.6589436133702596, tensor([0.4091, 0.4091], dtype=torch.float64)]\n",
            "train: [0.6623704528808594, tensor([0.3989, 0.3989], dtype=torch.float64)]\n",
            "train: [0.6617484459510217, tensor([0.3937, 0.3937], dtype=torch.float64)]\n",
            "train: [0.6632487685592087, tensor([0.3949, 0.3949], dtype=torch.float64)]\n",
            "train: [0.6626121657235282, tensor([0.3990, 0.3990], dtype=torch.float64)]\n",
            "train: [0.6622565696979391, tensor([0.4051, 0.4051], dtype=torch.float64)]\n",
            "train: [0.6619585037231446, tensor([0.4111, 0.4111], dtype=torch.float64)]\n",
            "train: [0.6636628181703629, tensor([0.4147, 0.4147], dtype=torch.float64)]\n",
            "train: [0.6637617349624634, tensor([0.4150, 0.4150], dtype=torch.float64)]\n",
            "train: [0.6633860270182291, tensor([0.4197, 0.4197], dtype=torch.float64)]\n",
            "train: [0.6640453899607939, tensor([0.4158, 0.4158], dtype=torch.float64)]\n",
            "train: [0.6649750845772879, tensor([0.4057, 0.4057], dtype=torch.float64)]\n",
            "train: [0.6647400326199002, tensor([0.4022, 0.4022], dtype=torch.float64)]\n",
            "train: [0.6632782188621728, tensor([0.4042, 0.4042], dtype=torch.float64)]\n",
            "train: [0.6637572238319799, tensor([0.4054, 0.4054], dtype=torch.float64)]\n",
            "train: [0.664581543360001, tensor([0.4093, 0.4093], dtype=torch.float64)]\n",
            "train: [0.6632389068603516, tensor([0.4155, 0.4155], dtype=torch.float64)]\n",
            "train: [0.6663529000631193, tensor([0.4187, 0.4187], dtype=torch.float64)]\n",
            "train: [0.6655861082531157, tensor([0.4202, 0.4202], dtype=torch.float64)]\n",
            "train: [0.666598031687182, tensor([0.4195, 0.4195], dtype=torch.float64)]\n",
            "train: [0.6658144864169034, tensor([0.4219, 0.4219], dtype=torch.float64)]\n",
            "train: [0.668828625149197, tensor([0.4182, 0.4182], dtype=torch.float64)]\n",
            "train: [0.6684062791907269, tensor([0.4141, 0.4141], dtype=torch.float64)]\n",
            "train: [0.6683893812463638, tensor([0.4134, 0.4134], dtype=torch.float64)]\n",
            "train: [0.6680803298950195, tensor([0.4177, 0.4177], dtype=torch.float64)]\n",
            "train: [0.6676220018036512, tensor([0.4232, 0.4232], dtype=torch.float64)]\n",
            "train: [0.6686516571044921, tensor([0.4268, 0.4268], dtype=torch.float64)]\n",
            "train: [0.6708629084568397, tensor([0.4296, 0.4296], dtype=torch.float64)]\n",
            "train: [0.6708376224224384, tensor([0.4335, 0.4335], dtype=torch.float64)]\n",
            "train: [0.6712667357246831, tensor([0.4360, 0.4360], dtype=torch.float64)]\n",
            "train: [0.6724136493824147, tensor([0.4341, 0.4341], dtype=torch.float64)]\n",
            "train: [0.6726572210138494, tensor([0.4344, 0.4344], dtype=torch.float64)]\n",
            "train: [0.6755614280700684, tensor([0.4311, 0.4311], dtype=torch.float64)]\n",
            "train: [0.6764824850517407, tensor([0.4303, 0.4303], dtype=torch.float64)]\n",
            "train: [0.6782317325986665, tensor([0.4276, 0.4276], dtype=torch.float64)]\n",
            "train: [0.6786491911290056, tensor([0.4287, 0.4287], dtype=torch.float64)]\n",
            "train: [0.6793112436930339, tensor([0.4307, 0.4307], dtype=torch.float64)]\n",
            "train: [0.6794010224889536, tensor([0.4325, 0.4325], dtype=torch.float64)]\n",
            "train: [0.6791027438256049, tensor([0.4348, 0.4348], dtype=torch.float64)]\n",
            "train: [0.6792931935143849, tensor([0.4338, 0.4338], dtype=torch.float64)]\n",
            "train: [0.6785863637924194, tensor([0.4319, 0.4319], dtype=torch.float64)]\n",
            "train: [0.6777544461763823, tensor([0.4264, 0.4264], dtype=torch.float64)]\n",
            "train: [0.6783297567656545, tensor([0.4200, 0.4200], dtype=torch.float64)]\n",
            "train: [0.6798845547348705, tensor([0.4145, 0.4145], dtype=torch.float64)]\n",
            "train: [0.6794461082009708, tensor([0.4126, 0.4126], dtype=torch.float64)]\n",
            "train: [0.6793701614158741, tensor([0.4123, 0.4123], dtype=torch.float64)]\n",
            "train: [0.6792127336774554, tensor([0.4130, 0.4130], dtype=torch.float64)]\n",
            "train: [0.6794667848398988, tensor([0.4145, 0.4145], dtype=torch.float64)]\n",
            "train: [0.6802736388312446, tensor([0.4162, 0.4162], dtype=torch.float64)]\n",
            "train: [0.680567545433567, tensor([0.4178, 0.4178], dtype=torch.float64)]\n",
            "train: [0.6802059379783837, tensor([0.4186, 0.4186], dtype=torch.float64)]\n",
            "train: [0.6793554178873698, tensor([0.4169, 0.4169], dtype=torch.float64)]\n",
            "train: [0.6802478589509663, tensor([0.4130, 0.4130], dtype=torch.float64)]\n",
            "train: [0.679803228997565, tensor([0.4114, 0.4114], dtype=torch.float64)]\n",
            "train: [0.6802335885854868, tensor([0.4122, 0.4122], dtype=torch.float64)]\n",
            "train: [0.6787294798259493, tensor([0.4150, 0.4150], dtype=torch.float64)]\n",
            "train: [0.6800570964813233, tensor([0.4153, 0.4153], dtype=torch.float64)]\n",
            "train: [0.6803664219232253, tensor([0.4171, 0.4171], dtype=torch.float64)]\n",
            "train: [0.6818736471780916, tensor([0.4167, 0.4167], dtype=torch.float64)]\n",
            "train: [0.6834217669015907, tensor([0.4156, 0.4156], dtype=torch.float64)]\n",
            "train: [0.682856559753418, tensor([0.4145, 0.4145], dtype=torch.float64)]\n",
            "train: [0.6828543719123391, tensor([0.4146, 0.4146], dtype=torch.float64)]\n",
            "train: [0.6823889710182367, tensor([0.4140, 0.4140], dtype=torch.float64)]\n",
            "train: [0.682122811503794, tensor([0.4150, 0.4150], dtype=torch.float64)]\n",
            "train: [0.6822103587063876, tensor([0.4151, 0.4151], dtype=torch.float64)]\n",
            "train: [0.682290152217565, tensor([0.4159, 0.4159], dtype=torch.float64)]\n",
            "train: [0.6819463941786025, tensor([0.4181, 0.4181], dtype=torch.float64)]\n",
            "train: [0.6823269351498111, tensor([0.4184, 0.4184], dtype=torch.float64)]\n",
            "train: [0.6817225580630095, tensor([0.4200, 0.4200], dtype=torch.float64)]\n",
            "train: [0.6809106232017599, tensor([0.4215, 0.4215], dtype=torch.float64)]\n",
            "train: [0.6811842411122424, tensor([0.4230, 0.4230], dtype=torch.float64)]\n",
            "train: [0.6815277902703536, tensor([0.4221, 0.4221], dtype=torch.float64)]\n",
            "train: [0.6810135046641032, tensor([0.4226, 0.4226], dtype=torch.float64)]\n",
            "train: [0.6804821368345281, tensor([0.4233, 0.4233], dtype=torch.float64)]\n",
            "train: [0.6804073878696987, tensor([0.4234, 0.4234], dtype=torch.float64)]\n",
            "train: [0.6808264375937105, tensor([0.4237, 0.4237], dtype=torch.float64)]\n",
            "train: [0.6813359069824219, tensor([0.4238, 0.4238], dtype=torch.float64)]\n",
            "train: [0.6810747656491724, tensor([0.4249, 0.4249], dtype=torch.float64)]\n",
            "train: [0.6808466443828508, tensor([0.4263, 0.4263], dtype=torch.float64)]\n",
            "train: [0.6815269988717385, tensor([0.4270, 0.4270], dtype=torch.float64)]\n",
            "train: [0.6811895370483398, tensor([0.4265, 0.4265], dtype=torch.float64)]\n",
            "train: [0.6817545572916667, tensor([0.4272, 0.4272], dtype=torch.float64)]\n",
            "train: [0.6816551640348615, tensor([0.4280, 0.4280], dtype=torch.float64)]\n",
            "train: [0.6823306217371861, tensor([0.4271, 0.4271], dtype=torch.float64)]\n",
            "train: [0.6823292484989872, tensor([0.4271, 0.4271], dtype=torch.float64)]\n",
            "train: [0.6830075465211081, tensor([0.4278, 0.4278], dtype=torch.float64)]\n",
            "train: [0.6832764365456321, tensor([0.4294, 0.4294], dtype=torch.float64)]\n",
            "train: [0.6834377254451718, tensor([0.4289, 0.4289], dtype=torch.float64)]\n",
            "train: [0.6836635725838798, tensor([0.4283, 0.4283], dtype=torch.float64)]\n",
            "train: [0.6836438474401964, tensor([0.4265, 0.4265], dtype=torch.float64)]\n",
            "train: [0.683697215297766, tensor([0.4238, 0.4238], dtype=torch.float64)]\n",
            "train: [0.6837136973505434, tensor([0.4221, 0.4221], dtype=torch.float64)]\n",
            "train: [0.6842311990672144, tensor([0.4218, 0.4218], dtype=torch.float64)]\n",
            "train: [0.6838789719801682, tensor([0.4229, 0.4229], dtype=torch.float64)]\n",
            "train: [0.6838254766949152, tensor([0.4238, 0.4238], dtype=torch.float64)]\n",
            "train: [0.6836898547260701, tensor([0.4223, 0.4223], dtype=torch.float64)]\n",
            "train: [0.683346684773763, tensor([0.4214, 0.4214], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6737659454345704, tensor([0.3922, 0.3922], dtype=torch.float64)]\n",
            "\n",
            "train: [0.6586527824401855, tensor([0.3158, 0.3158], dtype=torch.float64)]\n",
            "train: [0.6965653896331787, tensor([0.3318, 0.3318], dtype=torch.float64)]\n",
            "train: [0.6833009719848633, tensor([0.3482, 0.3482], dtype=torch.float64)]\n",
            "train: [0.6859405636787415, tensor([0.3902, 0.3902], dtype=torch.float64)]\n",
            "train: [0.6844184875488282, tensor([0.4010, 0.4010], dtype=torch.float64)]\n",
            "train: [0.6766098340352377, tensor([0.4239, 0.4239], dtype=torch.float64)]\n",
            "train: [0.670884200504848, tensor([0.4443, 0.4443], dtype=torch.float64)]\n",
            "train: [0.6744148135185242, tensor([0.4570, 0.4570], dtype=torch.float64)]\n",
            "train: [0.6713454988267686, tensor([0.4725, 0.4725], dtype=torch.float64)]\n",
            "train: [0.6845280170440674, tensor([0.4719, 0.4719], dtype=torch.float64)]\n",
            "train: [0.6809848005121405, tensor([0.4544, 0.4544], dtype=torch.float64)]\n",
            "train: [0.6794916788736979, tensor([0.4557, 0.4557], dtype=torch.float64)]\n",
            "train: [0.6791139749380258, tensor([0.4607, 0.4607], dtype=torch.float64)]\n",
            "train: [0.6766080856323242, tensor([0.4614, 0.4614], dtype=torch.float64)]\n",
            "train: [0.6756985982259115, tensor([0.4568, 0.4568], dtype=torch.float64)]\n",
            "train: [0.6797399520874023, tensor([0.4563, 0.4563], dtype=torch.float64)]\n",
            "train: [0.6763351103838753, tensor([0.4606, 0.4606], dtype=torch.float64)]\n",
            "train: [0.6762804455227323, tensor([0.4578, 0.4578], dtype=torch.float64)]\n",
            "train: [0.6743605764288652, tensor([0.4645, 0.4645], dtype=torch.float64)]\n",
            "train: [0.6738368988037109, tensor([0.4640, 0.4640], dtype=torch.float64)]\n",
            "train: [0.6725781304495675, tensor([0.4520, 0.4520], dtype=torch.float64)]\n",
            "train: [0.6704178723421964, tensor([0.4428, 0.4428], dtype=torch.float64)]\n",
            "train: [0.6685759088267451, tensor([0.4272, 0.4272], dtype=torch.float64)]\n",
            "train: [0.6768411000569662, tensor([0.4117, 0.4117], dtype=torch.float64)]\n",
            "train: [0.6768357849121094, tensor([0.4039, 0.4039], dtype=torch.float64)]\n",
            "train: [0.6767395459688627, tensor([0.4128, 0.4128], dtype=torch.float64)]\n",
            "train: [0.6779734293619791, tensor([0.4216, 0.4216], dtype=torch.float64)]\n",
            "train: [0.6784803526742118, tensor([0.4300, 0.4300], dtype=torch.float64)]\n",
            "train: [0.6779229394320784, tensor([0.4384, 0.4384], dtype=torch.float64)]\n",
            "train: [0.6769126892089844, tensor([0.4454, 0.4454], dtype=torch.float64)]\n",
            "train: [0.6768984025524508, tensor([0.4515, 0.4515], dtype=torch.float64)]\n",
            "train: [0.6765138506889343, tensor([0.4509, 0.4509], dtype=torch.float64)]\n",
            "train: [0.6758984652432528, tensor([0.4517, 0.4517], dtype=torch.float64)]\n",
            "train: [0.674751786624684, tensor([0.4433, 0.4433], dtype=torch.float64)]\n",
            "train: [0.6732833317347935, tensor([0.4413, 0.4413], dtype=torch.float64)]\n",
            "train: [0.6743068695068359, tensor([0.4391, 0.4391], dtype=torch.float64)]\n",
            "train: [0.6744404354610959, tensor([0.4360, 0.4360], dtype=torch.float64)]\n",
            "train: [0.6749892987703022, tensor([0.4315, 0.4315], dtype=torch.float64)]\n",
            "train: [0.6750214405548878, tensor([0.4293, 0.4293], dtype=torch.float64)]\n",
            "train: [0.6732076644897461, tensor([0.4326, 0.4326], dtype=torch.float64)]\n",
            "train: [0.6732527104819693, tensor([0.4339, 0.4339], dtype=torch.float64)]\n",
            "train: [0.6731268564860026, tensor([0.4341, 0.4341], dtype=torch.float64)]\n",
            "train: [0.6731491532436636, tensor([0.4296, 0.4296], dtype=torch.float64)]\n",
            "train: [0.674348614432595, tensor([0.4265, 0.4265], dtype=torch.float64)]\n",
            "train: [0.6752708435058594, tensor([0.4262, 0.4262], dtype=torch.float64)]\n",
            "train: [0.6755630244379458, tensor([0.4305, 0.4305], dtype=torch.float64)]\n",
            "train: [0.6775537450262841, tensor([0.4334, 0.4334], dtype=torch.float64)]\n",
            "train: [0.6781403223673502, tensor([0.4365, 0.4365], dtype=torch.float64)]\n",
            "train: [0.677921995824697, tensor([0.4364, 0.4364], dtype=torch.float64)]\n",
            "train: [0.6787803649902344, tensor([0.4288, 0.4288], dtype=torch.float64)]\n",
            "train: [0.6793474683574602, tensor([0.4216, 0.4216], dtype=torch.float64)]\n",
            "train: [0.6789550047654372, tensor([0.4149, 0.4149], dtype=torch.float64)]\n",
            "train: [0.6783717893204599, tensor([0.4144, 0.4144], dtype=torch.float64)]\n",
            "train: [0.6785185778582538, tensor([0.4146, 0.4146], dtype=torch.float64)]\n",
            "train: [0.6788101196289062, tensor([0.4184, 0.4184], dtype=torch.float64)]\n",
            "train: [0.6796463557652065, tensor([0.4192, 0.4192], dtype=torch.float64)]\n",
            "train: [0.6806204946417558, tensor([0.4210, 0.4210], dtype=torch.float64)]\n",
            "train: [0.6813945770263672, tensor([0.4221, 0.4221], dtype=torch.float64)]\n",
            "train: [0.6819078477762514, tensor([0.4214, 0.4214], dtype=torch.float64)]\n",
            "train: [0.681890869140625, tensor([0.4205, 0.4205], dtype=torch.float64)]\n",
            "train: [0.681405927314133, tensor([0.4220, 0.4220], dtype=torch.float64)]\n",
            "train: [0.6810857711299774, tensor([0.4244, 0.4244], dtype=torch.float64)]\n",
            "train: [0.6808272467719184, tensor([0.4263, 0.4263], dtype=torch.float64)]\n",
            "train: [0.6811604499816895, tensor([0.4251, 0.4251], dtype=torch.float64)]\n",
            "train: [0.681265610914964, tensor([0.4265, 0.4265], dtype=torch.float64)]\n",
            "train: [0.6805145957253196, tensor([0.4285, 0.4285], dtype=torch.float64)]\n",
            "train: [0.6809216399690998, tensor([0.4279, 0.4279], dtype=torch.float64)]\n",
            "train: [0.6804494296803194, tensor([0.4294, 0.4294], dtype=torch.float64)]\n",
            "train: [0.6803636965544327, tensor([0.4301, 0.4301], dtype=torch.float64)]\n",
            "train: [0.6804943629673549, tensor([0.4316, 0.4316], dtype=torch.float64)]\n",
            "train: [0.680723593268596, tensor([0.4337, 0.4337], dtype=torch.float64)]\n",
            "train: [0.6804527706570096, tensor([0.4338, 0.4338], dtype=torch.float64)]\n",
            "train: [0.6803033907119542, tensor([0.4316, 0.4316], dtype=torch.float64)]\n",
            "train: [0.6803708978601404, tensor([0.4293, 0.4293], dtype=torch.float64)]\n",
            "train: [0.6796918233235677, tensor([0.4262, 0.4262], dtype=torch.float64)]\n",
            "train: [0.679297497397975, tensor([0.4224, 0.4224], dtype=torch.float64)]\n",
            "train: [0.6796990431748428, tensor([0.4169, 0.4169], dtype=torch.float64)]\n",
            "train: [0.6797925998003055, tensor([0.4152, 0.4152], dtype=torch.float64)]\n",
            "train: [0.679361174378214, tensor([0.4129, 0.4129], dtype=torch.float64)]\n",
            "train: [0.6778549671173095, tensor([0.4147, 0.4147], dtype=torch.float64)]\n",
            "train: [0.6782814779399354, tensor([0.4155, 0.4155], dtype=torch.float64)]\n",
            "train: [0.6783179306402439, tensor([0.4164, 0.4164], dtype=torch.float64)]\n",
            "train: [0.6772783118558218, tensor([0.4185, 0.4185], dtype=torch.float64)]\n",
            "train: [0.6772442772274926, tensor([0.4185, 0.4185], dtype=torch.float64)]\n",
            "train: [0.6778695947983686, tensor([0.4164, 0.4164], dtype=torch.float64)]\n",
            "train: [0.6775995298873546, tensor([0.4160, 0.4160], dtype=torch.float64)]\n",
            "train: [0.6773953492614044, tensor([0.4146, 0.4146], dtype=torch.float64)]\n",
            "train: [0.6771394989707253, tensor([0.4147, 0.4147], dtype=torch.float64)]\n",
            "train: [0.6764859403117319, tensor([0.4171, 0.4171], dtype=torch.float64)]\n",
            "train: [0.6763109419080946, tensor([0.4189, 0.4189], dtype=torch.float64)]\n",
            "train: [0.6769963777982272, tensor([0.4193, 0.4193], dtype=torch.float64)]\n",
            "train: [0.6769703989443572, tensor([0.4202, 0.4202], dtype=torch.float64)]\n",
            "train: [0.6785141319356939, tensor([0.4186, 0.4186], dtype=torch.float64)]\n",
            "train: [0.6781804510887633, tensor([0.4155, 0.4155], dtype=torch.float64)]\n",
            "train: [0.6781839471114309, tensor([0.4118, 0.4118], dtype=torch.float64)]\n",
            "train: [0.6780987580617269, tensor([0.4093, 0.4093], dtype=torch.float64)]\n",
            "train: [0.6780717200839642, tensor([0.4089, 0.4089], dtype=torch.float64)]\n",
            "train: [0.6783732200155452, tensor([0.4058, 0.4058], dtype=torch.float64)]\n",
            "train: [0.6783605248037011, tensor([0.4024, 0.4024], dtype=torch.float64)]\n",
            "train: [0.678164291381836, tensor([0.3984, 0.3984], dtype=torch.float64)]\n",
            "train: [0.6780239898379486, tensor([0.3945, 0.3945], dtype=torch.float64)]\n",
            "train: [0.6778469459683287, tensor([0.3913, 0.3913], dtype=torch.float64)]\n",
            "train: [0.6776641549415958, tensor([0.3888, 0.3888], dtype=torch.float64)]\n",
            "train: [0.6777321742131159, tensor([0.3873, 0.3873], dtype=torch.float64)]\n",
            "train: [0.6773959205264137, tensor([0.3881, 0.3881], dtype=torch.float64)]\n",
            "train: [0.6772089544332253, tensor([0.3889, 0.3889], dtype=torch.float64)]\n",
            "train: [0.6766916435455608, tensor([0.3891, 0.3891], dtype=torch.float64)]\n",
            "train: [0.6769012875027127, tensor([0.3877, 0.3877], dtype=torch.float64)]\n",
            "train: [0.6764882638913776, tensor([0.3841, 0.3841], dtype=torch.float64)]\n",
            "train: [0.6764332857998935, tensor([0.3812, 0.3812], dtype=torch.float64)]\n",
            "train: [0.6765995197467976, tensor([0.3797, 0.3797], dtype=torch.float64)]\n",
            "train: [0.6770740236554827, tensor([0.3799, 0.3799], dtype=torch.float64)]\n",
            "train: [0.6766283828600318, tensor([0.3824, 0.3824], dtype=torch.float64)]\n",
            "train: [0.676570691560444, tensor([0.3838, 0.3838], dtype=torch.float64)]\n",
            "train: [0.6766985685929008, tensor([0.3845, 0.3845], dtype=torch.float64)]\n",
            "train: [0.6765916100863753, tensor([0.3860, 0.3860], dtype=torch.float64)]\n",
            "train: [0.6763329139122596, tensor([0.3881, 0.3881], dtype=torch.float64)]\n",
            "train: [0.6759513596356925, tensor([0.3891, 0.3891], dtype=torch.float64)]\n",
            "train: [0.6755756410230108, tensor([0.3900, 0.3900], dtype=torch.float64)]\n",
            "train: [0.6760969797770182, tensor([0.3908, 0.3908], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6465192522321429, tensor([0.6230, 0.6230], dtype=torch.float64)]\n",
            "\n",
            "train: [0.6984535455703735, tensor([0.6269, 0.6269], dtype=torch.float64)]\n",
            "train: [0.6815677881240845, tensor([0.6370, 0.6370], dtype=torch.float64)]\n",
            "train: [0.7018099625905355, tensor([0.5802, 0.5802], dtype=torch.float64)]\n",
            "train: [0.6871216893196106, tensor([0.5914, 0.5914], dtype=torch.float64)]\n",
            "train: [0.6811063289642334, tensor([0.5672, 0.5672], dtype=torch.float64)]\n",
            "train: [0.6809948285420736, tensor([0.5521, 0.5521], dtype=torch.float64)]\n",
            "train: [0.6866358348301479, tensor([0.5058, 0.5058], dtype=torch.float64)]\n",
            "train: [0.6794528365135193, tensor([0.4515, 0.4515], dtype=torch.float64)]\n",
            "train: [0.6803424623277452, tensor([0.4014, 0.4014], dtype=torch.float64)]\n",
            "train: [0.6759509086608887, tensor([0.3612, 0.3612], dtype=torch.float64)]\n",
            "train: [0.6723740751093085, tensor([0.3414, 0.3414], dtype=torch.float64)]\n",
            "train: [0.6767158508300781, tensor([0.3129, 0.3129], dtype=torch.float64)]\n",
            "train: [0.6748500970693735, tensor([0.2999, 0.2999], dtype=torch.float64)]\n",
            "train: [0.6727618489946637, tensor([0.2969, 0.2969], dtype=torch.float64)]\n",
            "train: [0.6755637486775716, tensor([0.2961, 0.2961], dtype=torch.float64)]\n",
            "train: [0.6785715818405151, tensor([0.2878, 0.2878], dtype=torch.float64)]\n",
            "train: [0.6774867001701804, tensor([0.2909, 0.2909], dtype=torch.float64)]\n",
            "train: [0.6769129965040419, tensor([0.2883, 0.2883], dtype=torch.float64)]\n",
            "train: [0.6765888113724557, tensor([0.2983, 0.2983], dtype=torch.float64)]\n",
            "train: [0.6766439914703369, tensor([0.3038, 0.3038], dtype=torch.float64)]\n",
            "train: [0.674705323718843, tensor([0.3052, 0.3052], dtype=torch.float64)]\n",
            "train: [0.6727036562832919, tensor([0.2914, 0.2914], dtype=torch.float64)]\n",
            "train: [0.6732837842858356, tensor([0.2787, 0.2787], dtype=torch.float64)]\n",
            "train: [0.6711722215016683, tensor([0.2671, 0.2671], dtype=torch.float64)]\n",
            "train: [0.6707682037353515, tensor([0.2564, 0.2564], dtype=torch.float64)]\n",
            "train: [0.6714191436767578, tensor([0.2491, 0.2491], dtype=torch.float64)]\n",
            "train: [0.6726979149712456, tensor([0.2418, 0.2418], dtype=torch.float64)]\n",
            "train: [0.6735637528555733, tensor([0.2431, 0.2431], dtype=torch.float64)]\n",
            "train: [0.6721940533868198, tensor([0.2512, 0.2512], dtype=torch.float64)]\n",
            "train: [0.6719252904256184, tensor([0.2605, 0.2605], dtype=torch.float64)]\n",
            "train: [0.6705846478862147, tensor([0.2721, 0.2721], dtype=torch.float64)]\n",
            "train: [0.6690487861633301, tensor([0.2830, 0.2830], dtype=torch.float64)]\n",
            "train: [0.6706402518532493, tensor([0.2899, 0.2899], dtype=torch.float64)]\n",
            "train: [0.6702058455523323, tensor([0.2999, 0.2999], dtype=torch.float64)]\n",
            "train: [0.6738212040492466, tensor([0.3075, 0.3075], dtype=torch.float64)]\n",
            "train: [0.673860232035319, tensor([0.3137, 0.3137], dtype=torch.float64)]\n",
            "train: [0.6725507684656091, tensor([0.3212, 0.3212], dtype=torch.float64)]\n",
            "train: [0.6715821717914782, tensor([0.3293, 0.3293], dtype=torch.float64)]\n",
            "train: [0.6709157992631961, tensor([0.3358, 0.3358], dtype=torch.float64)]\n",
            "train: [0.6713031768798828, tensor([0.3410, 0.3410], dtype=torch.float64)]\n",
            "train: [0.6711891453440596, tensor([0.3479, 0.3479], dtype=torch.float64)]\n",
            "train: [0.6707272302536738, tensor([0.3485, 0.3485], dtype=torch.float64)]\n",
            "train: [0.6716242501902026, tensor([0.3515, 0.3515], dtype=torch.float64)]\n",
            "train: [0.6721540797840465, tensor([0.3533, 0.3533], dtype=torch.float64)]\n",
            "train: [0.6721780565049913, tensor([0.3545, 0.3545], dtype=torch.float64)]\n",
            "train: [0.6719842993694803, tensor([0.3593, 0.3593], dtype=torch.float64)]\n",
            "train: [0.6712190749797415, tensor([0.3621, 0.3621], dtype=torch.float64)]\n",
            "train: [0.6713012059529623, tensor([0.3640, 0.3640], dtype=torch.float64)]\n",
            "train: [0.6703489653918208, tensor([0.3668, 0.3668], dtype=torch.float64)]\n",
            "train: [0.6700202178955078, tensor([0.3703, 0.3703], dtype=torch.float64)]\n",
            "train: [0.6709975448309207, tensor([0.3716, 0.3716], dtype=torch.float64)]\n",
            "train: [0.6710667976966271, tensor([0.3726, 0.3726], dtype=torch.float64)]\n",
            "train: [0.6702769297473835, tensor([0.3758, 0.3758], dtype=torch.float64)]\n",
            "train: [0.6708435482449002, tensor([0.3756, 0.3756], dtype=torch.float64)]\n",
            "train: [0.6709693215110085, tensor([0.3765, 0.3765], dtype=torch.float64)]\n",
            "train: [0.6706358364650181, tensor([0.3755, 0.3755], dtype=torch.float64)]\n",
            "train: [0.6710753189890009, tensor([0.3771, 0.3771], dtype=torch.float64)]\n",
            "train: [0.6704814516264817, tensor([0.3813, 0.3813], dtype=torch.float64)]\n",
            "train: [0.669726032321736, tensor([0.3846, 0.3846], dtype=torch.float64)]\n",
            "train: [0.6684540430704753, tensor([0.3870, 0.3870], dtype=torch.float64)]\n",
            "train: [0.6691468660948706, tensor([0.3861, 0.3861], dtype=torch.float64)]\n",
            "train: [0.6688523446359942, tensor([0.3873, 0.3873], dtype=torch.float64)]\n",
            "train: [0.6684902736118862, tensor([0.3872, 0.3872], dtype=torch.float64)]\n",
            "train: [0.6684927940368652, tensor([0.3843, 0.3843], dtype=torch.float64)]\n",
            "train: [0.6685733501727764, tensor([0.3834, 0.3834], dtype=torch.float64)]\n",
            "train: [0.6690530487985322, tensor([0.3859, 0.3859], dtype=torch.float64)]\n",
            "train: [0.6686506698380655, tensor([0.3889, 0.3889], dtype=torch.float64)]\n",
            "train: [0.6691647697897518, tensor([0.3916, 0.3916], dtype=torch.float64)]\n",
            "train: [0.669028185415959, tensor([0.3933, 0.3933], dtype=torch.float64)]\n",
            "train: [0.6688951764787946, tensor([0.3950, 0.3950], dtype=torch.float64)]\n",
            "train: [0.6693021210146622, tensor([0.3941, 0.3941], dtype=torch.float64)]\n",
            "train: [0.6687376764085557, tensor([0.3974, 0.3974], dtype=torch.float64)]\n",
            "train: [0.6682679685827804, tensor([0.3973, 0.3973], dtype=torch.float64)]\n",
            "train: [0.6688818029455237, tensor([0.3968, 0.3968], dtype=torch.float64)]\n",
            "train: [0.6695490010579427, tensor([0.3963, 0.3963], dtype=torch.float64)]\n",
            "train: [0.6700272811086554, tensor([0.3958, 0.3958], dtype=torch.float64)]\n",
            "train: [0.6699161281833401, tensor([0.3956, 0.3956], dtype=torch.float64)]\n",
            "train: [0.669501720330654, tensor([0.3943, 0.3943], dtype=torch.float64)]\n",
            "train: [0.6696114359022696, tensor([0.3932, 0.3932], dtype=torch.float64)]\n",
            "train: [0.669121265411377, tensor([0.3922, 0.3922], dtype=torch.float64)]\n",
            "train: [0.6690458603847174, tensor([0.3895, 0.3895], dtype=torch.float64)]\n",
            "train: [0.6694597383824791, tensor([0.3854, 0.3854], dtype=torch.float64)]\n",
            "train: [0.6687532907508942, tensor([0.3864, 0.3864], dtype=torch.float64)]\n",
            "train: [0.6693450382777623, tensor([0.3829, 0.3829], dtype=torch.float64)]\n",
            "train: [0.6687136033002068, tensor([0.3837, 0.3837], dtype=torch.float64)]\n",
            "train: [0.6686868002248365, tensor([0.3847, 0.3847], dtype=torch.float64)]\n",
            "train: [0.6691745012656025, tensor([0.3870, 0.3870], dtype=torch.float64)]\n",
            "train: [0.669368483803489, tensor([0.3883, 0.3883], dtype=torch.float64)]\n",
            "train: [0.6691027866320663, tensor([0.3904, 0.3904], dtype=torch.float64)]\n",
            "train: [0.6686289469401042, tensor([0.3928, 0.3928], dtype=torch.float64)]\n",
            "train: [0.6683939001062414, tensor([0.3947, 0.3947], dtype=torch.float64)]\n",
            "train: [0.667956020521081, tensor([0.3970, 0.3970], dtype=torch.float64)]\n",
            "train: [0.6679828602780578, tensor([0.3992, 0.3992], dtype=torch.float64)]\n",
            "train: [0.6684752930986121, tensor([0.3994, 0.3994], dtype=torch.float64)]\n",
            "train: [0.6681804456208882, tensor([0.3992, 0.3992], dtype=torch.float64)]\n",
            "train: [0.667606512705485, tensor([0.4012, 0.4012], dtype=torch.float64)]\n",
            "train: [0.6673238695282298, tensor([0.4014, 0.4014], dtype=torch.float64)]\n",
            "train: [0.6670168662557796, tensor([0.4007, 0.4007], dtype=torch.float64)]\n",
            "train: [0.667081351232047, tensor([0.3991, 0.3991], dtype=torch.float64)]\n",
            "train: [0.66747802734375, tensor([0.3983, 0.3983], dtype=torch.float64)]\n",
            "train: [0.667015000145034, tensor([0.3982, 0.3982], dtype=torch.float64)]\n",
            "train: [0.6669827629538143, tensor([0.3968, 0.3968], dtype=torch.float64)]\n",
            "train: [0.6671344794115974, tensor([0.3967, 0.3967], dtype=torch.float64)]\n",
            "train: [0.6667005098783053, tensor([0.3965, 0.3965], dtype=torch.float64)]\n",
            "train: [0.6663433983212426, tensor([0.3964, 0.3964], dtype=torch.float64)]\n",
            "train: [0.666440208003206, tensor([0.3964, 0.3964], dtype=torch.float64)]\n",
            "train: [0.6662311019184434, tensor([0.3967, 0.3967], dtype=torch.float64)]\n",
            "train: [0.6663367659957321, tensor([0.3967, 0.3967], dtype=torch.float64)]\n",
            "train: [0.6664474207326907, tensor([0.3967, 0.3967], dtype=torch.float64)]\n",
            "train: [0.6664953058416193, tensor([0.3973, 0.3973], dtype=torch.float64)]\n",
            "train: [0.6665343550948409, tensor([0.3976, 0.3976], dtype=torch.float64)]\n",
            "train: [0.666339465550014, tensor([0.3973, 0.3973], dtype=torch.float64)]\n",
            "train: [0.6661258798784915, tensor([0.3979, 0.3979], dtype=torch.float64)]\n",
            "train: [0.665859021638569, tensor([0.3978, 0.3978], dtype=torch.float64)]\n",
            "train: [0.6661826755689538, tensor([0.3971, 0.3971], dtype=torch.float64)]\n",
            "train: [0.6663883472311085, tensor([0.3956, 0.3956], dtype=torch.float64)]\n",
            "train: [0.6662492018479568, tensor([0.3940, 0.3940], dtype=torch.float64)]\n",
            "train: [0.6662394636768406, tensor([0.3934, 0.3934], dtype=torch.float64)]\n",
            "train: [0.6665614152155003, tensor([0.3939, 0.3939], dtype=torch.float64)]\n",
            "train: [0.6666969299316406, tensor([0.3929, 0.3929], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6665792192731584, tensor([0.1935, 0.1935], dtype=torch.float64)]\n",
            "\n",
            "train: [0.6673795580863953, tensor([0.3810, 0.3810], dtype=torch.float64)]\n",
            "train: [0.6699669361114502, tensor([0.3333, 0.3333], dtype=torch.float64)]\n",
            "train: [0.6575447718302408, tensor([0.3175, 0.3175], dtype=torch.float64)]\n",
            "train: [0.6526544094085693, tensor([0.2952, 0.2952], dtype=torch.float64)]\n",
            "train: [0.6625600337982178, tensor([0.2962, 0.2962], dtype=torch.float64)]\n",
            "train: [0.6597732305526733, tensor([0.3200, 0.3200], dtype=torch.float64)]\n",
            "train: [0.6602027756827218, tensor([0.3441, 0.3441], dtype=torch.float64)]\n",
            "train: [0.6594306826591492, tensor([0.3416, 0.3416], dtype=torch.float64)]\n",
            "train: [0.6599818335639106, tensor([0.3613, 0.3613], dtype=torch.float64)]\n",
            "train: [0.656253719329834, tensor([0.3740, 0.3740], dtype=torch.float64)]\n",
            "train: [0.65564472025091, tensor([0.3895, 0.3895], dtype=torch.float64)]\n",
            "train: [0.6508058706919352, tensor([0.4047, 0.4047], dtype=torch.float64)]\n",
            "train: [0.6493951357327975, tensor([0.4161, 0.4161], dtype=torch.float64)]\n",
            "train: [0.6452223914010184, tensor([0.4264, 0.4264], dtype=torch.float64)]\n",
            "train: [0.6457066218058268, tensor([0.4246, 0.4246], dtype=torch.float64)]\n",
            "train: [0.6421276330947876, tensor([0.4324, 0.4324], dtype=torch.float64)]\n",
            "train: [0.6415720546946806, tensor([0.4388, 0.4388], dtype=torch.float64)]\n",
            "train: [0.6438287099202474, tensor([0.4476, 0.4476], dtype=torch.float64)]\n",
            "train: [0.640936951888235, tensor([0.4520, 0.4520], dtype=torch.float64)]\n",
            "train: [0.6454021453857421, tensor([0.4553, 0.4553], dtype=torch.float64)]\n",
            "train: [0.6492807297479539, tensor([0.4495, 0.4495], dtype=torch.float64)]\n",
            "train: [0.6483762480995872, tensor([0.4522, 0.4522], dtype=torch.float64)]\n",
            "train: [0.6498560698136039, tensor([0.4525, 0.4525], dtype=torch.float64)]\n",
            "train: [0.6503932873407999, tensor([0.4533, 0.4533], dtype=torch.float64)]\n",
            "train: [0.6526011657714844, tensor([0.4520, 0.4520], dtype=torch.float64)]\n",
            "train: [0.6517331049992487, tensor([0.4584, 0.4584], dtype=torch.float64)]\n",
            "train: [0.6522773460105613, tensor([0.4597, 0.4597], dtype=torch.float64)]\n",
            "train: [0.6520429338727679, tensor([0.4662, 0.4662], dtype=torch.float64)]\n",
            "train: [0.6529785024708715, tensor([0.4683, 0.4683], dtype=torch.float64)]\n",
            "train: [0.6536063512166341, tensor([0.4711, 0.4711], dtype=torch.float64)]\n",
            "train: [0.6547778960197203, tensor([0.4717, 0.4717], dtype=torch.float64)]\n",
            "train: [0.654755175113678, tensor([0.4736, 0.4736], dtype=torch.float64)]\n",
            "train: [0.654664877689246, tensor([0.4702, 0.4702], dtype=torch.float64)]\n",
            "train: [0.6543042800005745, tensor([0.4692, 0.4692], dtype=torch.float64)]\n",
            "train: [0.6544533320835658, tensor([0.4629, 0.4629], dtype=torch.float64)]\n",
            "train: [0.6552571720547147, tensor([0.4577, 0.4577], dtype=torch.float64)]\n",
            "train: [0.6552730766502587, tensor([0.4528, 0.4528], dtype=torch.float64)]\n",
            "train: [0.6554221103065893, tensor([0.4528, 0.4528], dtype=torch.float64)]\n",
            "train: [0.6567403353177584, tensor([0.4492, 0.4492], dtype=torch.float64)]\n",
            "train: [0.6572266578674316, tensor([0.4463, 0.4463], dtype=torch.float64)]\n",
            "train: [0.656690504492783, tensor([0.4445, 0.4445], dtype=torch.float64)]\n",
            "train: [0.6569195247831798, tensor([0.4456, 0.4456], dtype=torch.float64)]\n",
            "train: [0.656447920688363, tensor([0.4481, 0.4481], dtype=torch.float64)]\n",
            "train: [0.6559778993779962, tensor([0.4503, 0.4503], dtype=torch.float64)]\n",
            "train: [0.6563231574164496, tensor([0.4500, 0.4500], dtype=torch.float64)]\n",
            "train: [0.6557774336441703, tensor([0.4515, 0.4515], dtype=torch.float64)]\n",
            "train: [0.6562148155050075, tensor([0.4539, 0.4539], dtype=torch.float64)]\n",
            "train: [0.6563011407852173, tensor([0.4553, 0.4553], dtype=torch.float64)]\n",
            "train: [0.6564408127142458, tensor([0.4539, 0.4539], dtype=torch.float64)]\n",
            "train: [0.656551513671875, tensor([0.4553, 0.4553], dtype=torch.float64)]\n",
            "train: [0.6560101976581648, tensor([0.4564, 0.4564], dtype=torch.float64)]\n",
            "train: [0.6554975509643555, tensor([0.4566, 0.4566], dtype=torch.float64)]\n",
            "train: [0.6555905612009876, tensor([0.4543, 0.4543], dtype=torch.float64)]\n",
            "train: [0.6559547141746238, tensor([0.4530, 0.4530], dtype=torch.float64)]\n",
            "train: [0.6570735584605824, tensor([0.4515, 0.4515], dtype=torch.float64)]\n",
            "train: [0.6570152555193219, tensor([0.4465, 0.4465], dtype=torch.float64)]\n",
            "train: [0.6580180787203604, tensor([0.4427, 0.4427], dtype=torch.float64)]\n",
            "train: [0.6584095132761988, tensor([0.4381, 0.4381], dtype=torch.float64)]\n",
            "train: [0.6570812160685912, tensor([0.4340, 0.4340], dtype=torch.float64)]\n",
            "train: [0.6573694864908854, tensor([0.4268, 0.4268], dtype=torch.float64)]\n",
            "train: [0.6580782405665664, tensor([0.4198, 0.4198], dtype=torch.float64)]\n",
            "train: [0.6567647995487336, tensor([0.4130, 0.4130], dtype=torch.float64)]\n",
            "train: [0.658218747093564, tensor([0.4065, 0.4065], dtype=torch.float64)]\n",
            "train: [0.6582709550857544, tensor([0.4001, 0.4001], dtype=torch.float64)]\n",
            "train: [0.658686769925631, tensor([0.3940, 0.3940], dtype=torch.float64)]\n",
            "train: [0.6587774103338068, tensor([0.3880, 0.3880], dtype=torch.float64)]\n",
            "train: [0.6590428138846782, tensor([0.3822, 0.3822], dtype=torch.float64)]\n",
            "train: [0.6591921974630917, tensor([0.3789, 0.3789], dtype=torch.float64)]\n",
            "train: [0.6592789801998414, tensor([0.3771, 0.3771], dtype=torch.float64)]\n",
            "train: [0.6589526040213448, tensor([0.3799, 0.3799], dtype=torch.float64)]\n",
            "train: [0.6588177210848096, tensor([0.3809, 0.3809], dtype=torch.float64)]\n",
            "train: [0.658989429473877, tensor([0.3800, 0.3800], dtype=torch.float64)]\n",
            "train: [0.6586925558847924, tensor([0.3805, 0.3805], dtype=torch.float64)]\n",
            "train: [0.6587762059392156, tensor([0.3810, 0.3810], dtype=torch.float64)]\n",
            "train: [0.6586550394694011, tensor([0.3826, 0.3826], dtype=torch.float64)]\n",
            "train: [0.6581325029072008, tensor([0.3847, 0.3847], dtype=torch.float64)]\n",
            "train: [0.659288926558061, tensor([0.3878, 0.3878], dtype=torch.float64)]\n",
            "train: [0.6593249883407202, tensor([0.3883, 0.3883], dtype=torch.float64)]\n",
            "train: [0.6585446128362342, tensor([0.3916, 0.3916], dtype=torch.float64)]\n",
            "train: [0.6586544513702393, tensor([0.3937, 0.3937], dtype=torch.float64)]\n",
            "train: [0.6591147434564284, tensor([0.3935, 0.3935], dtype=torch.float64)]\n",
            "train: [0.6593809825618092, tensor([0.3940, 0.3940], dtype=torch.float64)]\n",
            "train: [0.658818026623094, tensor([0.3974, 0.3974], dtype=torch.float64)]\n",
            "train: [0.6583119346981957, tensor([0.4002, 0.4002], dtype=torch.float64)]\n",
            "train: [0.6583029354319853, tensor([0.4023, 0.4023], dtype=torch.float64)]\n",
            "train: [0.6578130943830623, tensor([0.4046, 0.4046], dtype=torch.float64)]\n",
            "train: [0.6574306707272585, tensor([0.4074, 0.4074], dtype=torch.float64)]\n",
            "train: [0.6580140373923562, tensor([0.4090, 0.4090], dtype=torch.float64)]\n",
            "train: [0.6579234091083656, tensor([0.4103, 0.4103], dtype=torch.float64)]\n",
            "train: [0.657609388563368, tensor([0.4136, 0.4136], dtype=torch.float64)]\n",
            "train: [0.6582753108097956, tensor([0.4151, 0.4151], dtype=torch.float64)]\n",
            "train: [0.6583783522896145, tensor([0.4160, 0.4160], dtype=torch.float64)]\n",
            "train: [0.657808119250882, tensor([0.4185, 0.4185], dtype=torch.float64)]\n",
            "train: [0.6585868673121675, tensor([0.4187, 0.4187], dtype=torch.float64)]\n",
            "train: [0.6586141887464021, tensor([0.4193, 0.4193], dtype=torch.float64)]\n",
            "train: [0.6585538784662882, tensor([0.4190, 0.4190], dtype=torch.float64)]\n",
            "train: [0.6581792536470079, tensor([0.4199, 0.4199], dtype=torch.float64)]\n",
            "train: [0.658494910415338, tensor([0.4199, 0.4199], dtype=torch.float64)]\n",
            "train: [0.6580643316712043, tensor([0.4189, 0.4189], dtype=torch.float64)]\n",
            "train: [0.6584184265136719, tensor([0.4178, 0.4178], dtype=torch.float64)]\n",
            "train: [0.6583526158096766, tensor([0.4165, 0.4165], dtype=torch.float64)]\n",
            "train: [0.6589214848537072, tensor([0.4147, 0.4147], dtype=torch.float64)]\n",
            "train: [0.6596633762989229, tensor([0.4140, 0.4140], dtype=torch.float64)]\n",
            "train: [0.6594108434823843, tensor([0.4132, 0.4132], dtype=torch.float64)]\n",
            "train: [0.6598089308965773, tensor([0.4128, 0.4128], dtype=torch.float64)]\n",
            "train: [0.6594162707058888, tensor([0.4134, 0.4134], dtype=torch.float64)]\n",
            "train: [0.6590910581784828, tensor([0.4133, 0.4133], dtype=torch.float64)]\n",
            "train: [0.6587420569525825, tensor([0.4136, 0.4136], dtype=torch.float64)]\n",
            "train: [0.6586109826324182, tensor([0.4148, 0.4148], dtype=torch.float64)]\n",
            "train: [0.6584737604314631, tensor([0.4151, 0.4151], dtype=torch.float64)]\n",
            "train: [0.6584458909593187, tensor([0.4161, 0.4161], dtype=torch.float64)]\n",
            "train: [0.658282961164202, tensor([0.4177, 0.4177], dtype=torch.float64)]\n",
            "train: [0.6581972510413786, tensor([0.4186, 0.4186], dtype=torch.float64)]\n",
            "train: [0.6581374720523232, tensor([0.4187, 0.4187], dtype=torch.float64)]\n",
            "train: [0.6583127892535666, tensor([0.4188, 0.4188], dtype=torch.float64)]\n",
            "train: [0.6579695734484442, tensor([0.4192, 0.4192], dtype=torch.float64)]\n",
            "train: [0.6580418643788395, tensor([0.4195, 0.4195], dtype=torch.float64)]\n",
            "train: [0.657828702764996, tensor([0.4200, 0.4200], dtype=torch.float64)]\n",
            "train: [0.6576559243081999, tensor([0.4196, 0.4196], dtype=torch.float64)]\n",
            "train: [0.6571753819783529, tensor([0.4207, 0.4207], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6521134512765067, tensor([0.5902, 0.5902], dtype=torch.float64)]\n",
            "\n",
            "train: [0.6358158588409424, tensor([0.5385, 0.5385], dtype=torch.float64)]\n",
            "train: [0.6337642669677734, tensor([0.3337, 0.3337], dtype=torch.float64)]\n",
            "train: [0.6623100837071737, tensor([0.3155, 0.3155], dtype=torch.float64)]\n",
            "train: [0.6778160333633423, tensor([0.3285, 0.3285], dtype=torch.float64)]\n",
            "train: [0.6970434665679932, tensor([0.3410, 0.3410], dtype=torch.float64)]\n",
            "train: [0.6880106925964355, tensor([0.3372, 0.3372], dtype=torch.float64)]\n",
            "train: [0.6752955572945731, tensor([0.3675, 0.3675], dtype=torch.float64)]\n",
            "train: [0.6773363351821899, tensor([0.3642, 0.3642], dtype=torch.float64)]\n",
            "train: [0.6831049389309354, tensor([0.3747, 0.3747], dtype=torch.float64)]\n",
            "train: [0.6820530891418457, tensor([0.3772, 0.3772], dtype=torch.float64)]\n",
            "train: [0.6798274733803489, tensor([0.3695, 0.3695], dtype=torch.float64)]\n",
            "train: [0.6775109767913818, tensor([0.3812, 0.3812], dtype=torch.float64)]\n",
            "train: [0.6746163735022912, tensor([0.3795, 0.3795], dtype=torch.float64)]\n",
            "train: [0.6717912128993443, tensor([0.3817, 0.3817], dtype=torch.float64)]\n",
            "train: [0.6688463846842448, tensor([0.3729, 0.3729], dtype=torch.float64)]\n",
            "train: [0.6691322922706604, tensor([0.3728, 0.3728], dtype=torch.float64)]\n",
            "train: [0.6662671145270852, tensor([0.3730, 0.3730], dtype=torch.float64)]\n",
            "train: [0.6669424904717339, tensor([0.3685, 0.3685], dtype=torch.float64)]\n",
            "train: [0.665828453867059, tensor([0.3685, 0.3685], dtype=torch.float64)]\n",
            "train: [0.6677056312561035, tensor([0.3626, 0.3626], dtype=torch.float64)]\n",
            "train: [0.668402353922526, tensor([0.3586, 0.3586], dtype=torch.float64)]\n",
            "train: [0.6697946461764249, tensor([0.3514, 0.3514], dtype=torch.float64)]\n",
            "train: [0.6695030046545941, tensor([0.3453, 0.3453], dtype=torch.float64)]\n",
            "train: [0.6692798137664795, tensor([0.3440, 0.3440], dtype=torch.float64)]\n",
            "train: [0.6673162078857422, tensor([0.3483, 0.3483], dtype=torch.float64)]\n",
            "train: [0.6670802923349234, tensor([0.3510, 0.3510], dtype=torch.float64)]\n",
            "train: [0.6661417925799334, tensor([0.3585, 0.3585], dtype=torch.float64)]\n",
            "train: [0.6665209361485073, tensor([0.3593, 0.3593], dtype=torch.float64)]\n",
            "train: [0.6664875293600148, tensor([0.3610, 0.3610], dtype=torch.float64)]\n",
            "train: [0.665899912516276, tensor([0.3623, 0.3623], dtype=torch.float64)]\n",
            "train: [0.6647354864305065, tensor([0.3676, 0.3676], dtype=torch.float64)]\n",
            "train: [0.6635420322418213, tensor([0.3675, 0.3675], dtype=torch.float64)]\n",
            "train: [0.6641570004549894, tensor([0.3715, 0.3715], dtype=torch.float64)]\n",
            "train: [0.6641380646649528, tensor([0.3756, 0.3756], dtype=torch.float64)]\n",
            "train: [0.6643990652901786, tensor([0.3760, 0.3760], dtype=torch.float64)]\n",
            "train: [0.6646126641167535, tensor([0.3784, 0.3784], dtype=torch.float64)]\n",
            "train: [0.6648874025087099, tensor([0.3806, 0.3806], dtype=torch.float64)]\n",
            "train: [0.6657109511526007, tensor([0.3835, 0.3835], dtype=torch.float64)]\n",
            "train: [0.66559449220315, tensor([0.3872, 0.3872], dtype=torch.float64)]\n",
            "train: [0.6663303852081299, tensor([0.3905, 0.3905], dtype=torch.float64)]\n",
            "train: [0.6655786560802925, tensor([0.3960, 0.3960], dtype=torch.float64)]\n",
            "train: [0.6645166760399228, tensor([0.3996, 0.3996], dtype=torch.float64)]\n",
            "train: [0.6637399806532749, tensor([0.4046, 0.4046], dtype=torch.float64)]\n",
            "train: [0.6640972657637163, tensor([0.4078, 0.4078], dtype=torch.float64)]\n",
            "train: [0.6645938449435764, tensor([0.4100, 0.4100], dtype=torch.float64)]\n",
            "train: [0.6638369352921195, tensor([0.4134, 0.4134], dtype=torch.float64)]\n",
            "train: [0.6637873142323596, tensor([0.4156, 0.4156], dtype=torch.float64)]\n",
            "train: [0.6636585791905721, tensor([0.4155, 0.4155], dtype=torch.float64)]\n",
            "train: [0.6641823126345264, tensor([0.4153, 0.4153], dtype=torch.float64)]\n",
            "train: [0.6631162261962891, tensor([0.4170, 0.4170], dtype=torch.float64)]\n",
            "train: [0.662623311959061, tensor([0.4192, 0.4192], dtype=torch.float64)]\n",
            "train: [0.6621850820688101, tensor([0.4190, 0.4190], dtype=torch.float64)]\n",
            "train: [0.6619901837043043, tensor([0.4185, 0.4185], dtype=torch.float64)]\n",
            "train: [0.6622323636655454, tensor([0.4191, 0.4191], dtype=torch.float64)]\n",
            "train: [0.6629825245250355, tensor([0.4207, 0.4207], dtype=torch.float64)]\n",
            "train: [0.6627612113952637, tensor([0.4196, 0.4196], dtype=torch.float64)]\n",
            "train: [0.6621613753469366, tensor([0.4225, 0.4225], dtype=torch.float64)]\n",
            "train: [0.6622154630463699, tensor([0.4212, 0.4212], dtype=torch.float64)]\n",
            "train: [0.6618511393918829, tensor([0.4216, 0.4216], dtype=torch.float64)]\n",
            "train: [0.6616193135579427, tensor([0.4214, 0.4214], dtype=torch.float64)]\n",
            "train: [0.6621877326339972, tensor([0.4207, 0.4207], dtype=torch.float64)]\n",
            "train: [0.6617366421607233, tensor([0.4207, 0.4207], dtype=torch.float64)]\n",
            "train: [0.6608453175378224, tensor([0.4223, 0.4223], dtype=torch.float64)]\n",
            "train: [0.6611441373825073, tensor([0.4241, 0.4241], dtype=torch.float64)]\n",
            "train: [0.6603900615985577, tensor([0.4249, 0.4249], dtype=torch.float64)]\n",
            "train: [0.6604133952747692, tensor([0.4249, 0.4249], dtype=torch.float64)]\n",
            "train: [0.6594132950056845, tensor([0.4288, 0.4288], dtype=torch.float64)]\n",
            "train: [0.6592245662913603, tensor([0.4295, 0.4295], dtype=torch.float64)]\n",
            "train: [0.6587129122969033, tensor([0.4311, 0.4311], dtype=torch.float64)]\n",
            "train: [0.6584414890834264, tensor([0.4309, 0.4309], dtype=torch.float64)]\n",
            "train: [0.6585858842016945, tensor([0.4326, 0.4326], dtype=torch.float64)]\n",
            "train: [0.6578333112928603, tensor([0.4340, 0.4340], dtype=torch.float64)]\n",
            "train: [0.6578822201245451, tensor([0.4350, 0.4350], dtype=torch.float64)]\n",
            "train: [0.6569587604419606, tensor([0.4352, 0.4352], dtype=torch.float64)]\n",
            "train: [0.6564438883463541, tensor([0.4352, 0.4352], dtype=torch.float64)]\n",
            "train: [0.6576214338603773, tensor([0.4351, 0.4351], dtype=torch.float64)]\n",
            "train: [0.657443752536526, tensor([0.4371, 0.4371], dtype=torch.float64)]\n",
            "train: [0.6567314832638471, tensor([0.4372, 0.4372], dtype=torch.float64)]\n",
            "train: [0.6563594673253312, tensor([0.4370, 0.4370], dtype=torch.float64)]\n",
            "train: [0.655833101272583, tensor([0.4377, 0.4377], dtype=torch.float64)]\n",
            "train: [0.6559750121316792, tensor([0.4385, 0.4385], dtype=torch.float64)]\n",
            "train: [0.6553636411341225, tensor([0.4369, 0.4369], dtype=torch.float64)]\n",
            "train: [0.6559232688811888, tensor([0.4338, 0.4338], dtype=torch.float64)]\n",
            "train: [0.655243056161063, tensor([0.4347, 0.4347], dtype=torch.float64)]\n",
            "train: [0.6550942364860983, tensor([0.4343, 0.4343], dtype=torch.float64)]\n",
            "train: [0.6549215538557186, tensor([0.4340, 0.4340], dtype=torch.float64)]\n",
            "train: [0.6547223672099497, tensor([0.4345, 0.4345], dtype=torch.float64)]\n",
            "train: [0.6546658602627841, tensor([0.4338, 0.4338], dtype=torch.float64)]\n",
            "train: [0.6546896602330583, tensor([0.4342, 0.4342], dtype=torch.float64)]\n",
            "train: [0.6549808078342014, tensor([0.4341, 0.4341], dtype=torch.float64)]\n",
            "train: [0.6541482275658912, tensor([0.4353, 0.4353], dtype=torch.float64)]\n",
            "train: [0.6539067392763884, tensor([0.4362, 0.4362], dtype=torch.float64)]\n",
            "train: [0.6534297902096984, tensor([0.4354, 0.4354], dtype=torch.float64)]\n",
            "train: [0.6535058934637841, tensor([0.4345, 0.4345], dtype=torch.float64)]\n",
            "train: [0.6548633374665913, tensor([0.4344, 0.4344], dtype=torch.float64)]\n",
            "train: [0.6552021900812784, tensor([0.4353, 0.4353], dtype=torch.float64)]\n",
            "train: [0.6550090435853938, tensor([0.4356, 0.4356], dtype=torch.float64)]\n",
            "train: [0.6544335034428811, tensor([0.4368, 0.4368], dtype=torch.float64)]\n",
            "train: [0.6538251626371133, tensor([0.4380, 0.4380], dtype=torch.float64)]\n",
            "train: [0.6541908264160157, tensor([0.4370, 0.4370], dtype=torch.float64)]\n",
            "train: [0.653775432322285, tensor([0.4378, 0.4378], dtype=torch.float64)]\n",
            "train: [0.6537052229339001, tensor([0.4380, 0.4380], dtype=torch.float64)]\n",
            "train: [0.6538754065059921, tensor([0.4384, 0.4384], dtype=torch.float64)]\n",
            "train: [0.6540122398963342, tensor([0.4381, 0.4381], dtype=torch.float64)]\n",
            "train: [0.6539588564918155, tensor([0.4384, 0.4384], dtype=torch.float64)]\n",
            "train: [0.6540946240695018, tensor([0.4380, 0.4380], dtype=torch.float64)]\n",
            "train: [0.6539924122462762, tensor([0.4383, 0.4383], dtype=torch.float64)]\n",
            "train: [0.6534692976209853, tensor([0.4398, 0.4398], dtype=torch.float64)]\n",
            "train: [0.6536534860593464, tensor([0.4400, 0.4400], dtype=torch.float64)]\n",
            "train: [0.6536099520596591, tensor([0.4412, 0.4412], dtype=torch.float64)]\n",
            "train: [0.6533468435476492, tensor([0.4415, 0.4415], dtype=torch.float64)]\n",
            "train: [0.6530067580086845, tensor([0.4431, 0.4431], dtype=torch.float64)]\n",
            "train: [0.6537187289347691, tensor([0.4439, 0.4439], dtype=torch.float64)]\n",
            "train: [0.6534332141541598, tensor([0.4448, 0.4448], dtype=torch.float64)]\n",
            "train: [0.653319848102072, tensor([0.4446, 0.4446], dtype=torch.float64)]\n",
            "train: [0.6530766980401401, tensor([0.4456, 0.4456], dtype=torch.float64)]\n",
            "train: [0.6532416058401777, tensor([0.4462, 0.4462], dtype=torch.float64)]\n",
            "train: [0.6532453116724046, tensor([0.4456, 0.4456], dtype=torch.float64)]\n",
            "train: [0.6531555432231486, tensor([0.4462, 0.4462], dtype=torch.float64)]\n",
            "train: [0.6532312393188476, tensor([0.4461, 0.4461], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6555147988455636, tensor([0.5902, 0.5902], dtype=torch.float64)]\n",
            "\n",
            "train: [0.6200044751167297, tensor([0.6296, 0.6296], dtype=torch.float64)]\n",
            "train: [0.6607381105422974, tensor([0.5648, 0.5648], dtype=torch.float64)]\n",
            "train: [0.6618402401606241, tensor([0.5326, 0.5326], dtype=torch.float64)]\n",
            "train: [0.6448062658309937, tensor([0.5405, 0.5405], dtype=torch.float64)]\n",
            "train: [0.6307604789733887, tensor([0.5440, 0.5440], dtype=torch.float64)]\n",
            "train: [0.6301626364390055, tensor([0.5228, 0.5228], dtype=torch.float64)]\n",
            "train: [0.639653069632394, tensor([0.4967, 0.4967], dtype=torch.float64)]\n",
            "train: [0.6410617828369141, tensor([0.4928, 0.4928], dtype=torch.float64)]\n",
            "train: [0.6385933558146158, tensor([0.4845, 0.4845], dtype=torch.float64)]\n",
            "train: [0.636844539642334, tensor([0.4761, 0.4761], dtype=torch.float64)]\n",
            "train: [0.6367871111089533, tensor([0.4709, 0.4709], dtype=torch.float64)]\n",
            "train: [0.6366333166758219, tensor([0.4594, 0.4594], dtype=torch.float64)]\n",
            "train: [0.6396579742431641, tensor([0.4641, 0.4641], dtype=torch.float64)]\n",
            "train: [0.6396068164280483, tensor([0.4694, 0.4694], dtype=torch.float64)]\n",
            "train: [0.6398064295450846, tensor([0.4642, 0.4642], dtype=torch.float64)]\n",
            "train: [0.6364879608154297, tensor([0.4768, 0.4768], dtype=torch.float64)]\n",
            "train: [0.6355915069580078, tensor([0.4820, 0.4820], dtype=torch.float64)]\n",
            "train: [0.6366291575961642, tensor([0.4759, 0.4759], dtype=torch.float64)]\n",
            "train: [0.6365326329281455, tensor([0.4845, 0.4845], dtype=torch.float64)]\n",
            "train: [0.6407754421234131, tensor([0.4827, 0.4827], dtype=torch.float64)]\n",
            "train: [0.6414967491513207, tensor([0.4821, 0.4821], dtype=torch.float64)]\n",
            "train: [0.6450943946838379, tensor([0.4821, 0.4821], dtype=torch.float64)]\n",
            "train: [0.6441674439803414, tensor([0.4837, 0.4837], dtype=torch.float64)]\n",
            "train: [0.6444337368011475, tensor([0.4835, 0.4835], dtype=torch.float64)]\n",
            "train: [0.6460942840576172, tensor([0.4853, 0.4853], dtype=torch.float64)]\n",
            "train: [0.6471380087045523, tensor([0.4800, 0.4800], dtype=torch.float64)]\n",
            "train: [0.6469115504512081, tensor([0.4774, 0.4774], dtype=torch.float64)]\n",
            "train: [0.6464359419686454, tensor([0.4738, 0.4738], dtype=torch.float64)]\n",
            "train: [0.6473428791966932, tensor([0.4757, 0.4757], dtype=torch.float64)]\n",
            "train: [0.6470816294352214, tensor([0.4755, 0.4755], dtype=torch.float64)]\n",
            "train: [0.6453501793646044, tensor([0.4825, 0.4825], dtype=torch.float64)]\n",
            "train: [0.6450722813606262, tensor([0.4834, 0.4834], dtype=torch.float64)]\n",
            "train: [0.6456846757368608, tensor([0.4823, 0.4823], dtype=torch.float64)]\n",
            "train: [0.646087926976821, tensor([0.4843, 0.4843], dtype=torch.float64)]\n",
            "train: [0.6482025146484375, tensor([0.4844, 0.4844], dtype=torch.float64)]\n",
            "train: [0.6466744740804037, tensor([0.4876, 0.4876], dtype=torch.float64)]\n",
            "train: [0.6464898908460462, tensor([0.4921, 0.4921], dtype=torch.float64)]\n",
            "train: [0.6474303697284899, tensor([0.4928, 0.4928], dtype=torch.float64)]\n",
            "train: [0.6468784625713642, tensor([0.4904, 0.4904], dtype=torch.float64)]\n",
            "train: [0.6464050769805908, tensor([0.4890, 0.4890], dtype=torch.float64)]\n",
            "train: [0.6460690382050305, tensor([0.4897, 0.4897], dtype=torch.float64)]\n",
            "train: [0.6464551744006929, tensor([0.4924, 0.4924], dtype=torch.float64)]\n",
            "train: [0.6465620883675509, tensor([0.4907, 0.4907], dtype=torch.float64)]\n",
            "train: [0.6453102718700062, tensor([0.4925, 0.4925], dtype=torch.float64)]\n",
            "train: [0.646213150024414, tensor([0.4907, 0.4907], dtype=torch.float64)]\n",
            "train: [0.6468574689782184, tensor([0.4911, 0.4911], dtype=torch.float64)]\n",
            "train: [0.6469189664150806, tensor([0.4913, 0.4913], dtype=torch.float64)]\n",
            "train: [0.6464114983876547, tensor([0.4912, 0.4912], dtype=torch.float64)]\n",
            "train: [0.645632841149155, tensor([0.4912, 0.4912], dtype=torch.float64)]\n",
            "train: [0.6454679107666016, tensor([0.4949, 0.4949], dtype=torch.float64)]\n",
            "train: [0.6452838673311121, tensor([0.4940, 0.4940], dtype=torch.float64)]\n",
            "train: [0.6455451525174655, tensor([0.4937, 0.4937], dtype=torch.float64)]\n",
            "train: [0.6459597461628463, tensor([0.4952, 0.4952], dtype=torch.float64)]\n",
            "train: [0.6458618022777416, tensor([0.4960, 0.4960], dtype=torch.float64)]\n",
            "train: [0.645835321599787, tensor([0.4955, 0.4955], dtype=torch.float64)]\n",
            "train: [0.6446896280561175, tensor([0.4955, 0.4955], dtype=torch.float64)]\n",
            "train: [0.6445740816885965, tensor([0.4951, 0.4951], dtype=torch.float64)]\n",
            "train: [0.645166462865369, tensor([0.4958, 0.4958], dtype=torch.float64)]\n",
            "train: [0.644346786757647, tensor([0.4983, 0.4983], dtype=torch.float64)]\n",
            "train: [0.6440242767333985, tensor([0.4978, 0.4978], dtype=torch.float64)]\n",
            "train: [0.6440243330158171, tensor([0.4986, 0.4986], dtype=torch.float64)]\n",
            "train: [0.6436193527713898, tensor([0.4983, 0.4983], dtype=torch.float64)]\n",
            "train: [0.6443701850043403, tensor([0.4976, 0.4976], dtype=torch.float64)]\n",
            "train: [0.6442808508872986, tensor([0.4962, 0.4962], dtype=torch.float64)]\n",
            "train: [0.6436160160945013, tensor([0.4978, 0.4978], dtype=torch.float64)]\n",
            "train: [0.643235697890773, tensor([0.4988, 0.4988], dtype=torch.float64)]\n",
            "train: [0.6428851796619928, tensor([0.5004, 0.5004], dtype=torch.float64)]\n",
            "train: [0.6427351446712718, tensor([0.5001, 0.5001], dtype=torch.float64)]\n",
            "train: [0.6433925352234772, tensor([0.4994, 0.4994], dtype=torch.float64)]\n",
            "train: [0.6430086408342633, tensor([0.4998, 0.4998], dtype=torch.float64)]\n",
            "train: [0.6431554874903719, tensor([0.4986, 0.4986], dtype=torch.float64)]\n",
            "train: [0.6439974572923448, tensor([0.4971, 0.4971], dtype=torch.float64)]\n",
            "train: [0.6434342893835616, tensor([0.4968, 0.4968], dtype=torch.float64)]\n",
            "train: [0.6429852150581978, tensor([0.4963, 0.4963], dtype=torch.float64)]\n",
            "train: [0.6430333455403646, tensor([0.4966, 0.4966], dtype=torch.float64)]\n",
            "train: [0.6431564029894377, tensor([0.4948, 0.4948], dtype=torch.float64)]\n",
            "train: [0.6421174383782721, tensor([0.4957, 0.4957], dtype=torch.float64)]\n",
            "train: [0.6418445293719952, tensor([0.4956, 0.4956], dtype=torch.float64)]\n",
            "train: [0.6415122792690615, tensor([0.4958, 0.4958], dtype=torch.float64)]\n",
            "train: [0.640764570236206, tensor([0.4960, 0.4960], dtype=torch.float64)]\n",
            "train: [0.6401842847282504, tensor([0.4975, 0.4975], dtype=torch.float64)]\n",
            "train: [0.6394370474466463, tensor([0.4999, 0.4999], dtype=torch.float64)]\n",
            "train: [0.6403459755771131, tensor([0.4996, 0.4996], dtype=torch.float64)]\n",
            "train: [0.6403598785400391, tensor([0.4990, 0.4990], dtype=torch.float64)]\n",
            "train: [0.639937053007238, tensor([0.5001, 0.5001], dtype=torch.float64)]\n",
            "train: [0.6397257960119913, tensor([0.5003, 0.5003], dtype=torch.float64)]\n",
            "train: [0.6397863366137976, tensor([0.5005, 0.5005], dtype=torch.float64)]\n",
            "train: [0.6393690542741255, tensor([0.4999, 0.4999], dtype=torch.float64)]\n",
            "train: [0.6395908741468794, tensor([0.5002, 0.5002], dtype=torch.float64)]\n",
            "train: [0.638937250773112, tensor([0.5022, 0.5022], dtype=torch.float64)]\n",
            "train: [0.6391271234868647, tensor([0.5021, 0.5021], dtype=torch.float64)]\n",
            "train: [0.6387059999548871, tensor([0.5019, 0.5019], dtype=torch.float64)]\n",
            "train: [0.6390977674914945, tensor([0.5010, 0.5010], dtype=torch.float64)]\n",
            "train: [0.6389774971819938, tensor([0.5010, 0.5010], dtype=torch.float64)]\n",
            "train: [0.6384868822599712, tensor([0.5006, 0.5006], dtype=torch.float64)]\n",
            "train: [0.6379892031351725, tensor([0.5020, 0.5020], dtype=torch.float64)]\n",
            "train: [0.6376137487667123, tensor([0.5024, 0.5024], dtype=torch.float64)]\n",
            "train: [0.6373044228067204, tensor([0.5025, 0.5025], dtype=torch.float64)]\n",
            "train: [0.6374357974890507, tensor([0.5021, 0.5021], dtype=torch.float64)]\n",
            "train: [0.6378576278686523, tensor([0.5011, 0.5011], dtype=torch.float64)]\n",
            "train: [0.6383824112391708, tensor([0.5011, 0.5011], dtype=torch.float64)]\n",
            "train: [0.6383456809847963, tensor([0.5016, 0.5016], dtype=torch.float64)]\n",
            "train: [0.6384209938419675, tensor([0.5024, 0.5024], dtype=torch.float64)]\n",
            "train: [0.6382629687969501, tensor([0.5026, 0.5026], dtype=torch.float64)]\n",
            "train: [0.6380370367140997, tensor([0.5033, 0.5033], dtype=torch.float64)]\n",
            "train: [0.6379879645581515, tensor([0.5031, 0.5031], dtype=torch.float64)]\n",
            "train: [0.6383266983745254, tensor([0.5035, 0.5035], dtype=torch.float64)]\n",
            "train: [0.6379155053032769, tensor([0.5035, 0.5035], dtype=torch.float64)]\n",
            "train: [0.6387536985064866, tensor([0.5019, 0.5019], dtype=torch.float64)]\n",
            "train: [0.6385994651100853, tensor([0.5023, 0.5023], dtype=torch.float64)]\n",
            "train: [0.6382469658379082, tensor([0.5035, 0.5035], dtype=torch.float64)]\n",
            "train: [0.6381076404026577, tensor([0.5045, 0.5045], dtype=torch.float64)]\n",
            "train: [0.6376603388153346, tensor([0.5057, 0.5057], dtype=torch.float64)]\n",
            "train: [0.6373264915064761, tensor([0.5052, 0.5052], dtype=torch.float64)]\n",
            "train: [0.6382241290548574, tensor([0.5045, 0.5045], dtype=torch.float64)]\n",
            "train: [0.6380661931531183, tensor([0.5040, 0.5040], dtype=torch.float64)]\n",
            "train: [0.6379663190271101, tensor([0.5043, 0.5043], dtype=torch.float64)]\n",
            "train: [0.6379660913499735, tensor([0.5045, 0.5045], dtype=torch.float64)]\n",
            "train: [0.6378004570969013, tensor([0.5047, 0.5047], dtype=torch.float64)]\n",
            "train: [0.637722396850586, tensor([0.5056, 0.5056], dtype=torch.float64)]\n",
            "\n",
            "valiation stats valid: [0.6073104313441685, tensor([0.5000, 0.5000], dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(learner, filename):\n",
        "    fname = Path(filename)\n",
        "    fname.parent.mkdir(parents=True, exist_ok = True)\n",
        "    checkpoint_dict = {\n",
        "        'model': learn.model.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint_dict, fname)"
      ],
      "metadata": {
        "id": "m74MMR93Wwwj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_checkpoint(learn, '/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/checkpoints/xtesnet34-2epochs-val-only.pt')"
      ],
      "metadata": {
        "id": "2RkTAUCAmnsH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# submission - load and predict"
      ],
      "metadata": {
        "id": "96R0ysRfzC5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path2= Path('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/')\n",
        "upload_path =path2/'uploads'\n",
        "upload_path.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "coMQEDlbO23h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st = torch.load('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/checkpoints/xtesnet34-2epochs-val-only.pt')"
      ],
      "metadata": {
        "id": "BxpOYV0thsjW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.keys()"
      ],
      "metadata": {
        "id": "rCHOD9EkhtkJ",
        "outputId": "35cf1522-d06d-48d7-dad5-ddf8004e4fe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['model'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.model.load_state_dict(st['model'])"
      ],
      "metadata": {
        "id": "JEhWdRjsgsRf",
        "outputId": "e6c139fd-cb72-43d0-db78-a3bd55026b26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_path = (path2/'data/v1/dev')\n",
        "# audios = get_files(dev_path)\n",
        "class AudioList(ItemList):\n",
        "    @classmethod\n",
        "    def from_files(cls, path, extensions = None, recurse=True, include=None, **kwargs):\n",
        "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
        "    \n",
        "    def get(self, fn):\n",
        "        return torch.load(fn)\n",
        "\n",
        "tfms = [Reshape(), PadorTrim(250), DummyChannel()]        \n",
        "        \n",
        "al=AudioList.from_files(dev_path, tfms=tfms)"
      ],
      "metadata": {
        "id": "oCUc5zUWQO1_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset=torch.cat([al[idx] for idx, _ in enumerate(al.items)], dim=0)\n",
        "testset.shape"
      ],
      "metadata": {
        "id": "LiU6rB89jeDW",
        "outputId": "07ebe846-f5f1-4983-ebb8-7c3047d26006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3342, 26, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(learn, dev):\n",
        "    test_n = dev.shape[0]\n",
        "    learn.model.eval()\n",
        "    res = []\n",
        "    with torch.no_grad():        \n",
        "        for i in range((test_n-1)//bs + 1):\n",
        "            xb = dev[i*bs:(i+1)*bs]\n",
        "            out = learn.model(xb)\n",
        "            res += [o.item() for o in out.argmax(1)]\n",
        "    return res"
      ],
      "metadata": {
        "id": "WpHqRqexU_Q-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_predictions(learn, testset.unsqueeze(1).cuda())"
      ],
      "metadata": {
        "id": "qXtq3XJ_nJIL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(res)"
      ],
      "metadata": {
        "id": "eQ0naIkkp31-",
        "outputId": "f9bed481-c630-47d1-9962-ae0e0b484b9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3342"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res[:10]"
      ],
      "metadata": {
        "id": "NPPTSqyPOR6x",
        "outputId": "3b22e70f-7929-4ff0-ecb4-7b23a24434f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 1, 1, 0, 1, 1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_convert = {0:[1, 1], 1:[0, 0], 2:[1,0], 3:[0, 1]}\n",
        "# submission = list(map(lambda o: label_convert[int(o)], res))\n",
        "# submission[0]"
      ],
      "metadata": {
        "id": "eAen-tySOSnO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_path"
      ],
      "metadata": {
        "id": "Q6bWOMwEOlZ5",
        "outputId": "a9fffe62-34d8-4ea1-87ce-c5e07cc42800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/gdrive/Shareddrives/Dion-Account/2122WS/8-dl4slp/coding-project/ser/uploads')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trg_json = upload_path/'xtesnet34-2epochs.json'"
      ],
      "metadata": {
        "id": "o8qy44vHQWxz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "ly7gU4KDQnVT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with trg_json.open() as f: v1_json = json.load(f)"
      ],
      "metadata": {
        "id": "qiPz8pmPQgLp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1_json['0']"
      ],
      "metadata": {
        "id": "8LuzTtd5QmD_",
        "outputId": "4055b8e6-745a-4a2e-d556-1b10e55bc75d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 1, 'valence': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (k, v) in v1_json.items():\n",
        "    v1_json[k]['valence'] = res[int(k)]"
      ],
      "metadata": {
        "id": "W9RWiWfFQuaM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1_json['0']"
      ],
      "metadata": {
        "id": "lRYDrWV0Oq_B",
        "outputId": "a8e0a207-525e-4434-df9c-885134b12660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 1, 'valence': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(upload_path/'xtesnet34-2epochs-val-only.json', 'w') as f:\n",
        "    json.dump(v1_json, f)"
      ],
      "metadata": {
        "id": "LGcgj6PlRIJg"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}