{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvL-c-XtYgGA"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npcpPp0DblBz",
        "outputId": "c0ead48d-c5b2-4c9f-9394-554c98d03362"
      },
      "source": [
        "!git clone https://github.com/fastai/course-v3\n",
        "%cd /content/course-v3/nbs/dl2\n",
        "from exp.nb_08 import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 5893, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5893 (delta 0), reused 2 (delta 0), pack-reused 5890\u001b[K\n",
            "Receiving objects: 100% (5893/5893), 263.10 MiB | 13.34 MiB/s, done.\n",
            "Resolving deltas: 100% (3251/3251), done.\n",
            "/content/course-v3/nbs/dl2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpO7exIEc2Nl",
        "outputId": "cdf42937-0243-49f4-9db3-2592549d6cb8"
      },
      "source": [
        "torch.optim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.optim' from '/usr/local/lib/python3.7/dist-packages/torch/optim/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjgSM05QdS4P"
      },
      "source": [
        "## Load dataset and vanila model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9RCv7pN3efdG",
        "outputId": "b330528f-414b-407d-cf84-d709bd9f9b2e"
      },
      "source": [
        "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhgxDzkyejtC"
      },
      "source": [
        "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]\n",
        "bs = 128\n",
        "il = ImageList.from_files(path, tfms=tfms)\n",
        "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
        "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
        "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66zCmXQJfhmV"
      },
      "source": [
        "nfs = [32, 64, 128, 256]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfg5SQ-Ofjxo"
      },
      "source": [
        "cbfs = [partial(AvgStatsCallback, accuracy),\n",
        "        CudaCallback,\n",
        "        partial(BatchTransformXCallback, norm_imagenette)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADmaIKupfufO"
      },
      "source": [
        "learn, run= get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OvMHrQOgHVf",
        "outputId": "22bc8bf6-4ccc-431e-a5dd-827323e86b6f"
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [1.8139950100327384, tensor(0.3672, device='cuda:0')]\n",
            "valid: [1.6473867933917197, tensor(0.4306, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3UWY4b_heqY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW-mvxgmhfWI"
      },
      "source": [
        "## Refining the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii9HFTuvgLro"
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, steppers, **defaults):\n",
        "        self.steppers = listify(steppers)        \n",
        "        self.param_groups = list(params)\n",
        "        # ensure params is a list of lists\n",
        "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
        "        self.hypers = [{**defaults} for p in self.param_groups]\n",
        "\n",
        "    def grad_params(self):\n",
        "        gps = []\n",
        "        for pg, hyper in zip(self.param_groups, self.hypers):\n",
        "            for p in pg:\n",
        "                if p.grad is not None:\n",
        "                    gps = gps + [(p, hyper)]\n",
        "        return gps\n",
        "    def zero_grad(self):\n",
        "        for p, hyper in self.grad_params():\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "    def step(self):\n",
        "        for p, hyper in grad_params:\n",
        "            compose(p, self.steppers, **hyper)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c5L4UyzdnCp"
      },
      "source": [
        "def sgd_step(p, lr, **kwargs):\n",
        "    print(f\"lr: {lr}\\nkwargs: {kwargs}\")\n",
        "    # pytorch inplace function of sum. second parameter will be multiplied to first parameter\n",
        "    p.data.add_(-lr, p.grad.data)\n",
        "    return p\n",
        "# steppers is compositional function\n",
        "opt_func = partial(Optimizer, steppers=[sgd_step])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlgDjJrWhB_o",
        "collapsed": true,
        "outputId": "2ea76c78-176c-4721-ab37-46a1f99c334a"
      },
      "source": [
        "Optimizer(learn.model.parameters(), sgd_step).param_groups"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Parameter containing:\n",
              "  tensor([[[[ 0.3289,  0.2969,  0.0545],\n",
              "            [-0.0472,  0.2823,  0.1843],\n",
              "            [-0.1065,  0.2787, -0.1526]],\n",
              "  \n",
              "           [[ 0.2337,  0.3831,  0.0793],\n",
              "            [-0.1422, -0.1537,  0.1516],\n",
              "            [ 0.1776,  0.8838,  0.1525]],\n",
              "  \n",
              "           [[ 0.4825,  0.0050,  0.2736],\n",
              "            [-0.0998,  0.2738,  0.1084],\n",
              "            [-0.0649,  0.1470, -0.0415]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.3343, -0.1267,  0.1231],\n",
              "            [ 0.0606,  0.2506,  0.3913],\n",
              "            [ 0.7008,  0.0214,  0.3130]],\n",
              "  \n",
              "           [[-0.1296, -0.2690,  0.2535],\n",
              "            [-0.2055, -0.2898,  0.3143],\n",
              "            [ 0.1537, -0.2819, -0.0739]],\n",
              "  \n",
              "           [[ 0.1057, -0.3752,  0.2703],\n",
              "            [-0.0540,  0.2486,  0.1926],\n",
              "            [ 0.0905,  0.3146, -0.0874]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.1146, -0.4689,  0.3813],\n",
              "            [ 0.0655, -0.3051, -0.3552],\n",
              "            [ 0.0393, -0.1617,  0.0360]],\n",
              "  \n",
              "           [[ 0.4338, -0.2380,  0.1627],\n",
              "            [-0.0490,  0.1799, -0.0997],\n",
              "            [ 0.1730,  0.0851, -0.3394]],\n",
              "  \n",
              "           [[ 0.0378, -0.2500, -0.0332],\n",
              "            [ 0.3880,  0.3756, -0.3442],\n",
              "            [-0.0930,  0.1862, -0.6298]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0866, -0.1773,  0.0594],\n",
              "            [ 0.2013, -0.1678, -0.0899],\n",
              "            [-0.4134,  0.3489,  0.2705]],\n",
              "  \n",
              "           [[ 0.1280,  0.1164, -0.3311],\n",
              "            [ 0.3405,  0.2590, -0.1157],\n",
              "            [-0.1350,  0.4482,  0.2706]],\n",
              "  \n",
              "           [[ 0.0913, -0.3449,  0.1922],\n",
              "            [-0.0015,  0.1825, -0.0881],\n",
              "            [ 0.3517,  0.1895, -0.1844]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0248, -0.1826, -0.3847],\n",
              "            [ 0.1556,  0.4109,  0.2338],\n",
              "            [ 0.1132,  0.0345,  0.0501]],\n",
              "  \n",
              "           [[ 0.4544,  0.1284, -0.0656],\n",
              "            [-0.1875,  0.0661,  0.1622],\n",
              "            [-0.4545,  0.1370, -0.0916]],\n",
              "  \n",
              "           [[ 0.2319, -0.2468, -0.2027],\n",
              "            [ 0.3015, -0.0325, -0.1883],\n",
              "            [ 0.1128, -0.1119,  0.0175]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.3245,  0.0403,  0.0883],\n",
              "            [-0.0379,  0.1612,  0.2831],\n",
              "            [ 0.4119,  0.6947,  0.0050]],\n",
              "  \n",
              "           [[-0.0470,  0.0308,  0.1317],\n",
              "            [ 0.3506, -0.2916, -0.3010],\n",
              "            [-0.3485, -0.0175, -0.2276]],\n",
              "  \n",
              "           [[ 0.1652, -0.4281,  0.1796],\n",
              "            [ 0.1689,  0.1769,  0.1147],\n",
              "            [-0.2288,  0.0917,  0.0093]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.1541, -0.3951, -0.1336],\n",
              "            [-0.3938,  0.4801, -0.0783],\n",
              "            [-0.0933,  0.2133,  0.0918]],\n",
              "  \n",
              "           [[ 0.1937, -0.3535,  0.0334],\n",
              "            [-0.1039, -0.4017, -0.3163],\n",
              "            [-0.3067, -0.5126, -0.3044]],\n",
              "  \n",
              "           [[ 0.3899,  0.6940, -0.2026],\n",
              "            [-0.1702,  0.0907,  0.2067],\n",
              "            [-0.1861,  0.1146,  0.0924]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0123, -0.0419,  0.2323],\n",
              "            [-0.2092,  0.0372, -0.5179],\n",
              "            [-0.1463, -0.4409,  0.2182]],\n",
              "  \n",
              "           [[ 0.2838,  0.1367,  0.1655],\n",
              "            [ 0.3009, -0.0838, -0.0317],\n",
              "            [ 0.2485,  0.0056, -0.9190]],\n",
              "  \n",
              "           [[ 0.2208,  0.3649, -0.2413],\n",
              "            [-0.2083, -0.3720,  0.1333],\n",
              "            [ 0.2016, -0.1057,  0.2399]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.2235, -0.2323, -0.3331],\n",
              "            [ 0.0081,  0.0262,  0.2191],\n",
              "            [ 0.4432,  0.2048,  0.2394]],\n",
              "  \n",
              "           [[-0.3556, -0.2890, -0.1767],\n",
              "            [-0.0397,  0.1213,  0.0860],\n",
              "            [ 0.3746, -0.3670,  0.2898]],\n",
              "  \n",
              "           [[ 0.0289, -0.2588, -0.1110],\n",
              "            [-0.0177,  0.3794,  0.3552],\n",
              "            [ 0.2537, -0.2566,  0.1052]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.3075, -0.2199,  0.0039],\n",
              "            [-0.0251,  0.2019, -0.2379],\n",
              "            [ 0.1247, -0.1633,  0.0963]],\n",
              "  \n",
              "           [[-0.0459,  0.3077, -0.2593],\n",
              "            [ 0.4496,  0.3803,  0.0814],\n",
              "            [ 0.2562, -0.0598, -0.0920]],\n",
              "  \n",
              "           [[ 0.4187,  0.1844, -0.2762],\n",
              "            [-0.3875,  0.1443, -0.5867],\n",
              "            [-0.0317,  0.2507, -0.4008]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0085,  0.0735, -0.0066],\n",
              "            [-0.0304, -0.5056,  0.0727],\n",
              "            [-0.3023, -0.1643, -0.3193]],\n",
              "  \n",
              "           [[ 0.0604,  0.3446,  0.0535],\n",
              "            [ 0.0844,  0.1854,  0.1396],\n",
              "            [-0.2280, -0.1283,  0.1028]],\n",
              "  \n",
              "           [[ 0.1633,  0.1016, -0.0877],\n",
              "            [-0.0211,  0.3239,  0.2219],\n",
              "            [ 0.5279,  0.2360, -0.0711]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.3886, -0.3348, -0.0069],\n",
              "            [ 0.2880, -0.2786,  0.1329],\n",
              "            [ 0.3297,  0.0726,  0.2251]],\n",
              "  \n",
              "           [[ 0.2390, -0.3362,  0.2431],\n",
              "            [ 0.0046,  0.1687, -0.1304],\n",
              "            [-0.0322, -0.0825,  0.6917]],\n",
              "  \n",
              "           [[ 0.0144, -0.6337,  0.0779],\n",
              "            [-0.4456, -0.1976, -0.2616],\n",
              "            [-0.1016, -0.2689, -0.3745]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.2445,  0.2705,  0.1368],\n",
              "            [ 0.0589,  0.0762,  0.0011],\n",
              "            [ 0.0075, -0.1846,  0.5111]],\n",
              "  \n",
              "           [[ 0.1921,  0.1175,  0.0630],\n",
              "            [ 0.2991,  0.1332, -0.1092],\n",
              "            [-0.1106,  0.1243, -0.1831]],\n",
              "  \n",
              "           [[ 0.3077, -0.1363, -0.0176],\n",
              "            [ 0.2863,  0.1460,  0.2160],\n",
              "            [-0.2143,  0.3213, -0.4256]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0549,  0.1922,  0.0934],\n",
              "            [-0.2473,  0.4065,  0.1844],\n",
              "            [-0.5535,  0.4324, -0.1759]],\n",
              "  \n",
              "           [[-0.2104,  0.1116,  0.1148],\n",
              "            [-0.0849, -0.1027,  0.2043],\n",
              "            [-0.2502,  0.0761,  0.0242]],\n",
              "  \n",
              "           [[ 0.2096, -0.0848, -0.1490],\n",
              "            [-0.1182, -0.3033,  0.4848],\n",
              "            [-0.5338,  0.2852,  0.1890]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.2916,  0.5010,  0.2892],\n",
              "            [ 0.3447, -0.0563,  0.2208],\n",
              "            [ 0.1509,  0.1459, -0.3195]],\n",
              "  \n",
              "           [[-0.1849, -0.1320, -0.1393],\n",
              "            [-0.9562,  0.4105, -0.4439],\n",
              "            [-0.2359,  0.0591, -0.3346]],\n",
              "  \n",
              "           [[-0.0292,  0.0055, -0.6209],\n",
              "            [ 0.2899, -0.1441,  0.0288],\n",
              "            [ 0.1306, -0.1414, -0.0419]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0523,  0.1737,  0.0512],\n",
              "            [ 0.0980,  0.2906,  0.0351],\n",
              "            [ 0.0897,  0.0018, -0.3841]],\n",
              "  \n",
              "           [[ 0.3216,  0.0121,  0.3550],\n",
              "            [ 0.3733,  0.3072, -0.0471],\n",
              "            [-0.0080, -0.0339,  0.1486]],\n",
              "  \n",
              "           [[ 0.2803,  0.1736,  0.4177],\n",
              "            [-0.2740, -0.0821, -0.2257],\n",
              "            [ 0.2299, -0.1595,  0.1465]]]], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([0.9456, 0.9630, 1.0150, 0.9655, 0.9831, 0.9632, 0.9946, 0.9567, 1.0590,\n",
              "          1.0565, 1.0259, 1.0038, 0.9401, 1.0644, 1.0387, 1.0261],\n",
              "         device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([-0.0130,  0.0185, -0.0062,  0.0303, -0.0036, -0.0555, -0.0038, -0.0100,\n",
              "          -0.0981, -0.0476,  0.0693,  0.0293,  0.0617,  0.0597, -0.0056,  0.0714],\n",
              "         device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[-1.3172e-01, -2.1360e-01, -1.1409e-01],\n",
              "            [ 1.1200e-01,  2.0296e-01,  6.9569e-02],\n",
              "            [ 9.1270e-02,  1.0196e-03, -8.3737e-02]],\n",
              "  \n",
              "           [[-1.6837e-01, -1.2359e-01, -2.1299e-01],\n",
              "            [ 2.6209e-01,  3.0601e-02,  2.1586e-02],\n",
              "            [ 3.1664e-03,  1.1031e-01,  5.0469e-02]],\n",
              "  \n",
              "           [[ 5.5835e-03, -6.8118e-02, -7.7320e-02],\n",
              "            [ 1.1935e-01,  1.1108e-01,  1.2785e-02],\n",
              "            [ 4.8395e-02, -2.2844e-02, -7.8000e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 3.6958e-02, -1.3597e-01, -1.7371e-01],\n",
              "            [-1.0974e-02,  6.5554e-02,  8.3603e-02],\n",
              "            [-9.4232e-03, -3.2933e-02,  4.8458e-02]],\n",
              "  \n",
              "           [[ 1.5064e-01,  7.4050e-02, -1.3003e-01],\n",
              "            [ 6.6747e-02, -1.8341e-03, -1.1929e-01],\n",
              "            [-2.5443e-02,  7.9881e-02, -8.8567e-02]],\n",
              "  \n",
              "           [[-4.0682e-02, -5.7080e-02, -1.6294e-01],\n",
              "            [-4.9857e-03, -1.6365e-02,  4.8215e-02],\n",
              "            [-9.4523e-02, -9.1372e-02, -1.0564e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[ 1.4177e-01,  4.8020e-02, -2.9730e-04],\n",
              "            [ 9.3833e-02,  3.1699e-02,  2.3401e-01],\n",
              "            [-9.4046e-03, -2.2880e-03,  4.5357e-02]],\n",
              "  \n",
              "           [[ 5.2803e-03,  1.7145e-01, -1.2141e-01],\n",
              "            [-1.1128e-01, -1.4686e-02, -2.4481e-02],\n",
              "            [ 8.0180e-02, -4.9799e-02,  7.1365e-02]],\n",
              "  \n",
              "           [[-7.3120e-02, -1.1464e-01, -2.2352e-02],\n",
              "            [ 1.7803e-02, -9.9076e-02, -7.2701e-02],\n",
              "            [-2.2231e-01, -8.0245e-02,  2.3197e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-9.8728e-02, -5.3515e-02, -9.5435e-02],\n",
              "            [ 9.9169e-02,  3.7907e-02, -1.2107e-01],\n",
              "            [ 3.7888e-02, -6.6410e-02,  2.1331e-01]],\n",
              "  \n",
              "           [[ 3.4183e-02, -8.2902e-02,  1.8822e-01],\n",
              "            [-6.7492e-02, -4.8161e-03, -1.1916e-01],\n",
              "            [-3.4258e-02,  4.4324e-02, -7.1644e-02]],\n",
              "  \n",
              "           [[ 6.6446e-02,  1.1723e-01,  3.5390e-02],\n",
              "            [-1.4029e-01,  6.3237e-03, -1.0953e-01],\n",
              "            [ 9.7796e-02,  1.6247e-01,  2.8062e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[ 1.0587e-02, -2.9439e-02,  6.5605e-02],\n",
              "            [ 1.7382e-01, -1.3310e-01, -6.9202e-02],\n",
              "            [-1.3219e-01,  7.4979e-02, -8.5087e-03]],\n",
              "  \n",
              "           [[-1.5100e-01, -1.1311e-01,  4.5675e-02],\n",
              "            [-1.9205e-01, -1.7403e-02,  2.0271e-01],\n",
              "            [-1.2589e-01, -1.5766e-01, -1.9663e-01]],\n",
              "  \n",
              "           [[ 6.0486e-02, -7.7132e-02,  1.7711e-02],\n",
              "            [-1.2378e-01, -6.9289e-02,  1.8550e-01],\n",
              "            [ 4.6399e-02,  5.8851e-02, -5.2660e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 9.2805e-02,  2.1107e-01,  3.4599e-01],\n",
              "            [ 4.6635e-02, -6.0557e-02, -1.0538e-01],\n",
              "            [-2.6361e-02,  8.3191e-02,  3.1068e-01]],\n",
              "  \n",
              "           [[ 7.8479e-02, -1.8297e-02,  1.2482e-01],\n",
              "            [-2.1649e-01,  1.9036e-01, -1.3135e-01],\n",
              "            [-1.8162e-01,  1.7133e-01,  3.2511e-03]],\n",
              "  \n",
              "           [[-2.4778e-02, -1.4381e-01, -1.3186e-01],\n",
              "            [-6.4694e-02, -1.1850e-02, -9.1065e-02],\n",
              "            [ 1.1548e-02, -1.4998e-01, -1.2635e-01]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 7.9311e-02,  9.0633e-02,  2.1749e-01],\n",
              "            [ 6.4700e-02,  1.5079e-01,  8.1491e-02],\n",
              "            [ 3.0281e-02,  1.1779e-01, -7.1662e-02]],\n",
              "  \n",
              "           [[-4.7408e-02,  4.9131e-02,  1.0710e-01],\n",
              "            [ 5.3245e-02,  1.7853e-01,  6.0573e-02],\n",
              "            [-8.9329e-02, -1.8748e-01, -1.3300e-01]],\n",
              "  \n",
              "           [[ 5.2969e-02, -1.9787e-01,  1.0936e-01],\n",
              "            [-1.5704e-01,  1.1692e-01,  1.3452e-01],\n",
              "            [-5.6690e-02, -1.1860e-01, -3.2054e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-5.5364e-02,  1.0126e-01,  5.9560e-03],\n",
              "            [ 1.6937e-01, -4.8068e-02,  1.8042e-02],\n",
              "            [ 7.1380e-02, -1.1225e-01, -1.6767e-02]],\n",
              "  \n",
              "           [[ 2.4962e-01, -1.6070e-01, -7.2747e-02],\n",
              "            [-9.1396e-03,  6.0115e-02, -2.4282e-01],\n",
              "            [ 3.7359e-02,  2.1383e-01, -1.6735e-01]],\n",
              "  \n",
              "           [[ 1.0555e-01, -3.6400e-02,  3.2249e-02],\n",
              "            [-3.7172e-02,  1.4463e-02,  7.4401e-02],\n",
              "            [ 1.7859e-01,  3.1089e-02,  3.1368e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[ 8.9522e-02,  9.3310e-02,  9.8888e-03],\n",
              "            [-1.9926e-01, -2.9531e-01,  1.7901e-01],\n",
              "            [-1.7949e-01, -1.2079e-01,  1.0117e-01]],\n",
              "  \n",
              "           [[-1.7736e-01, -5.2734e-02, -6.2664e-02],\n",
              "            [-2.7603e-02, -7.0846e-02, -2.1168e-01],\n",
              "            [-9.5653e-02, -3.7914e-02,  3.7086e-02]],\n",
              "  \n",
              "           [[ 1.9302e-01, -1.2088e-01, -6.0362e-02],\n",
              "            [ 5.1430e-02, -2.5475e-01, -1.1330e-02],\n",
              "            [ 4.5202e-02, -1.4475e-01, -1.8754e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-1.6035e-01,  1.4554e-01, -8.5411e-02],\n",
              "            [ 1.2347e-01,  2.6759e-03,  1.1439e-01],\n",
              "            [-1.1377e-01,  2.3603e-01,  1.9880e-01]],\n",
              "  \n",
              "           [[-7.6844e-02,  1.6099e-01, -1.4582e-01],\n",
              "            [ 1.4569e-01, -2.2496e-01, -2.8874e-02],\n",
              "            [ 4.6198e-02,  1.6070e-01,  1.4193e-01]],\n",
              "  \n",
              "           [[-1.5184e-01, -1.6214e-01,  1.0145e-01],\n",
              "            [-1.0624e-01, -1.1229e-01,  4.2515e-02],\n",
              "            [ 6.7601e-02,  4.9469e-02, -9.3470e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-4.2571e-03, -4.6863e-03, -9.3208e-02],\n",
              "            [-3.7487e-02,  1.9991e-01, -5.7715e-02],\n",
              "            [ 1.3247e-01,  6.5230e-02, -5.2033e-02]],\n",
              "  \n",
              "           [[-9.4186e-02, -2.1495e-01,  7.5368e-02],\n",
              "            [-4.7990e-02,  1.2268e-02, -3.8305e-03],\n",
              "            [ 1.0458e-01,  7.3698e-03,  6.5763e-02]],\n",
              "  \n",
              "           [[-9.2178e-02,  5.9995e-02,  2.0145e-01],\n",
              "            [-5.8042e-02, -1.1758e-01,  1.6641e-01],\n",
              "            [ 1.3926e-01, -1.0727e-01,  7.7560e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 4.1416e-02, -1.3058e-01,  8.2424e-02],\n",
              "            [-1.0594e-02, -9.8086e-02, -5.8844e-02],\n",
              "            [-9.4107e-02, -1.0916e-01,  6.6154e-02]],\n",
              "  \n",
              "           [[ 1.8349e-02, -2.7089e-02,  8.1584e-02],\n",
              "            [ 4.6320e-02, -7.0837e-02,  7.6674e-02],\n",
              "            [-1.2126e-02, -1.1447e-01,  8.2729e-02]],\n",
              "  \n",
              "           [[ 1.3765e-01,  1.1515e-01, -1.2806e-02],\n",
              "            [-1.8006e-01,  1.1227e-01, -4.5692e-02],\n",
              "            [ 1.2435e-01,  1.6544e-01, -7.9753e-02]]]], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([1.0118, 0.9787, 0.9561, 0.9784, 1.0369, 1.0273, 1.0085, 0.9808, 1.0323,\n",
              "          0.9792, 0.9657, 1.0037, 0.9345, 0.9722, 1.0010, 1.0683, 1.0350, 1.0445,\n",
              "          1.0319, 1.0101, 0.9757, 1.0421, 0.9651, 0.9986, 0.9649, 1.0183, 0.9963,\n",
              "          1.0195, 0.9920, 0.9795, 1.0287, 0.9560], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 0.0014, -0.0025, -0.0173,  0.0415, -0.0255, -0.0369,  0.0291,  0.0149,\n",
              "           0.0119,  0.0350,  0.0093,  0.0284,  0.0241,  0.0182,  0.0389,  0.0044,\n",
              "          -0.0248, -0.0214,  0.0071,  0.0628,  0.0409, -0.0184,  0.0282,  0.0309,\n",
              "           0.0186,  0.0079,  0.0002, -0.0441,  0.0096,  0.0290, -0.0366, -0.0408],\n",
              "         device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[-6.7973e-02,  1.9650e-02, -1.0207e-01],\n",
              "            [ 7.9949e-02, -1.4738e-02,  2.6980e-02],\n",
              "            [-6.0744e-02,  8.2213e-02,  2.3026e-02]],\n",
              "  \n",
              "           [[-1.0043e-01, -6.2045e-02, -1.7158e-01],\n",
              "            [ 1.0774e-01, -7.8236e-02, -2.3392e-02],\n",
              "            [-4.6674e-02, -8.9175e-02, -1.1577e-02]],\n",
              "  \n",
              "           [[-3.4153e-03,  9.0347e-02,  2.2746e-02],\n",
              "            [-9.2537e-04, -1.5831e-01,  6.7609e-03],\n",
              "            [-1.7506e-01, -4.8869e-02,  1.4587e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-3.4115e-02, -1.0621e-01,  1.4725e-01],\n",
              "            [ 9.0209e-02,  1.5957e-02,  2.7899e-02],\n",
              "            [-6.8019e-02,  1.0186e-01,  1.5673e-01]],\n",
              "  \n",
              "           [[ 4.0861e-03,  5.6774e-02, -7.5882e-02],\n",
              "            [ 5.9545e-02, -6.7463e-02,  6.0172e-02],\n",
              "            [-5.8444e-02, -4.0093e-03,  5.4659e-02]],\n",
              "  \n",
              "           [[-9.8304e-02, -3.2830e-02,  2.1895e-02],\n",
              "            [-1.2410e-02, -1.2877e-01,  3.1754e-02],\n",
              "            [ 4.1717e-02,  7.9857e-02, -5.5960e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-8.1010e-02, -1.0535e-01, -7.2117e-02],\n",
              "            [-1.1325e-01,  3.1781e-02,  5.5339e-02],\n",
              "            [ 7.5841e-02, -4.1578e-02, -1.2943e-01]],\n",
              "  \n",
              "           [[ 9.7448e-02, -2.7993e-02, -3.5150e-02],\n",
              "            [ 4.5525e-02,  8.2844e-02, -9.7530e-02],\n",
              "            [-1.0115e-01, -5.9956e-02,  4.1914e-02]],\n",
              "  \n",
              "           [[ 7.9084e-02, -1.5185e-01, -4.9448e-03],\n",
              "            [-1.9273e-01,  2.7836e-02, -1.2134e-01],\n",
              "            [-1.0089e-01,  1.1375e-01,  9.4689e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 1.0796e-02, -1.2863e-01, -3.6324e-02],\n",
              "            [-1.0568e-01,  9.0811e-02,  2.8512e-02],\n",
              "            [-1.0198e-01, -2.0092e-02,  6.9664e-02]],\n",
              "  \n",
              "           [[-2.2550e-02,  3.4571e-02,  2.1056e-02],\n",
              "            [ 1.7095e-01, -6.4062e-03,  7.4004e-03],\n",
              "            [ 4.9216e-02, -1.0614e-01,  4.2783e-02]],\n",
              "  \n",
              "           [[-1.7041e-02, -6.5451e-02, -1.7044e-01],\n",
              "            [-1.4540e-01, -1.0255e-01,  1.1542e-01],\n",
              "            [ 1.3569e-03, -3.1163e-02, -7.5291e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[ 8.2226e-02, -1.4187e-02,  1.0263e-01],\n",
              "            [-6.3062e-02, -1.7261e-03, -4.2168e-02],\n",
              "            [ 2.6506e-02, -4.4906e-02, -7.2394e-02]],\n",
              "  \n",
              "           [[ 2.6575e-02, -1.6735e-01, -3.1612e-02],\n",
              "            [ 1.3135e-02, -2.3872e-02, -1.4282e-03],\n",
              "            [-4.1796e-02,  3.4573e-02, -5.9027e-02]],\n",
              "  \n",
              "           [[ 1.2086e-01,  1.1490e-01, -4.9512e-03],\n",
              "            [-6.8776e-02, -7.8817e-03, -3.9958e-02],\n",
              "            [ 3.5852e-06,  7.5470e-02, -3.0051e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-1.3725e-01, -2.8361e-02,  2.1364e-01],\n",
              "            [-1.8203e-01,  9.2761e-03, -1.1511e-01],\n",
              "            [ 6.0110e-02, -4.8751e-02,  2.2092e-02]],\n",
              "  \n",
              "           [[ 7.9848e-02,  9.2675e-02, -1.5777e-01],\n",
              "            [ 1.0427e-01,  3.3276e-02, -2.4198e-01],\n",
              "            [ 7.7776e-02,  8.9774e-02,  1.8094e-03]],\n",
              "  \n",
              "           [[ 2.6334e-02,  2.1655e-02,  7.4747e-03],\n",
              "            [-2.6565e-02, -4.0350e-02,  1.7606e-01],\n",
              "            [ 8.0287e-02,  1.2391e-01,  5.9252e-02]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 6.1748e-02,  6.1974e-02,  1.1345e-01],\n",
              "            [ 1.0296e-01, -2.2918e-01, -6.1690e-02],\n",
              "            [ 9.1145e-02, -1.6419e-02,  1.0423e-01]],\n",
              "  \n",
              "           [[-5.9866e-02,  7.8767e-02,  1.2027e-01],\n",
              "            [ 1.2052e-01,  9.4591e-02,  1.4323e-01],\n",
              "            [-1.6270e-02,  7.9430e-02,  7.2755e-02]],\n",
              "  \n",
              "           [[-1.5489e-02, -3.9262e-02,  1.5682e-01],\n",
              "            [-4.0670e-02, -9.8736e-02,  7.7717e-02],\n",
              "            [-1.9940e-01, -8.0578e-02, -3.5671e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-8.4426e-02,  1.4644e-01, -4.2583e-02],\n",
              "            [ 5.0339e-04,  7.9474e-02,  5.5160e-02],\n",
              "            [-5.9671e-02, -4.9592e-02, -4.3970e-02]],\n",
              "  \n",
              "           [[-8.3330e-02, -6.8587e-02,  2.3694e-02],\n",
              "            [ 4.3591e-02,  8.8411e-03, -1.3866e-01],\n",
              "            [-5.1495e-02, -1.2958e-01, -1.1453e-01]],\n",
              "  \n",
              "           [[ 6.5004e-02,  6.1301e-02,  5.3381e-02],\n",
              "            [-2.1465e-02,  6.0831e-02,  1.8867e-02],\n",
              "            [-6.6455e-02,  5.9357e-02, -8.7182e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-6.2307e-02,  8.7948e-02,  1.6781e-02],\n",
              "            [ 1.0093e-01,  3.9889e-02,  3.1410e-03],\n",
              "            [ 1.4102e-01, -4.8483e-02,  8.3850e-02]],\n",
              "  \n",
              "           [[-1.9082e-01,  2.4769e-02, -1.0277e-01],\n",
              "            [-9.1011e-02, -1.0940e-01,  1.6345e-01],\n",
              "            [ 2.4818e-02,  1.2242e-01,  7.2421e-02]],\n",
              "  \n",
              "           [[ 9.2412e-02,  2.0413e-02,  7.7526e-02],\n",
              "            [ 1.9538e-01,  3.3278e-02,  1.1522e-02],\n",
              "            [ 2.0346e-01, -9.8981e-02,  1.6117e-01]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-5.3233e-02,  1.3522e-03,  3.7187e-02],\n",
              "            [ 2.1391e-01, -4.9821e-02,  3.0435e-02],\n",
              "            [-1.0478e-03,  4.1413e-02, -1.3283e-01]],\n",
              "  \n",
              "           [[ 1.0274e-01, -7.5079e-03, -1.1114e-01],\n",
              "            [-4.6036e-02, -1.5025e-03,  2.2177e-02],\n",
              "            [ 3.9524e-02,  3.6536e-02, -1.1187e-01]],\n",
              "  \n",
              "           [[-1.3116e-01,  6.3671e-02, -3.5132e-02],\n",
              "            [ 9.1509e-02, -7.3906e-02, -7.3447e-02],\n",
              "            [ 2.1189e-02,  6.1091e-02,  9.1281e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-1.3229e-01, -1.7374e-01, -9.0510e-02],\n",
              "            [-1.9666e-01,  1.0929e-02, -6.2598e-02],\n",
              "            [ 4.4911e-02, -2.5964e-02, -2.0229e-02]],\n",
              "  \n",
              "           [[-9.4724e-02, -3.9128e-03, -8.9926e-02],\n",
              "            [-1.0586e-02, -8.9744e-02, -7.0132e-02],\n",
              "            [ 7.0191e-03,  5.0012e-02, -2.8738e-02]],\n",
              "  \n",
              "           [[ 5.2663e-02, -7.1776e-03,  6.4913e-02],\n",
              "            [ 3.5536e-02,  6.8635e-02,  2.5589e-01],\n",
              "            [-9.5602e-02, -9.2227e-02, -7.5209e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-2.7933e-02,  7.0109e-02,  1.5303e-01],\n",
              "            [ 1.0263e-01,  1.2601e-01, -5.6963e-02],\n",
              "            [ 1.0985e-01, -2.9067e-02,  5.6609e-02]],\n",
              "  \n",
              "           [[ 4.0496e-02,  3.8600e-02, -6.2788e-04],\n",
              "            [ 7.8397e-02, -1.5691e-01, -5.3683e-02],\n",
              "            [-7.7765e-02, -1.8125e-02,  3.2131e-02]],\n",
              "  \n",
              "           [[ 5.4111e-02, -3.9783e-02,  1.2254e-01],\n",
              "            [-2.9192e-02, -7.7756e-02,  6.8803e-02],\n",
              "            [-3.6144e-02, -4.0000e-02,  3.6350e-02]]]], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([1.0011, 0.9902, 1.0217, 0.9899, 0.9868, 0.9945, 1.0176, 0.9735, 0.9935,\n",
              "          0.9971, 1.0015, 1.0110, 0.9835, 0.9822, 0.9945, 0.9934, 0.9894, 1.0274,\n",
              "          0.9814, 0.9826, 1.0240, 1.0183, 0.9624, 0.9942, 0.9879, 0.9989, 1.0146,\n",
              "          0.9915, 1.0430, 1.0006, 1.0312, 0.9817, 0.9797, 1.0239, 0.9964, 0.9580,\n",
              "          0.9954, 0.9968, 1.0265, 1.0115, 0.9766, 0.9976, 1.0050, 1.0395, 1.0273,\n",
              "          1.0105, 1.0138, 1.0049, 1.0036, 0.9427, 1.0057, 1.0161, 0.9678, 1.0387,\n",
              "          1.0376, 1.0051, 1.0006, 0.9953, 0.9821, 1.0193, 0.9770, 0.9850, 0.9935,\n",
              "          1.0044], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 1.2784e-02,  4.9391e-03,  1.8030e-02,  7.3145e-03,  2.2712e-02,\n",
              "           4.1924e-03, -4.4272e-03,  6.2878e-03, -4.8070e-03,  7.7012e-03,\n",
              "           1.7459e-04,  4.9843e-03, -6.2242e-03, -1.2168e-02, -1.3022e-03,\n",
              "           1.9514e-03,  1.1316e-02, -1.3931e-02,  5.7693e-03,  1.1351e-02,\n",
              "           1.4668e-02,  4.4780e-03, -6.5290e-03,  6.5772e-03, -3.3240e-04,\n",
              "          -1.6437e-02, -5.4985e-03, -8.1534e-03,  1.1093e-02,  2.1284e-03,\n",
              "           9.4131e-03,  1.8916e-02,  1.6192e-02, -8.3852e-03, -1.5173e-02,\n",
              "          -2.0259e-02,  2.8437e-03, -1.5833e-02,  1.4800e-02, -1.3575e-02,\n",
              "           1.2259e-02, -1.2126e-02, -1.6653e-02, -5.4381e-03,  6.0277e-03,\n",
              "          -1.1801e-02,  4.1344e-03,  2.0102e-03,  6.3293e-03, -1.2433e-02,\n",
              "          -6.7685e-03, -1.9038e-02,  7.4432e-03, -1.4789e-02,  7.6265e-04,\n",
              "          -1.7055e-03,  6.0367e-05,  1.6270e-02, -1.0874e-02, -1.6354e-03,\n",
              "          -2.6666e-03, -5.1644e-03,  1.1123e-02, -1.0163e-02], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[-0.0035,  0.0427, -0.0198],\n",
              "            [-0.0075,  0.0040, -0.0455],\n",
              "            [-0.1705, -0.0335, -0.0287]],\n",
              "  \n",
              "           [[ 0.0430,  0.0736,  0.0077],\n",
              "            [ 0.0973,  0.0170, -0.0492],\n",
              "            [-0.0439,  0.0171, -0.0959]],\n",
              "  \n",
              "           [[ 0.0704,  0.1453,  0.0257],\n",
              "            [-0.0269, -0.0203,  0.0010],\n",
              "            [ 0.0041, -0.0526, -0.0112]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.1931, -0.0202, -0.0860],\n",
              "            [-0.0033, -0.0584, -0.0211],\n",
              "            [-0.1115, -0.1150,  0.0114]],\n",
              "  \n",
              "           [[ 0.0876, -0.0110,  0.0562],\n",
              "            [-0.0489, -0.0635,  0.1117],\n",
              "            [-0.0788, -0.0413, -0.0055]],\n",
              "  \n",
              "           [[-0.0808, -0.0571,  0.0602],\n",
              "            [-0.0699, -0.0656,  0.0408],\n",
              "            [ 0.0288, -0.0887, -0.0953]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0580,  0.0703,  0.0091],\n",
              "            [ 0.0208, -0.0324, -0.0097],\n",
              "            [ 0.0039,  0.0129,  0.0701]],\n",
              "  \n",
              "           [[-0.0125, -0.0448, -0.0383],\n",
              "            [-0.0067,  0.0507,  0.0769],\n",
              "            [-0.0168, -0.0515, -0.0295]],\n",
              "  \n",
              "           [[ 0.0649,  0.0524, -0.0500],\n",
              "            [ 0.0557, -0.0738, -0.0761],\n",
              "            [ 0.0399, -0.0966, -0.0792]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0043, -0.0692,  0.0719],\n",
              "            [ 0.0527,  0.0703,  0.0801],\n",
              "            [ 0.0928,  0.0502,  0.0386]],\n",
              "  \n",
              "           [[ 0.0023,  0.0067, -0.0557],\n",
              "            [-0.0815,  0.0951,  0.0113],\n",
              "            [ 0.1634, -0.0250,  0.0464]],\n",
              "  \n",
              "           [[ 0.0160, -0.0325, -0.0691],\n",
              "            [ 0.0564,  0.0865,  0.0365],\n",
              "            [-0.0023, -0.0123,  0.0188]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0194, -0.0355,  0.0482],\n",
              "            [-0.0007, -0.0114, -0.1179],\n",
              "            [ 0.0198,  0.0353,  0.0011]],\n",
              "  \n",
              "           [[ 0.0171,  0.1103,  0.0084],\n",
              "            [-0.0173,  0.0614, -0.0332],\n",
              "            [ 0.0125,  0.0138, -0.0818]],\n",
              "  \n",
              "           [[ 0.1058, -0.0236,  0.0120],\n",
              "            [-0.0362, -0.0015, -0.0315],\n",
              "            [-0.1060,  0.0439,  0.0138]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0873, -0.0675, -0.0017],\n",
              "            [ 0.0146,  0.0175,  0.0718],\n",
              "            [ 0.1202,  0.0081, -0.0806]],\n",
              "  \n",
              "           [[-0.0673,  0.0855,  0.0159],\n",
              "            [ 0.0805, -0.0351,  0.0552],\n",
              "            [ 0.0859, -0.0106,  0.0323]],\n",
              "  \n",
              "           [[ 0.0003, -0.1352, -0.0074],\n",
              "            [ 0.0802,  0.0468, -0.0925],\n",
              "            [ 0.1018,  0.0155, -0.0746]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 0.0383,  0.0675,  0.0301],\n",
              "            [ 0.0911,  0.0368,  0.0174],\n",
              "            [-0.0226, -0.0883, -0.0057]],\n",
              "  \n",
              "           [[-0.0212, -0.0345, -0.0666],\n",
              "            [-0.0109, -0.0428,  0.0988],\n",
              "            [-0.0636, -0.1004, -0.1720]],\n",
              "  \n",
              "           [[-0.0311,  0.0625,  0.0549],\n",
              "            [ 0.1021, -0.0331, -0.0850],\n",
              "            [ 0.0914, -0.0342,  0.0064]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0220, -0.0708,  0.0171],\n",
              "            [ 0.0002, -0.0929,  0.0468],\n",
              "            [ 0.0255, -0.0062,  0.0082]],\n",
              "  \n",
              "           [[ 0.0037, -0.0602, -0.0329],\n",
              "            [-0.0150,  0.0209, -0.0263],\n",
              "            [-0.0028,  0.0766,  0.0306]],\n",
              "  \n",
              "           [[-0.0315, -0.0382, -0.0180],\n",
              "            [ 0.1172, -0.1356, -0.0229],\n",
              "            [ 0.1190,  0.0063,  0.0167]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0631,  0.0032, -0.0323],\n",
              "            [ 0.0981, -0.0674,  0.0522],\n",
              "            [-0.0637,  0.0342, -0.0311]],\n",
              "  \n",
              "           [[ 0.0399,  0.0825,  0.0351],\n",
              "            [ 0.1073, -0.0535, -0.0424],\n",
              "            [ 0.0643, -0.0805, -0.0567]],\n",
              "  \n",
              "           [[ 0.0621,  0.0645, -0.0227],\n",
              "            [ 0.0319, -0.1271,  0.0656],\n",
              "            [-0.0139,  0.0069,  0.0852]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0075, -0.0036,  0.0245],\n",
              "            [-0.0078, -0.0382,  0.0664],\n",
              "            [ 0.0812,  0.0671,  0.0959]],\n",
              "  \n",
              "           [[ 0.0086, -0.0135,  0.1000],\n",
              "            [-0.0236,  0.0833,  0.0846],\n",
              "            [-0.0458,  0.0132, -0.0369]],\n",
              "  \n",
              "           [[-0.0268,  0.0145,  0.1044],\n",
              "            [ 0.0462,  0.0643,  0.0166],\n",
              "            [ 0.0259,  0.0554,  0.0343]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.1022,  0.0055, -0.1793],\n",
              "            [ 0.0085, -0.1778, -0.0362],\n",
              "            [ 0.0497,  0.0025, -0.0057]],\n",
              "  \n",
              "           [[ 0.0143, -0.0374,  0.0328],\n",
              "            [-0.0411, -0.0073, -0.0008],\n",
              "            [ 0.0194, -0.0974,  0.0227]],\n",
              "  \n",
              "           [[-0.0617,  0.0156, -0.0191],\n",
              "            [-0.0575, -0.0235, -0.1066],\n",
              "            [-0.0401,  0.0277, -0.0503]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0586,  0.0226,  0.0682],\n",
              "            [ 0.0194,  0.1411, -0.1571],\n",
              "            [-0.0012,  0.1465, -0.0089]],\n",
              "  \n",
              "           [[-0.0906,  0.0346,  0.0309],\n",
              "            [-0.0263, -0.0874,  0.0422],\n",
              "            [-0.1379, -0.0151, -0.0344]],\n",
              "  \n",
              "           [[-0.0376,  0.0310,  0.0113],\n",
              "            [ 0.0184,  0.0155, -0.0229],\n",
              "            [ 0.0354, -0.0462,  0.0623]]]], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([0.9789, 1.0269, 0.9363, 1.0554, 0.9754, 1.0325, 0.9595, 1.0115, 1.0301,\n",
              "          0.9969, 0.9738, 0.9135, 0.9655, 0.9920, 1.0183, 0.9860, 0.9314, 1.0216,\n",
              "          0.9755, 0.9825, 0.9597, 0.9658, 1.0261, 1.0283, 1.0329, 1.0257, 1.0099,\n",
              "          0.9734, 1.1108, 1.0020, 1.0408, 1.0549], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 0.0069, -0.0210, -0.0018, -0.0084, -0.0136, -0.0263, -0.0056, -0.0244,\n",
              "          -0.0367, -0.0274,  0.0118,  0.0333,  0.0347,  0.0026, -0.0050,  0.0202,\n",
              "          -0.0126, -0.0405,  0.0021, -0.0450,  0.0086, -0.0156,  0.0015, -0.0021,\n",
              "           0.0272,  0.0045,  0.0049,  0.0289,  0.0043, -0.0005,  0.0006, -0.0152],\n",
              "         device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[ 0.0116,  0.1058, -0.1714],\n",
              "            [ 0.0134,  0.0280, -0.0319],\n",
              "            [ 0.0460,  0.0479, -0.1267]],\n",
              "  \n",
              "           [[ 0.0165, -0.1236, -0.0222],\n",
              "            [ 0.0426,  0.0728,  0.1180],\n",
              "            [-0.0362, -0.0734,  0.1279]],\n",
              "  \n",
              "           [[-0.0604,  0.0251, -0.0508],\n",
              "            [-0.0429, -0.0237,  0.0249],\n",
              "            [-0.0391,  0.0959, -0.0179]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0962, -0.0139,  0.1448],\n",
              "            [ 0.0475, -0.0991, -0.0422],\n",
              "            [-0.0390,  0.1254,  0.1332]],\n",
              "  \n",
              "           [[-0.0808, -0.0251, -0.1613],\n",
              "            [ 0.0945,  0.0519,  0.1153],\n",
              "            [ 0.1017, -0.0846,  0.1519]],\n",
              "  \n",
              "           [[-0.0151,  0.0067,  0.0493],\n",
              "            [ 0.1156, -0.0971, -0.0472],\n",
              "            [ 0.1427, -0.1036, -0.0162]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.1461,  0.0888,  0.0340],\n",
              "            [ 0.0029, -0.0709,  0.0548],\n",
              "            [ 0.0615, -0.0058,  0.0055]],\n",
              "  \n",
              "           [[-0.1724, -0.0885,  0.1036],\n",
              "            [-0.0397,  0.0070,  0.0125],\n",
              "            [-0.2165,  0.0723, -0.1280]],\n",
              "  \n",
              "           [[-0.0280, -0.0289, -0.0577],\n",
              "            [-0.0957, -0.0814,  0.0549],\n",
              "            [-0.0755, -0.0235, -0.0076]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0987, -0.0704, -0.0343],\n",
              "            [ 0.0018, -0.0381,  0.0313],\n",
              "            [-0.1266,  0.0037, -0.0859]],\n",
              "  \n",
              "           [[-0.1026,  0.1183, -0.0117],\n",
              "            [ 0.0198, -0.0093,  0.1589],\n",
              "            [-0.0406,  0.0730,  0.0104]],\n",
              "  \n",
              "           [[ 0.1079, -0.0265,  0.0328],\n",
              "            [ 0.0225, -0.0623,  0.1267],\n",
              "            [-0.0272,  0.1256,  0.0674]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0437,  0.0782,  0.0604],\n",
              "            [-0.1020, -0.0492,  0.0589],\n",
              "            [ 0.1520, -0.0474,  0.1367]],\n",
              "  \n",
              "           [[-0.0242, -0.0997, -0.0755],\n",
              "            [-0.0815, -0.0270,  0.1179],\n",
              "            [-0.0357, -0.0543, -0.0245]],\n",
              "  \n",
              "           [[ 0.0784,  0.0103,  0.0656],\n",
              "            [ 0.1251, -0.0373, -0.0044],\n",
              "            [ 0.0045,  0.0489, -0.0180]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0589,  0.1280,  0.1365],\n",
              "            [-0.0103, -0.0065, -0.0036],\n",
              "            [-0.0878, -0.0115,  0.0273]],\n",
              "  \n",
              "           [[ 0.0719,  0.0679,  0.0196],\n",
              "            [ 0.0811,  0.1014,  0.1627],\n",
              "            [-0.0012,  0.1290,  0.0327]],\n",
              "  \n",
              "           [[ 0.0278,  0.1233,  0.0422],\n",
              "            [-0.0265,  0.1019,  0.0928],\n",
              "            [-0.0084, -0.0249,  0.0543]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 0.0691,  0.0535,  0.0932],\n",
              "            [-0.1016,  0.0475, -0.1216],\n",
              "            [ 0.0174, -0.0946,  0.1056]],\n",
              "  \n",
              "           [[-0.1053,  0.0287, -0.0295],\n",
              "            [-0.1349, -0.2078,  0.1034],\n",
              "            [ 0.0171, -0.0755, -0.0687]],\n",
              "  \n",
              "           [[-0.0373, -0.0780, -0.0035],\n",
              "            [-0.0811, -0.1007, -0.0418],\n",
              "            [-0.0371, -0.0408, -0.1048]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0389, -0.0925,  0.0352],\n",
              "            [ 0.1420,  0.0990, -0.0714],\n",
              "            [ 0.0072, -0.1629,  0.0124]],\n",
              "  \n",
              "           [[-0.0684, -0.1687, -0.1293],\n",
              "            [-0.0720,  0.0276,  0.0361],\n",
              "            [-0.0612,  0.0491, -0.1628]],\n",
              "  \n",
              "           [[ 0.0142, -0.1054, -0.0441],\n",
              "            [ 0.0205, -0.0912,  0.0672],\n",
              "            [ 0.0293,  0.0773, -0.0486]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.1004, -0.0497, -0.0212],\n",
              "            [-0.0163, -0.0542,  0.0643],\n",
              "            [ 0.0230,  0.0823, -0.0531]],\n",
              "  \n",
              "           [[-0.0158, -0.1510, -0.0734],\n",
              "            [-0.0310,  0.0876, -0.0627],\n",
              "            [-0.0044,  0.1744,  0.1494]],\n",
              "  \n",
              "           [[ 0.0504, -0.0516, -0.0691],\n",
              "            [-0.0311, -0.0582,  0.0792],\n",
              "            [ 0.0026,  0.0340, -0.0825]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0213,  0.0362,  0.0200],\n",
              "            [-0.0752,  0.0825,  0.0596],\n",
              "            [ 0.2226,  0.0053,  0.0660]],\n",
              "  \n",
              "           [[-0.1401,  0.1458, -0.0092],\n",
              "            [ 0.0418,  0.0577,  0.1496],\n",
              "            [-0.0870, -0.0321,  0.1499]],\n",
              "  \n",
              "           [[ 0.1718,  0.0600, -0.0004],\n",
              "            [-0.1345, -0.1130,  0.0166],\n",
              "            [ 0.0276, -0.0933, -0.0679]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0236,  0.1028, -0.0284],\n",
              "            [ 0.0973, -0.1288,  0.1448],\n",
              "            [-0.0687, -0.0138, -0.0094]],\n",
              "  \n",
              "           [[-0.0153, -0.1766, -0.0827],\n",
              "            [ 0.0665,  0.0278, -0.0391],\n",
              "            [-0.0815, -0.1307,  0.0441]],\n",
              "  \n",
              "           [[ 0.0591, -0.0011, -0.0365],\n",
              "            [ 0.0187, -0.0454, -0.0291],\n",
              "            [ 0.0713,  0.0980,  0.1491]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0396, -0.1206,  0.0310],\n",
              "            [-0.0546, -0.0658, -0.0815],\n",
              "            [-0.0605,  0.0463, -0.0458]],\n",
              "  \n",
              "           [[-0.0241,  0.0176,  0.0351],\n",
              "            [-0.0539,  0.1256,  0.1050],\n",
              "            [-0.0958, -0.0124,  0.0491]],\n",
              "  \n",
              "           [[ 0.0188,  0.0912,  0.0323],\n",
              "            [ 0.1360,  0.0440,  0.1456],\n",
              "            [-0.2130, -0.0976, -0.1663]]]], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([0.9961, 0.9961, 1.0088, 0.9739, 1.0025, 1.0091, 0.9885, 1.0156, 0.9942,\n",
              "          0.9731, 1.0084, 0.9974, 1.0172, 0.9979, 0.9796, 0.9973, 0.9938, 0.9865,\n",
              "          1.0076, 1.0018, 0.9957, 1.0257, 0.9905, 0.9978, 1.0234, 0.9845, 1.0372,\n",
              "          0.9647, 1.0005, 1.0263, 1.0176, 1.0700, 1.0183, 0.9964, 0.9805, 0.9972,\n",
              "          1.0265, 0.9768, 1.0110, 1.0063, 0.9858, 0.9878, 0.9514, 0.9625, 0.9660,\n",
              "          1.0260, 0.9842, 1.0095, 1.0050, 1.0252, 1.0150, 1.0028, 0.9858, 0.9833,\n",
              "          0.9948, 0.9807, 1.0328, 0.9740, 1.0234, 1.0080, 0.9639, 1.0172, 1.0090,\n",
              "          1.0151], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 0.0198, -0.0125, -0.0266, -0.0077, -0.0039, -0.0058, -0.0095, -0.0009,\n",
              "          -0.0018,  0.0108,  0.0135,  0.0074, -0.0213, -0.0232,  0.0022,  0.0029,\n",
              "           0.0057, -0.0307, -0.0120,  0.0117, -0.0089, -0.0111,  0.0068,  0.0132,\n",
              "           0.0165,  0.0097,  0.0049,  0.0092,  0.0083,  0.0010,  0.0009, -0.0117,\n",
              "          -0.0032,  0.0015,  0.0160,  0.0069, -0.0049,  0.0065, -0.0129, -0.0042,\n",
              "           0.0168,  0.0053,  0.0015,  0.0127, -0.0080,  0.0014, -0.0205, -0.0156,\n",
              "          -0.0095,  0.0069,  0.0120, -0.0116,  0.0235, -0.0244,  0.0080, -0.0198,\n",
              "          -0.0023, -0.0070, -0.0243,  0.0149, -0.0095, -0.0138, -0.0115, -0.0099],\n",
              "         device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[ 4.9853e-02,  1.0301e-02, -1.0275e-02],\n",
              "            [-8.6874e-04, -8.5744e-02, -6.6558e-02],\n",
              "            [ 1.9306e-02, -9.6955e-02,  3.0723e-02]],\n",
              "  \n",
              "           [[ 4.8280e-02, -1.9202e-02, -5.9220e-04],\n",
              "            [ 4.0286e-02, -5.6159e-02, -3.2785e-02],\n",
              "            [ 1.0500e-01,  2.0962e-02, -7.4458e-03]],\n",
              "  \n",
              "           [[-3.9366e-02,  1.3114e-02,  3.1400e-02],\n",
              "            [-3.4940e-02, -7.4864e-02,  9.1674e-02],\n",
              "            [ 3.6611e-02, -7.1151e-02,  7.7414e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 7.3113e-02, -4.6545e-02,  9.4715e-02],\n",
              "            [-3.7181e-02, -6.9599e-03,  6.2785e-02],\n",
              "            [-5.1066e-02,  7.5736e-02, -2.1954e-02]],\n",
              "  \n",
              "           [[-1.3623e-02,  2.4205e-02, -5.1191e-02],\n",
              "            [-3.8019e-02, -3.3673e-02,  2.6577e-02],\n",
              "            [-3.1041e-02, -4.7847e-02,  2.7882e-02]],\n",
              "  \n",
              "           [[ 2.4122e-03, -4.3507e-02, -9.0744e-02],\n",
              "            [-7.4857e-03,  1.2215e-01,  4.6818e-02],\n",
              "            [ 1.3768e-04, -3.1611e-02,  1.5522e-01]]],\n",
              "  \n",
              "  \n",
              "          [[[ 4.5810e-03, -1.8755e-02, -2.3686e-02],\n",
              "            [ 4.0349e-02,  4.1202e-02,  6.2861e-03],\n",
              "            [-3.5216e-02, -4.7001e-02,  2.2402e-02]],\n",
              "  \n",
              "           [[ 1.9316e-02, -3.1251e-02,  1.3555e-02],\n",
              "            [ 2.2929e-02, -8.2269e-02,  5.7767e-02],\n",
              "            [-9.9468e-02,  2.3289e-02,  8.8097e-02]],\n",
              "  \n",
              "           [[ 3.6982e-03, -1.2443e-03, -1.4915e-03],\n",
              "            [-6.7386e-02,  5.6545e-02,  2.3470e-02],\n",
              "            [ 2.4258e-02,  6.4781e-02,  7.4841e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 2.8781e-02, -2.1015e-02,  4.2030e-03],\n",
              "            [-4.5939e-04, -1.6903e-02,  6.8813e-02],\n",
              "            [-4.7452e-02, -4.4078e-03, -2.9153e-02]],\n",
              "  \n",
              "           [[ 1.1939e-01,  4.5836e-02,  8.3008e-02],\n",
              "            [-6.9233e-02,  6.3132e-02,  3.7249e-02],\n",
              "            [-9.9644e-02,  2.3320e-02, -5.2269e-02]],\n",
              "  \n",
              "           [[-2.3496e-02,  1.3595e-01, -8.2254e-02],\n",
              "            [-2.4291e-02, -6.4410e-02, -9.9589e-02],\n",
              "            [-2.3664e-02,  6.6660e-02,  3.7031e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-2.3501e-03, -1.2030e-01,  8.0956e-02],\n",
              "            [ 1.4405e-01,  1.0214e-01,  6.7702e-03],\n",
              "            [ 8.0396e-02,  1.0600e-01,  8.6556e-02]],\n",
              "  \n",
              "           [[-2.3732e-02, -1.8502e-02, -2.0102e-02],\n",
              "            [-2.3608e-02,  5.2255e-02,  6.6230e-03],\n",
              "            [-8.0455e-02, -1.7789e-02,  6.6075e-04]],\n",
              "  \n",
              "           [[ 2.3511e-02,  5.9679e-03,  3.3633e-02],\n",
              "            [ 8.0576e-02, -1.1277e-01,  5.6700e-02],\n",
              "            [ 8.2519e-03,  1.6546e-02, -3.5056e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-2.4259e-03,  4.2799e-02,  1.1232e-01],\n",
              "            [ 8.8123e-02,  3.8911e-02,  3.8569e-02],\n",
              "            [-4.1261e-02, -1.2519e-01,  7.9857e-02]],\n",
              "  \n",
              "           [[ 1.8351e-03,  1.4422e-01,  1.1271e-02],\n",
              "            [ 3.0465e-02, -4.8862e-02, -9.9108e-03],\n",
              "            [ 1.6428e-02,  1.2622e-02,  1.4347e-01]],\n",
              "  \n",
              "           [[ 4.6257e-02, -6.8103e-02, -3.1529e-02],\n",
              "            [ 4.6735e-03, -3.5187e-02, -2.2746e-02],\n",
              "            [-4.1775e-02, -8.4716e-02,  1.2314e-02]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[ 5.9159e-02, -3.6668e-02, -5.9172e-02],\n",
              "            [ 2.8821e-02, -3.9624e-02, -2.2476e-02],\n",
              "            [-5.3292e-02,  1.6231e-01,  3.4318e-02]],\n",
              "  \n",
              "           [[-8.0244e-03,  2.0426e-03, -2.7281e-02],\n",
              "            [-9.7783e-02, -1.8856e-02,  1.0653e-01],\n",
              "            [ 5.8312e-02, -2.1287e-02, -5.2931e-02]],\n",
              "  \n",
              "           [[ 8.0113e-02,  5.2981e-02, -8.0176e-02],\n",
              "            [-2.1255e-02, -7.3915e-02, -3.1479e-02],\n",
              "            [ 2.1001e-02,  3.6837e-02,  2.0096e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-7.1046e-02,  3.1114e-02,  8.5628e-02],\n",
              "            [-1.3015e-01, -2.5743e-02, -1.5538e-02],\n",
              "            [-9.1046e-02,  7.0498e-02, -2.0289e-02]],\n",
              "  \n",
              "           [[-1.2838e-02,  4.4334e-02, -6.9494e-02],\n",
              "            [ 4.1539e-02, -4.3406e-02,  5.2590e-02],\n",
              "            [ 4.8692e-02,  9.0981e-02,  8.5267e-02]],\n",
              "  \n",
              "           [[-1.4878e-02,  4.1198e-02, -4.0332e-02],\n",
              "            [ 5.7525e-02,  4.3442e-02, -1.7207e-02],\n",
              "            [-1.4163e-01, -1.9237e-02,  9.1341e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-8.8013e-03, -1.6854e-04, -1.3139e-01],\n",
              "            [ 4.6093e-02,  5.5610e-02,  4.5092e-02],\n",
              "            [-6.8096e-02,  8.4904e-02,  2.7696e-02]],\n",
              "  \n",
              "           [[ 2.5336e-02,  9.3237e-03,  5.5347e-02],\n",
              "            [-8.6651e-02,  1.0076e-01,  3.9547e-02],\n",
              "            [ 1.7239e-02, -5.7580e-02, -2.2351e-02]],\n",
              "  \n",
              "           [[-7.9427e-02, -6.2575e-02, -1.4370e-02],\n",
              "            [-4.9458e-02, -8.1310e-02,  3.9545e-02],\n",
              "            [ 4.2882e-02, -5.4948e-02, -5.8400e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-6.6055e-04,  2.5468e-02, -5.9711e-02],\n",
              "            [ 1.6876e-02,  2.4972e-02,  2.5167e-02],\n",
              "            [ 2.1404e-02, -3.1579e-02, -2.5025e-02]],\n",
              "  \n",
              "           [[-4.0986e-03, -7.4162e-02,  1.2312e-01],\n",
              "            [ 3.4183e-02, -4.4005e-02,  5.8295e-02],\n",
              "            [-3.5149e-02,  5.0256e-02, -4.0124e-02]],\n",
              "  \n",
              "           [[-2.9809e-02,  2.8048e-02,  3.5165e-02],\n",
              "            [ 6.9013e-02,  7.1615e-02, -6.9519e-02],\n",
              "            [-4.0921e-02, -5.7989e-03,  3.7946e-02]]],\n",
              "  \n",
              "  \n",
              "          [[[-6.4971e-02,  2.6823e-02,  7.3472e-03],\n",
              "            [ 1.9466e-03, -3.9222e-02, -4.4531e-02],\n",
              "            [-3.8080e-02, -2.5718e-02, -7.6912e-02]],\n",
              "  \n",
              "           [[ 1.4722e-01,  4.9731e-02, -2.9377e-02],\n",
              "            [ 5.2830e-02,  9.0427e-02, -4.0578e-02],\n",
              "            [-2.2020e-03, -1.2828e-02,  6.5766e-02]],\n",
              "  \n",
              "           [[ 1.6723e-02,  4.5569e-02,  1.2400e-01],\n",
              "            [-2.5034e-02, -6.9459e-02,  8.7721e-03],\n",
              "            [ 4.7161e-02,  2.2781e-02, -3.1238e-02]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 5.9492e-02, -2.1374e-02,  7.1323e-02],\n",
              "            [ 1.0302e-02,  9.2895e-02, -6.5860e-02],\n",
              "            [ 6.4298e-02,  3.9606e-02,  1.0489e-01]],\n",
              "  \n",
              "           [[ 1.2565e-01,  5.5343e-02, -7.2273e-02],\n",
              "            [-4.5734e-02,  2.3400e-02, -3.7635e-03],\n",
              "            [-1.3364e-01, -3.6379e-02, -7.7885e-02]],\n",
              "  \n",
              "           [[-3.6384e-02,  7.1352e-02,  4.4229e-02],\n",
              "            [ 3.6590e-02,  8.3548e-02, -1.0367e-02],\n",
              "            [ 1.7363e-02,  3.9597e-02, -3.2623e-02]]]], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([0.9890, 0.9841, 0.9881, 0.9978, 1.0008, 1.0059, 0.9940, 0.9777, 0.9840,\n",
              "          1.0125, 0.9890, 1.0016, 1.0036, 0.9849, 0.9811, 0.9778, 1.0122, 1.0014,\n",
              "          1.0279, 1.0013, 1.0038, 1.0138, 0.9981, 0.9994, 0.9963, 1.0095, 0.9824,\n",
              "          1.0071, 0.9831, 1.0316, 1.0037, 1.0317, 1.0082, 1.0018, 1.0148, 1.0183,\n",
              "          0.9919, 0.9782, 1.0108, 1.0133, 1.0162, 0.9934, 1.0055, 0.9991, 1.0085,\n",
              "          1.0066, 1.0021, 1.0002, 1.0019, 0.9828, 0.9957, 1.0057, 0.9890, 1.0124,\n",
              "          0.9844, 0.9842, 1.0167, 0.9903, 0.9815, 0.9763, 1.0186, 1.0175, 1.0090,\n",
              "          0.9995, 0.9997, 0.9839, 0.9950, 1.0048, 0.9844, 0.9975, 0.9951, 1.0171,\n",
              "          1.0030, 1.0158, 1.0046, 0.9935, 0.9926, 0.9881, 0.9900, 1.0274, 1.0216,\n",
              "          0.9912, 0.9710, 0.9876, 1.0022, 1.0214, 1.0191, 1.0054, 0.9972, 0.9755,\n",
              "          0.9894, 0.9874, 1.0238, 1.0023, 1.0124, 0.9826, 0.9790, 0.9992, 0.9853,\n",
              "          0.9827, 1.0118, 1.0016, 0.9846, 0.9799, 1.0055, 1.0063, 1.0008, 1.0040,\n",
              "          0.9890, 1.0089, 0.9923, 1.0062, 1.0073, 1.0326, 0.9920, 1.0077, 1.0340,\n",
              "          1.0084, 0.9983, 1.0111, 0.9909, 1.0264, 0.9923, 0.9995, 0.9898, 0.9978,\n",
              "          0.9842, 0.9959], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([-3.3778e-03, -4.8864e-03,  1.3393e-02, -1.1261e-02, -7.5905e-03,\n",
              "           1.0244e-02,  1.4091e-02, -8.9074e-03,  4.0893e-03, -9.1490e-04,\n",
              "          -7.0803e-03,  7.5854e-03, -7.2127e-05,  3.8119e-03,  5.9078e-03,\n",
              "          -2.0602e-03,  1.1766e-02, -9.9564e-03, -7.1117e-03,  1.0378e-02,\n",
              "          -2.1157e-03,  7.1353e-03, -2.2101e-03, -3.9460e-03,  2.2473e-02,\n",
              "          -7.2700e-03, -8.3582e-03,  3.8837e-03,  1.4890e-02, -3.6445e-04,\n",
              "          -6.4987e-03, -5.1018e-03,  4.0500e-03,  1.1719e-02,  9.6106e-03,\n",
              "          -1.0728e-03, -6.3354e-03,  3.9215e-03, -1.7961e-02,  2.7977e-03,\n",
              "          -5.4623e-03, -2.3988e-03,  2.6646e-03,  2.2144e-04,  2.4118e-02,\n",
              "          -1.1156e-02, -6.1366e-03,  7.2834e-03,  7.2074e-03,  3.1455e-03,\n",
              "          -1.5164e-03, -1.4887e-02,  3.1127e-03, -3.5960e-03,  1.2854e-02,\n",
              "          -1.0852e-03,  1.9085e-03, -1.8667e-03,  5.9024e-03, -1.0868e-02,\n",
              "          -1.1089e-02,  8.4262e-03, -1.0730e-02, -3.9001e-03, -3.3778e-03,\n",
              "           4.8901e-04, -2.4993e-03,  5.5412e-03, -1.0151e-02, -4.6307e-03,\n",
              "          -2.3231e-03, -2.6096e-03,  8.1600e-03,  4.3564e-03, -1.8268e-03,\n",
              "           1.3501e-02,  1.1845e-02, -7.6347e-03,  6.2975e-03, -1.3202e-02,\n",
              "           1.2270e-03, -2.4438e-03, -5.4783e-03, -8.8781e-04,  2.7975e-03,\n",
              "           3.3499e-03, -7.6398e-03,  9.8157e-03, -2.9057e-03,  6.9701e-03,\n",
              "          -8.4792e-03, -1.4798e-03, -1.0389e-02,  2.5026e-03,  1.5058e-03,\n",
              "           4.9300e-03,  1.2899e-02,  1.2490e-02,  1.2715e-03,  1.2266e-02,\n",
              "          -2.8604e-03, -3.7828e-03, -6.3126e-03,  7.9424e-03,  1.1700e-02,\n",
              "           7.4701e-03, -1.7931e-02, -7.1528e-04,  1.3758e-03,  1.8720e-02,\n",
              "           1.5462e-02, -2.7519e-03, -4.0337e-03,  3.6003e-03,  8.4605e-03,\n",
              "          -1.7868e-03,  9.4913e-03,  1.0191e-02, -9.2196e-03,  6.1698e-03,\n",
              "          -9.7876e-03,  1.3907e-02, -4.5442e-03,  6.5804e-03,  2.2113e-03,\n",
              "          -6.1106e-03,  5.8334e-03,  2.3025e-03], device='cuda:0',\n",
              "         requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[[[-0.0654,  0.0115, -0.0328],\n",
              "            [ 0.0516, -0.0341, -0.0333],\n",
              "            [ 0.0158,  0.0404, -0.0270]],\n",
              "  \n",
              "           [[-0.0096,  0.0339,  0.0028],\n",
              "            [ 0.0463,  0.0307,  0.0288],\n",
              "            [-0.0077, -0.0698, -0.0422]],\n",
              "  \n",
              "           [[ 0.0561,  0.0170,  0.0462],\n",
              "            [-0.0260,  0.0554,  0.0603],\n",
              "            [ 0.0063,  0.0523, -0.0739]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0077, -0.0439, -0.0418],\n",
              "            [-0.0168,  0.0683, -0.0696],\n",
              "            [-0.0167,  0.0196,  0.0134]],\n",
              "  \n",
              "           [[ 0.0310,  0.0170,  0.0066],\n",
              "            [-0.0573,  0.0761,  0.0037],\n",
              "            [ 0.0332, -0.0746, -0.1094]],\n",
              "  \n",
              "           [[-0.0293,  0.0136, -0.0031],\n",
              "            [ 0.0516, -0.0354,  0.0050],\n",
              "            [-0.0015, -0.0246, -0.0049]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0569, -0.0147, -0.0574],\n",
              "            [-0.0412, -0.0353, -0.0417],\n",
              "            [ 0.0181,  0.0526,  0.1029]],\n",
              "  \n",
              "           [[-0.0418, -0.0585, -0.0129],\n",
              "            [ 0.0172,  0.0136, -0.0623],\n",
              "            [-0.0514,  0.0206,  0.0667]],\n",
              "  \n",
              "           [[-0.0327,  0.0152, -0.0521],\n",
              "            [-0.0222, -0.0308,  0.0239],\n",
              "            [ 0.0228,  0.0238,  0.0339]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0635, -0.0121,  0.0051],\n",
              "            [ 0.0583,  0.0298, -0.0276],\n",
              "            [-0.0045,  0.0018, -0.0465]],\n",
              "  \n",
              "           [[-0.0516,  0.0634,  0.0035],\n",
              "            [ 0.0103,  0.0250, -0.0367],\n",
              "            [ 0.0382, -0.0338, -0.0200]],\n",
              "  \n",
              "           [[-0.0282,  0.0052,  0.0127],\n",
              "            [-0.0371,  0.0482,  0.0378],\n",
              "            [-0.0241, -0.0124, -0.0241]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0204, -0.0679,  0.0048],\n",
              "            [ 0.1034,  0.0260,  0.0365],\n",
              "            [-0.0501, -0.0671,  0.0505]],\n",
              "  \n",
              "           [[ 0.0105, -0.0738,  0.0143],\n",
              "            [-0.0030,  0.0160, -0.0153],\n",
              "            [-0.0258, -0.0140, -0.0280]],\n",
              "  \n",
              "           [[-0.0415,  0.0018, -0.0037],\n",
              "            [-0.0336,  0.0569, -0.0634],\n",
              "            [ 0.0615, -0.0099,  0.0394]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0306,  0.0512,  0.0511],\n",
              "            [ 0.0134,  0.0017,  0.0185],\n",
              "            [ 0.0236,  0.1036,  0.0426]],\n",
              "  \n",
              "           [[-0.0258, -0.0227, -0.0024],\n",
              "            [-0.0084,  0.0383,  0.0207],\n",
              "            [-0.0280, -0.0502, -0.0728]],\n",
              "  \n",
              "           [[ 0.0172,  0.0108,  0.0124],\n",
              "            [ 0.0228, -0.0113,  0.0544],\n",
              "            [-0.0179,  0.0166, -0.0707]]],\n",
              "  \n",
              "  \n",
              "          ...,\n",
              "  \n",
              "  \n",
              "          [[[-0.0476, -0.0672, -0.0132],\n",
              "            [-0.0012,  0.0058,  0.0484],\n",
              "            [ 0.0135,  0.0157, -0.0259]],\n",
              "  \n",
              "           [[-0.0033,  0.0802,  0.0067],\n",
              "            [-0.0092, -0.0345, -0.0374],\n",
              "            [ 0.0060,  0.0823, -0.0083]],\n",
              "  \n",
              "           [[ 0.1357, -0.0112,  0.0443],\n",
              "            [-0.0200,  0.0191,  0.0080],\n",
              "            [-0.0174, -0.0179,  0.0237]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0510,  0.0269,  0.0086],\n",
              "            [-0.0217, -0.0413, -0.0556],\n",
              "            [-0.0306,  0.0875,  0.0320]],\n",
              "  \n",
              "           [[-0.0039,  0.0229, -0.0348],\n",
              "            [ 0.0009, -0.0039, -0.0006],\n",
              "            [-0.0428, -0.0043,  0.0177]],\n",
              "  \n",
              "           [[-0.0293, -0.0076, -0.0353],\n",
              "            [ 0.0098,  0.0623, -0.0196],\n",
              "            [ 0.0318, -0.0184,  0.0456]]],\n",
              "  \n",
              "  \n",
              "          [[[-0.0043, -0.0184, -0.0291],\n",
              "            [-0.0351,  0.0678,  0.0008],\n",
              "            [-0.0073,  0.0006, -0.0529]],\n",
              "  \n",
              "           [[-0.0350,  0.0340,  0.0166],\n",
              "            [-0.0690,  0.0680,  0.0191],\n",
              "            [ 0.0414,  0.0347, -0.0364]],\n",
              "  \n",
              "           [[-0.0157,  0.0796,  0.0242],\n",
              "            [-0.0317, -0.0388, -0.0045],\n",
              "            [-0.0060, -0.0378,  0.0433]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[-0.0123, -0.0556,  0.0020],\n",
              "            [ 0.0853, -0.0078,  0.0008],\n",
              "            [-0.0047,  0.0242,  0.0407]],\n",
              "  \n",
              "           [[ 0.0511,  0.0215, -0.0497],\n",
              "            [ 0.0007, -0.0546, -0.0420],\n",
              "            [ 0.0841,  0.0448, -0.0240]],\n",
              "  \n",
              "           [[-0.0120, -0.0562, -0.0227],\n",
              "            [-0.0619,  0.0050, -0.0160],\n",
              "            [ 0.0739,  0.0236, -0.0391]]],\n",
              "  \n",
              "  \n",
              "          [[[ 0.0163,  0.1440,  0.0152],\n",
              "            [ 0.0448,  0.0015,  0.0053],\n",
              "            [ 0.0566,  0.0082,  0.0324]],\n",
              "  \n",
              "           [[-0.0013, -0.0271, -0.0137],\n",
              "            [-0.0540,  0.0699, -0.0084],\n",
              "            [-0.1059,  0.0354, -0.0344]],\n",
              "  \n",
              "           [[ 0.0393, -0.0399, -0.1047],\n",
              "            [-0.0350, -0.0303,  0.0499],\n",
              "            [-0.0690, -0.0020,  0.0075]],\n",
              "  \n",
              "           ...,\n",
              "  \n",
              "           [[ 0.0055, -0.0065,  0.0123],\n",
              "            [ 0.0178, -0.0694, -0.0256],\n",
              "            [-0.0828, -0.0058,  0.0309]],\n",
              "  \n",
              "           [[-0.0457, -0.1125, -0.0423],\n",
              "            [ 0.0216,  0.0516, -0.0771],\n",
              "            [ 0.0645,  0.0405,  0.0381]],\n",
              "  \n",
              "           [[ 0.1259, -0.0313, -0.0255],\n",
              "            [ 0.0075, -0.0318, -0.0778],\n",
              "            [-0.0414,  0.0448, -0.0347]]]], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([0.9903, 0.9892, 1.0051, 0.9894, 0.9948, 1.0093, 1.0060, 0.9843, 1.0002,\n",
              "          0.9842, 0.9930, 0.9960, 0.9856, 0.9906, 0.9862, 0.9916, 0.9845, 0.9858,\n",
              "          0.9900, 0.9830, 0.9874, 0.9871, 0.9952, 0.9907, 0.9896, 0.9835, 0.9901,\n",
              "          1.0111, 0.9930, 0.9944, 0.9878, 0.9915, 0.9797, 1.0023, 0.9859, 0.9887,\n",
              "          0.9891, 0.9958, 0.9815, 0.9868, 1.0037, 0.9873, 0.9934, 0.9903, 1.0152,\n",
              "          1.0004, 1.0021, 0.9942, 1.0021, 0.9996, 0.9841, 0.9928, 0.9912, 0.9988,\n",
              "          0.9905, 0.9848, 1.0092, 0.9894, 0.9855, 0.9836, 0.9848, 0.9799, 0.9991,\n",
              "          0.9883, 0.9895, 0.9929, 0.9826, 0.9881, 0.9905, 0.9860, 0.9870, 0.9904,\n",
              "          0.9879, 0.9922, 1.0023, 1.0046, 0.9833, 0.9927, 0.9857, 0.9918, 0.9999,\n",
              "          0.9814, 1.0076, 0.9828, 0.9961, 0.9909, 0.9828, 0.9906, 0.9865, 0.9861,\n",
              "          1.0012, 0.9893, 1.0045, 0.9934, 0.9915, 0.9918, 0.9870, 0.9888, 1.0058,\n",
              "          0.9863, 0.9891, 0.9867, 0.9977, 0.9875, 0.9989, 0.9881, 0.9898, 0.9870,\n",
              "          0.9972, 0.9965, 0.9737, 0.9865, 1.0101, 0.9856, 0.9879, 0.9861, 0.9930,\n",
              "          0.9977, 0.9906, 0.9897, 0.9875, 0.9893, 0.9942, 1.0004, 0.9720, 0.9941,\n",
              "          1.0007, 1.0103, 0.9958, 0.9829, 1.0032, 0.9912, 0.9780, 0.9920, 0.9851,\n",
              "          1.0030, 0.9830, 0.9934, 0.9975, 0.9910, 0.9855, 0.9983, 0.9855, 0.9878,\n",
              "          0.9981, 0.9923, 0.9891, 0.9915, 1.0003, 0.9808, 0.9812, 0.9920, 1.0111,\n",
              "          0.9924, 0.9861, 1.0067, 1.0009, 0.9944, 0.9779, 0.9870, 1.0008, 0.9869,\n",
              "          1.0007, 1.0019, 0.9794, 0.9883, 0.9828, 0.9878, 1.0000, 0.9861, 0.9918,\n",
              "          1.0069, 0.9837, 0.9871, 0.9916, 0.9957, 0.9904, 0.9891, 0.9903, 0.9963,\n",
              "          0.9932, 0.9868, 0.9906, 0.9913, 0.9785, 0.9916, 0.9907, 0.9832, 0.9911,\n",
              "          0.9906, 0.9919, 0.9907, 0.9941, 0.9919, 0.9893, 0.9883, 0.9947, 0.9872,\n",
              "          0.9949, 0.9934, 0.9981, 1.0062, 0.9772, 0.9869, 0.9845, 0.9857, 0.9895,\n",
              "          0.9844, 0.9867, 1.0037, 0.9898, 0.9898, 0.9896, 0.9990, 0.9854, 0.9841,\n",
              "          0.9951, 0.9903, 1.0019, 0.9901, 0.9888, 0.9783, 0.9890, 0.9911, 1.0000,\n",
              "          1.0086, 0.9859, 0.9782, 0.9984, 0.9998, 1.0018, 0.9940, 0.9943, 0.9964,\n",
              "          0.9914, 0.9915, 0.9980, 0.9968, 0.9883, 0.9855, 0.9902, 0.9991, 1.0020,\n",
              "          1.0083, 1.0017, 0.9921, 0.9967, 0.9921, 0.9844, 0.9912, 0.9861, 0.9959,\n",
              "          0.9938, 0.9951, 0.9780, 0.9937], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([-4.3302e-03,  2.8690e-03,  5.7943e-03, -9.5429e-03,  3.7200e-02,\n",
              "           5.6827e-03,  1.1939e-02, -6.8586e-05,  1.7489e-02, -2.1096e-02,\n",
              "          -1.4829e-02,  1.2507e-02, -1.6454e-02, -9.6678e-03,  7.6330e-03,\n",
              "           1.0878e-05,  1.8169e-02, -1.8432e-02, -8.5066e-03, -1.1388e-02,\n",
              "          -1.7450e-02, -2.1743e-02,  9.5527e-03,  1.9972e-02, -4.1375e-03,\n",
              "           6.2026e-03,  1.6408e-02, -2.2105e-02,  1.9987e-03,  1.0287e-03,\n",
              "           5.8410e-03,  3.0378e-03,  8.8343e-04, -2.3297e-02, -1.4881e-02,\n",
              "          -1.6336e-02, -1.9546e-02,  2.0353e-02, -1.1098e-02, -1.1477e-02,\n",
              "          -9.8524e-04,  9.1372e-03, -7.3152e-03, -9.0785e-03, -9.6095e-03,\n",
              "           1.9535e-02, -3.2125e-03,  5.5136e-04, -2.9360e-02,  1.1884e-02,\n",
              "          -6.6781e-03,  7.2289e-03, -3.4703e-04,  2.1107e-02, -1.2178e-02,\n",
              "          -3.0063e-02,  1.7584e-02, -2.7280e-02, -1.1147e-02, -1.8504e-03,\n",
              "          -1.5844e-02, -2.5888e-03, -2.1733e-02,  1.7812e-02, -1.1915e-02,\n",
              "           4.1656e-03, -8.7985e-03, -9.1344e-03, -7.4535e-03,  8.2441e-03,\n",
              "           1.2202e-02, -1.0791e-02,  7.5724e-03,  6.0804e-04, -7.0473e-03,\n",
              "           1.1560e-02, -1.8850e-02,  1.5580e-03,  1.0875e-02,  2.4842e-02,\n",
              "           2.8786e-02,  1.8661e-02, -1.6906e-02, -2.6188e-03,  7.4253e-03,\n",
              "          -1.2167e-02, -1.8157e-02, -1.1093e-02, -2.5272e-02,  1.3086e-02,\n",
              "           7.2507e-03, -3.6528e-03,  1.0616e-02,  2.5627e-02, -3.5022e-03,\n",
              "          -6.9494e-03, -9.8663e-03, -1.0052e-03, -6.4139e-03,  8.7460e-03,\n",
              "          -9.5281e-03,  1.3687e-02, -1.7777e-02,  1.1102e-02,  2.7223e-03,\n",
              "          -2.9999e-03, -2.3872e-02, -2.8388e-02, -1.8623e-02,  1.3335e-02,\n",
              "          -5.3260e-03, -1.7548e-02, -3.6485e-03,  1.1680e-02,  2.1481e-02,\n",
              "          -4.3279e-03, -1.6566e-03, -1.3696e-02,  3.0362e-02, -4.6479e-03,\n",
              "          -3.0462e-02, -2.3182e-02,  1.0874e-04, -5.4277e-03, -2.3505e-02,\n",
              "           1.0011e-02,  1.8212e-03, -2.6717e-02,  4.9516e-03,  6.3705e-03,\n",
              "           9.7157e-03, -1.6845e-02, -1.0816e-02, -2.4693e-02,  2.9488e-02,\n",
              "           2.5841e-03, -9.5283e-03, -8.8822e-03, -3.3424e-02, -1.2988e-02,\n",
              "          -1.7843e-02, -1.4496e-02, -1.3190e-02, -7.4653e-03, -3.0259e-02,\n",
              "          -3.4013e-03, -1.4652e-02,  4.0796e-05, -4.4944e-02,  6.0203e-03,\n",
              "           1.0217e-02, -5.0492e-03, -2.4515e-02, -6.4526e-03,  1.0615e-02,\n",
              "           6.3413e-03, -4.4721e-03,  2.0790e-02,  2.6890e-02,  3.0391e-02,\n",
              "           1.2565e-03, -1.1533e-02,  2.0529e-02, -3.8607e-02, -3.8997e-02,\n",
              "           1.6013e-02,  2.1842e-02,  1.4020e-02, -7.0899e-02,  3.8267e-03,\n",
              "           1.9691e-03,  2.5255e-02, -1.5168e-03,  2.4661e-02,  1.6245e-02,\n",
              "           1.3986e-02, -2.5210e-04, -3.4504e-02,  1.5349e-02, -1.0652e-02,\n",
              "           1.7813e-02, -1.3794e-02,  6.8414e-03, -1.0625e-02, -3.1440e-03,\n",
              "          -1.2895e-02,  6.7675e-03, -9.1612e-03,  5.6227e-03, -8.9360e-03,\n",
              "           3.3040e-02,  4.2805e-03,  1.3805e-02,  7.5951e-03, -1.0989e-04,\n",
              "           7.6543e-03,  1.2088e-02,  1.6242e-02,  1.7477e-02, -9.0758e-03,\n",
              "          -3.9272e-03, -2.3112e-03,  1.7669e-02, -1.9485e-02, -3.9570e-03,\n",
              "           2.1146e-02, -9.1425e-03, -1.3849e-02, -4.9264e-04, -2.2881e-02,\n",
              "          -3.4619e-03,  1.0223e-02, -8.9687e-04,  2.7932e-02, -2.3438e-02,\n",
              "          -2.0730e-02, -3.3475e-02,  1.9754e-02, -7.9519e-03, -9.4855e-05,\n",
              "          -3.5039e-02, -9.2854e-03,  3.2884e-02,  1.8040e-02,  3.1282e-02,\n",
              "           9.5357e-03, -2.5903e-02, -1.1245e-02, -2.2359e-02, -1.9693e-02,\n",
              "           2.3501e-02,  3.2858e-05,  9.8993e-03, -6.2573e-03,  8.8977e-03,\n",
              "           2.4036e-02,  1.6002e-02,  1.1096e-04,  5.7427e-03, -1.6850e-03,\n",
              "          -3.3409e-02, -6.3485e-03,  1.1751e-02,  1.0001e-02, -1.8815e-02,\n",
              "           3.2091e-03,  2.9910e-02,  7.1872e-03, -3.2014e-02,  1.9643e-02,\n",
              "           6.9966e-03, -1.0778e-03,  6.4181e-03,  1.5777e-03, -7.9555e-03,\n",
              "           1.9477e-02], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[ 3.5323e-02,  2.4304e-02,  1.7831e-03,  ..., -1.1826e-02,\n",
              "           -2.5543e-02, -2.6955e-02],\n",
              "          [-1.9495e-02,  1.2606e-05,  1.6221e-02,  ..., -2.4142e-03,\n",
              "           -2.0522e-02,  6.5258e-02],\n",
              "          [ 1.2161e-02, -3.2516e-02,  9.3746e-02,  ..., -6.4636e-02,\n",
              "            3.2114e-02,  5.8135e-03],\n",
              "          ...,\n",
              "          [-3.5858e-02,  4.6280e-03, -6.4636e-02,  ..., -1.7052e-02,\n",
              "           -1.6737e-02, -3.2313e-02],\n",
              "          [ 5.5321e-02, -2.0331e-02, -1.0988e-01,  ...,  1.0280e-01,\n",
              "           -3.5023e-02, -2.7871e-02],\n",
              "          [-8.7577e-02,  7.5635e-02,  3.6783e-02,  ..., -5.1128e-02,\n",
              "           -1.8428e-02,  2.8987e-02]], device='cuda:0', requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([-0.3100, -0.0181,  0.0322, -0.0609,  0.0116, -0.0371,  0.1071,  0.1895,\n",
              "          -0.0933,  0.0358], device='cuda:0', requires_grad=True)]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74nH8ofNPjon"
      },
      "source": [
        "qq: Can I get a pre-defined keyword parameter as an **kwargs?\n",
        "this is because, as compose function only gets function and value, but sgd_step (which might be one of the compositional functions) requires lr parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj90oputd6RU"
      },
      "source": [
        "dir(torch.optim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QleQK68xi4H0"
      },
      "source": [
        "- Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UDDfRWWfZxP"
      },
      "source": [
        "print(inspect.getsource(Recorder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nb0VFnHiitR"
      },
      "source": [
        "torch_opt_func = torch.optim.SGD(learn.model.parameters(), lr=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEc6-Bmtjkig"
      },
      "source": [
        "torch_opt_func"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg_ow3NHim2M"
      },
      "source": [
        "torch_opt_func.param_groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmYaELi2Yiu-"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEMLr0_SYRbv",
        "outputId": "eb4c346a-b628-4a5e-9a7a-9386052ca5c1"
      },
      "source": [
        "torch_opt_func.param_groups[0]['params'].__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C6H9NyZj2nt"
      },
      "source": [
        "# original one (i.e., dependency on pytorch)\n",
        "class Recorder(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.lrs = [[] for _ in self.opt.param_groups]\n",
        "        self.losses = []\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        for pg,lr in zip(self.opt.param_groups,self.lrs): lr.append(pg['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())\n",
        "\n",
        "    def plot_lr  (self, pgid=-1): plt.plot(self.lrs[pgid])\n",
        "    def plot_loss(self, skip_last=0): plt.plot(self.losses[:len(self.losses)-skip_last])\n",
        "\n",
        "    def plot(self, skip_last=0, pgid=-1):\n",
        "        losses = [o.item() for o in self.losses]\n",
        "        lrs    = self.lrs[pgid]\n",
        "        n = len(losses)-skip_last\n",
        "        plt.xscale('log')\n",
        "        plt.plot(lrs[:n], losses[:n])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e405WzGIj62H"
      },
      "source": [
        "# adjusted one\n",
        "class Recorder(Callback):\n",
        "    def begin_fit(self): self.lrs, self.losses = [], []\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.lrs.append(self.opt.hypers[-1]['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())\n",
        "    \n",
        "    def plot_lr  (self, pgid=-1): plt.plot(self.lrs)\n",
        "    def plot_loss(self, skip_last=0): plt.plot(self.losses)\n",
        "\n",
        "    def plot(self, skip_last=0, pgid=-1):\n",
        "        losses = [o.item() for o in self.losses]\n",
        "        lrs    = self.lrs[pgid]\n",
        "        n = len(losses)-skip_last\n",
        "        plt.xscale('log')\n",
        "        plt.plot(lrs[:n], losses[:n])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrYPDMqmlPVn"
      },
      "source": [
        "# original one\n",
        "class ParamScheduler(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, pname, sched_funcs): self.pname,self.sched_funcs = pname,sched_funcs\n",
        "\n",
        "    def begin_fit(self):\n",
        "        if not isinstance(self.sched_funcs, (list,tuple)):\n",
        "            self.sched_funcs = [self.sched_funcs] * len(self.opt.param_groups)\n",
        "\n",
        "    def set_param(self):\n",
        "        assert len(self.opt.param_groups)==len(self.sched_funcs)\n",
        "        for pg,f in zip(self.opt.param_groups,self.sched_funcs):\n",
        "            pg[self.pname] = f(self.n_epochs/self.epochs)\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if self.in_train: self.set_param()\n",
        "\n",
        "class ParamScheduler(Callback):\n",
        "    _order = 1\n",
        "    def __init__(self, pname, sched_funcs): self.pname, self.sched_funcs = pname, listify(sched_funcs)\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        fs = self.sched_funcs\n",
        "        \"I don't know why we should multiply(i.e., copy) the number of pg here when (only) the length is one\"\n",
        "        if len(fs) == 1:\n",
        "            # print(f\"before multiplying: {fs}\")\n",
        "            fs = fs * len(self.opt.param_groups)\n",
        "            # print(f\"after multiplying: {fs}\")\n",
        "        pos = self.n_epochs / self.epochs\n",
        "        for f, h in zip(fs, self.opt.hypers):\n",
        "            h[self.pname] = f(pos)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4HfPV28RO3I",
        "outputId": "dbc284e7-b2d3-4bbc-c517-98c641f33447"
      },
      "source": [
        "learn.opt.param_groups.__len__()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BpSiOsmTZ0_"
      },
      "source": [
        "# original one\n",
        "\n",
        "class LR_Find(Callback):\n",
        "    _order=1\n",
        "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
        "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        pos = self.n_iter/self.max_iter\n",
        "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
        "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
        "\n",
        "    def after_step(self):\n",
        "        if self.n_iter>=self.max_iter or self.loss>self.best_loss*10:\n",
        "            raise CancelTrainException()\n",
        "        if self.loss < self.best_loss: self.best_loss = self.loss\n",
        "\n",
        "# adjusted one\n",
        "\n",
        "class LR_Find(Callback):\n",
        "    _order = 1\n",
        "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
        "        self.max_iter, self.min_lr, self.max_lr = max_iter, min_lr, max_lr\n",
        "        self.best_loss = 1e9\n",
        "    \n",
        "    def begin_batch(self):\n",
        "        if not self.in_train: return\n",
        "        pos = self.n_iter / self.max_iter\n",
        "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
        "        # New\n",
        "        for pg in self.opt.hyper: pg['lr'] = lr\n",
        "    \n",
        "    def after_step(self):\n",
        "        if self.n_iter >= self.max_iter or self.loss > self.best_loss*10:\n",
        "            raise CancelTrainException()\n",
        "        if self.loss < self.best_loss: self.best_loss = self.loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tJT91unltRI"
      },
      "source": [
        "## Weight decay - AdamW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJrNx5CRluRh"
      },
      "source": [
        "def weight_decay(p, lr, wd, **kwargs):\n",
        "    p.data.mul_(1-lr*wd)\n",
        "    return p\n",
        "weight_decay._defaults = dict({'wd':0.})"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU-P1PQ8nVgd"
      },
      "source": [
        "def l2_reg(p, lr, wd, **kwargs):\n",
        "    p.data.grad.add_(lr, wd)\n",
        "    return p\n",
        "l2_reg._defaults = dict({'wd':0.})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz-HI3f3FhDq"
      },
      "source": [
        "def sgd_step(p, lr, **kwargs):\n",
        "    # pytorch inplace function of sum. second parameter will be multiplied to first parameter\n",
        "    p.data.add_(-lr, p.grad.data)\n",
        "    return p"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIHayYAnMWZE",
        "outputId": "f63616a5-8a44-4bf4-f841-8d764150b249"
      },
      "source": [
        "sum([0.4, 0.3, 0.2, 0.1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FkEYrm-DCi7"
      },
      "source": [
        "- To see first layer output\n",
        "\n",
        "```\n",
        "learn.model[0]\n",
        "param_groups[0].shape\n",
        "xb, yb = next(iter(data.train_dl))\n",
        "xb.shape\n",
        "learn.model[0].forward(xb).shape\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v21WIEfBm3cq"
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, steppers, **defaults):\n",
        "        self.steppers = listify(steppers)        \n",
        "        self.param_groups = list(params)\n",
        "        maybe_update(self.steppers, defaults, get_defaults)\n",
        "        # ensure params is a list of lists\n",
        "        if not isinstance(self.param_groups[0], list): self.param_groups = [self.param_groups]\n",
        "        self.hypers = [{**defaults} for p in self.param_groups]\n",
        "\n",
        "    def grad_params(self):\n",
        "        gps = []\n",
        "        for pg, hyper in zip(self.param_groups, self.hypers):\n",
        "            for p in pg:\n",
        "                if p.grad is not None:\n",
        "                    gps = gps + [(p, hyper)]\n",
        "        return gps\n",
        "    def zero_grad(self):\n",
        "        for p, hyper in self.grad_params():\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "    def step(self):\n",
        "        for p, hyper in self.grad_params():\n",
        "            compose(p, self.steppers, **hyper)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHb150b1-1ZM"
      },
      "source": [
        "def maybe_update(os, dest, f):\n",
        "    '''\n",
        "    os: optimizers\n",
        "    '''\n",
        "    for o in os:\n",
        "        for k, v in f(o).items():\n",
        "            if not k in dest: dest[k] = v\n",
        "def get_defaults(o): return getattr(o, '_defaults', {})            "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDDYu5YK_d2G"
      },
      "source": [
        "sgd_opt = partial(Optimizer, steppers = [weight_decay,sgd_step])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INRi6gJiNLoW",
        "outputId": "566d6be7-c897-444a-bdc5-f2b0f64f158e"
      },
      "source": [
        "import inspect\n",
        "inspect.getfullargspec(get_learn_run)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FullArgSpec(args=['nfs', 'data', 'lr', 'layer', 'cbs', 'opt_func'], varargs=None, varkw='kwargs', defaults=(None, None), kwonlyargs=[], kwonlydefaults=None, annotations={})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_krNjsOSW7l"
      },
      "source": [
        "- I don't know how the length of parameter group gets bigger than 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxE3bRg-NpsQ"
      },
      "source": [
        "sched = combine_scheds(torch.tensor([.4, .3, .2, .1]), [sched_cos(0.8, .01), sched_cos(0.8, .01), sched_cos(0.8, .01), sched_cos(0.8, .01)])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtly5JAlNcfz",
        "outputId": "b24354f8-3ac4-495e-df34-78742fa9549b"
      },
      "source": [
        "cbfs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[functools.partial(<class 'exp.nb_05b.AvgStatsCallback'>, <function accuracy at 0x7f2085933e60>),\n",
              " exp.nb_06.CudaCallback,\n",
              " functools.partial(<class 'exp.nb_06.BatchTransformXCallback'>, functools.partial(<function normalize_chan at 0x7f1f79b5e050>, mean=tensor([0.4700, 0.4800, 0.4500], device='cuda:0'), std=tensor([0.2900, 0.2800, 0.3000], device='cuda:0')))]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4BK9lo4M4Ce"
      },
      "source": [
        "learn, run= get_learn_run(nfs, data, 0.4, conv_layer,\n",
        "                          cbs=cbfs + [partial(ParamScheduler, pname='lr', sched_funcs=sched), Recorder],\n",
        "                          opt_func = sgd_opt)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkYXmgZ3Oltz",
        "outputId": "48207877-505a-4005-d162-9cad58977fc3"
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [1.906849200351146, tensor(0.3447, device='cuda:0')]\n",
            "valid: [1.6567807026273886, tensor(0.4408, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LzvvJqn0SQvd",
        "outputId": "8b38adbe-835e-4311-8036-67998d77b079"
      },
      "source": [
        "run.recorder.plot_lr()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXhcZ3Xwf2dmNDPaZW0jWat3S95t2Y5jJ05iJ9gJdRogiR2gCVuAQoEWWpK2X75+adOFFmiBQEkLlEJWQgBDFmdz9sSx7Hhf5X2XvNuyLc3yfn/MjDxRZGs0c+/ce0fv73n8eObO1cy5950599yzilIKjUaj0Tgfl9UCaDQajcYYtELXaDSaLEErdI1Go8kStELXaDSaLEErdI1Go8kSPFZ9cHl5uWpsbLTq4zUajcaRrFq16qhSqqKv1yxT6I2NjbS2tlr18RqNRuNIRGTPpV7TLheNRqPJErRC12g0mixBK3SNRqPJErRC12g0mixBK3SNRqPJEpJS6CKyQES2ikibiNzTx+v1IrJcRN4TkXUicqPxomo0Go3mcvSr0EXEDTwILASagSUi0txrt78FnlBKTQEWAz80WlCNRqPRXJ5k8tBnAG1KqZ0AIvIYcDOwKWEfBRTFHhcDB40UMpFVe47zVtsx6svyqCvNo740j7J8LyJi1kdqLKY7FGHVnhNMbSjB53FbLU7Ws/toJ+1nupgxrNRqUTQDJBmFXgPsS3i+H5jZa5+/A54XkT8D8oH5fb2RiNwN3A1QX18/UFkBaN19gm+/sO1924r8Hj48aSh3zKhnfE1xSu+rsS/LNh7mzx59j/ICL0tm1PPxmQ1UFfutFitr+Y+XtvOb9w7wqdmN3LuwCa9n8ITaIhGFy+Vc49CoStElwP8opb4tIrOAX4jIeKVUJHEnpdRDwEMALS0tKU3W+PzcEdx5ZSP7T5xj7/Fz7D12jnX7T/HU6v08smIvE2qKuWNmPbdMqcGfo625bOD0hSAAIysL+MHyNn70yg4WTqjmb29qIlCkFbvRnO8Ok+MWfvbmblbtOcEPlkylvizParFM52xXiFn/9BLfuW0y1zcHrBYnJZK59B4A6hKe18a2JfIZ4AkApdTbgB8oN0LAvvDnuBlZWch1YwPcNXsY37l9Miv+ej7/b9E4ukMR7n1qPR/+/hu8t/eEWSJoMkgoHL32P3jHVF79xrXcdWUjL246wkd++BZt7Wctli77CIYjjA4U8uNPTmP30U5u+t7rPLv+kNVimc6Jzm7OXAjxjIOPNRmFvhIYJSLDRMRLNOi5tNc+e4F5ACLSRFShdxgpaH8U5+Zw55WNPPe1q/jZXdPp7Arx0R+9xQNPb+JCMJxJUTQGEwxHb/RyPC7qy/L42w8388TnZ9EVCvOx/3yLVXuOWyxhdhGMKDxuFx8aV8XTX7mKEZUFfOmR1Ww+dNpq0UylO/Y9e6PtKE4dzdmvQldKhYAvA8uAzUSzWTaKyP0isii229eBz4nIWuBR4C5l0RkREa4dW8nzf341i2fU81+v72Lhf7zOuv0nrRBHYwDBmIWe47r4dZ1QW8xTX5zNkDwvd/zXCpZtPGyVeFlHKBzB6476ketK8/j5p2ZQlJvDA09vdqyiS4b4nWDHmS62HjljsTSpkVS0Qyn1jFJqtFJqhFLqgdi2+5RSS2OPNymlZiulJimlJiulnjdT6GQo9Ofwj7dM4OHPzqQ7FGHxQ+/w2raM3jRoDCIUt9Dd7w9W1Zfl8eQXZjG2uogv/nIVv19rWnLVoCIYjuBJuHgW5+Xw1XmjeKPtKMu3tlsombnE7wQB3th+1EJJUifrw9ezR5bzmz+9koayfD7z85Us1T96xxH/obn7yD4oK/Dx6OdmMrV+CN/89Tp2dGiferoEw4qcXpktn7iigeHl+Tzw9Ob3Kb5s4n0KvU0rdNtSWeTnsbuvYEr9EL762Hv8/K3dVoukGQDBiCLHLZesNcjzevj+HVPweVx86eHVOmaSJsFwhJxeF88ct4t7b2xiR0cnj7671yLJzCXu2htRkc+KncfpCjnvezQoFDpEg6b/++kZzG8K8H+XbuQHL2+3WiRNkgRDEXLcl/+qVhfn8p3bJ7Pl8Bnu/8Omy+6ruTyhsMLj/uDFc35TJbOGl/HdF7Zx6lzQAsnMJe7au3ZMJeeDYVbvcV7cbdAodIimO/7o41O5ZUoN//b8Nn7Vuq//P9JYTiii8CRR7HHtmEo+P3c4j6zYq11raRAM930BFRH+5qYmTp4P8oPl2WcQxbNcrhpdgdslvOlAt8ugUugAHreLb31sInNGlnPvU+sduWiDjWA4knS14jduGMO0hiHc++t17DraabJk2Ukwcuk7ovE1xXxsai3/89ZuDpw8n2HJzCWe5VKa52VyXQmvO1A3DDqFDlF/4A8/MZXhFfl84Zer2O7QFKXBQu+si8uR43bx/SVTyPG4+OaT67I6zc4sQmH1gYyiRL4ybxTBsOI3q/dnUCrziQdFPW5hzshy1u8/6TjX0qBU6ABF/hx+etd0/Dlu7vrZStrPXLBaJM0lCIUVOZ7k+2sMLcnlLz80hnd3H+fZDTo/faAEwxE8l4lZ1JXmMWNYKU+tPpBVF8xgJFbv4HYxZ1Q5EQVv7XCWlT5oFTpA7ZA8fnJnC8c7u7n7f1fRHcrOdCyn0x2OvK+oKBlub6ljbFUh//TsZp31MkCCYYW3nyD0R6fWsPNoJ2v2OS9weCkS6x0m15VQ4PM4Ln1xUCt0gIm1JXz7tkms2XeS7/Tq4qixB5fKurgcHreLv72pmX3Hz/OzN3ebI1iWEnVxXf58L5xQjc/j4qnVvds6OZeLLhcXOW4XVwwv1Qrdidw4oZolM+r58Ws7dJDUhoQuE6S7HHNGlTO/qZIHl7fRcabLBMmyk+gF9PLnu8ifww3jqvj9uoOOzNfui54WEzHjYfbIcvYcO8e+4+esFGtAaIUe4/98uInh5fn8+eNrON7ZbbU4mgS6k1Awl+Kvb2ziQjDMd17YarBU2YlSimDkYi+Xy/GRqTWcPBdk+ZbsaKnR0wQu5t67alS0YayTrHSt0GPkeT18b8kUTp4L8ldPrs2qYI/TSWwWNVCGVxTwyVkNPL5yH5sOZne3QCMIRxRKkdQF9KqR5ZQX+HgqS7Jd4mmL8bYHIyoKKM33smavc+IEWqEnMG5oMd9cOJYXN7fzy3f2WC2OJsZA0hb74qvzRlGUm8M/PbvZQKmyk1BCpkd/eNwu/njyUJZvbedEFtzVxguL4vEDEWFYeT57jjunnkEr9F58enYj14yp4B+e3qwLU2xCMIWgaCIleV6+MHcEr28/qtso90P3JTpbXoqPTK0lGFb8YZ3zK3N7LPSEi1lDaR57jmkfumMREb710Yl43S7+z283aNeLDQhFIv2m0fXHx2fWU+j38J+v7jBIquwkrtSSabUA0Dy0iLFVhfw6C7JdguEILnl/V8+GsnwOnbrgmNRXrdD7oLLIz18tGMMbbUf53RrnWx5OJxhKz0KHaH/8T1zRwLMbDus7r8uQOB0qWT46tZY1+046vnVxXy0PGmKzVJ2S6ZLUqonIAhHZKiJtInJPH69/V0TWxP5tExHH39feMbOByXUl/P0fNnHynPP9g07mcr1FBsKnZjeS43bx0GvaSr8UvTM9kmHR5KEAjp8aFQypD3zP4sOxneJ26XfVRMQNPAgsBJqBJSLSnLiPUurPY5OKJgPfB54yQ9hM4nYJ/3jLBE6eD/LPz26xWpxBzaW6/w2UykI/H5tWy69XHaD9tG710BcXMz2SvyMKFPlpri7i1a3OTl+M1ju8/7gby/IB2JNFFvoMoE0ptVMp1Q08Btx8mf2XEJ0r6niahxbx2TnDeGzlPt7dpQcRW0UonFz73GS4+6rhhCIRfqqrR/ukp1pygFlFc8dUsGrPCc5ccFYzq0SCfdQ7DMnLodDnYc8xZ7jpklm1GiCxcfj+2LYPICINwDDg5Uu8freItIpIa0eHM67mX50/ipqSXP7mN+t1rxeLCIYjA/LpXo7G8nwWTqjm4Xf2cNrByscsgn1keiTD3NEVhCKKt3YcM0OsjNDXpCYRoaHcOZkuRgdFFwNPKqX6DAkrpR5SSrUopVoqKioM/mhzyPN6uP/mcWxvP8svdG66JQTD6gM/tHT44twRnOkK8fA72TlKLR2CA0xbjDO1fggFPg+vOngQe+gShkNDaX5WWegHgLqE57WxbX2xmCxxtyQyrynAVaPK+d5L23WA1AJCBvnQ44yvKWbOyHJ++uYufdfVi1DkYoOqgeD1uLhyRBmvbu1wbKpv8BKuvYayPPafON/TjdHOJLNqK4FRIjJMRLxElfbS3juJyFhgCPC2sSLag7++sYnTF4L84OU2q0UZdPTl20yXT89ppONMFy9sOmLo+zqd3g2qBsLcMRUcOHmeHR3OsGZ7c6nge0NZHqGI4uBJ+wfS+/2VKKVCwJeBZcBm4Aml1EYRuV9EFiXsuhh4TDn18twPTdVF3Dqtlp+/vZu9DvGnZQPxZlGpKJjLMXd0JTUluVk7wT5VLrpcBn4BvXpU1I3qVLfLpRV6PNPF/heqpFZNKfWMUmq0UmqEUuqB2Lb7lFJLE/b5O6XUB3LUs4mv3zAGj8vFvzyn0xgzRbxZlJEuF4impd4+vY432o6yWxca9dBX+Xuy1JXmMaIi37EKPRTpe/Reg4Ny0XWl6AAIFPm5++rhPL3+EKv2nLBanEFBvFlUupWifXH79DrcLuHRldpKj9O7QdVAmTu6khU7jzmmVD6R7lDfo/cChX58HpcjAqNaoQ+Qu68eTkWhjwee3uTY4I+TiLsA0u3l0heBIj/zxlbyZOt+HRyNkY6FDlE/elcowjs7nZe+GIr0PXrP5RLqHdKkSyv0AZLv8/D160ezeu9JntMDiE0nOMBmUQPljpn1HOvsdnzZulGkmrYYZ+awUnwelyPdLtHh2H0fd0OZVuhZy60tdYyoyOe7L24jEtFWupmEwqml0SXL1aMqqB2SyyMrtNsF0guKAvhz3FwxvMyhCl1dskK2oSzaF93ud+VaoaeA2yV8df5oth05y9PrD1ktTlbTbaLLBaK300tm1PP2zmPsdHi3QCMYyICLSzF3dAU7Ozod06EwTigcwXuJHjYNZXlcCEZot/lsWq3QU+SmCdWMDhTw7y9uI6ytdNPo6c9tQlA0zq3TavG4RKcwktDLJY3zPXdMNH3xFYdZ6ZebjNWTumhzt4tW6Cnidglfmz+aHR2d/H6t7pluFvHKRaPTFhOpLPIzvynAk6v2Z80E+1RJtZdLIsPL86ku9jsuMBoMf7B9bpyG0mjq4m6bZ7pohZ4GC8ZVMbaqkO+9tN0RZcFOpDuUeuXiQFgys54T54Is39Ju6ufYnXSDohBtaDW9sZTW3cdt73NOJFpY1Pdx1wzJxe0S2xcVaoWeBq6Ylb7zaKeebGQSmbDQAWaPKKOi0Mdv3nP+KLV0CKXYPrc304eVcuR0F/uOnzdCrIwQLSzq+7hz3C5qSnJt3xddK/Q0+dC4AOOGFvG9l7WVbgZBk7Nc4njcLhZNGsryLR2DugFbOr1cEpneOASAd3c7Z45AMHTptEWIpy5ql0tWIxK10vccO8dTg9y6M4MeBWNSHnoit0ypoTsc4Zn1gzcnPRoYFETSO9+jKwsp8ntodZJC72cYuRNy0bVCN4D5TZWMryniP1/ZoTNeDObiSDTzv6rjhhYxsrKA3w7iC/Pl3A4DweUSWhpLnWWhhy8/jLyxLJ9T54O2voPTCt0ARIQvzh3JzqOdPK8rDg0lmGZvkYEgItwypYZ3dx93XA61UXT343YYCNMbS9nZ0cnRs/bO3QaIRBThfi5m9aX2b9KlFbpBLBhfRWNZHj96dYejIvt2J93KxYGyaFJ0gv3v1gxOKz06KNmYcz1jWNSP3rrb/o3sgkkE3+O56HZOXdQK3SDcLuHzc0ewbv8p3mxzVv6tnTEiL3og1JXmMWNYKb9578CgvDAHQ323kE2F8TXFeD0uVjrA7RJKomdQ3EK3c+qiVugG8pGpNVQW+vjRq3qqkVFcHIlmvsslzi1TatjR0cmGA6cz9pl2IRi5dLXkQPF53EyuK3FEYDSZO8Fcr5tAkc/WqYtJrZyILBCRrSLSJiJ9DrEQkdtEZJOIbBSRR4wV0xn4PG4+e9Uw3mw7xtp9J60WJyuIW+hm9XLpixvHV+N1uwZlTnoorPAaGICe0VjKhoOn6ewKGfaeZpBsumZ9aR57nazQRcQNPAgsBJqBJSLS3GufUcC9wGyl1DjgaybI6giWzKinyO/hP1/dYbUoWYERvUUGSnFeDteNrWTp2oODrrYgnrZoFC2NQwhHFO/ttbeBk2wBW1VxLkdO23e2aDKX4hlAm1Jqp1KqG3gMuLnXPp8DHlRKnQBQSg3a+ulCfw5/MquR5zYeZofu3pc2oQwHReP88ZQajp7t4s0dgysecrl+JqkwrWEILsH2fvRgKN4Erh+FXuTj8KkLto2vJLNyNcC+hOf7Y9sSGQ2MFpE3ReQdEVnQ1xuJyN0i0ioirR0dzurENhDumt2I1+3ix9pKT5vunsKizCr0a8ZUUODz8My6wdUe+XL9TFKh0J/D2Koi+yv0SHI9bAJFfrpCEU6dD2ZCrAFj1K/EA4wCrgGWAP8lIiW9d1JKPaSUalFKtVRUVBj00fajvMDHrS21/Pa9g3TYvH+y3QlZ4HKB6KCG+U2VLNt0uMftMxgIRfqeq5kOM4aV8t7ek7Y+j8mmx1YV+wE4bFO3SzIrdwCoS3heG9uWyH5gqVIqqJTaBWwjquAHLZ+ePYzucIRfvrPHalEcjREDF1LlxgnVnDwX5O1B5HYxMm0xzvTGUs4Hw2w8aN+soWRnqVbHFfop5yr0lcAoERkmIl5gMbC01z6/JWqdIyLlRF0wOw2U03EMryhg3thKfvnOHkdOQLcL8eHNZrfP7YurR8fcLoNoKlXQwMKiOPFGXSt32dft0p3knWCgyOEKXSkVAr4MLAM2A08opTaKyP0isii22zLgmIhsApYDf6mUGjxmzSX4zJxhHOvsHrRVh0YQihjTLCoV/Dlu5jVVsmzj4HG7hAwOikJ0gEhDWZ6t/eihJNNjKwud73JBKfWMUmq0UmqEUuqB2Lb7lFJLY4+VUuovlFLNSqkJSqnHzBTaKcwaUUZTdRE/eWOXbaPidqe/hklms3B8NSfOBVmx077KyEiMTluMM6WuhDX7Ttr2d5BszyCvx0V5gde2qYu6UtRERITPzBnGtiNneaPtqNXiOJJgOJLxDJdErhlTQb7XPWiGgUezXIw/35PrSmg/02Vby3YgffcDRX7nulw06fFHk6opL/Dxkzd2WS2KIwmFVUZa514Kf46b65oCLNt4eFAUGUXz0I230CfVRZPe7FpBPZCK5KoiP4dP2zN7TSt0k/F53Nw5q4FXtnbQ1n7GanEch1kugIFw04Qqjnd2s8LGQT2jCIWNT1sEaKouIsctvGdThT6Q9NiqYr92uQxmPn5FAz6Pi5+8sdtqURyH0ZWLqXDNmEryBonbJWjQgIve+HPcNFcX2ddCH0B6bFWRn+Od3bbMXtMKPQOU5nv5yNQanlq939bTTuyI0ZWLqeDPcXPd2EqWbTic9ROpzDzfk+pKWL//lC3PYXAA6bGBWC56uw3dLlqhZ4g7r2ykKxThidZ9/e+s6cGMysVUuGlCNcc6u1mxK7uzcc1IW4wzua6Ezu4wbe3263GUbHMuiFroYM/URet/KYOEsVVFzBxWyv++vceWFopdsYPLBaJul9wcN89tyO4Rg91h40bQ9SYeGF2zz34TjOI9g5L1oYNW6IOeO69sZP+J8yzfMmibUQ4YO7hcIDrc4OrR5Ty/8Yhtc6mNIGRimuiwsnyK/B7W7DtlyvunQzwomkyWS7xa9IgNUxe1Qs8g1zcHqCry8/O3d1stimMw0wUwUG5oruLw6QusP2A/hWQE4Ygioszrm+NyCZPqSmwZGB1IHnqR30Nujltb6IOdHLeLT1xRz+vbj+pe6UnSbYO0xTjXja3E7RKe33jEalFMIRPDRCbXlbD1yBnOd9srQySYxEzROCJCdbE9i4u0Qs8wi2fU43W7+MXbugtjMoTCEUNHoqXDkHwvMxpLWbYxO/3o8c6WZo77m1RbQjii2HDQXnc5ybbPjRMo8msLXRPtlX7TxGqeXLWfszafs2gHQhFlGwsd4IZxAba3n2VnFt5hxVP3zLTQewKjNhtJFworXALuJL9rVdpC18T5k1kNnO0K8dTq/VaLYnu6Q/ZIW4xzfXMAgBc2ZZ/bJT61x8zzXVHoo6YklzX77aXQB9rDJlDkp/3MBSI2y1izzy9lEDGlfgiTaov5+Vu7szpjwghCEWWqC2Cg1A7JY3xNEc9no0Lv6Wdi7h3R5LoS21noA02PrSryEQwrjtusUNA+v5RBxidnNbKjo5O3d2Z3oUq6BE3Mi06VG5qrWL33BO1n7HfLnQ49/UxM7m45ua6EAyfP22o8YygysPTYKptOLtIK3SI+PLGa4twcHn5nr9Wi2Bo7pS3GuWFcAKXgxU3ZVU8Qt9DN7m4Z96Ovs5HbJTjApmRVxbmAQxW6iCwQka0i0iYi9/Tx+l0i0iEia2L/Pmu8qNmFP8fNrdNqWbbxMO02jJbbBbsUFiUyJlBIfWkez2/KrmyXnkwPk4PQ42uKcLuENTbKRw+GB+bas2v5f79HICJu4EFgIdAMLBGR5j52fVwpNTn2778NljMr+fgVDYQiisdX6v4ulyLaPtdeFrqIcENzgLfajnHmQtBqcQwj2UHJ6ZLn9TA6UGgzhT4w1155gReXYLs2usms3AygTSm1UynVDTwG3GyuWIODYeX5zBlZzqPv7tX9XS6BHV0uADeMq6I7HOHVbR1Wi2IYyQ5KNoLJdcWs23/KNkkBA/2eedwuKgp9jnS51ACJJuT+2LbefFRE1onIkyJS19cbicjdItIqIq0dHdnzQ0iHT1xRz8FTF3R/l0vQbUOXC8C0hiGU5XtZlkVVo6EBFtekw4SaEk6dD7Lv+HnTPysZUqlIrrJhcZFRK/d7oFEpNRF4Afh5XzsppR5SSrUopVoqKioM+mhnM68pQGWhj1+u0JWjfREyaeBCurhdwrVjK3lla3uP79npBDPkcgGYUFMMYJu+OKEUZqkGiuw3uSiZIzgAJFrctbFtPSiljiml4jlI/w1MM0a87CfH7WLxjHpe3dbBvuPnrBbHVkQiinBE2S5tMc78pgBnLoRYuTs7RtNdLCwy/3yPrirA63ax7oA9/OipzFKtKvZzyIEul5XAKBEZJiJeYDGwNHEHEalOeLoI2GyciNnPkhl1uER4eIVOYUwkOIChA1Zw1ahyvG5X1qQvhgYwKDldfB43Y6oK2WATC32gaYsQVehnLoQ4122fFh79HoFSKgR8GVhGVFE/oZTaKCL3i8ii2G5fEZGNIrIW+Apwl1kCZyPVxbnMG1vJE6376ArZqwudlVzMurCnhZ7v8zBrRBkvbcmOHumZ6LaYyITaYtbbJDAaDEcGfCHrSV20kZWe1BEopZ5RSo1WSo1QSj0Q23afUmpp7PG9SqlxSqlJSqlrlVJbzBQ6G/nEFQ0c7+zO+ok4AyGYocrFdJjfHGDPsXNZ0Q450+d7Qk0xpy+E2GsDV2MoBdeeHXPR7ftLGWTMGVlOXWkuj76r3S5xMlW5mA7zxlYC8EIWuF2CGXS5wMXA6Lr91rtdukMpBEVj5f92Coza95cyyHC5hMXT63ln5/GssPaMIFOVi+kwtCSXcUOLeGmz89MXQxl2uYwOFOJ1u2zhR49mU6VooZ+yT08ardBtxK0ttXhcwmPaSgcu+tDt1D63L+Y1BVi99wTHztrnh50KwUjm0hYBvB4XTdWFtrDQU0lbzPd5KPR5tIWu6ZvKQj83jAvw5Kr9XAjq4OjFLBf7WugA85sqiShYvtXZxXLxAReZPN/ja4rZcND6wGgwrFKKHURTF+1RHAVaoduOO2Y0cOJcMGvHnA2EgY4Fs4rxQ4sJFPkc73YJWZAmOrG2mDMXQuw5Zm1gNBiO4PUM/EJWVezn8Gn73JnZ+5cyCLlyRBn1pXk8onPSM9YsKl1cLuG6sQFe29bh6LTTnkHJGbbQAdZZ7EdPtQlcoMjPEaelLWoyh8slLJlRz4pdx2lrH9zB0Uw2i0qX65sr6ewO885O51aNXgxCZ04tjA4U4vVYHxgNhVOrSA4U+eg422WbUXRaoduQW1tqyXHr4GiPhW7jPPQ4V44ox5/jcrTbJRiO4HYJrgxmFeW4XTRVF1k+7KI7hcIiiFro4YjiWKc9RtHZ/5cyCCkv8HFDcxVPrh7cwdGL3f/sb6H7c9zMGVnBS5vbLQ/wpUoorAbccdAIJtQUsfHAaUut3FQKiyCayAD2yUXXCt2m3DGznpPngoO6cvSiy8UZX9P5TZUcOHmeLYfPWC1KSgx0ao9RTKwp4UxXiN3HOjP+2XCxCVwqsZrKIh+AbebLOuOXMgiZNbyMhrK8QV05mslmUUZwXaxq9GWH9ra3aiD3eItb6abTBC4QKy5qt0mmizN+KYOQeOXoil2Dt3I0082i0qWyyM/E2mLH+tFDkYF3HDSCUYECfB4X6y0qMAqm0QSuoiBqoR/RCl3THx+bNrgrRzNduWgE142t5L19JznqwKrR7pA1Lpd4YNQqCz2URlMyr8dFab6XI9rloumPikJfT+Wok/ObU8VJQdE485sCKAWvOLBqNGqhW3OuJ9YWs/GgNYHRdJvAVRb6tMtFkxyLp9dz4lyQ57NodmWyBB0WFAUYN7SIQJGPl7c4b72sHMg9vqaYs10hdlkQGE23CVygyK+DoprkmDOynNohg7Otbjq+TasQEa4bW8lr247SHXLWrNFUBiUbRbyVrhUFRulWJAeKfM5KWxSRBSKyVUTaROSey+z3URFRItJinIiDm3jl6Fs7jrHrqDVpXVZhReWiEcwbG+BsV4h3dzmrajQUjuC1qPf8qErrAqPpViRXFvo5erabsA2qRftdPRFxAw8CC4FmYImINPexXyHwVWCF0UIOdm6dVovbJTy2cnBZ6SEHDLjoi9kjy/F5XLzkMLdL0PWpvAQAACAASURBVKLCIoi61awKjKbblCxQ5ItVi1rvR0/mCGYAbUqpnUqpbuAx4OY+9vt74F8Ae9x7ZBGVRX7mja3kydb9jruNT4eeKfQ2HnDRF7leN7NHljuuajSVQclGMqHGmsBoMJSey6XSRrnoyRxBDbAv4fn+2LYeRGQqUKeUevpybyQid4tIq4i0dnQ4LwvASpbMrOdYZzcvOjTHORXS/aFZyXVjK9l73FmzRlMZlGwkE2KB0UxXjPYYDim7XOxTLZr26omIC/gO8PX+9lVKPaSUalFKtVRUVKT70YOKq0dVUFOSO6ja6oYiEVwCbodZ6HCxavTFzc6pGk21n4lRWFUxGh/skerFLF4taofiomSO4ABQl/C8NrYtTiEwHnhFRHYDVwBLdWDUWNwu4fbpdbzRdpS9Fg8DyBTdFrsA0mFoSS7N1UW87CCFHrQwbRGiFaNWtNINxVw8qbr2Kgrj1aLOsNBXAqNEZJiIeIHFwNL4i0qpU0qpcqVUo1KqEXgHWKSUajVF4kHMbS11uIRBExwNWdQsyijmNVXSuuc4J2zSWrU/guGIpSmiVlWMxrNcUg2+57hdlBd4aT/jAAtdKRUCvgwsAzYDTyilNorI/SKyyGwBNRepKvZz3dgAT7Tu70npy2ZCFjWLMop5TQEiCl7d5ox4USjFqT1GYkUrXSP67lcU+ml3iIWOUuoZpdRopdQIpdQDsW33KaWW9rHvNdo6N487ZtZx9GyXYxtADYTuFAf32oWJNcWUF/gcE8i22uUC0cBoplvp9rSYSGGmaJxocZEDLHSNvZg7upLqYj+PvLuv/50dTigcwetgCz06a7SCV7d1OOKOymqXC1gTGO1OozlXnECh3zE+dI2NiAdHX9/ewb7j2R0ctTov2gjmNQU4cyHESgdUjYZSHPJgJFbMGA0Z0GKissjH0bNdlleLOvvXMki5raUOAR5fmd1WejCiLLcY02XOyHK8Hpcj0heDIetjFjluF01VhRm10HtaTKRxMass8hNRcMzitslaoTuQoSW5XDumkida9zniVj5VQuGI5RZjuuT7PMwaXsZLW47Yvmo0GLG2sCjO+JrijAZG433307mYBQrtMejC+tXTpMSSGfW0n+ly7LizZAiGrS10MYr5TZXsOXaOHR32bq5ml/MdD4zuyZBLMd3CIkgo/7e4WlQrdIdyzZgKqor8WV05GswCCx3guqYAgK0zk+KDku2QVZTpwGgokn7f/UCRttA1aeBxu7hteh2vZXFwNBiOOK51bl/UlOTSVF3ESzb2o8f7mVjVPjeR0YFCvO7MBUaN6LtfXuBDxPpqUetXT5Myi6dHg6PZWjkaCqu0coPtxLyx0arRk+fsWTUaz/SwQ2dLr8fF2OrCjPVGN6Lvfo7bRVm+z/JqUa3QHczQklyuG1vJ4yuzs3I0aBMXgBHMa6okYuNZo+lO7TGa8TXFbDh4KiOB5GA4gtsluNK8mEVni2oLXZMGd8ys5+jZLl7YZF//bKoEQ9YXuhjFpNoSW1eNdttsIPeEmmLOXAixJwON6EIGDfYIFPk4ooOimnSYO7oya9vqhiLZERQF+1eNGhEYNJL4jNG1+0+a/lndBvWBDxT5LR9yYY/V06SM2yUsjrXV3Z1lM0ejaXTZ8xWNV43acdao3YaJjKkqxOdxsS4DfvSQQemalYXRatGQhRdse6yeJi1um16H2yU8+m52Wel26C1iJFeNis4ataN7LBixl8slx+2ieWgR6zJgoYcixrSY6KkWtbBdslboWUCgyM/8pkp+tWo/XaGw1eIYRiissiJtMU6e18OckeW8sMl+VaN2C4pCNO6w4cBp0/ujdIeM6bsfsMFsUfusniYt7pjZwPHObp7bcNhqUQwjGI5kTdpinOubAxw4eZ7Nh85YLcr7CIbtN5B7Ym0x54Nh2trNncsatdCNCYqCtbnoWqFnCVeNLKeuNLuCo0EbDFwwmnlNAUSwndslmObUHjOYWJuZwKhRFcmVhbHZohZmuiR1FCKyQES2ikibiNzTx+tfEJH1IrJGRN4QkWbjRdVcDpdLuGNGAyt2HWf7EXtZf6kSHbhgH4vRCCoKfUypK+GFzfa6kwoaMLXHaIaXF1Dg85juRw8alLZYXuCNVYva2OUiIm7gQWAh0Aws6UNhP6KUmqCUmgx8C/iO4ZJq+uW2llq8bhe/fGeP1aIYQjalLSYyvznAhgOnOXjyvNWi9BDPzLBDc644LpcwvqbI9EyXYDhiSMsDj9tFeYGPDptb6DOANqXUTqVUN/AYcHPiDkqp0wlP8wF7RXwGCWUFPm6aWM2vVx+gsytktThpoZTKurTFODc0R5t12anIqNuAnuBmMKm2hM2HTpsa7DeqsAiiqYu2ttCBGiBxksL+2Lb3ISJfEpEdRC30r/T1RiJyt4i0ikhrR4c9S6CdzieuaOBsV4jfrjlgtShpEYplNjh5BN2lGFFRwLDyfFv50Y2Y2mMGE2tLCIYVW0wMIncb2NUzUGTtKDrDLsdKqQeVUiOAbwJ/e4l9HlJKtSilWioqKoz6aE0CU+tLaK4u4hdv77FdatxA6GkWZTOL0QhEhOubA7yz8xinLwStFge4WClqNws9Hhg1049u5CCVQJG1DbqSOYoDQF3C89rYtkvxGPDH6QilSR0R4ZOzGthy+Ayr9pywWpyU6bZhGp2RXN8cIBhWvGqTZl3dNrXQa4fkUprvZa2JfnQjg++VhX5Lq0WTUegrgVEiMkxEvMBiYGniDiIyKuHpTcB240TUDJSbJw+l0O/hFw4OjsZ/EHboz20GU+uHUJrvtY3bpScoaqMsF4gaKBNri0210I0cRh4o8qMUllnp/R6FUioEfBlYBmwGnlBKbRSR+0VkUWy3L4vIRhFZA/wFcKdpEmv6Jc/r4WPTanlm/SGOWjy0NlXiPnS7KRijcLuE68ZWsnxruy2addkxDz3OxNoS2trPmhboDxk4jLy6JJqLfuiUNRlMSa2eUuoZpdRopdQIpdQDsW33KaWWxh5/VSk1Tik1WSl1rVJqo5lCa/rnE1c0EAwrHl+5r/+dbUh3yF69Rczg+uZos64VO61v1nUxD91+53tSbTERhWkTjIwcdVhTkgvAwZPWBEbtdznWGMKIigJmjyzjkRV7Te+FYQZxC91uQTojuXpUBbk5bp7beMhqUXpcLnY83xNrSwBMy0ePpi0ac9zVxQ6w0DXO5JNXNHDg5HlbDye+FEEbFroYTa7XzTVjKli28QgRiy+6wZ6sIvud74pCH0OL/awzyULvDkfwGtQzqNCfQ6HPoy10jfHMbwpQU5LLz97cbbUoAyZoY4vRSBaMr6LjTBer91qbkRS0adpinIm1JaYFRkMG9wwaWpJrWRWwPVdPYwget4tPzmrg7Z3H2HL4dP9/YCPsWuhiNNeNrcTrdvGsxV0y7TbgojcT64rZc+ycKUO2o2mLxh13dYmfQ6e0ha4xgcXT6/DnuPj5W7utFmVADBYLvdCfw5xR5Ty34bClhWChSASRaPaNHZlkoh/d6EEq1cXaQteYREmel1um1PCb9w5wwsJJKgOlx6ebpWmLiSwYX8WBk+fZcMC6uygjy9/NYEJtMSLw3l7j3S5GZrkA1JT4OdbZzYVg5ofN2HcFNYZx55WNXAhGeLzVOSmMQZtNoTeT65sCuF3Csxusy3aJToey77ku8ucwurLQ8FhDOKKIKGODwdXF0dTFwxa4XbRCHwSMrSpi1vAyfvH2HksH2A4Eu/YWMYMh+V6uGF5qqdslFI7YsqgokakNJazee8LQjCAzXHvx4iIr3C72XkGNYdw1u5EDJ8/bqmXr5egO2TeNzgwWjK9m59FOtps8bu1SdBuYi20WU+uHcOZCiLYO487RxXoH475nPcVF2kLXmEU8hfGnDklhjFvoRgzvdQIfao6Opnt2vTXZLiGDA4NmMK1hCACrDWw6Z0YPm6p4cZG20DVm4XYJd17ZwLu7jrPxoLkTYIwgm9vn9kVlkZ9p9UMs86MbHRg0g2Hl+QzJyzG0i2i3CT1sfB435QVeDlpQLWrvFdQYyu0t9eR53fzk9V1Wi9Iv2d4+ty8WjK9iy+Ez7D7amfHPDkaU7d1bIsLU+iGGBkZDJvWwiRYXaZeLxkSK83K4fXodS9cetKzXRLLEf2jZ2j63LxaMrwKwpMgoGIo4wr01tWEIOzo6DUvBNaveobrYb8lvzP4rqDGUT88eRkQp/sfmvvTgILTQa4fkMbmuhN+vPZjxzw45wEKHi3709/YZY6Wb1cMmWlykLXSNydSV5rFwQjWPrNjLGZuMP+sLO/fnNpNFk4ay6dBp2jKc7eIEHzpER9K5XcLqPcYUGMW/Z0bfndSU5HK2K5TxEYP2X0GN4dx91XDOdIVs3Su9J53M5ql0RvPhidW4BJZm2EoPhiOOONd5Xg/N1UWGBUbNCr73DLrIsJWe1FGIyAIR2SoibSJyTx+v/4WIbBKRdSLykog0GC+qxigm1ZUwY1gpP3tzty2m5fRFcBAMuOiLyiI/Vwwv4/drD2a0yCgUdobLBaJulzX7ThpSJNdtUkVyvFo008VF/Sp0EXEDDwILgWZgiYg099rtPaBFKTUReBL4ltGCaozl7quGc+DkeZ5Zb/1whb4Ixix0uzaLMpM/mjSUXUc7M9rbxSkuF4Ap9SWcD4bZcvhM2u9l1mCPi8VFNlPowAygTSm1UynVDTwG3Jy4g1JquVLqXOzpO0CtsWJqjOa6sZUMr8jnv17faWmXv0sR74AnMvgU+sLxVeS4hd+vy5zbJdpC1hnnuqfAyID0xYtN4Iw99opCHx6X2M9CB2qARGfr/ti2S/EZ4Nl0hNKYj8slfO6q4Ww4cJq3dx6zWpwPEHKQxWg0JXlerh5Vwe/XHszYJKNQxDnnu6Ykl0CRzxA/es9gD4OD726XECjy29OHniwi8gmgBfjXS7x+t4i0ikhrR0eHkR+tSYFbptRQXuDjR6/ssFqUDxAMq0GVstibRZOHcujUBVoNrIq8HMGwckxVrpEFRj2xGhMCwkNL/LZ0uRwA6hKe18a2vQ8RmQ/8DbBIKdXV1xsppR5SSrUopVoqKipSkVdjIP4cN5+7ahivbz/KexaPQOtNMBwZVEVFvZnfFMCf42Lp2g/81EwhmuXinAvotIYh7Dt+nvYz6VnAPdlUBs0UTcSKXPRkfjErgVEiMkxEvMBiYGniDiIyBfgxUWXebryYGrP4+BUNlOTl8ODyNqtFeR9GTmJ3Ivk+D/ObAjyz/nBGMpGcFBSFaMUokHY+etCE5lxxqkv8HD51IaMDwPs9CqVUCPgysAzYDDyhlNooIveLyKLYbv8KFAC/EpE1IrL0Em+nsRkFPg+funIYL25uZ9NB+8wdDYYjjkmjM4s/mjSU453dvNl21PTPclLaIsC4oUV4PS5adx9P633iQVEz2h7UlOTSHY5wLIOTwpI6CqXUM0qp0UqpEUqpB2Lb7lNKLY09nq+UCiilJsf+Lbr8O2rsxF1XNlLg8/DgK/ax0oMR5YjeImZyzZgKCv0elq4xP9vF7iPoeuPzuJlWP4S3dqQX0O9pn2vCxcyKXHTnrKDGNIrzcviTWQ08s/5QxkvOL0VIW+j4PG4+PHEoz244bHqbhpCD0hbjXDmijE2HTqfVqMvMYeTV8b7oGQyMaoWuAeAzc4bh87hsk/HiNJ+uWdzWUsv5YJin15lbAOaktMU4V44sB0gr7TbucjHjYtZTXJTBwKizVlBjGmUFPu6Y0cBv1xxg3/Fz/f+ByTgpjc5MJteVMKqygCdMHPCtlHLk+Z5YW0y+181bO1KPMZhpoZfk5eDPcWmXi8Ya7r56OG4RfmgDX7rT0ujMQkS4raWO1XtP0taefql7X1xshOas853jdjFzeBlvtaVuoceP3Qz3nogwtDiXQxmcLaoVuqaHqmI/S2bU8UTrfkum5iQS9enqryfAH0+pweMSftW635T3d3Kr4itHlLHzaGfKfupuEwuLIDa5SPvQNVbxpetG4nW7+O6L2yyVIxjRQdE4FYU+rhtbya9X7zclJ92sfiaZ4MoRUT96qlZ6KBLB7RJcJh17dbFfu1w01lFZ6OdTsxtZuvYgmw9Zl5ceDDtjJFqmuK2ljqNnu1m+xfi6vXjqnhMrc8dWFVKa7+XNFP3oZreYqC7Jpf1MV8baVDtvBTWm8/mrR1Dg8/Dt57daJoPTCl3M5poxFVQU+njCBLfLRQvdeerA5RJmDS/j7R3HUuoaarbhMLTYj1Jw5HRm/OjOW0GN6RTn5fCFuSN4cXO7YZNhBkp3OOK4rAsz8bhdfHRqLcu3tqfdv6Q3QROLazLBlSPLOHTqArtSiPuYbTjUDImmLu4/kRm3i/7FaPrkU7MbKS/w8q/LtljSLz0U1pWivbm1pZZwRPGb1cY27DJrrmamiPvR30yhatTseocRFQUAbM9QwZ4zV1BjOnleD1++diTv7DzOm2mkhaVKKBxxZJDOTEZUFNDSMITHV+4ztOGTmal7maCxLI+hxX7eTsGPHjQ5m6q62E+hz8P2I+aknPZGK3TNJVkys56aklz++bnNGe0YB9AdVo5MozObT85qYOfRTl7dbtw8gZ7UPYda6CLCrBHlvL3j2IC/p/HJWGYhIowMFLBNK3SN1fg8bv5qwRg2HDjNr1aZV6nYF6GILizqi4XjqwkU+fjpG7sMe8+ewiKHWugAs0eWceJckM2HB5aZFYqYH6sZXVnI9iPa5aKxAYsmDaWlYQj/umwrp01uEJVIMKSDon3h9bj4k1mNvL79qGFWn1mDkjNJqvno3SHzJ2ONChRwrLObY2f7nPtjKM5dQU1GEBH+7x+N41hnN99/aXvGPjcY0ZWil2LJjHp8Hhc/e3O3Ie/XbeKQh0xRVexneEU+rw3QFRWKmD8Za3SgEIBtGbDSnbuCmowxobaY26bV8bM3d7OjIzO3jiGTfZtOpjTfy0em1vDU6v1ptY6NEzKx42Amub4pwNs7jnHqXPJ3ksEMBN/jCn27Sb14EklKoYvIAhHZKiJtInJPH69fLSKrRSQkIh8zXkyN1XzjQ2PIzXHzD3/YZPpnhSOKiHK2C8BsPjV7GF2hCI+8uzft9zKz42AmWTC+ilBE8eLmI0n/jdlZLgCBIh+Ffk9GAqP9HomIuIEHgYVAM7BERJp77bYXuAt4xGgBNfagotDHV+aNYvnWDlPKzxNxeqFLJhgdKOSqUeX84u09aZeV91SKOvx8T6otobrYz7MbDif9N5nouy8ijA4U2sblMgNoU0rtVEp1A48BNyfuoJTarZRaB2SmYYHGEu68spHhFfnc/4dNXAiGTfucHovRwT7dTPDp2cM4fPrCgBRYX4Qizi4siuNyCR8aV8Vr2zs42xVK6m8yNalpdKCA7UfOmF6kl8wK1gCJOWv7Y9s0gwyvx8X9i8az62inqd0Ys8WnazZzR1cwvDyfn7yxKy1FcfGOyNkKHeDGCdV0hyK8nORdZDBDLSZGVRZy4lyQo2fNHRid0RUUkbtFpFVEWjs6jCuM0GSOOaPKWTy9jv96bSdr95005TOCkexRMGbicgmfnjOMtftO8tr2dKb2OLd9bm+mNQyhvMDHcxuSG9mXqa6ePYFRk/3oyRzJAaAu4XltbNuAUUo9pJRqUUq1VFRUpPIWGhvw1zc1UVno5y+fXEtXyHjXS1zBON0FkAlua6mjdkgu/7Zsa8pWetDB7XN743YJHxoXYPmWDs539//dDEUy09VzdCDa08XswGgyK7gSGCUiw0TECywGlpoqlcbWFPlz+KePTGDbkbM8+LLx4+pCOiiaNF6Pi6/NH836A6dYtjE1X3ooiyx0iLpdzgfDvLqtfy9AMJSZ4dgVhT6Kc3PYZnKTrn6PRCkVAr4MLAM2A08opTaKyP0isghARKaLyH7gVuDHIrLRTKE11nPt2Eo+MrWGH76yg40HTxn63tmSRpcpbplSw4iKfL79/DbCKfTccfIIur6YOayUIXk5PJuE2yVawGb+hSya6VJgC5cLSqlnlFKjlVIjlFIPxLbdp5RaGnu8UilVq5TKV0qVKaXGmSm0xh7c9+FmhuR7+ctfretp8GQEQR0UHRBul/D1G8awvf0sv1szcG9oz/nOkqwij9vF9c0BXt7c3q9LMFpYlJnjHhVLXTQz0yU7VlBjCSV5Xv7xlglsOnSaB542ruAo5OAJOlaxYFwV44YW8e8vbh/wxfViL5fsuYAuHF/Nma4Qb7ZdPlicyWHkYwKFnDofpOOMeT1d9C9GkxbXNwf47Jxh/PztPSlZh33RnWUugEzgcgnfuGEMe4+f44nWgXXGjLtc3FniQ4foFKNCv4dn1l8+rtCdwRYTo3oCo+b50fUvRpM231w4lumNQ7jn1+sN8RH2WIxZpGAywTVjKmhpGML3X96eVIZHnLgfWSR7zrfP4+b65gDLNhzmzGW6hIYyUCka52KTLvP86Fqha9Imx+3iB3dMJd/n5gu/XJV0ld6l6PHpagt9QIgI31w4liOnuwY04DtTmR6Z5q4rGznTFeLRS/S7ifcMylQ2VXmBj9J8r6lNurJvFTWWECjy8/0lU9l1tJN7fr0uvcrFeGGRttAHzPTGUj4+s56fvLmLVXuOJ/U3oYj5PcGtYGJtCVeOKOMnb+zqM65gRTbVqMoC7XLROINZI8r4xofG8Id1h/jui6n3Tr9Y+q+/nqlw741NDC3O5S+fXJdUz51g2Pye4Fbx+bkjOHK6q8/4TtCCYPDoQCHbDpvX0yU7V1FjGV+cO4Jbp9XyvZe289+v70zpPXQeenoU+Dz880cnsLOjk+++0H/PnUym7mWaq0eVM7aqkIde2/mBeaNWGA6jAwWc6Qpx+PQFU94/O1dRYxkiwj9/dCI3TajmH57ezGMp9OvW7XPT56pRFdGeO6/v5L29Jy67byicmfJ3KxARvjB3BNvbz7J86/sbdlnRM2iUydOLtELXGI7bJXz39slcM6aCe3+znt+vPTigv9e9XIzhr29qIlDk79f10p2hBlVWcdPEampKcvnxq++/Y7z4PcusywWgzaQWANm7ihpL8Xpc/Ojj05jeWMqfP75mQEpd93IxhnjPnbb2s3zjV2sv2RYgmy10iLpUPjNnGO/uPs6qPRfvVkIWzFItzffy5j3X8enZjaa8v1boGtPI9br5yZ0tTKkv4c8efY9/W7b1A37MvghmwdBiu3DNmEruXTiWP6w7xP/53YY+g3GZmNpjNbdPr6M4N4eHXtvRs80q115NSa5pOf/ZvYoayyn05/DLz85k8fQ6frC8jbt/0XrZQg/QLhej+fzcEXzxmhE8smIv31r2wfz0YERlfe/5fJ+HO2c1sGzjEZ5ZH23alY3fs+w5Eo1t8Xnc/NNHJnD/zeNYvrWDW3741mUrSkMR7XIxmr/60BjumFnPj17ZwX++uuN9r4XCkYz6ka3iT68dybSGIfz542tYvfdEVk1qipM9R6KxNSLCn8xq5Jefmcmxs10s+I/Xue93Gzh29oONioI6D91wRIS/v3k8H55YzT8/u4V/W7a1J1CazWmLifhz3Dz0yWlUFfv53M9b2XW0E8iupmTZv4oaWzFrRBkv/MVc7phRz8Mr9nLNv77Cj17Z8b4sDCsKPgYDbpfwndsm89GptfxgeRsf+vfXeHVbB8EsD4omUlbg46d3TScUUdz71HoguwyH7DkSjWMoL/Dx9388nmVfu4qZw0v5l+e2MP2BF/nSw6v59ar9dJzpwu3KrmZRdsHrcfHt2ybx8Gdn4hbhzp++y4YDp7LKj9wfIyoK+PEnp2VlAVtSRyIiC0Rkq4i0icg9fbzuE5HHY6+vEJFGowXVZB8jKwv57zun89jdV7BwfBXv7j7O13+1lodX7M3K3iJ2YvbIcp792lV8/frRuF1CRaHPapEyyhXDy/jWxyaS53VTVeS3WhzDkP56CoiIG9gGXA/sJzpjdIlSalPCPn8KTFRKfUFEFgO3KKVuv9z7trS0qNbW1nTl12QRkYhi48HTvLylnXyfm89eNdxqkQYFJzq78Xpc5Ps8VouSccIR5bg+8CKySinV0tdryazgDKBNKbUz9maPATcDiSNqbgb+Lvb4SeAHIiLKzFlLmqzD5RIm1BYzobbYalEGFUPyvVaLYBlOU+b9kYzLpQZIHIGyP7atz31iQ6VPAWVGCKjRaDSa5MhoNEBE7haRVhFp7ejoyORHazQaTdaTjEI/ANQlPK+NbetzHxHxAMXAsd5vpJR6SCnVopRqqaioSE1ijUaj0fRJMgp9JTBKRIaJiBdYDCzttc9S4M7Y448BL2v/uUaj0WSWfoOiSqmQiHwZWAa4gZ8qpTaKyP1Aq1JqKfAT4Bci0gYcJ6r0NRqNRpNBkspTUko9AzzTa9t9CY8vALcaK5pGo9FoBkL2lEhpNBrNIEcrdI1Go8kS+q0UNe2DRTqAPSn+eTlw1EBxzELLaRxOkBG0nEbiBBkh83I2KKX6TBO0TKGng4i0Xqr01U5oOY3DCTKCltNInCAj2EtO7XLRaDSaLEErdI1Go8kSnKrQH7JagCTRchqHE2QELaeROEFGsJGcjvShazQajeaDONVC12g0Gk0vtELXaDSaLMFxCr2/cXhWISI/FZF2EdmQsK1URF4Qke2x/4dYLGOdiCwXkU0islFEvmpTOf0i8q6IrI3J+f9i24fFRhy2xUYeWj6ZQUTcIvKeiPzBxjLuFpH1IrJGRFpj22y15jGZSkTkSRHZIiKbRWSW3eQUkTGx8xj/d1pEvmYXOR2l0GPj8B4EFgLNwBIRabZWqh7+B1jQa9s9wEtKqVHAS7HnVhICvq6UagauAL4UO392k7MLuE4pNQmYDCwQkSuAfwG+q5QaCZwAPmOhjHG+CmxOeG5HGQGuVUpNTsiXttuaA/wH8JxSaiwwieh5tZWcSqmtsfM4GZgGnAN+g13kVEo55h8wC1iW8Pxe/K5XsAAAAqlJREFU4F6r5UqQpxHYkPB8K1Ade1wNbLVaxl7y/o7orFjbygnkAauBmUSr8Tx9fRcskq2W6I/3OuAPgNhNxpgcu4HyXttsteZEZyjsIpaoYVc5e8l2A/CmneR0lIVOcuPw7ERAKXUo9vgwELBSmEREpBGYAqzAhnLGXBlrgHbgBWAHcFJFRxyCPdb+34G/AiKx52XYT0YABTwvIqtE5O7YNrut+TCgA/hZzIX13yKSj/3kTGQx8GjssS3kdJpCdywqeum2RY6oiBQAvwa+ppQ6nfiaXeRUSoVV9La2luig8rEWi/Q+ROTDQLtSapXVsiTBHKXUVKKuyi+JyNWJL9pkzT3AVOBHSqkpQCe93BY2kROAWGxkEfCr3q9ZKafTFHoy4/DsxBERqQaI/d9usTyISA5RZf6wUuqp2GbbyRlHKXUSWE7UfVESG3EI1q/9bGCRiOwGHiPqdvkP7CUjAEqpA7H/24n6e2dgvzXfD+xXSq2IPX+SqIK3m5xxFgKrlVJHYs9tIafTFHoy4/DsROJovjuJ+qwtQ0SE6HSpzUqp7yS8ZDc5K0SkJPY4l6iffzNRxf6x2G6WyqmUulcpVauUaiT6PXxZKfVxbCQjgIjki0hh/DFRv+8GbLbmSqnDwD4RGRPbNA/YhM3kTGAJF90tYBc5rQ4spBCIuBHYRtSn+jdWy5Mg16PAISBI1Nr4DFGf6kvAduBFoNRiGecQvRVcB6yJ/bvRhnJOBN6LybkBuC+2fTjwLtBG9FbXZ/W6x+S6BviDHWWMybM29m9j/DdjtzWPyTQZaI2t+2+BITaVMx84BhQnbLOFnLr0X6PRaLIEp7lcNBqNRnMJtELXaDSaLEErdI1Go8kStELXaDSaLEErdI1Go8kStELXaDSaLEErdI1Go8kS/j8W9qfVhy65SAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "KQ3M7NKnUSBe",
        "outputId": "e8bfc0ba-32e1-446f-9632-6fe62c1edb81"
      },
      "source": [
        "run.recorder.plot() #TODO"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-d1ad48fe56e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-e64c9d3d0d91>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, skip_last, pgid)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mskip_last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSAkVww8Oknc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_0o4ZtKVI9J",
        "outputId": "442252d4-effe-490c-bb0e-963a0cf86c91"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (3): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (4): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): GeneralRelu()\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (7): AdaptiveAvgPool2d(output_size=1)\n",
              "  (8): Lambda()\n",
              "  (9): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bxuvThPVJ16",
        "outputId": "57d7d030-a716-4f9d-ccfe-b9eaed651226"
      },
      "source": [
        "learn.opt.hypers #TODO"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'lr': 0.04506473956948709, 'wd': 0.0}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkqxq0qXZHR"
      },
      "source": [
        "- Let's calculate number of parameters quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UOFMuwBOVXde",
        "outputId": "d119327d-bfdd-4fbd-d581-0e1a7d15085c"
      },
      "source": [
        "mps = [len(p.storage()) for p in learn.opt.param_groups[-1]]\n",
        "f\"Total parameters: {sum(mps)},\\n parameter list: {mps}\""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Total parameters: 432730,\\n parameter list: [432, 16, 16, 4608, 32, 32, 18432, 64, 64, 18432, 32, 32, 18432, 64, 64, 73728, 128, 128, 294912, 256, 256, 2560, 10]'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU9BHJKAaaoM"
      },
      "source": [
        "- Checking stride, storage, shape\n",
        "```\n",
        "p1, p2 = learn.opt.param_groups[-1][0], learn.opt.param_groups[-1][-2]\n",
        "p1.shape, p2.shape\n",
        "p1.stride(), p2.stride()\n",
        "```"
      ]
    }
  ]
}