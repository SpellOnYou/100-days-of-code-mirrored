## Contents

### CS224n Assignments

1. Assignment3 [written](https://spellonyou.github.io/2020/06/cs224n-19w-course5/) [coding](https://github.com/SpellOnYou/10000-days-of-code/tree/master/code/cs224n-hw/a3)



### NLP model/algorithms
1. Statistical approach of Neural Network

  - Expectation-maximization (binomial)
    - R, [ipynb](https://github.com/SpellOnYou/10000-days-of-code/blob/master/code/R/EM-latent(binomial).ipynb)
  - Expectation-maximization (normal)
    - R, [ipynb](https://github.com/SpellOnYou/10000-days-of-code/blob/master/code/R/EM-latent(normal).ipynb)
  - k-means
    - R, [ipynb](https://github.com/SpellOnYou/100_Days_of_ML_Code/blob/master/code/R/Kmeans-R.ipynb)
  - Gaussian Mixure Model with Expectation-Maximization Algorithm
    - R, [ipynb](https://github.com/SpellOnYou/100_Days_of_ML_Code/blob/master/code/R/GMM-EM.ipynb)
  - Hidden Markov Model
  
2. Neural MT
  - NNLM
    - python, [colab](https://github.com/SpellOnYou/100_Days_of_ML_Code/blob/master/code/Neural_Network_Language_Model_v2.ipynb)
  
3. Word Embeddings And Language Models
  - CNN
  - RNN
  - LSTM
  - Bi-LSTM
  
4. Sequence to sequence
  - seq2seq
  - attention in seq2seq
  
5. Language models for pretrained embedding
  - Semi-supervised Sequence Learning
  - ELMo
  - ULMFiT
  - OPEN AI Transformer
  - BERT
    - [colab](https://github.com/SpellOnYou/100_Days_of_ML_Code/blob/master/code/python/BERT_torch.ipynb)
  - GPT-2
    - [colab](https://github.com/SpellOnYou/100_Days_of_ML_Code/blob/master/code/python/GPT_2.ipynb) - terrible results.. without korean-pretrained model

### Others

Segmenting document without punctuation

### Helpful links

[Tatoeba](https://tatoeba.org/eng/)
